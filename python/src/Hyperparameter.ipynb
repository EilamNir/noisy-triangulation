{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-25T21:39:29.800067Z",
     "start_time": "2023-12-25T21:17:37.717589600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2897, 1)\n",
      "(1, 207, 2897)\n",
      "(61140, 1)\n",
      "(1, 207, 61140)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from simulation.generate_path import generate_path\n",
    "import matplotlib.pyplot as plt\n",
    "from estimation.distance_sensor import distance_sensors\n",
    "from estimation.non_iterative_estimator import non_iterative_estimator\n",
    "from estimation.kalman_filter_from_points_with_acc import kalman_filter_from_points_acc\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# create test data\n",
    "target_initial_pos = np.array([0, 0, 5000])\n",
    "target_speed_xy = 50\n",
    "target_speed_z = 10\n",
    "target_rot_speed = 3\n",
    "time_res = 0.1\n",
    "sensor_loc = [[-5000, 0, 0], [400, -7400, 0], [800, 800, 0]]\n",
    "\n",
    "path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "path1.add_straight_interval(100)\n",
    "path1.add_xy_turn_interval(90, -np.deg2rad(target_rot_speed))\n",
    "path1.add_straight_interval(100)\n",
    "outliers = np.random.randint(0, 100, size=len(path1.path))\n",
    "outliers = outliers > (100 - 2)\n",
    "\n",
    "# create noisy sensors\n",
    "sensors = distance_sensors([[-5000, 0, 0], [400, -7400, 0], [800, 800, 0]], 15)\n",
    "sensors.calculate_measurements(path1.path)\n",
    "non_it_est = non_iterative_estimator(sensors, path1.path[0, :])\n",
    "estimated_path = non_it_est.estimate_path()\n",
    "\n",
    "sensors_noisy = distance_sensors([[-5000, 0, 0], [400, -7400, 0], [800, 800, 0]], 200)\n",
    "sensors_noisy.calculate_measurements(path1.path)\n",
    "non_it_est_noisy = non_iterative_estimator(sensors_noisy, path1.path[0, :])\n",
    "estimated_path_noisy = non_it_est_noisy.estimate_path()\n",
    "\n",
    "sigma_a = 1\n",
    "sigma_v = 500\n",
    "kf = kalman_filter_from_points_acc(time_res, sigma_a, sigma_v, non_diag_reduction_ratio=2)\n",
    "kf_path, P, X, L, delta_x = kf.filter_path(estimated_path)\n",
    "\n",
    "sample = 1\n",
    "XTest = []\n",
    "n = []\n",
    "for i in np.arange(len(kf_path) - sample):\n",
    "    # tmp = np.concatenate((kf_path[i, :].reshape(1,-1), np.reshape(P[i, :, :], (1,-1)), X[i,:].reshape(1,-1), L[i,:], delta_x[i,:]), 1)\n",
    "    # tmp = np.concatenate((L[i,:].reshape(1,-1), delta_x[i,:].reshape(1,-1)), 1)\n",
    "    # tmp = np.array([7000, 5000, 3000]).reshape(1,3)\n",
    "    if outliers[i + 1]:\n",
    "        X_n, P_n, L_n, delta_x_n = kf.kalman_step(X[i, :], P[i, :], estimated_path_noisy[i + 1, :])\n",
    "        tmp = np.concatenate((estimated_path_noisy[i + 1, :].reshape(1, -1), np.reshape(P[i + 1, :, :], (1, -1)),\n",
    "                              X[i + 1, :].reshape(1, -1), L[i + 1, :].reshape(1, -1), delta_x[i + 1, :].reshape(1, -1),\n",
    "                              np.reshape(P_n, (1, -1)), X_n.reshape(1, -1), L_n.reshape(1, -1),\n",
    "                              delta_x_n.reshape(1, -1)), 1)\n",
    "        # tmp =  np.concatenate((tmp, estimated_path_noisy[i+1, :].reshape(1,-1)),1)\n",
    "    else:\n",
    "        X_n, P_n, L_n, delta_x_n = kf.kalman_step(X[i, :], P[i, :], estimated_path[i + 1, :])\n",
    "        tmp = np.concatenate((estimated_path[i + 1, :].reshape(1, -1), np.reshape(P[i + 1, :, :], (1, -1)),\n",
    "                              X[i + 1, :].reshape(1, -1), L[i + 1, :].reshape(1, -1), delta_x[i + 1, :].reshape(1, -1),\n",
    "                              np.reshape(P_n, (1, -1)), X_n.reshape(1, -1), L_n.reshape(1, -1),\n",
    "                              delta_x_n.reshape(1, -1)), 1)\n",
    "        # tmp =  np.concatenate((tmp, estimated_path[i+1, :].reshape(1,-1)),1)\n",
    "\n",
    "    # tmp = np.concatenate((tmp, outliers[i+1].reshape(1,1)), 1)\n",
    "\n",
    "    # tmp = outliers[i+1].reshape(1,1)\n",
    "    tmp = tmp.reshape(1, tmp.shape[1], 1)\n",
    "    if i > 0:\n",
    "        XTest = np.concatenate((XTest, tmp), 2)\n",
    "        # loc = kf.H@X_n\n",
    "        n = np.concatenate((n, X_n.reshape(1, 9)), 0)\n",
    "    else:\n",
    "        XTest = tmp\n",
    "        # loc = kf.H@X_n\n",
    "        n = X_n.reshape(1, 9)\n",
    "\n",
    "YTest = outliers[1:].reshape(-1, 1)\n",
    "\n",
    "print(np.shape(YTest))\n",
    "print(np.shape(XTest))\n",
    "# create train data\n",
    "run_number = 60\n",
    "XTrain = []\n",
    "YTrain = []\n",
    "for k in np.arange(run_number):\n",
    "    target_initial_pos = np.random.randint(-7000, 7000, size=(1, 3))[0]\n",
    "    sensors_pos = np.random.randint(-7000, 7000, size=(3, 3))[:, :]\n",
    "    target_speed_xy = 50\n",
    "    target_speed_z = 10\n",
    "    target_rot_speed = 3\n",
    "    time_res = 0.1\n",
    "\n",
    "    path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "    path1.add_straight_interval(np.random.randint(0, 100, size=1)[0])\n",
    "    path1.add_xy_turn_interval(np.random.randint(0, 100, size=1)[0],\n",
    "                               -random.choice([-1, 1]) * np.deg2rad(target_rot_speed))\n",
    "    outliers = np.random.randint(0, 100, size=len(path1.path))\n",
    "    outliers = outliers > (100 - 50)\n",
    "\n",
    "    # create noisy sensors\n",
    "    sensors = distance_sensors(sensors_pos, 15)\n",
    "    sensors.calculate_measurements(path1.path)\n",
    "    non_it_est = non_iterative_estimator(sensors, path1.path[0, :])\n",
    "    estimated_path = non_it_est.estimate_path()\n",
    "\n",
    "    sensors_noisy = distance_sensors(sensors_pos, 200)\n",
    "    sensors_noisy.calculate_measurements(path1.path)\n",
    "    non_it_est_noisy = non_iterative_estimator(sensors_noisy, path1.path[0, :])\n",
    "    estimated_path_noisy = non_it_est_noisy.estimate_path()\n",
    "\n",
    "    sigma_a = 1\n",
    "    sigma_v = 500\n",
    "    kf = kalman_filter_from_points_acc(time_res, sigma_a, sigma_v, non_diag_reduction_ratio=2)\n",
    "    kf_path, P, X, L, delta_x = kf.filter_path(estimated_path)\n",
    "\n",
    "    sample = 1\n",
    "    for i in np.arange(len(kf_path) - sample):\n",
    "        # tmp = np.concatenate((kf_path[i, :].reshape(1,-1), np.reshape(P[i, :, :], (1,-1)), X[i,:].reshape(1,-1)), 1)\n",
    "        # tmp = np.concatenate((L[i,:].reshape(1,-1), delta_x[i,:].reshape(1,-1)), 1)\n",
    "        if outliers[i + 1]:\n",
    "            X_n, P_n, L_n, delta_x_n = kf.kalman_step(X[i, :], P[i, :], estimated_path_noisy[i + 1, :])\n",
    "            tmp = np.concatenate((estimated_path_noisy[i + 1, :].reshape(1, -1), np.reshape(P[i + 1, :, :], (1, -1)),\n",
    "                                  X[i + 1, :].reshape(1, -1), L[i + 1, :].reshape(1, -1),\n",
    "                                  delta_x[i + 1, :].reshape(1, -1), np.reshape(P_n, (1, -1)), X_n.reshape(1, -1),\n",
    "                                  L_n.reshape(1, -1), delta_x_n.reshape(1, -1)), 1)\n",
    "            # tmp =  np.concatenate((tmp, estimated_path_noisy[i+1, :].reshape(1,-1)),1)\n",
    "        else:\n",
    "            X_n, P_n, L_n, delta_x_n = kf.kalman_step(X[i, :], P[i, :], estimated_path[i + 1, :])\n",
    "            tmp = np.concatenate((estimated_path[i + 1, :].reshape(1, -1), np.reshape(P[i + 1, :, :], (1, -1)),\n",
    "                                  X[i + 1, :].reshape(1, -1), L[i + 1, :].reshape(1, -1),\n",
    "                                  delta_x[i + 1, :].reshape(1, -1), np.reshape(P_n, (1, -1)), X_n.reshape(1, -1),\n",
    "                                  L_n.reshape(1, -1), delta_x_n.reshape(1, -1)), 1)\n",
    "            # tmp =  np.concatenate((tmp, estimated_path[i+1, :].reshape(1,-1)),1)\n",
    "\n",
    "        # tmp = np.concatenate((tmp, outliers[i+1].reshape(1,1)), 1)\n",
    "\n",
    "        tmp = tmp.reshape(1, tmp.shape[1], 1)\n",
    "        if (k == 0) & (i == 0):\n",
    "            XTrain = tmp\n",
    "        else:\n",
    "            XTrain = np.concatenate((XTrain, tmp), 2)\n",
    "\n",
    "    if k > 0:\n",
    "        YTrain = np.concatenate((YTrain, outliers[1:].reshape(-1, 1)))\n",
    "    else:\n",
    "        YTrain = outliers[1:].reshape(-1, 1)\n",
    "\n",
    "print(np.shape(YTrain))\n",
    "print(np.shape(XTrain))\n",
    "\n",
    "# shuffle data\n",
    "ind = np.arange(len(YTest))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XVal = torch.from_numpy(np.transpose(XTest[:, :, ind], (2, 0, 1)))\n",
    "YVal = torch.from_numpy(YTest[ind, :])\n",
    "\n",
    "ind = np.arange(len(YTrain))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XTrain = torch.from_numpy(np.transpose(XTrain[:, :, ind], (2, 0, 1)))\n",
    "YTrain = torch.from_numpy(YTrain[ind, :])\n",
    "\n",
    "\n",
    "# create network\n",
    "class state_estimat(nn.Module):\n",
    "    def __init__(self, d_in, num_classes):\n",
    "        # initialzing the parent object (important!)\n",
    "        super(state_estimat, self).__init__()\n",
    "        # Create a pipeline - a sequence of layers\n",
    "        self.pipe = torch.nn.Sequential(\n",
    "            # nn.Conv1d(1, 16, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(97, 10),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(97, 2),\n",
    "            # nn.ReLU(),\n",
    "            nn.Conv1d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool1d(2, stride=2),\n",
    "            # nn.Conv1d(16,16, kernel_size=3, padding=1),\n",
    "            # nn.MaxPool1d(2, stride=2),\n",
    "            # nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(207, 256),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(6624, num_classes))\n",
    "        # nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = nn.functional.normalize(x, p=1.0, dim = 1)\n",
    "        return self.pipe(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "state_estimat(\n",
      "  (pipe): Sequential(\n",
      "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (3): ReLU()\n",
      "    (4): Flatten(start_dim=1, end_dim=-1)\n",
      "    (5): Linear(in_features=6624, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters:\n",
    "# num_epochs = 100\n",
    "num_epochs = 20\n",
    "# batch_size = 512\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "learning_rate_drop_period = 120\n",
    "\n",
    "# Device configuration, as before\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(device)\n",
    "# create model\n",
    "model = state_estimat(d_in=4, num_classes=1).to(device)\n",
    "print(model)\n",
    "# Loss and optimizer\n",
    "# criterion = torch.nn.BCELoss()\n",
    "#criterion = torch.nn.MSELoss()\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=learning_rate_drop_period, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T21:39:30.543836300Z",
     "start_time": "2023-12-25T21:39:29.819765100Z"
    }
   },
   "id": "a5512ca28943a69a"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [5/119], Loss: 430.2151, Time: 2.1603 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [10/119], Loss: 343.4858, Time: 2.7244 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [15/119], Loss: 247.4408, Time: 3.1863 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [20/119], Loss: 33.5227, Time: 3.6873 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [25/119], Loss: 113.9442, Time: 4.1261 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [30/119], Loss: 85.2877, Time: 4.4854 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [35/119], Loss: 76.2446, Time: 4.9238 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [40/119], Loss: 14.1708, Time: 5.2923 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [45/119], Loss: 45.7572, Time: 5.6837 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [50/119], Loss: 15.1691, Time: 6.1070 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [55/119], Loss: 7.8779, Time: 6.6013 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [60/119], Loss: 6.2960, Time: 7.0532 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [65/119], Loss: 62.2894, Time: 7.5029 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [70/119], Loss: 59.4127, Time: 7.9882 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [75/119], Loss: 48.8001, Time: 8.3652 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [80/119], Loss: 33.1120, Time: 8.7409 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [85/119], Loss: 19.3620, Time: 9.1311 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [90/119], Loss: 35.1639, Time: 9.5086 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [95/119], Loss: 14.7502, Time: 9.9254 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [100/119], Loss: 9.3522, Time: 10.3473 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [105/119], Loss: 24.0515, Time: 10.8263 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [110/119], Loss: 19.9659, Time: 11.2648 secs, learning rate: 0.0010\n",
      "Epoch [1/5], Step [115/119], Loss: 13.5897, Time: 11.6552 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [5/119], Loss: 13.0770, Time: 13.8446 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [10/119], Loss: 19.5928, Time: 14.2040 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [15/119], Loss: 14.5094, Time: 14.5584 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [20/119], Loss: 7.1857, Time: 14.9207 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [25/119], Loss: 19.4775, Time: 15.2815 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [30/119], Loss: 10.2934, Time: 15.6421 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [35/119], Loss: 9.1942, Time: 16.0032 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [40/119], Loss: 15.4123, Time: 16.4364 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [45/119], Loss: 12.4735, Time: 16.8036 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [50/119], Loss: 7.2719, Time: 17.1660 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [55/119], Loss: 13.0016, Time: 17.5254 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [60/119], Loss: 10.0252, Time: 17.9016 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [65/119], Loss: 3.9756, Time: 18.2563 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [70/119], Loss: 13.8122, Time: 18.6236 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [75/119], Loss: 7.6555, Time: 18.9839 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [80/119], Loss: 4.8615, Time: 19.3500 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [85/119], Loss: 11.9225, Time: 19.7166 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [90/119], Loss: 7.2534, Time: 20.1475 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [95/119], Loss: 3.9557, Time: 20.5388 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [100/119], Loss: 5.3149, Time: 20.9301 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [105/119], Loss: 4.6058, Time: 21.2947 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [110/119], Loss: 4.5540, Time: 21.7275 secs, learning rate: 0.0010\n",
      "Epoch [2/5], Step [115/119], Loss: 3.4395, Time: 22.1138 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [5/119], Loss: 5.2402, Time: 24.5340 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [10/119], Loss: 2.9907, Time: 24.9089 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [15/119], Loss: 4.5639, Time: 25.3166 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [20/119], Loss: 2.8426, Time: 25.6767 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [25/119], Loss: 3.8088, Time: 26.0753 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [30/119], Loss: 4.5825, Time: 26.4952 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [35/119], Loss: 3.3771, Time: 26.8465 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [40/119], Loss: 3.9277, Time: 27.2072 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [45/119], Loss: 3.9372, Time: 27.5797 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [50/119], Loss: 3.0002, Time: 27.9402 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [55/119], Loss: 3.7498, Time: 28.3009 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [60/119], Loss: 2.3874, Time: 28.6698 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [65/119], Loss: 3.8507, Time: 29.0291 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [70/119], Loss: 1.9535, Time: 29.3900 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [75/119], Loss: 2.3771, Time: 29.7508 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [80/119], Loss: 1.7659, Time: 30.1172 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [85/119], Loss: 2.1014, Time: 30.4696 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [90/119], Loss: 1.4970, Time: 30.8302 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [95/119], Loss: 1.9420, Time: 31.2185 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [100/119], Loss: 1.9650, Time: 31.5945 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [105/119], Loss: 1.7391, Time: 32.0416 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [110/119], Loss: 1.9132, Time: 32.4017 secs, learning rate: 0.0010\n",
      "Epoch [3/5], Step [115/119], Loss: 1.8217, Time: 32.8079 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [5/119], Loss: 2.5924, Time: 34.9314 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [10/119], Loss: 3.0048, Time: 35.2907 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [15/119], Loss: 1.6195, Time: 35.6665 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [20/119], Loss: 2.8064, Time: 36.0454 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [25/119], Loss: 2.3349, Time: 36.4137 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [30/119], Loss: 2.5810, Time: 36.7660 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [35/119], Loss: 1.8834, Time: 37.1334 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [40/119], Loss: 2.2193, Time: 37.5248 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [45/119], Loss: 1.8934, Time: 38.0017 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [50/119], Loss: 2.3150, Time: 38.4499 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [55/119], Loss: 2.0288, Time: 38.9158 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [60/119], Loss: 2.1708, Time: 39.4691 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [65/119], Loss: 1.9567, Time: 39.9535 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [70/119], Loss: 1.7444, Time: 40.3609 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [75/119], Loss: 2.2907, Time: 40.7639 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [80/119], Loss: 1.5983, Time: 41.2119 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [85/119], Loss: 1.9034, Time: 41.6032 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [90/119], Loss: 2.0026, Time: 41.9888 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [95/119], Loss: 1.7845, Time: 42.4006 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [100/119], Loss: 1.8429, Time: 42.9963 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [105/119], Loss: 1.4787, Time: 43.4246 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [110/119], Loss: 2.2834, Time: 43.7847 secs, learning rate: 0.0010\n",
      "Epoch [4/5], Step [115/119], Loss: 1.7333, Time: 44.1762 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [5/119], Loss: 1.7284, Time: 46.4311 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [10/119], Loss: 1.6327, Time: 46.8293 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [15/119], Loss: 1.5799, Time: 47.2993 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [20/119], Loss: 1.5130, Time: 47.7552 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [25/119], Loss: 1.7331, Time: 48.2404 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [30/119], Loss: 1.5707, Time: 48.6649 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [35/119], Loss: 1.3747, Time: 49.0729 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [40/119], Loss: 1.3984, Time: 49.4871 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [45/119], Loss: 0.9837, Time: 49.8864 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [50/119], Loss: 0.8359, Time: 50.2465 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [55/119], Loss: 0.9350, Time: 50.5980 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [60/119], Loss: 1.0198, Time: 50.9574 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [65/119], Loss: 0.8337, Time: 51.3495 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [70/119], Loss: 0.9670, Time: 51.7724 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [75/119], Loss: 1.1783, Time: 52.2469 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [80/119], Loss: 0.9085, Time: 52.6775 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [85/119], Loss: 0.9041, Time: 53.1224 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [90/119], Loss: 0.8752, Time: 53.5372 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [95/119], Loss: 0.7759, Time: 53.9134 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [100/119], Loss: 0.8163, Time: 54.3306 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [105/119], Loss: 0.6824, Time: 54.7287 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [110/119], Loss: 0.8285, Time: 55.1043 secs, learning rate: 0.0010\n",
      "Epoch [5/5], Step [115/119], Loss: 0.6762, Time: 55.5269 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [5/119], Loss: 401.3740, Time: 59.3464 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [10/119], Loss: 269.1719, Time: 59.7058 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [15/119], Loss: 256.9727, Time: 60.0824 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [20/119], Loss: 91.3105, Time: 60.4886 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [25/119], Loss: 17.3659, Time: 60.9858 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [30/119], Loss: 99.9936, Time: 61.3782 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [35/119], Loss: 13.1966, Time: 61.8054 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [40/119], Loss: 20.0727, Time: 62.2556 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [45/119], Loss: 14.4001, Time: 62.6487 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [50/119], Loss: 14.7110, Time: 63.0463 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [55/119], Loss: 6.1144, Time: 63.4370 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [60/119], Loss: 14.6182, Time: 63.8309 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [65/119], Loss: 6.6185, Time: 64.2030 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [70/119], Loss: 4.9974, Time: 64.5499 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [75/119], Loss: 60.6715, Time: 64.9958 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [80/119], Loss: 44.1298, Time: 65.3708 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [85/119], Loss: 42.8890, Time: 65.7924 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [90/119], Loss: 9.3418, Time: 66.1418 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [95/119], Loss: 65.8357, Time: 66.4887 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [100/119], Loss: 77.8911, Time: 66.8654 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [105/119], Loss: 8.1387, Time: 67.2421 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [110/119], Loss: 31.7699, Time: 67.6217 secs, learning rate: 0.0010\n",
      "Epoch [1/10], Step [115/119], Loss: 43.5542, Time: 67.9724 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [5/119], Loss: 43.8549, Time: 70.2147 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [10/119], Loss: 9.0485, Time: 70.7149 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [15/119], Loss: 15.3245, Time: 71.0929 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [20/119], Loss: 27.3829, Time: 71.5618 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [25/119], Loss: 7.5665, Time: 71.9358 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [30/119], Loss: 12.7593, Time: 72.2963 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [35/119], Loss: 11.7711, Time: 72.6598 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [40/119], Loss: 3.0700, Time: 73.0380 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [45/119], Loss: 15.6843, Time: 73.4175 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [50/119], Loss: 3.8976, Time: 73.7942 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [55/119], Loss: 3.4539, Time: 74.1594 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [60/119], Loss: 11.6088, Time: 74.5075 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [65/119], Loss: 8.2506, Time: 74.8990 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [70/119], Loss: 5.7400, Time: 75.2681 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [75/119], Loss: 11.8328, Time: 75.6575 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [80/119], Loss: 7.8938, Time: 76.0090 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [85/119], Loss: 5.7778, Time: 76.3478 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [90/119], Loss: 9.7279, Time: 76.6917 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [95/119], Loss: 6.6492, Time: 77.0297 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [100/119], Loss: 3.6074, Time: 77.3941 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [105/119], Loss: 7.2197, Time: 77.7610 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [110/119], Loss: 7.1155, Time: 78.1238 secs, learning rate: 0.0010\n",
      "Epoch [2/10], Step [115/119], Loss: 3.7170, Time: 78.4728 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [5/119], Loss: 2.8221, Time: 80.5983 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [10/119], Loss: 6.7342, Time: 81.0514 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [15/119], Loss: 5.3876, Time: 81.4702 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [20/119], Loss: 3.6374, Time: 81.9744 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [25/119], Loss: 4.8251, Time: 82.3511 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [30/119], Loss: 3.4443, Time: 82.7138 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [35/119], Loss: 2.5570, Time: 83.0888 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [40/119], Loss: 1.6803, Time: 83.4794 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [45/119], Loss: 1.5021, Time: 83.8840 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [50/119], Loss: 1.7029, Time: 84.2544 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [55/119], Loss: 1.3902, Time: 84.6362 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [60/119], Loss: 1.3098, Time: 85.0655 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [65/119], Loss: 1.2492, Time: 85.5196 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [70/119], Loss: 1.6974, Time: 85.9581 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [75/119], Loss: 1.4793, Time: 86.4131 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [80/119], Loss: 1.2130, Time: 86.8515 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [85/119], Loss: 1.1243, Time: 87.1966 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [90/119], Loss: 1.1495, Time: 87.5635 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [95/119], Loss: 1.0967, Time: 87.9697 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [100/119], Loss: 1.1893, Time: 88.3073 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [105/119], Loss: 1.3650, Time: 88.6979 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [110/119], Loss: 1.0010, Time: 89.1157 secs, learning rate: 0.0010\n",
      "Epoch [3/10], Step [115/119], Loss: 1.0063, Time: 89.5175 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [5/119], Loss: 1.3054, Time: 91.6942 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [10/119], Loss: 1.3678, Time: 92.0380 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [15/119], Loss: 1.0618, Time: 92.4259 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [20/119], Loss: 1.0128, Time: 92.8181 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [25/119], Loss: 1.4519, Time: 93.1655 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [30/119], Loss: 1.2570, Time: 93.5672 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [35/119], Loss: 1.1477, Time: 93.9472 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [40/119], Loss: 1.1443, Time: 94.3080 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [45/119], Loss: 0.9952, Time: 94.6747 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [50/119], Loss: 1.1663, Time: 95.0967 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [55/119], Loss: 1.1995, Time: 95.4678 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [60/119], Loss: 1.0966, Time: 95.8606 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [65/119], Loss: 0.7968, Time: 96.2236 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [70/119], Loss: 0.7828, Time: 96.6190 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [75/119], Loss: 1.4299, Time: 96.9957 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [80/119], Loss: 0.8014, Time: 97.3551 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [85/119], Loss: 1.0872, Time: 97.7352 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [90/119], Loss: 1.0703, Time: 98.0756 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [95/119], Loss: 0.8402, Time: 98.4338 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [100/119], Loss: 1.5064, Time: 98.7983 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [105/119], Loss: 2.4108, Time: 99.1420 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [110/119], Loss: 1.4851, Time: 99.4975 secs, learning rate: 0.0010\n",
      "Epoch [4/10], Step [115/119], Loss: 1.4478, Time: 99.8201 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [5/119], Loss: 1.5968, Time: 101.9367 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [10/119], Loss: 1.3720, Time: 102.3333 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [15/119], Loss: 0.7865, Time: 102.6950 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [20/119], Loss: 0.9015, Time: 103.0389 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [25/119], Loss: 0.7453, Time: 103.3903 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [30/119], Loss: 1.0210, Time: 103.7567 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [35/119], Loss: 0.7369, Time: 104.1026 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [40/119], Loss: 0.8130, Time: 104.4512 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [45/119], Loss: 0.7431, Time: 104.7978 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [50/119], Loss: 0.7868, Time: 105.1194 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [55/119], Loss: 0.9017, Time: 105.4631 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [60/119], Loss: 0.7486, Time: 105.8010 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [65/119], Loss: 0.8659, Time: 106.1437 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [70/119], Loss: 0.6431, Time: 106.4883 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [75/119], Loss: 0.7013, Time: 106.8271 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [80/119], Loss: 0.6367, Time: 107.1953 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [85/119], Loss: 0.8372, Time: 107.5430 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [90/119], Loss: 0.5916, Time: 107.8964 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [95/119], Loss: 1.1330, Time: 108.2243 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [100/119], Loss: 1.1015, Time: 108.5724 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [105/119], Loss: 1.3796, Time: 108.9332 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [110/119], Loss: 0.6763, Time: 109.2788 secs, learning rate: 0.0010\n",
      "Epoch [5/10], Step [115/119], Loss: 1.3662, Time: 109.6382 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [5/119], Loss: 0.7439, Time: 111.7216 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [10/119], Loss: 0.7250, Time: 112.0810 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [15/119], Loss: 0.6794, Time: 112.4596 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [20/119], Loss: 0.6025, Time: 112.8365 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [25/119], Loss: 0.9423, Time: 113.2722 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [30/119], Loss: 1.3187, Time: 113.7230 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [35/119], Loss: 0.9861, Time: 114.1234 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [40/119], Loss: 2.1539, Time: 114.5146 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [45/119], Loss: 3.3334, Time: 114.9066 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [50/119], Loss: 2.9150, Time: 115.2711 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [55/119], Loss: 1.7509, Time: 115.6481 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [60/119], Loss: 1.0994, Time: 116.0589 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [65/119], Loss: 1.1443, Time: 116.4719 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [70/119], Loss: 1.0777, Time: 116.8486 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [75/119], Loss: 1.5498, Time: 117.2354 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [80/119], Loss: 0.9093, Time: 117.6444 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [85/119], Loss: 0.6986, Time: 118.0409 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [90/119], Loss: 0.7140, Time: 118.4480 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [95/119], Loss: 0.6746, Time: 118.8267 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [100/119], Loss: 0.6501, Time: 119.2354 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [105/119], Loss: 1.0375, Time: 119.6676 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [110/119], Loss: 0.6147, Time: 120.1934 secs, learning rate: 0.0010\n",
      "Epoch [6/10], Step [115/119], Loss: 0.5321, Time: 120.5528 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [5/119], Loss: 0.8878, Time: 122.8191 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [10/119], Loss: 0.6462, Time: 123.1629 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [15/119], Loss: 0.5456, Time: 123.5093 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [20/119], Loss: 0.6262, Time: 123.8615 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [25/119], Loss: 0.9370, Time: 124.2471 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [30/119], Loss: 0.8026, Time: 124.6915 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [35/119], Loss: 0.6092, Time: 125.0721 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [40/119], Loss: 0.6483, Time: 125.4335 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [45/119], Loss: 0.5063, Time: 125.8085 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [50/119], Loss: 0.8302, Time: 126.1757 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [55/119], Loss: 0.5601, Time: 126.6577 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [60/119], Loss: 0.7448, Time: 127.1110 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [65/119], Loss: 0.5016, Time: 127.5530 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [70/119], Loss: 0.5031, Time: 127.9916 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [75/119], Loss: 0.7982, Time: 128.4135 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [80/119], Loss: 0.6315, Time: 128.8701 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [85/119], Loss: 1.4852, Time: 129.2146 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [90/119], Loss: 0.9108, Time: 129.6386 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [95/119], Loss: 0.9054, Time: 130.0607 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [100/119], Loss: 0.5351, Time: 130.4670 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [105/119], Loss: 0.5526, Time: 130.8596 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [110/119], Loss: 0.5854, Time: 131.2948 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [115/119], Loss: 0.5761, Time: 131.7356 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [5/119], Loss: 0.7423, Time: 134.0688 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [10/119], Loss: 0.5981, Time: 134.4239 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [15/119], Loss: 0.4805, Time: 134.7688 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [20/119], Loss: 0.5632, Time: 135.1051 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [25/119], Loss: 0.5478, Time: 135.4562 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [30/119], Loss: 0.5575, Time: 135.8007 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [35/119], Loss: 0.6056, Time: 136.1523 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [40/119], Loss: 0.6852, Time: 136.5041 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [45/119], Loss: 0.7226, Time: 136.8641 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [50/119], Loss: 0.4769, Time: 137.2095 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [55/119], Loss: 0.5998, Time: 137.5696 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [60/119], Loss: 0.8484, Time: 137.9146 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [65/119], Loss: 0.8114, Time: 138.2663 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [70/119], Loss: 0.7633, Time: 138.6045 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [75/119], Loss: 0.4865, Time: 138.9646 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [80/119], Loss: 1.0277, Time: 139.3083 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [85/119], Loss: 1.0917, Time: 139.6528 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [90/119], Loss: 0.5775, Time: 140.0136 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [95/119], Loss: 0.5188, Time: 140.3511 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [100/119], Loss: 0.6833, Time: 140.7180 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [105/119], Loss: 0.4891, Time: 141.0542 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [110/119], Loss: 0.5722, Time: 141.4142 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [115/119], Loss: 0.6762, Time: 141.7513 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [5/119], Loss: 0.4386, Time: 143.8418 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [10/119], Loss: 0.4461, Time: 144.1929 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [15/119], Loss: 0.5050, Time: 144.5224 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [20/119], Loss: 0.4504, Time: 144.8889 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [25/119], Loss: 0.4421, Time: 145.2274 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [30/119], Loss: 0.4424, Time: 145.5719 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [35/119], Loss: 0.4890, Time: 145.9246 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [40/119], Loss: 0.4670, Time: 146.2711 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [45/119], Loss: 0.4726, Time: 146.6156 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [50/119], Loss: 0.4955, Time: 146.9520 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [55/119], Loss: 0.4574, Time: 147.2998 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [60/119], Loss: 0.4440, Time: 147.6443 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [65/119], Loss: 0.4634, Time: 147.9954 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [70/119], Loss: 0.4471, Time: 148.3503 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [75/119], Loss: 0.4674, Time: 148.6954 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [80/119], Loss: 0.4182, Time: 149.0468 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [85/119], Loss: 0.4699, Time: 149.3827 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [90/119], Loss: 0.4445, Time: 149.7438 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [95/119], Loss: 0.4149, Time: 150.0836 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [100/119], Loss: 0.4724, Time: 150.4348 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [105/119], Loss: 0.4323, Time: 150.7793 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [110/119], Loss: 0.5606, Time: 151.1191 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [115/119], Loss: 0.4723, Time: 151.4699 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [5/119], Loss: 0.4551, Time: 153.5566 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [10/119], Loss: 0.4225, Time: 153.9078 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [15/119], Loss: 0.4349, Time: 154.2529 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [20/119], Loss: 0.4070, Time: 154.6051 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [25/119], Loss: 0.4688, Time: 154.9426 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [30/119], Loss: 0.4253, Time: 155.2871 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [35/119], Loss: 0.4876, Time: 155.6597 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [40/119], Loss: 0.4117, Time: 156.0208 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [45/119], Loss: 0.4217, Time: 156.3652 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [50/119], Loss: 0.3911, Time: 156.7162 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [55/119], Loss: 0.5446, Time: 157.0533 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [60/119], Loss: 0.4379, Time: 157.3978 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [65/119], Loss: 0.4536, Time: 157.7493 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [70/119], Loss: 0.5251, Time: 158.1164 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [75/119], Loss: 0.5281, Time: 158.4610 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [80/119], Loss: 0.4518, Time: 158.8016 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [85/119], Loss: 0.4092, Time: 159.1520 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [90/119], Loss: 0.4021, Time: 159.5391 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [95/119], Loss: 0.4921, Time: 160.0629 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [100/119], Loss: 0.4685, Time: 160.5859 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [105/119], Loss: 0.5279, Time: 160.9296 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [110/119], Loss: 0.5294, Time: 161.2841 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [115/119], Loss: 1.0188, Time: 161.6384 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [5/119], Loss: 218.7124, Time: 165.5353 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [10/119], Loss: 258.6707, Time: 165.9884 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [15/119], Loss: 114.1660, Time: 166.4499 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [20/119], Loss: 32.0625, Time: 166.9037 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [25/119], Loss: 37.0405, Time: 167.3239 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [30/119], Loss: 84.5621, Time: 167.7152 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [35/119], Loss: 65.5229, Time: 168.0597 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [40/119], Loss: 25.4835, Time: 168.4272 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [45/119], Loss: 28.1477, Time: 168.7945 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [50/119], Loss: 13.1254, Time: 169.1398 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [55/119], Loss: 13.4870, Time: 169.4911 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [60/119], Loss: 11.5148, Time: 169.8517 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [65/119], Loss: 12.9888, Time: 170.1806 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [70/119], Loss: 8.7007, Time: 170.6141 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [75/119], Loss: 9.6340, Time: 171.0211 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [80/119], Loss: 14.3002, Time: 171.3811 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [85/119], Loss: 13.7427, Time: 171.7412 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [90/119], Loss: 9.1374, Time: 172.0860 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [95/119], Loss: 10.9105, Time: 172.4400 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [100/119], Loss: 12.1299, Time: 172.7845 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [105/119], Loss: 13.1500, Time: 173.1289 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [110/119], Loss: 4.6425, Time: 173.4734 secs, learning rate: 0.0010\n",
      "Epoch [1/15], Step [115/119], Loss: 4.6997, Time: 173.8491 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [5/119], Loss: 2.8925, Time: 175.9441 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [10/119], Loss: 5.6855, Time: 176.2879 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [15/119], Loss: 7.3351, Time: 176.6415 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [20/119], Loss: 3.8429, Time: 176.9923 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [25/119], Loss: 2.1068, Time: 177.3367 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [30/119], Loss: 5.2088, Time: 177.6816 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [35/119], Loss: 2.9075, Time: 178.0265 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [40/119], Loss: 5.7989, Time: 178.3788 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [45/119], Loss: 1.8804, Time: 178.7234 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [50/119], Loss: 7.6953, Time: 179.0604 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [55/119], Loss: 6.5307, Time: 179.4113 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [60/119], Loss: 8.1925, Time: 179.7562 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [65/119], Loss: 9.4226, Time: 180.1006 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [70/119], Loss: 10.0270, Time: 180.4607 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [75/119], Loss: 7.9072, Time: 180.7895 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [80/119], Loss: 5.7632, Time: 181.1563 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [85/119], Loss: 5.3212, Time: 181.5015 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [90/119], Loss: 9.0204, Time: 181.8459 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [95/119], Loss: 5.4799, Time: 182.1949 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [100/119], Loss: 7.2667, Time: 182.5316 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [105/119], Loss: 5.2566, Time: 182.8764 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [110/119], Loss: 5.2277, Time: 183.2299 secs, learning rate: 0.0010\n",
      "Epoch [2/15], Step [115/119], Loss: 4.1160, Time: 183.5801 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [5/119], Loss: 5.8705, Time: 185.6497 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [10/119], Loss: 5.7140, Time: 186.0022 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [15/119], Loss: 4.9209, Time: 186.3474 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [20/119], Loss: 5.1093, Time: 186.6839 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [25/119], Loss: 5.0240, Time: 187.0350 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [30/119], Loss: 3.4489, Time: 187.3798 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [35/119], Loss: 4.8071, Time: 187.7242 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [40/119], Loss: 6.0114, Time: 188.0804 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [45/119], Loss: 5.6805, Time: 188.4255 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [50/119], Loss: 3.3594, Time: 188.7699 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [55/119], Loss: 3.7911, Time: 189.1213 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [60/119], Loss: 4.5788, Time: 189.4662 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [65/119], Loss: 5.6070, Time: 189.8106 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [70/119], Loss: 2.4666, Time: 190.1700 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [75/119], Loss: 4.2600, Time: 190.5150 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [80/119], Loss: 2.9802, Time: 190.8810 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [85/119], Loss: 4.2391, Time: 191.2328 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [90/119], Loss: 3.5234, Time: 191.5609 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [95/119], Loss: 3.2895, Time: 191.9130 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [100/119], Loss: 3.9132, Time: 192.2483 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [105/119], Loss: 4.2129, Time: 192.6090 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [110/119], Loss: 3.0097, Time: 192.9477 secs, learning rate: 0.0010\n",
      "Epoch [3/15], Step [115/119], Loss: 3.2348, Time: 193.2972 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [5/119], Loss: 2.0919, Time: 195.3670 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [10/119], Loss: 3.3301, Time: 195.7107 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [15/119], Loss: 2.7602, Time: 196.0552 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [20/119], Loss: 3.1850, Time: 196.3902 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [25/119], Loss: 2.9301, Time: 196.7412 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [30/119], Loss: 2.8106, Time: 197.0856 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [35/119], Loss: 3.8188, Time: 197.4301 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [40/119], Loss: 2.9021, Time: 197.7872 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [45/119], Loss: 2.3904, Time: 198.1309 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [50/119], Loss: 3.3721, Time: 198.4975 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [55/119], Loss: 2.3863, Time: 198.8380 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [60/119], Loss: 1.9403, Time: 199.1824 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [65/119], Loss: 2.7938, Time: 199.5342 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [70/119], Loss: 2.8778, Time: 199.8744 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [75/119], Loss: 2.1545, Time: 200.2189 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [80/119], Loss: 3.2705, Time: 200.5734 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [85/119], Loss: 1.8195, Time: 200.9139 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [90/119], Loss: 2.2554, Time: 201.2741 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [95/119], Loss: 2.4861, Time: 201.6239 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [100/119], Loss: 2.0948, Time: 201.9770 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [105/119], Loss: 2.4494, Time: 202.3214 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [110/119], Loss: 2.5974, Time: 202.6753 secs, learning rate: 0.0010\n",
      "Epoch [4/15], Step [115/119], Loss: 2.4682, Time: 203.0255 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [5/119], Loss: 1.6898, Time: 205.0955 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [10/119], Loss: 1.8919, Time: 205.4392 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [15/119], Loss: 2.0685, Time: 205.7837 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [20/119], Loss: 2.6339, Time: 206.1501 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [25/119], Loss: 2.3655, Time: 206.4855 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [30/119], Loss: 2.1314, Time: 206.8299 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [35/119], Loss: 1.6028, Time: 207.1659 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [40/119], Loss: 1.5365, Time: 207.5262 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [45/119], Loss: 1.8604, Time: 207.8713 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [50/119], Loss: 3.1879, Time: 208.2158 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [55/119], Loss: 0.9297, Time: 208.5602 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [60/119], Loss: 0.8151, Time: 208.9047 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [65/119], Loss: 0.7628, Time: 209.2568 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [70/119], Loss: 0.8970, Time: 209.6012 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [75/119], Loss: 0.7732, Time: 209.9456 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [80/119], Loss: 0.9063, Time: 210.2902 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [85/119], Loss: 0.6991, Time: 210.6405 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [90/119], Loss: 0.8569, Time: 210.9930 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [95/119], Loss: 1.0291, Time: 211.3224 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [100/119], Loss: 0.6148, Time: 211.7009 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [105/119], Loss: 0.6030, Time: 212.0391 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [110/119], Loss: 2.1278, Time: 212.3836 secs, learning rate: 0.0010\n",
      "Epoch [5/15], Step [115/119], Loss: 4.1577, Time: 212.7346 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [5/119], Loss: 3.0979, Time: 214.8047 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [10/119], Loss: 2.4713, Time: 215.1328 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [15/119], Loss: 2.4881, Time: 215.4774 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [20/119], Loss: 2.6526, Time: 215.8575 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [25/119], Loss: 1.0868, Time: 216.2234 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [30/119], Loss: 0.8931, Time: 216.5681 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [35/119], Loss: 1.3929, Time: 216.9036 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [40/119], Loss: 2.8904, Time: 217.2645 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [45/119], Loss: 1.8308, Time: 217.6098 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [50/119], Loss: 1.6257, Time: 217.9462 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [55/119], Loss: 1.4436, Time: 218.2997 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [60/119], Loss: 1.3178, Time: 218.6597 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [65/119], Loss: 1.4434, Time: 219.0042 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [70/119], Loss: 0.9680, Time: 219.3556 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [75/119], Loss: 0.7689, Time: 219.7001 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [80/119], Loss: 1.0594, Time: 220.0445 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [85/119], Loss: 1.3637, Time: 220.3964 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [90/119], Loss: 1.3055, Time: 220.7604 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [95/119], Loss: 1.6824, Time: 221.1045 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [100/119], Loss: 1.4324, Time: 221.4490 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [105/119], Loss: 1.2635, Time: 221.8021 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [110/119], Loss: 1.4203, Time: 222.1503 secs, learning rate: 0.0010\n",
      "Epoch [6/15], Step [115/119], Loss: 1.3534, Time: 222.4947 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [5/119], Loss: 1.5402, Time: 224.5741 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [10/119], Loss: 1.2723, Time: 224.9022 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [15/119], Loss: 1.5095, Time: 225.2682 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [20/119], Loss: 1.1486, Time: 225.5986 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [25/119], Loss: 1.1134, Time: 225.9645 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [30/119], Loss: 1.0197, Time: 226.3168 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [35/119], Loss: 1.4625, Time: 226.6615 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [40/119], Loss: 1.1482, Time: 227.0137 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [45/119], Loss: 0.9498, Time: 227.3657 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [50/119], Loss: 0.7222, Time: 227.7107 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [55/119], Loss: 0.9802, Time: 228.0678 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [60/119], Loss: 0.6173, Time: 228.4125 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [65/119], Loss: 0.5879, Time: 228.7570 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [70/119], Loss: 0.5513, Time: 229.1235 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [75/119], Loss: 0.5504, Time: 229.4587 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [80/119], Loss: 0.5913, Time: 229.8032 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [85/119], Loss: 0.5033, Time: 230.1633 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [90/119], Loss: 0.5218, Time: 230.5078 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [95/119], Loss: 0.7496, Time: 230.8586 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [100/119], Loss: 0.5710, Time: 231.2031 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [105/119], Loss: 0.5678, Time: 231.5476 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [110/119], Loss: 0.6176, Time: 231.9017 secs, learning rate: 0.0010\n",
      "Epoch [7/15], Step [115/119], Loss: 0.7190, Time: 232.2622 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [5/119], Loss: 0.6489, Time: 234.3394 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [10/119], Loss: 0.7751, Time: 234.6676 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [15/119], Loss: 0.5348, Time: 235.0281 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [20/119], Loss: 0.6480, Time: 235.3727 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [25/119], Loss: 1.0137, Time: 235.7172 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [30/119], Loss: 0.4840, Time: 236.0573 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [35/119], Loss: 0.5082, Time: 236.4018 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [40/119], Loss: 0.4413, Time: 236.7619 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [45/119], Loss: 0.8283, Time: 237.1069 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [50/119], Loss: 0.6679, Time: 237.4670 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [55/119], Loss: 0.5003, Time: 237.8183 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [60/119], Loss: 0.6044, Time: 238.1789 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [65/119], Loss: 0.9875, Time: 238.5235 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [70/119], Loss: 0.6770, Time: 238.8679 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [75/119], Loss: 0.5094, Time: 239.2198 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [80/119], Loss: 0.5625, Time: 239.5574 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [85/119], Loss: 0.6203, Time: 239.9175 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [90/119], Loss: 0.4794, Time: 240.2682 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [95/119], Loss: 0.5601, Time: 240.6050 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [100/119], Loss: 0.7476, Time: 240.9499 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [105/119], Loss: 0.4811, Time: 241.3064 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [110/119], Loss: 0.5378, Time: 241.6508 secs, learning rate: 0.0010\n",
      "Epoch [8/15], Step [115/119], Loss: 0.7216, Time: 242.0072 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [5/119], Loss: 0.5128, Time: 244.0790 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [10/119], Loss: 0.5884, Time: 244.4228 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [15/119], Loss: 0.5240, Time: 244.7733 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [20/119], Loss: 0.4768, Time: 245.1179 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [25/119], Loss: 0.4297, Time: 245.4708 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [30/119], Loss: 0.5472, Time: 245.8225 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [35/119], Loss: 0.7753, Time: 246.1830 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [40/119], Loss: 0.4916, Time: 246.5431 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [45/119], Loss: 0.6760, Time: 246.8945 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [50/119], Loss: 0.8991, Time: 247.2300 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [55/119], Loss: 0.4705, Time: 247.5908 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [60/119], Loss: 0.5136, Time: 247.9432 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [65/119], Loss: 0.7265, Time: 248.2831 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [70/119], Loss: 0.4439, Time: 248.6432 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [75/119], Loss: 0.7031, Time: 248.9954 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [80/119], Loss: 0.8579, Time: 249.3399 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [85/119], Loss: 0.5000, Time: 249.6837 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [90/119], Loss: 0.5240, Time: 250.0369 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [95/119], Loss: 0.6307, Time: 250.3969 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [100/119], Loss: 0.4369, Time: 250.7418 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [105/119], Loss: 0.5000, Time: 251.0772 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [110/119], Loss: 0.6010, Time: 251.4270 secs, learning rate: 0.0010\n",
      "Epoch [9/15], Step [115/119], Loss: 0.5509, Time: 251.7716 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [5/119], Loss: 0.4414, Time: 253.8491 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [10/119], Loss: 0.4121, Time: 254.1928 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [15/119], Loss: 0.7155, Time: 254.5446 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [20/119], Loss: 0.4325, Time: 254.8799 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [25/119], Loss: 0.7599, Time: 255.2405 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [30/119], Loss: 1.9909, Time: 255.5851 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [35/119], Loss: 1.6426, Time: 255.9218 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [40/119], Loss: 2.2563, Time: 256.2662 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [45/119], Loss: 1.4282, Time: 256.6264 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [50/119], Loss: 1.4271, Time: 256.9630 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [55/119], Loss: 1.6662, Time: 257.3075 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [60/119], Loss: 1.5099, Time: 257.6676 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [65/119], Loss: 0.5133, Time: 258.0041 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [70/119], Loss: 0.8549, Time: 258.3488 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [75/119], Loss: 0.5297, Time: 258.7033 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [80/119], Loss: 0.4659, Time: 259.0439 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [85/119], Loss: 0.4889, Time: 259.3883 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [90/119], Loss: 0.4600, Time: 259.7426 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [95/119], Loss: 0.4484, Time: 260.0847 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [100/119], Loss: 0.3940, Time: 260.4291 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [105/119], Loss: 0.5191, Time: 260.7736 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [110/119], Loss: 0.4360, Time: 261.1294 secs, learning rate: 0.0010\n",
      "Epoch [10/15], Step [115/119], Loss: 0.4685, Time: 261.4739 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [5/119], Loss: 0.4398, Time: 263.5470 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [10/119], Loss: 0.4387, Time: 263.8908 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [15/119], Loss: 0.4183, Time: 264.2352 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [20/119], Loss: 0.4317, Time: 264.5798 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [25/119], Loss: 0.4010, Time: 264.9373 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [30/119], Loss: 0.4075, Time: 265.2878 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [35/119], Loss: 0.4055, Time: 265.6322 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [40/119], Loss: 0.3976, Time: 265.9767 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [45/119], Loss: 0.4126, Time: 266.3312 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [50/119], Loss: 0.4190, Time: 266.6756 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [55/119], Loss: 0.4058, Time: 267.0200 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [60/119], Loss: 0.3717, Time: 267.3724 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [65/119], Loss: 0.3886, Time: 267.7277 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [70/119], Loss: 0.3898, Time: 268.0725 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [75/119], Loss: 0.4074, Time: 268.4170 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [80/119], Loss: 0.4568, Time: 268.7771 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [85/119], Loss: 0.4040, Time: 269.1216 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [90/119], Loss: 0.4315, Time: 269.4590 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [95/119], Loss: 0.4169, Time: 269.7995 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [100/119], Loss: 0.3774, Time: 270.1439 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [105/119], Loss: 0.3926, Time: 270.4991 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [110/119], Loss: 0.3926, Time: 270.8436 secs, learning rate: 0.0010\n",
      "Epoch [11/15], Step [115/119], Loss: 0.3972, Time: 271.1880 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [5/119], Loss: 0.4112, Time: 273.2579 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [10/119], Loss: 0.4459, Time: 273.6017 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [15/119], Loss: 0.3989, Time: 273.9618 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [20/119], Loss: 0.4449, Time: 274.3067 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [25/119], Loss: 0.3978, Time: 274.6668 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [30/119], Loss: 0.4629, Time: 275.0179 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [35/119], Loss: 0.3791, Time: 275.3549 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [40/119], Loss: 0.3667, Time: 275.7306 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [45/119], Loss: 0.3882, Time: 276.1297 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [50/119], Loss: 0.3781, Time: 276.4678 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [55/119], Loss: 0.3724, Time: 276.8279 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [60/119], Loss: 0.3557, Time: 277.1628 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [65/119], Loss: 0.4724, Time: 277.5233 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [70/119], Loss: 0.3798, Time: 277.8747 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [75/119], Loss: 0.3851, Time: 278.2191 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [80/119], Loss: 0.4636, Time: 278.5636 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [85/119], Loss: 0.4359, Time: 278.9293 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [90/119], Loss: 0.3735, Time: 279.2737 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [95/119], Loss: 0.3991, Time: 279.6238 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [100/119], Loss: 0.4792, Time: 279.9591 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [105/119], Loss: 0.4000, Time: 280.3035 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [110/119], Loss: 0.3553, Time: 280.6558 secs, learning rate: 0.0010\n",
      "Epoch [12/15], Step [115/119], Loss: 0.3565, Time: 281.0068 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [5/119], Loss: 0.4347, Time: 283.0871 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [10/119], Loss: 0.3765, Time: 283.4309 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [15/119], Loss: 0.3776, Time: 283.7753 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [20/119], Loss: 0.4491, Time: 284.1150 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [25/119], Loss: 0.3647, Time: 284.4751 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [30/119], Loss: 0.4041, Time: 284.8137 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [35/119], Loss: 0.3613, Time: 285.1741 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [40/119], Loss: 0.4242, Time: 285.5186 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [45/119], Loss: 0.3819, Time: 285.8787 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [50/119], Loss: 0.3660, Time: 286.2322 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [55/119], Loss: 0.3820, Time: 286.5766 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [60/119], Loss: 0.3303, Time: 286.9249 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [65/119], Loss: 0.4488, Time: 287.2761 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [70/119], Loss: 0.4169, Time: 287.6674 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [75/119], Loss: 0.4988, Time: 287.9963 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [80/119], Loss: 0.3991, Time: 288.3639 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [85/119], Loss: 0.3891, Time: 288.7012 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [90/119], Loss: 0.3647, Time: 289.0613 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [95/119], Loss: 0.3562, Time: 289.4061 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [100/119], Loss: 0.3413, Time: 289.7728 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [105/119], Loss: 0.3532, Time: 290.1175 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [110/119], Loss: 0.4709, Time: 290.4619 secs, learning rate: 0.0010\n",
      "Epoch [13/15], Step [115/119], Loss: 0.3814, Time: 290.8065 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [5/119], Loss: 0.3808, Time: 292.8770 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [10/119], Loss: 0.3895, Time: 293.2207 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [15/119], Loss: 0.4722, Time: 293.5810 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [20/119], Loss: 0.3475, Time: 293.9334 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [25/119], Loss: 0.4300, Time: 294.2722 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [30/119], Loss: 0.4654, Time: 294.6167 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [35/119], Loss: 0.3855, Time: 294.9688 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [40/119], Loss: 0.3336, Time: 295.3140 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [45/119], Loss: 0.3575, Time: 295.6584 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [50/119], Loss: 0.4134, Time: 296.0158 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [55/119], Loss: 0.3923, Time: 296.3677 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [60/119], Loss: 0.3989, Time: 296.7277 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [65/119], Loss: 0.3739, Time: 297.0728 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [70/119], Loss: 0.4614, Time: 297.4248 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [75/119], Loss: 0.3937, Time: 297.7626 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [80/119], Loss: 0.5231, Time: 298.1226 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [85/119], Loss: 0.4114, Time: 298.4573 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [90/119], Loss: 0.4931, Time: 298.8080 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [95/119], Loss: 0.4063, Time: 299.1533 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [100/119], Loss: 0.3347, Time: 299.5053 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [105/119], Loss: 0.3747, Time: 299.8473 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [110/119], Loss: 0.4387, Time: 300.2074 secs, learning rate: 0.0010\n",
      "Epoch [14/15], Step [115/119], Loss: 0.3461, Time: 300.5519 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [5/119], Loss: 0.4061, Time: 302.6193 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [10/119], Loss: 0.3385, Time: 302.9630 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [15/119], Loss: 0.4065, Time: 303.3232 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [20/119], Loss: 0.4943, Time: 303.7356 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [25/119], Loss: 0.3724, Time: 304.1512 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [30/119], Loss: 0.3658, Time: 304.5038 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [35/119], Loss: 0.4220, Time: 304.8482 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [40/119], Loss: 0.3619, Time: 305.1830 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [45/119], Loss: 0.4004, Time: 305.5425 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [50/119], Loss: 0.3638, Time: 305.9026 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [55/119], Loss: 0.3524, Time: 306.2407 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [60/119], Loss: 0.3627, Time: 306.6008 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [65/119], Loss: 0.3394, Time: 306.9536 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [70/119], Loss: 0.3411, Time: 307.2989 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [75/119], Loss: 0.3425, Time: 307.6434 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [80/119], Loss: 0.3982, Time: 307.9933 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [85/119], Loss: 0.4149, Time: 308.3377 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [90/119], Loss: 0.5097, Time: 308.6981 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [95/119], Loss: 0.3556, Time: 309.0336 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [100/119], Loss: 0.3860, Time: 309.3927 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [105/119], Loss: 0.3586, Time: 309.7533 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [110/119], Loss: 0.3847, Time: 310.0957 secs, learning rate: 0.0010\n",
      "Epoch [15/15], Step [115/119], Loss: 0.4932, Time: 310.4401 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [5/119], Loss: 88.8222, Time: 313.9383 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [10/119], Loss: 302.7754, Time: 314.2976 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [15/119], Loss: 122.8283, Time: 314.6509 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [20/119], Loss: 31.0739, Time: 315.0116 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [25/119], Loss: 63.7797, Time: 315.3720 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [30/119], Loss: 77.6091, Time: 315.7396 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [35/119], Loss: 53.5467, Time: 316.0846 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [40/119], Loss: 22.2217, Time: 316.4448 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [45/119], Loss: 30.1887, Time: 316.8054 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [50/119], Loss: 40.7919, Time: 317.1655 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [55/119], Loss: 29.5203, Time: 317.5100 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [60/119], Loss: 7.9832, Time: 317.8773 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [65/119], Loss: 23.3690, Time: 318.2450 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [70/119], Loss: 8.9968, Time: 318.6051 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [75/119], Loss: 5.0123, Time: 318.9569 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [80/119], Loss: 5.3692, Time: 319.3013 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [85/119], Loss: 4.2924, Time: 319.6615 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [90/119], Loss: 3.0404, Time: 320.0287 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [95/119], Loss: 2.7291, Time: 320.3794 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [100/119], Loss: 6.0474, Time: 320.7455 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [105/119], Loss: 4.8257, Time: 321.1063 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [110/119], Loss: 6.2568, Time: 321.4581 secs, learning rate: 0.0010\n",
      "Epoch [1/20], Step [115/119], Loss: 4.0658, Time: 321.8245 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [5/119], Loss: 11.9071, Time: 323.9248 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [10/119], Loss: 11.2659, Time: 324.2686 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [15/119], Loss: 1.7136, Time: 324.6288 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [20/119], Loss: 10.7441, Time: 324.9952 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [25/119], Loss: 10.2355, Time: 325.3626 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [30/119], Loss: 1.6514, Time: 325.7081 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [35/119], Loss: 4.6584, Time: 326.0683 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [40/119], Loss: 15.8678, Time: 326.4201 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [45/119], Loss: 3.5716, Time: 326.7803 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [50/119], Loss: 2.6166, Time: 327.1179 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [55/119], Loss: 9.7494, Time: 327.4761 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [60/119], Loss: 10.9424, Time: 327.8364 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [65/119], Loss: 8.1464, Time: 328.1957 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [70/119], Loss: 10.6440, Time: 328.5475 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [75/119], Loss: 4.5595, Time: 328.8928 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [80/119], Loss: 3.7573, Time: 329.2440 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [85/119], Loss: 9.8134, Time: 329.6041 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [90/119], Loss: 6.8167, Time: 329.9714 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [95/119], Loss: 4.0861, Time: 330.3163 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [100/119], Loss: 7.9285, Time: 330.6845 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [105/119], Loss: 5.1919, Time: 331.0360 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [110/119], Loss: 2.7436, Time: 331.3968 secs, learning rate: 0.0010\n",
      "Epoch [2/20], Step [115/119], Loss: 5.8315, Time: 331.7570 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [5/119], Loss: 5.7159, Time: 333.8431 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [10/119], Loss: 4.3793, Time: 334.2024 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [15/119], Loss: 2.8576, Time: 334.5470 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [20/119], Loss: 5.2855, Time: 334.8932 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [25/119], Loss: 3.2111, Time: 335.2525 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [30/119], Loss: 1.7508, Time: 335.6106 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [35/119], Loss: 3.4044, Time: 335.9559 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [40/119], Loss: 2.9391, Time: 336.3070 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [45/119], Loss: 2.4245, Time: 336.6645 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [50/119], Loss: 1.9686, Time: 337.0247 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [55/119], Loss: 1.2834, Time: 337.3760 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [60/119], Loss: 1.3352, Time: 337.7428 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [65/119], Loss: 1.4229, Time: 338.1008 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [70/119], Loss: 0.9804, Time: 338.4453 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [75/119], Loss: 1.0272, Time: 338.7897 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [80/119], Loss: 0.9947, Time: 339.1342 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [85/119], Loss: 1.0637, Time: 339.4942 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [90/119], Loss: 0.9441, Time: 339.8387 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [95/119], Loss: 1.1016, Time: 340.1893 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [100/119], Loss: 1.1393, Time: 340.5337 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [105/119], Loss: 0.7751, Time: 340.9109 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [110/119], Loss: 0.8239, Time: 341.2555 secs, learning rate: 0.0010\n",
      "Epoch [3/20], Step [115/119], Loss: 1.0270, Time: 341.6226 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [5/119], Loss: 0.8496, Time: 343.7052 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [10/119], Loss: 0.8406, Time: 344.0490 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [15/119], Loss: 0.9231, Time: 344.4091 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [20/119], Loss: 0.8204, Time: 344.7583 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [25/119], Loss: 0.8060, Time: 345.1185 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [30/119], Loss: 1.1843, Time: 345.4586 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [35/119], Loss: 1.0945, Time: 345.8155 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [40/119], Loss: 0.8777, Time: 346.1601 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [45/119], Loss: 0.7483, Time: 346.5111 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [50/119], Loss: 0.7046, Time: 346.8766 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [55/119], Loss: 0.6767, Time: 347.2211 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [60/119], Loss: 0.9330, Time: 347.6066 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [65/119], Loss: 0.9743, Time: 347.9723 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [70/119], Loss: 1.0097, Time: 348.3172 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [75/119], Loss: 0.6981, Time: 348.6772 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [80/119], Loss: 0.8000, Time: 349.0306 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [85/119], Loss: 0.8926, Time: 349.3732 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [90/119], Loss: 1.0180, Time: 349.7332 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [95/119], Loss: 0.8604, Time: 350.0851 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [100/119], Loss: 0.7296, Time: 350.4451 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [105/119], Loss: 1.2041, Time: 350.7896 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [110/119], Loss: 0.9951, Time: 351.1418 secs, learning rate: 0.0010\n",
      "Epoch [4/20], Step [115/119], Loss: 0.7920, Time: 351.4920 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [5/119], Loss: 0.8199, Time: 353.5714 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [10/119], Loss: 0.7979, Time: 353.9222 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [15/119], Loss: 0.8311, Time: 354.2673 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [20/119], Loss: 0.8138, Time: 354.6191 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [25/119], Loss: 1.1627, Time: 354.9702 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [30/119], Loss: 0.5814, Time: 355.4479 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [35/119], Loss: 1.1235, Time: 356.0087 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [40/119], Loss: 0.7573, Time: 356.4149 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [45/119], Loss: 0.5890, Time: 356.7678 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [50/119], Loss: 0.6418, Time: 357.1280 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [55/119], Loss: 1.4733, Time: 357.4784 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [60/119], Loss: 1.5014, Time: 357.8385 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [65/119], Loss: 2.3167, Time: 358.1979 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [70/119], Loss: 1.3759, Time: 358.5496 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [75/119], Loss: 2.4226, Time: 358.8941 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [80/119], Loss: 0.7064, Time: 359.2545 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [85/119], Loss: 0.6936, Time: 359.6086 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [90/119], Loss: 0.8161, Time: 359.9535 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [95/119], Loss: 0.8341, Time: 360.3068 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [100/119], Loss: 2.0392, Time: 360.6669 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [105/119], Loss: 0.9610, Time: 361.0116 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [110/119], Loss: 1.1411, Time: 361.3716 secs, learning rate: 0.0010\n",
      "Epoch [5/20], Step [115/119], Loss: 0.8375, Time: 361.7223 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [5/119], Loss: 0.6818, Time: 363.7996 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [10/119], Loss: 0.6970, Time: 364.1497 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [15/119], Loss: 0.5875, Time: 364.4944 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [20/119], Loss: 0.7537, Time: 364.8545 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [25/119], Loss: 0.5600, Time: 365.2000 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [30/119], Loss: 0.5516, Time: 365.5444 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [35/119], Loss: 0.5704, Time: 365.9121 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [40/119], Loss: 0.5234, Time: 366.2635 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [45/119], Loss: 0.5480, Time: 366.6236 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [50/119], Loss: 0.5472, Time: 366.9681 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [55/119], Loss: 0.5260, Time: 367.3283 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [60/119], Loss: 0.6951, Time: 367.6680 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [65/119], Loss: 0.5015, Time: 368.0280 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [70/119], Loss: 0.4700, Time: 368.3729 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [75/119], Loss: 0.5284, Time: 368.7246 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [80/119], Loss: 0.6356, Time: 369.0848 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [85/119], Loss: 0.7018, Time: 369.4365 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [90/119], Loss: 0.6146, Time: 369.8214 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [95/119], Loss: 0.7565, Time: 370.1723 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [100/119], Loss: 0.7971, Time: 370.5168 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [105/119], Loss: 0.8090, Time: 370.8693 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [110/119], Loss: 0.7402, Time: 371.2294 secs, learning rate: 0.0010\n",
      "Epoch [6/20], Step [115/119], Loss: 0.7185, Time: 371.5745 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [5/119], Loss: 0.4612, Time: 373.6688 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [10/119], Loss: 0.4252, Time: 374.0126 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [15/119], Loss: 0.4836, Time: 374.3696 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [20/119], Loss: 0.4834, Time: 374.7134 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [25/119], Loss: 0.4145, Time: 375.1417 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [30/119], Loss: 0.4808, Time: 375.5248 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [35/119], Loss: 0.4638, Time: 375.9007 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [40/119], Loss: 0.4284, Time: 376.2613 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [45/119], Loss: 0.4259, Time: 376.6295 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [50/119], Loss: 0.5563, Time: 377.0429 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [55/119], Loss: 0.6303, Time: 377.3952 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [60/119], Loss: 0.6279, Time: 377.7390 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [65/119], Loss: 0.4484, Time: 378.0941 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [70/119], Loss: 0.5088, Time: 378.4535 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [75/119], Loss: 0.4992, Time: 378.7987 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [80/119], Loss: 0.5682, Time: 379.1645 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [85/119], Loss: 0.5211, Time: 379.5153 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [90/119], Loss: 0.3900, Time: 379.8597 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [95/119], Loss: 0.5222, Time: 380.2199 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [100/119], Loss: 0.4332, Time: 380.5741 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [105/119], Loss: 0.6217, Time: 380.9341 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [110/119], Loss: 0.5695, Time: 381.2943 secs, learning rate: 0.0010\n",
      "Epoch [7/20], Step [115/119], Loss: 0.4876, Time: 381.6467 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [5/119], Loss: 0.4783, Time: 383.7304 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [10/119], Loss: 0.5351, Time: 384.0741 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [15/119], Loss: 0.4726, Time: 384.4186 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [20/119], Loss: 0.4522, Time: 384.7787 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [25/119], Loss: 0.4822, Time: 385.1297 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [30/119], Loss: 0.4354, Time: 385.4742 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [35/119], Loss: 0.4888, Time: 385.8343 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [40/119], Loss: 0.3929, Time: 386.1951 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [45/119], Loss: 0.4106, Time: 386.5557 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [50/119], Loss: 0.4360, Time: 386.9162 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [55/119], Loss: 0.5115, Time: 387.2663 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [60/119], Loss: 0.3917, Time: 387.6264 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [65/119], Loss: 0.4600, Time: 387.9865 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [70/119], Loss: 0.4502, Time: 388.3271 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [75/119], Loss: 0.4007, Time: 388.6775 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [80/119], Loss: 0.4426, Time: 389.0431 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [85/119], Loss: 0.4478, Time: 389.3885 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [90/119], Loss: 0.3941, Time: 389.7545 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [95/119], Loss: 0.4731, Time: 390.1146 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [100/119], Loss: 0.3629, Time: 390.4594 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [105/119], Loss: 0.4832, Time: 390.8116 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [110/119], Loss: 0.4108, Time: 391.1692 secs, learning rate: 0.0010\n",
      "Epoch [8/20], Step [115/119], Loss: 0.4741, Time: 391.5142 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [5/119], Loss: 0.3897, Time: 393.7865 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [10/119], Loss: 0.4197, Time: 394.2161 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [15/119], Loss: 0.4965, Time: 394.5762 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [20/119], Loss: 0.4495, Time: 394.9295 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [25/119], Loss: 0.4456, Time: 395.2834 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [30/119], Loss: 0.3721, Time: 395.6498 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [35/119], Loss: 0.4111, Time: 396.0099 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [40/119], Loss: 0.4147, Time: 396.3615 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [45/119], Loss: 0.3729, Time: 396.7373 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [50/119], Loss: 0.4417, Time: 397.0992 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [55/119], Loss: 0.9003, Time: 397.4594 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [60/119], Loss: 0.6536, Time: 397.8270 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [65/119], Loss: 0.6428, Time: 398.1943 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [70/119], Loss: 0.5518, Time: 398.5388 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [75/119], Loss: 0.7140, Time: 398.8744 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [80/119], Loss: 0.6268, Time: 399.2276 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [85/119], Loss: 0.6138, Time: 399.5722 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [90/119], Loss: 0.4674, Time: 399.9519 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [95/119], Loss: 0.6051, Time: 400.2968 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [100/119], Loss: 0.6218, Time: 400.6412 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [105/119], Loss: 0.3881, Time: 401.0017 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [110/119], Loss: 0.4525, Time: 401.3620 secs, learning rate: 0.0010\n",
      "Epoch [9/20], Step [115/119], Loss: 0.3737, Time: 401.7129 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [5/119], Loss: 0.4078, Time: 403.7994 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [10/119], Loss: 0.3293, Time: 404.1431 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [15/119], Loss: 0.3862, Time: 404.5093 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [20/119], Loss: 0.3231, Time: 404.8603 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [25/119], Loss: 0.3704, Time: 405.2049 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [30/119], Loss: 0.3937, Time: 405.5595 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [35/119], Loss: 0.3967, Time: 405.9028 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [40/119], Loss: 0.4952, Time: 406.2629 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [45/119], Loss: 0.4918, Time: 406.6223 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [50/119], Loss: 0.3549, Time: 406.9734 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [55/119], Loss: 0.3462, Time: 407.3399 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [60/119], Loss: 0.3779, Time: 407.7156 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [65/119], Loss: 0.4304, Time: 408.0757 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [70/119], Loss: 0.3844, Time: 408.4429 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [75/119], Loss: 0.3707, Time: 408.8150 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [80/119], Loss: 0.3833, Time: 409.1673 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [85/119], Loss: 0.3392, Time: 409.5183 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [90/119], Loss: 0.3782, Time: 409.8785 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [95/119], Loss: 0.3585, Time: 410.2387 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [100/119], Loss: 0.3870, Time: 410.5905 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [105/119], Loss: 0.3807, Time: 410.9442 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [110/119], Loss: 0.3517, Time: 411.2888 secs, learning rate: 0.0010\n",
      "Epoch [10/20], Step [115/119], Loss: 0.3676, Time: 411.6332 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [5/119], Loss: 0.3248, Time: 413.7282 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [10/119], Loss: 0.4479, Time: 414.0719 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [15/119], Loss: 0.5535, Time: 414.4163 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [20/119], Loss: 0.4476, Time: 414.7704 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [25/119], Loss: 0.3878, Time: 415.1305 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [30/119], Loss: 0.3968, Time: 415.4907 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [35/119], Loss: 0.3721, Time: 415.8353 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [40/119], Loss: 0.4552, Time: 416.1955 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [45/119], Loss: 0.3781, Time: 416.5616 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [50/119], Loss: 0.4060, Time: 416.9062 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [55/119], Loss: 0.4159, Time: 417.2729 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [60/119], Loss: 0.4187, Time: 417.6174 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [65/119], Loss: 0.3775, Time: 417.9774 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [70/119], Loss: 0.3364, Time: 418.3340 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [75/119], Loss: 0.3690, Time: 418.6945 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [80/119], Loss: 0.3792, Time: 419.0547 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [85/119], Loss: 0.4381, Time: 419.3994 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [90/119], Loss: 0.4181, Time: 419.7552 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [95/119], Loss: 0.3884, Time: 420.1067 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [100/119], Loss: 0.6130, Time: 420.4520 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [105/119], Loss: 0.3479, Time: 420.8187 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [110/119], Loss: 0.4248, Time: 421.1790 secs, learning rate: 0.0010\n",
      "Epoch [11/20], Step [115/119], Loss: 0.3948, Time: 421.5242 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [5/119], Loss: 0.3178, Time: 423.6286 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [10/119], Loss: 0.3258, Time: 423.9723 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [15/119], Loss: 0.4064, Time: 424.3317 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [20/119], Loss: 0.3707, Time: 424.6845 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [25/119], Loss: 0.3868, Time: 425.0296 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [30/119], Loss: 0.4100, Time: 425.3815 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [35/119], Loss: 0.3498, Time: 425.7357 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [40/119], Loss: 0.3438, Time: 426.0959 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [45/119], Loss: 0.3520, Time: 426.4565 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [50/119], Loss: 0.3570, Time: 426.8229 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [55/119], Loss: 0.3624, Time: 427.1676 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [60/119], Loss: 0.3730, Time: 427.5188 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [65/119], Loss: 0.3964, Time: 427.8782 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [70/119], Loss: 0.3188, Time: 428.2227 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [75/119], Loss: 0.3252, Time: 428.5720 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [80/119], Loss: 0.3903, Time: 428.9165 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [85/119], Loss: 0.3594, Time: 429.2765 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [90/119], Loss: 0.3641, Time: 429.6291 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [95/119], Loss: 0.3339, Time: 429.9794 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [100/119], Loss: 0.3445, Time: 430.3398 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [105/119], Loss: 0.3657, Time: 430.6999 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [110/119], Loss: 0.3621, Time: 431.0600 secs, learning rate: 0.0010\n",
      "Epoch [12/20], Step [115/119], Loss: 0.4345, Time: 431.4050 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [5/119], Loss: 0.4431, Time: 433.4844 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [10/119], Loss: 0.3535, Time: 433.8281 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [15/119], Loss: 0.3192, Time: 434.1824 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [20/119], Loss: 0.4281, Time: 434.5481 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [25/119], Loss: 0.3215, Time: 434.8987 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [30/119], Loss: 0.3829, Time: 435.2432 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [35/119], Loss: 0.3334, Time: 435.6102 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [40/119], Loss: 0.3655, Time: 435.9554 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [45/119], Loss: 0.3577, Time: 436.3155 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [50/119], Loss: 0.3255, Time: 436.6603 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [55/119], Loss: 0.3647, Time: 437.0204 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [60/119], Loss: 0.3569, Time: 437.3805 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [65/119], Loss: 0.3620, Time: 437.7499 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [70/119], Loss: 0.3910, Time: 438.1103 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [75/119], Loss: 0.3731, Time: 438.4643 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [80/119], Loss: 0.3335, Time: 438.8245 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [85/119], Loss: 0.3557, Time: 439.1756 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [90/119], Loss: 0.3329, Time: 439.5262 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [95/119], Loss: 0.3747, Time: 439.8712 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [100/119], Loss: 0.3462, Time: 440.2257 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [105/119], Loss: 0.3534, Time: 440.5717 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [110/119], Loss: 0.3118, Time: 440.9319 secs, learning rate: 0.0010\n",
      "Epoch [13/20], Step [115/119], Loss: 0.3532, Time: 441.2842 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [5/119], Loss: 0.3935, Time: 443.3639 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [10/119], Loss: 0.3163, Time: 443.7076 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [15/119], Loss: 0.2901, Time: 444.0677 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [20/119], Loss: 0.3333, Time: 444.4129 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [25/119], Loss: 0.3286, Time: 444.7731 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [30/119], Loss: 0.3621, Time: 445.1249 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [35/119], Loss: 0.3343, Time: 445.4693 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [40/119], Loss: 0.3195, Time: 445.8295 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [45/119], Loss: 0.4009, Time: 446.1741 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [50/119], Loss: 0.3709, Time: 446.5344 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [55/119], Loss: 0.4273, Time: 446.9046 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [60/119], Loss: 0.3580, Time: 447.2491 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [65/119], Loss: 0.3474, Time: 447.6007 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [70/119], Loss: 0.3644, Time: 447.9608 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [75/119], Loss: 0.3858, Time: 448.3121 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [80/119], Loss: 0.3123, Time: 448.6651 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [85/119], Loss: 0.3382, Time: 449.0096 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [90/119], Loss: 0.3421, Time: 449.3699 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [95/119], Loss: 0.3481, Time: 449.7304 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [100/119], Loss: 0.3345, Time: 450.0754 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [105/119], Loss: 0.3094, Time: 450.4348 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [110/119], Loss: 0.3222, Time: 450.8267 secs, learning rate: 0.0010\n",
      "Epoch [14/20], Step [115/119], Loss: 0.3675, Time: 451.1868 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [5/119], Loss: 0.3195, Time: 453.2724 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [10/119], Loss: 0.3486, Time: 453.6162 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [15/119], Loss: 0.3153, Time: 453.9762 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [20/119], Loss: 0.3422, Time: 454.3287 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [25/119], Loss: 0.3124, Time: 454.6731 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [30/119], Loss: 0.3038, Time: 455.0332 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [35/119], Loss: 0.3134, Time: 455.3874 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [40/119], Loss: 0.3400, Time: 455.7691 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [45/119], Loss: 0.3763, Time: 456.1119 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [50/119], Loss: 0.3396, Time: 456.4667 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [55/119], Loss: 0.2873, Time: 456.8180 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [60/119], Loss: 0.3245, Time: 457.1787 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [65/119], Loss: 0.3512, Time: 457.5240 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [70/119], Loss: 0.3651, Time: 457.8840 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [75/119], Loss: 0.3683, Time: 458.2294 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [80/119], Loss: 0.3670, Time: 458.6044 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [85/119], Loss: 0.3741, Time: 458.9492 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [90/119], Loss: 0.3443, Time: 459.3164 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [95/119], Loss: 0.3252, Time: 459.6615 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [100/119], Loss: 0.3401, Time: 460.0166 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [105/119], Loss: 0.3371, Time: 460.3611 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [110/119], Loss: 0.3395, Time: 460.7212 secs, learning rate: 0.0010\n",
      "Epoch [15/20], Step [115/119], Loss: 0.2886, Time: 461.0730 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [5/119], Loss: 0.3300, Time: 463.1703 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [10/119], Loss: 0.3175, Time: 463.5140 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [15/119], Loss: 0.3168, Time: 463.8810 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [20/119], Loss: 0.2964, Time: 464.2263 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [25/119], Loss: 0.3113, Time: 464.5812 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [30/119], Loss: 0.2889, Time: 464.9413 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [35/119], Loss: 0.3301, Time: 465.2863 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [40/119], Loss: 0.2967, Time: 465.6541 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [45/119], Loss: 0.3335, Time: 466.0158 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [50/119], Loss: 0.3538, Time: 466.3609 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [55/119], Loss: 0.3608, Time: 466.7211 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [60/119], Loss: 0.3090, Time: 467.0816 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [65/119], Loss: 0.3009, Time: 467.4262 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [70/119], Loss: 0.3356, Time: 467.8020 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [75/119], Loss: 0.3355, Time: 468.1676 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [80/119], Loss: 0.3143, Time: 468.5125 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [85/119], Loss: 0.3135, Time: 468.8718 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [90/119], Loss: 0.3558, Time: 469.2219 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [95/119], Loss: 0.3190, Time: 469.5796 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [100/119], Loss: 0.3189, Time: 469.9530 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [105/119], Loss: 0.3074, Time: 470.2931 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [110/119], Loss: 0.3348, Time: 470.6596 secs, learning rate: 0.0010\n",
      "Epoch [16/20], Step [115/119], Loss: 0.3116, Time: 471.0200 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [5/119], Loss: 0.3295, Time: 473.1213 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [10/119], Loss: 0.2813, Time: 473.4651 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [15/119], Loss: 0.3362, Time: 473.8211 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [20/119], Loss: 0.3082, Time: 474.2076 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [25/119], Loss: 0.3102, Time: 474.5520 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [30/119], Loss: 0.3487, Time: 474.9042 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [35/119], Loss: 0.3451, Time: 475.2545 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [40/119], Loss: 0.3123, Time: 475.6208 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [45/119], Loss: 0.2932, Time: 475.9816 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [50/119], Loss: 0.3244, Time: 476.3262 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [55/119], Loss: 0.3189, Time: 476.6762 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [60/119], Loss: 0.3421, Time: 477.0206 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [65/119], Loss: 0.2783, Time: 477.3808 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [70/119], Loss: 0.3187, Time: 477.7412 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [75/119], Loss: 0.3392, Time: 478.0859 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [80/119], Loss: 0.2916, Time: 478.4386 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [85/119], Loss: 0.3123, Time: 478.7993 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [90/119], Loss: 0.2959, Time: 479.1659 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [95/119], Loss: 0.3458, Time: 479.5203 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [100/119], Loss: 0.3437, Time: 479.8960 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [105/119], Loss: 0.3008, Time: 480.2411 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [110/119], Loss: 0.2962, Time: 480.5856 secs, learning rate: 0.0010\n",
      "Epoch [17/20], Step [115/119], Loss: 0.3348, Time: 480.9391 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [5/119], Loss: 0.3246, Time: 483.0609 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [10/119], Loss: 0.3224, Time: 483.4047 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [15/119], Loss: 0.3090, Time: 483.7491 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [20/119], Loss: 0.3210, Time: 484.1092 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [25/119], Loss: 0.3139, Time: 484.4625 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [30/119], Loss: 0.3028, Time: 484.8159 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [35/119], Loss: 0.3776, Time: 485.1611 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [40/119], Loss: 0.3494, Time: 485.5056 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [45/119], Loss: 0.3192, Time: 485.8658 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [50/119], Loss: 0.3217, Time: 486.2110 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [55/119], Loss: 0.2931, Time: 486.5764 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [60/119], Loss: 0.3309, Time: 486.9377 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [65/119], Loss: 0.2943, Time: 487.2980 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [70/119], Loss: 0.3203, Time: 487.6427 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [75/119], Loss: 0.3686, Time: 488.0031 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [80/119], Loss: 0.3768, Time: 488.3562 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [85/119], Loss: 0.3299, Time: 488.7169 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [90/119], Loss: 0.4152, Time: 489.0677 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [95/119], Loss: 0.3601, Time: 489.4357 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [100/119], Loss: 0.3194, Time: 489.7809 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [105/119], Loss: 0.3001, Time: 490.1342 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [110/119], Loss: 0.3702, Time: 490.4969 secs, learning rate: 0.0010\n",
      "Epoch [18/20], Step [115/119], Loss: 0.3428, Time: 490.8421 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [5/119], Loss: 0.3048, Time: 492.9131 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [10/119], Loss: 0.3478, Time: 493.2724 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [15/119], Loss: 0.3129, Time: 493.6252 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [20/119], Loss: 0.3580, Time: 493.9762 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [25/119], Loss: 0.3449, Time: 494.3206 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [30/119], Loss: 0.3274, Time: 494.6807 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [35/119], Loss: 0.3327, Time: 495.0327 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [40/119], Loss: 0.3058, Time: 495.3771 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [45/119], Loss: 0.2953, Time: 495.7371 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [50/119], Loss: 0.3459, Time: 496.0991 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [55/119], Loss: 0.3075, Time: 496.4596 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [60/119], Loss: 0.2962, Time: 496.8040 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [65/119], Loss: 0.3094, Time: 497.1641 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [70/119], Loss: 0.2671, Time: 497.5086 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [75/119], Loss: 0.2965, Time: 497.8687 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [80/119], Loss: 0.2882, Time: 498.2288 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [85/119], Loss: 0.3064, Time: 498.5955 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [90/119], Loss: 0.3009, Time: 498.9406 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [95/119], Loss: 0.3357, Time: 499.3008 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [100/119], Loss: 0.2807, Time: 499.6517 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [105/119], Loss: 0.3234, Time: 500.0120 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [110/119], Loss: 0.3836, Time: 500.3571 secs, learning rate: 0.0010\n",
      "Epoch [19/20], Step [115/119], Loss: 0.3316, Time: 500.7264 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [5/119], Loss: 0.2929, Time: 502.8105 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [10/119], Loss: 0.3113, Time: 503.1613 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [15/119], Loss: 0.3055, Time: 503.5214 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [20/119], Loss: 0.3242, Time: 503.8730 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [25/119], Loss: 0.2867, Time: 504.2237 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [30/119], Loss: 0.3392, Time: 504.5681 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [35/119], Loss: 0.3329, Time: 504.9208 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [40/119], Loss: 0.3061, Time: 505.2809 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [45/119], Loss: 0.2957, Time: 505.6262 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [50/119], Loss: 0.3260, Time: 505.9863 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [55/119], Loss: 0.2862, Time: 506.3398 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [60/119], Loss: 0.2806, Time: 506.7004 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [65/119], Loss: 0.2782, Time: 507.0400 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [70/119], Loss: 0.3081, Time: 507.4136 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [75/119], Loss: 0.2881, Time: 507.7743 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [80/119], Loss: 0.3307, Time: 508.1346 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [85/119], Loss: 0.3342, Time: 508.4947 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [90/119], Loss: 0.3079, Time: 508.8423 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [95/119], Loss: 0.2960, Time: 509.2025 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [100/119], Loss: 0.3011, Time: 509.5538 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [105/119], Loss: 0.2783, Time: 509.9139 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [110/119], Loss: 0.2854, Time: 510.2646 secs, learning rate: 0.0010\n",
      "Epoch [20/20], Step [115/119], Loss: 0.3093, Time: 510.6092 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [5/119], Loss: 143.8284, Time: 514.1335 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [10/119], Loss: 226.7895, Time: 514.5085 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [15/119], Loss: 89.3852, Time: 514.8841 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [20/119], Loss: 25.8970, Time: 515.2669 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [25/119], Loss: 41.4196, Time: 515.6363 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [30/119], Loss: 39.9673, Time: 516.0201 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [35/119], Loss: 16.4111, Time: 516.3963 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [40/119], Loss: 26.7435, Time: 516.7493 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [45/119], Loss: 23.0472, Time: 517.1413 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [50/119], Loss: 16.9910, Time: 517.5013 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [55/119], Loss: 22.3120, Time: 517.8775 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [60/119], Loss: 16.4373, Time: 518.2531 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [65/119], Loss: 11.8947, Time: 518.6444 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [70/119], Loss: 23.4604, Time: 519.0131 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [75/119], Loss: 14.0652, Time: 519.4576 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [80/119], Loss: 9.8500, Time: 520.0701 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [85/119], Loss: 12.4945, Time: 520.5292 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [90/119], Loss: 14.4327, Time: 520.9049 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [95/119], Loss: 13.1955, Time: 521.2713 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [100/119], Loss: 10.6460, Time: 521.6558 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [105/119], Loss: 8.0598, Time: 522.0305 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [110/119], Loss: 5.7050, Time: 522.3974 secs, learning rate: 0.0010\n",
      "Epoch [1/25], Step [115/119], Loss: 7.0385, Time: 522.7797 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [5/119], Loss: 3.1085, Time: 524.8965 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [10/119], Loss: 2.2229, Time: 525.2558 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [15/119], Loss: 8.3922, Time: 525.6325 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [20/119], Loss: 5.2972, Time: 526.0160 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [25/119], Loss: 3.2117, Time: 526.3768 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [30/119], Loss: 4.2343, Time: 526.7602 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [35/119], Loss: 6.2278, Time: 527.1352 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [40/119], Loss: 6.3888, Time: 527.5007 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [45/119], Loss: 3.5806, Time: 527.9078 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [50/119], Loss: 5.1886, Time: 528.2748 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [55/119], Loss: 3.8381, Time: 528.6506 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [60/119], Loss: 4.1613, Time: 529.0263 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [65/119], Loss: 2.8447, Time: 529.4086 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [70/119], Loss: 4.3500, Time: 529.7759 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [75/119], Loss: 3.5076, Time: 530.1360 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [80/119], Loss: 4.2715, Time: 530.5185 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [85/119], Loss: 3.8390, Time: 530.8970 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [90/119], Loss: 4.8763, Time: 531.2781 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [95/119], Loss: 3.0346, Time: 531.6383 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [100/119], Loss: 2.9601, Time: 532.0214 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [105/119], Loss: 3.5912, Time: 532.3831 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [110/119], Loss: 3.6979, Time: 532.7593 secs, learning rate: 0.0010\n",
      "Epoch [2/25], Step [115/119], Loss: 3.1251, Time: 533.1244 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [5/119], Loss: 3.2091, Time: 535.2495 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [10/119], Loss: 4.3043, Time: 535.6245 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [15/119], Loss: 3.6644, Time: 535.9891 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [20/119], Loss: 2.6503, Time: 536.3651 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [25/119], Loss: 3.7836, Time: 536.7191 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [30/119], Loss: 2.0114, Time: 537.1019 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [35/119], Loss: 2.3261, Time: 537.4680 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [40/119], Loss: 2.7823, Time: 537.8439 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [45/119], Loss: 2.3536, Time: 538.2197 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [50/119], Loss: 3.0522, Time: 538.5865 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [55/119], Loss: 2.2474, Time: 538.9625 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [60/119], Loss: 2.9496, Time: 539.3226 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [65/119], Loss: 2.5181, Time: 539.6910 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [70/119], Loss: 2.7915, Time: 540.0673 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [75/119], Loss: 2.7592, Time: 540.4430 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [80/119], Loss: 2.8025, Time: 540.7964 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [85/119], Loss: 2.4394, Time: 541.1887 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [90/119], Loss: 3.3291, Time: 541.5487 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [95/119], Loss: 2.4015, Time: 541.9247 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [100/119], Loss: 2.3195, Time: 542.2960 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [105/119], Loss: 2.2891, Time: 542.7034 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [110/119], Loss: 2.3289, Time: 543.1330 secs, learning rate: 0.0010\n",
      "Epoch [3/25], Step [115/119], Loss: 2.6560, Time: 543.5088 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [5/119], Loss: 2.1738, Time: 545.6194 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [10/119], Loss: 2.2446, Time: 545.9787 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [15/119], Loss: 2.0442, Time: 546.3544 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [20/119], Loss: 2.3082, Time: 546.7303 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [25/119], Loss: 1.6959, Time: 547.1176 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [30/119], Loss: 2.1321, Time: 547.4777 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [35/119], Loss: 1.5007, Time: 547.8533 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [40/119], Loss: 2.2766, Time: 548.2362 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [45/119], Loss: 2.0387, Time: 548.6034 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [50/119], Loss: 2.2027, Time: 548.9792 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [55/119], Loss: 1.3545, Time: 549.3393 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [60/119], Loss: 2.0074, Time: 549.7315 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [65/119], Loss: 1.1378, Time: 550.0915 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [70/119], Loss: 2.1025, Time: 550.4674 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [75/119], Loss: 1.4237, Time: 550.8340 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [80/119], Loss: 1.9195, Time: 551.2099 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [85/119], Loss: 1.3919, Time: 551.5700 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [90/119], Loss: 1.3708, Time: 551.9614 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [95/119], Loss: 1.5079, Time: 552.3215 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [100/119], Loss: 1.0674, Time: 552.7040 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [105/119], Loss: 1.3918, Time: 553.0641 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [110/119], Loss: 1.7200, Time: 553.4472 secs, learning rate: 0.0010\n",
      "Epoch [4/25], Step [115/119], Loss: 1.4090, Time: 553.8235 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [5/119], Loss: 1.6129, Time: 555.9345 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [10/119], Loss: 1.7622, Time: 556.3017 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [15/119], Loss: 1.3691, Time: 556.6774 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [20/119], Loss: 1.7720, Time: 557.0609 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [25/119], Loss: 1.0381, Time: 557.4335 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [30/119], Loss: 0.9209, Time: 557.8095 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [35/119], Loss: 0.9386, Time: 558.1696 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [40/119], Loss: 0.7549, Time: 558.5385 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [45/119], Loss: 1.4578, Time: 558.9049 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [50/119], Loss: 1.0188, Time: 559.2962 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [55/119], Loss: 1.4410, Time: 559.6660 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [60/119], Loss: 1.2205, Time: 560.0410 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [65/119], Loss: 1.4486, Time: 560.4168 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [70/119], Loss: 1.0688, Time: 560.7768 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [75/119], Loss: 1.3449, Time: 561.1751 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [80/119], Loss: 1.1997, Time: 561.5424 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [85/119], Loss: 1.2263, Time: 561.9279 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [90/119], Loss: 1.1894, Time: 562.2977 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [95/119], Loss: 1.1872, Time: 562.6735 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [100/119], Loss: 0.9836, Time: 563.0546 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [105/119], Loss: 1.3169, Time: 563.4207 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [110/119], Loss: 0.9280, Time: 563.8119 secs, learning rate: 0.0010\n",
      "Epoch [5/25], Step [115/119], Loss: 1.1668, Time: 564.1720 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [5/119], Loss: 1.1269, Time: 566.5673 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [10/119], Loss: 1.2218, Time: 566.9735 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [15/119], Loss: 0.8281, Time: 567.3493 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [20/119], Loss: 1.2203, Time: 567.9515 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [25/119], Loss: 0.7053, Time: 568.4059 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [30/119], Loss: 0.8926, Time: 568.8886 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [35/119], Loss: 0.7697, Time: 569.6341 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [40/119], Loss: 1.2544, Time: 570.1264 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [45/119], Loss: 1.1174, Time: 570.5190 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [50/119], Loss: 0.8061, Time: 570.9890 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [55/119], Loss: 0.6255, Time: 571.3858 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [60/119], Loss: 1.3092, Time: 571.7871 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [65/119], Loss: 1.2213, Time: 572.2150 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [70/119], Loss: 1.6308, Time: 572.8555 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [75/119], Loss: 0.6073, Time: 573.5095 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [80/119], Loss: 0.9396, Time: 574.0108 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [85/119], Loss: 0.7353, Time: 574.6345 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [90/119], Loss: 0.5667, Time: 575.2625 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [95/119], Loss: 0.7532, Time: 575.8586 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [100/119], Loss: 0.7421, Time: 576.4498 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [105/119], Loss: 0.6183, Time: 577.0095 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [110/119], Loss: 0.6135, Time: 577.6604 secs, learning rate: 0.0010\n",
      "Epoch [6/25], Step [115/119], Loss: 0.4679, Time: 578.3692 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [5/119], Loss: 0.6653, Time: 581.2909 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [10/119], Loss: 0.4439, Time: 581.8958 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [15/119], Loss: 0.6957, Time: 582.3432 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [20/119], Loss: 0.4713, Time: 582.8012 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [25/119], Loss: 0.4431, Time: 583.2167 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [30/119], Loss: 0.5103, Time: 583.7426 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [35/119], Loss: 0.5502, Time: 584.3461 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [40/119], Loss: 0.4192, Time: 584.9043 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [45/119], Loss: 0.4665, Time: 585.5912 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [50/119], Loss: 0.4270, Time: 586.5448 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [55/119], Loss: 0.5917, Time: 587.4804 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [60/119], Loss: 0.3729, Time: 588.0948 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [65/119], Loss: 0.4444, Time: 588.7095 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [70/119], Loss: 0.3752, Time: 589.1495 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [75/119], Loss: 0.4061, Time: 589.7182 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [80/119], Loss: 0.4748, Time: 590.0929 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [85/119], Loss: 0.4697, Time: 590.4538 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [90/119], Loss: 0.4777, Time: 590.8230 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [95/119], Loss: 0.4624, Time: 591.1836 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [100/119], Loss: 0.4069, Time: 591.5579 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [105/119], Loss: 0.3655, Time: 591.9350 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [110/119], Loss: 0.3960, Time: 592.3051 secs, learning rate: 0.0010\n",
      "Epoch [7/25], Step [115/119], Loss: 0.3800, Time: 592.6733 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [5/119], Loss: 0.4429, Time: 594.8052 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [10/119], Loss: 0.4530, Time: 595.1672 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [15/119], Loss: 0.3733, Time: 595.5369 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [20/119], Loss: 0.3844, Time: 595.9119 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [25/119], Loss: 0.5315, Time: 596.2804 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [30/119], Loss: 0.4024, Time: 596.6516 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [35/119], Loss: 0.3769, Time: 597.0128 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [40/119], Loss: 0.4132, Time: 597.3859 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [45/119], Loss: 0.3610, Time: 597.7585 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [50/119], Loss: 0.6416, Time: 598.1284 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [55/119], Loss: 0.5899, Time: 598.4975 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [60/119], Loss: 0.4085, Time: 598.8630 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [65/119], Loss: 0.5339, Time: 599.2281 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [70/119], Loss: 0.3951, Time: 599.6098 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [75/119], Loss: 0.3765, Time: 599.9700 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [80/119], Loss: 0.4471, Time: 600.3423 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [85/119], Loss: 0.4461, Time: 600.7251 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [90/119], Loss: 0.4298, Time: 601.1075 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [95/119], Loss: 0.3791, Time: 601.4731 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [100/119], Loss: 0.7972, Time: 601.8413 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [105/119], Loss: 0.5129, Time: 602.2071 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [110/119], Loss: 0.4579, Time: 602.5695 secs, learning rate: 0.0010\n",
      "Epoch [8/25], Step [115/119], Loss: 0.3539, Time: 602.9590 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [5/119], Loss: 0.4219, Time: 605.1052 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [10/119], Loss: 0.6160, Time: 605.5051 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [15/119], Loss: 0.4977, Time: 605.9871 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [20/119], Loss: 0.4608, Time: 606.4171 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [25/119], Loss: 0.5107, Time: 606.8118 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [30/119], Loss: 0.3811, Time: 607.2396 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [35/119], Loss: 0.4273, Time: 607.6113 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [40/119], Loss: 0.5958, Time: 607.9819 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [45/119], Loss: 0.3716, Time: 608.3479 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [50/119], Loss: 0.4281, Time: 608.7156 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [55/119], Loss: 0.3617, Time: 609.0789 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [60/119], Loss: 0.4303, Time: 609.4493 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [65/119], Loss: 0.4379, Time: 609.8233 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [70/119], Loss: 0.3743, Time: 610.1855 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [75/119], Loss: 0.4169, Time: 610.5555 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [80/119], Loss: 0.4135, Time: 610.9927 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [85/119], Loss: 0.3587, Time: 611.3615 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [90/119], Loss: 0.3564, Time: 611.7257 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [95/119], Loss: 0.4704, Time: 612.1003 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [100/119], Loss: 0.3489, Time: 612.4618 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [105/119], Loss: 0.5460, Time: 612.9044 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [110/119], Loss: 0.4695, Time: 613.4804 secs, learning rate: 0.0010\n",
      "Epoch [9/25], Step [115/119], Loss: 0.6051, Time: 613.9312 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [5/119], Loss: 0.3614, Time: 616.0455 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [10/119], Loss: 0.4369, Time: 616.4078 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [15/119], Loss: 0.3313, Time: 616.7746 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [20/119], Loss: 0.3616, Time: 617.1432 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [25/119], Loss: 0.4680, Time: 617.5022 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [30/119], Loss: 0.5072, Time: 617.8802 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [35/119], Loss: 0.3395, Time: 618.2436 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [40/119], Loss: 0.4301, Time: 618.6081 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [45/119], Loss: 0.3456, Time: 618.9747 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [50/119], Loss: 0.5511, Time: 619.3386 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [55/119], Loss: 0.3724, Time: 619.7035 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [60/119], Loss: 0.4192, Time: 620.0688 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [65/119], Loss: 0.4653, Time: 620.4364 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [70/119], Loss: 0.5307, Time: 620.8020 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [75/119], Loss: 0.5490, Time: 621.1721 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [80/119], Loss: 0.3275, Time: 621.5466 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [85/119], Loss: 0.3425, Time: 621.9134 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [90/119], Loss: 0.6101, Time: 622.2773 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [95/119], Loss: 0.4393, Time: 622.6415 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [100/119], Loss: 0.3825, Time: 623.0087 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [105/119], Loss: 0.3854, Time: 623.3720 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [110/119], Loss: 0.3699, Time: 623.7362 secs, learning rate: 0.0010\n",
      "Epoch [10/25], Step [115/119], Loss: 0.3838, Time: 624.1053 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [5/119], Loss: 0.3926, Time: 626.2251 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [10/119], Loss: 0.3678, Time: 626.5862 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [15/119], Loss: 0.3932, Time: 626.9546 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [20/119], Loss: 0.4759, Time: 627.3146 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [25/119], Loss: 0.4234, Time: 627.6838 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [30/119], Loss: 0.4652, Time: 628.0469 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [35/119], Loss: 0.3286, Time: 628.4216 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [40/119], Loss: 0.4348, Time: 628.7877 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [45/119], Loss: 0.3612, Time: 629.1620 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [50/119], Loss: 0.3972, Time: 629.5283 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [55/119], Loss: 0.3099, Time: 629.8996 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [60/119], Loss: 0.3612, Time: 630.2688 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [65/119], Loss: 0.2966, Time: 630.6300 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [70/119], Loss: 0.3566, Time: 631.0068 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [75/119], Loss: 0.3788, Time: 631.3796 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [80/119], Loss: 0.3290, Time: 631.7631 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [85/119], Loss: 0.3101, Time: 632.1228 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [90/119], Loss: 0.3380, Time: 632.4965 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [95/119], Loss: 0.4714, Time: 632.8610 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [100/119], Loss: 0.3314, Time: 633.2279 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [105/119], Loss: 0.3048, Time: 633.6092 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [110/119], Loss: 0.3326, Time: 633.9727 secs, learning rate: 0.0010\n",
      "Epoch [11/25], Step [115/119], Loss: 0.3307, Time: 634.3573 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [5/119], Loss: 0.4427, Time: 636.5220 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [10/119], Loss: 0.3451, Time: 636.9634 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [15/119], Loss: 0.3786, Time: 637.3642 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [20/119], Loss: 0.6160, Time: 637.7381 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [25/119], Loss: 0.3684, Time: 638.1099 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [30/119], Loss: 0.3936, Time: 638.4969 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [35/119], Loss: 0.3409, Time: 638.8819 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [40/119], Loss: 0.4143, Time: 639.2514 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [45/119], Loss: 0.3185, Time: 639.6236 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [50/119], Loss: 0.4142, Time: 639.9939 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [55/119], Loss: 0.9490, Time: 640.3602 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [60/119], Loss: 0.5958, Time: 640.7275 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [65/119], Loss: 0.6646, Time: 641.0973 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [70/119], Loss: 0.6022, Time: 641.4588 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [75/119], Loss: 0.3693, Time: 641.8290 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [80/119], Loss: 0.3766, Time: 642.1991 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [85/119], Loss: 0.3182, Time: 642.5604 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [90/119], Loss: 0.4391, Time: 642.9325 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [95/119], Loss: 0.4020, Time: 643.3012 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [100/119], Loss: 0.5456, Time: 643.6811 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [105/119], Loss: 0.3362, Time: 644.0547 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [110/119], Loss: 0.5273, Time: 644.4163 secs, learning rate: 0.0010\n",
      "Epoch [12/25], Step [115/119], Loss: 0.7799, Time: 644.7923 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [5/119], Loss: 0.5009, Time: 646.9260 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [10/119], Loss: 0.4588, Time: 647.2943 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [15/119], Loss: 0.4905, Time: 647.6704 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [20/119], Loss: 0.4701, Time: 648.0381 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [25/119], Loss: 0.5146, Time: 648.4496 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [30/119], Loss: 0.4813, Time: 648.8138 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [35/119], Loss: 0.4657, Time: 649.1844 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [40/119], Loss: 0.4388, Time: 649.5564 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [45/119], Loss: 0.3662, Time: 649.9311 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [50/119], Loss: 0.3605, Time: 650.2993 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [55/119], Loss: 0.3672, Time: 650.6633 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [60/119], Loss: 0.3735, Time: 651.0345 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [65/119], Loss: 0.3218, Time: 651.4106 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [70/119], Loss: 0.3336, Time: 651.7891 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [75/119], Loss: 0.3500, Time: 652.1610 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [80/119], Loss: 0.3524, Time: 652.5368 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [85/119], Loss: 0.3237, Time: 652.9348 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [90/119], Loss: 0.3281, Time: 653.3427 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [95/119], Loss: 0.3605, Time: 653.7170 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [100/119], Loss: 0.3535, Time: 654.0830 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [105/119], Loss: 0.3646, Time: 654.4500 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [110/119], Loss: 0.3598, Time: 654.8213 secs, learning rate: 0.0010\n",
      "Epoch [13/25], Step [115/119], Loss: 0.3457, Time: 655.2126 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [5/119], Loss: 0.3245, Time: 657.3687 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [10/119], Loss: 0.3970, Time: 657.7347 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [15/119], Loss: 0.3939, Time: 658.1064 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [20/119], Loss: 0.3442, Time: 658.4792 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [25/119], Loss: 0.3822, Time: 658.8433 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [30/119], Loss: 0.3559, Time: 659.2054 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [35/119], Loss: 0.3267, Time: 659.5891 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [40/119], Loss: 0.3490, Time: 659.9662 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [45/119], Loss: 0.3329, Time: 660.3322 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [50/119], Loss: 0.3501, Time: 660.6893 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [55/119], Loss: 0.3057, Time: 661.0529 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [60/119], Loss: 0.3372, Time: 661.4152 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [65/119], Loss: 0.3266, Time: 661.7907 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [70/119], Loss: 0.3044, Time: 662.1618 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [75/119], Loss: 0.3128, Time: 662.5210 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [80/119], Loss: 0.3241, Time: 662.8845 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [85/119], Loss: 0.3131, Time: 663.2534 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [90/119], Loss: 0.3183, Time: 663.6318 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [95/119], Loss: 0.3242, Time: 663.9992 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [100/119], Loss: 0.3236, Time: 664.3716 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [105/119], Loss: 0.3184, Time: 664.7340 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [110/119], Loss: 0.3416, Time: 665.0985 secs, learning rate: 0.0010\n",
      "Epoch [14/25], Step [115/119], Loss: 0.2952, Time: 665.4684 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [5/119], Loss: 0.3017, Time: 667.5784 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [10/119], Loss: 0.3177, Time: 667.9513 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [15/119], Loss: 0.3052, Time: 668.3155 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [20/119], Loss: 0.2968, Time: 668.6896 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [25/119], Loss: 0.3113, Time: 669.0511 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [30/119], Loss: 0.3112, Time: 669.4123 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [35/119], Loss: 0.2648, Time: 669.7728 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [40/119], Loss: 0.2941, Time: 670.1355 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [45/119], Loss: 0.3163, Time: 670.4996 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [50/119], Loss: 0.3301, Time: 670.8635 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [55/119], Loss: 0.4110, Time: 671.2337 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [60/119], Loss: 0.3025, Time: 671.5968 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [65/119], Loss: 0.2966, Time: 671.9678 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [70/119], Loss: 0.3149, Time: 672.3405 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [75/119], Loss: 0.3129, Time: 672.7207 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [80/119], Loss: 0.3433, Time: 673.0845 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [85/119], Loss: 0.3154, Time: 673.4517 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [90/119], Loss: 0.3243, Time: 673.8790 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [95/119], Loss: 0.3235, Time: 674.2665 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [100/119], Loss: 0.2820, Time: 674.6307 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [105/119], Loss: 0.3205, Time: 674.9972 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [110/119], Loss: 0.3161, Time: 675.3622 secs, learning rate: 0.0010\n",
      "Epoch [15/25], Step [115/119], Loss: 0.3247, Time: 675.7255 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [5/119], Loss: 0.3161, Time: 677.8590 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [10/119], Loss: 0.2839, Time: 678.2236 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [15/119], Loss: 0.3008, Time: 678.5893 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [20/119], Loss: 0.2718, Time: 678.9553 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [25/119], Loss: 0.2695, Time: 679.3268 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [30/119], Loss: 0.2987, Time: 679.6954 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [35/119], Loss: 0.3010, Time: 680.0680 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [40/119], Loss: 0.3116, Time: 680.4286 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [45/119], Loss: 0.3553, Time: 680.7996 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [50/119], Loss: 0.3490, Time: 681.1661 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [55/119], Loss: 0.2856, Time: 681.5462 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [60/119], Loss: 0.3574, Time: 681.9116 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [65/119], Loss: 0.4289, Time: 682.2736 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [70/119], Loss: 0.4197, Time: 682.6341 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [75/119], Loss: 0.3457, Time: 683.0058 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [80/119], Loss: 0.2938, Time: 683.3837 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [85/119], Loss: 0.3271, Time: 683.7511 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [90/119], Loss: 0.2968, Time: 684.1659 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [95/119], Loss: 0.3045, Time: 684.5955 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [100/119], Loss: 0.3105, Time: 684.9853 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [105/119], Loss: 0.2801, Time: 685.3552 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [110/119], Loss: 0.2946, Time: 685.7229 secs, learning rate: 0.0010\n",
      "Epoch [16/25], Step [115/119], Loss: 0.2848, Time: 686.0892 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [5/119], Loss: 0.2903, Time: 688.1993 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [10/119], Loss: 0.2807, Time: 688.5628 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [15/119], Loss: 0.2839, Time: 688.9345 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [20/119], Loss: 0.2593, Time: 689.3064 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [25/119], Loss: 0.2904, Time: 689.6657 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [30/119], Loss: 0.2908, Time: 690.0395 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [35/119], Loss: 0.2808, Time: 690.4556 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [40/119], Loss: 0.2749, Time: 691.0092 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [45/119], Loss: 0.2783, Time: 691.5526 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [50/119], Loss: 0.2830, Time: 691.9407 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [55/119], Loss: 0.2891, Time: 692.3014 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [60/119], Loss: 0.2904, Time: 692.6670 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [65/119], Loss: 0.2675, Time: 693.0304 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [70/119], Loss: 0.2724, Time: 693.3978 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [75/119], Loss: 0.3149, Time: 693.7679 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [80/119], Loss: 0.2804, Time: 694.1427 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [85/119], Loss: 0.2664, Time: 694.5138 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [90/119], Loss: 0.2887, Time: 694.8955 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [95/119], Loss: 0.2685, Time: 695.2630 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [100/119], Loss: 0.2971, Time: 695.6365 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [105/119], Loss: 0.2878, Time: 696.0410 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [110/119], Loss: 0.3001, Time: 696.4036 secs, learning rate: 0.0010\n",
      "Epoch [17/25], Step [115/119], Loss: 0.3242, Time: 696.7759 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [5/119], Loss: 0.2627, Time: 698.8963 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [10/119], Loss: 0.2906, Time: 699.2565 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [15/119], Loss: 0.2752, Time: 699.6250 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [20/119], Loss: 0.2960, Time: 699.9871 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [25/119], Loss: 0.2829, Time: 700.3493 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [30/119], Loss: 0.2477, Time: 700.7198 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [35/119], Loss: 0.2882, Time: 701.0799 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [40/119], Loss: 0.3089, Time: 701.4413 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [45/119], Loss: 0.2808, Time: 701.8171 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [50/119], Loss: 0.3205, Time: 702.1907 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [55/119], Loss: 0.2867, Time: 702.5548 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [60/119], Loss: 0.2925, Time: 702.9202 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [65/119], Loss: 0.2882, Time: 703.2831 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [70/119], Loss: 0.2902, Time: 703.6503 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [75/119], Loss: 0.3312, Time: 704.0235 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [80/119], Loss: 0.2863, Time: 704.4053 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [85/119], Loss: 0.3246, Time: 704.7697 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [90/119], Loss: 0.3176, Time: 705.1393 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [95/119], Loss: 0.2887, Time: 705.5091 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [100/119], Loss: 0.3051, Time: 705.8791 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [105/119], Loss: 0.3354, Time: 706.2481 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [110/119], Loss: 0.2731, Time: 706.6168 secs, learning rate: 0.0010\n",
      "Epoch [18/25], Step [115/119], Loss: 0.2932, Time: 706.9879 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [5/119], Loss: 0.2693, Time: 709.1034 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [10/119], Loss: 0.2758, Time: 709.4646 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [15/119], Loss: 0.2977, Time: 709.8346 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [20/119], Loss: 0.2745, Time: 710.2624 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [25/119], Loss: 0.2919, Time: 710.6462 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [30/119], Loss: 0.2637, Time: 711.0154 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [35/119], Loss: 0.2757, Time: 711.3794 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [40/119], Loss: 0.2995, Time: 711.7543 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [45/119], Loss: 0.2847, Time: 712.1254 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [50/119], Loss: 0.2642, Time: 712.4876 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [55/119], Loss: 0.2754, Time: 712.8591 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [60/119], Loss: 0.2796, Time: 713.2294 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [65/119], Loss: 0.2928, Time: 713.6349 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [70/119], Loss: 0.2738, Time: 714.1207 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [75/119], Loss: 0.2637, Time: 714.5151 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [80/119], Loss: 0.2852, Time: 714.9078 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [85/119], Loss: 0.2700, Time: 715.3041 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [90/119], Loss: 0.2889, Time: 715.6732 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [95/119], Loss: 0.2941, Time: 716.0488 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [100/119], Loss: 0.3032, Time: 716.4091 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [105/119], Loss: 0.2769, Time: 716.7807 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [110/119], Loss: 0.2644, Time: 717.1427 secs, learning rate: 0.0010\n",
      "Epoch [19/25], Step [115/119], Loss: 0.2862, Time: 717.5174 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [5/119], Loss: 0.2689, Time: 719.6476 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [10/119], Loss: 0.2783, Time: 720.0113 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [15/119], Loss: 0.2843, Time: 720.3763 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [20/119], Loss: 0.2740, Time: 720.7397 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [25/119], Loss: 0.2773, Time: 721.0996 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [30/119], Loss: 0.3086, Time: 721.4711 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [35/119], Loss: 0.2513, Time: 721.8462 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [40/119], Loss: 0.3228, Time: 722.2349 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [45/119], Loss: 0.3016, Time: 722.6058 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [50/119], Loss: 0.3415, Time: 722.9771 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [55/119], Loss: 0.2865, Time: 723.3440 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [60/119], Loss: 0.2724, Time: 723.7088 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [65/119], Loss: 0.2736, Time: 724.0778 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [70/119], Loss: 0.2655, Time: 724.4391 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [75/119], Loss: 0.2491, Time: 724.8225 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [80/119], Loss: 0.2588, Time: 725.1907 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [85/119], Loss: 0.2432, Time: 725.5527 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [90/119], Loss: 0.2644, Time: 725.9176 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [95/119], Loss: 0.2652, Time: 726.2872 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [100/119], Loss: 0.2511, Time: 726.6510 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [105/119], Loss: 0.2690, Time: 727.0086 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [110/119], Loss: 0.2661, Time: 727.3866 secs, learning rate: 0.0010\n",
      "Epoch [20/25], Step [115/119], Loss: 0.2748, Time: 727.7579 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [5/119], Loss: 0.2643, Time: 729.8836 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [10/119], Loss: 0.2756, Time: 730.2443 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [15/119], Loss: 0.2753, Time: 730.6101 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [20/119], Loss: 0.2932, Time: 730.9797 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [25/119], Loss: 0.2956, Time: 731.3544 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [30/119], Loss: 0.2718, Time: 731.7249 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [35/119], Loss: 0.2902, Time: 732.0909 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [40/119], Loss: 0.2721, Time: 732.4613 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [45/119], Loss: 0.2630, Time: 732.8290 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [50/119], Loss: 0.2560, Time: 733.2014 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [55/119], Loss: 0.2433, Time: 733.5720 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [60/119], Loss: 0.2720, Time: 733.9407 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [65/119], Loss: 0.2727, Time: 734.3003 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [70/119], Loss: 0.2780, Time: 734.6607 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [75/119], Loss: 0.2883, Time: 735.0244 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [80/119], Loss: 0.2917, Time: 735.3846 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [85/119], Loss: 0.2708, Time: 735.7570 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [90/119], Loss: 0.2648, Time: 736.1213 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [95/119], Loss: 0.2766, Time: 736.4805 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [100/119], Loss: 0.2690, Time: 736.8548 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [105/119], Loss: 0.2463, Time: 737.2160 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [110/119], Loss: 0.2665, Time: 737.5785 secs, learning rate: 0.0010\n",
      "Epoch [21/25], Step [115/119], Loss: 0.2863, Time: 737.9453 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [5/119], Loss: 0.2752, Time: 740.0666 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [10/119], Loss: 0.2668, Time: 740.4267 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [15/119], Loss: 0.2817, Time: 740.7872 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [20/119], Loss: 0.2592, Time: 741.1501 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [25/119], Loss: 0.2721, Time: 741.5154 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [30/119], Loss: 0.2692, Time: 741.8794 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [35/119], Loss: 0.2745, Time: 742.2590 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [40/119], Loss: 0.2674, Time: 742.6268 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [45/119], Loss: 0.2626, Time: 743.0022 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [50/119], Loss: 0.2949, Time: 743.3721 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [55/119], Loss: 0.2672, Time: 743.7479 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [60/119], Loss: 0.2761, Time: 744.1163 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [65/119], Loss: 0.2619, Time: 744.4767 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [70/119], Loss: 0.2595, Time: 744.8490 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [75/119], Loss: 0.2598, Time: 745.2190 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [80/119], Loss: 0.3014, Time: 745.5792 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [85/119], Loss: 0.2814, Time: 745.9480 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [90/119], Loss: 0.2464, Time: 746.3195 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [95/119], Loss: 0.2783, Time: 746.6801 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [100/119], Loss: 0.2572, Time: 747.0490 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [105/119], Loss: 0.2641, Time: 747.4131 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [110/119], Loss: 0.2807, Time: 747.7803 secs, learning rate: 0.0010\n",
      "Epoch [22/25], Step [115/119], Loss: 0.2676, Time: 748.1439 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [5/119], Loss: 0.2590, Time: 750.2687 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [10/119], Loss: 0.2671, Time: 750.6618 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [15/119], Loss: 0.2749, Time: 751.0799 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [20/119], Loss: 0.2615, Time: 751.4427 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [25/119], Loss: 0.2799, Time: 751.8215 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [30/119], Loss: 0.2495, Time: 752.1921 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [35/119], Loss: 0.2594, Time: 752.5635 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [40/119], Loss: 0.2710, Time: 752.9268 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [45/119], Loss: 0.2666, Time: 753.2897 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [50/119], Loss: 0.2646, Time: 753.6609 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [55/119], Loss: 0.2631, Time: 754.0396 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [60/119], Loss: 0.2666, Time: 754.4070 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [65/119], Loss: 0.2741, Time: 754.7752 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [70/119], Loss: 0.2884, Time: 755.1396 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [75/119], Loss: 0.2434, Time: 755.5127 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [80/119], Loss: 0.2819, Time: 755.9149 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [85/119], Loss: 0.2582, Time: 756.3500 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [90/119], Loss: 0.2649, Time: 756.9235 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [95/119], Loss: 0.2623, Time: 757.3846 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [100/119], Loss: 0.2689, Time: 757.7558 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [105/119], Loss: 0.2559, Time: 758.1292 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [110/119], Loss: 0.2819, Time: 758.4919 secs, learning rate: 0.0010\n",
      "Epoch [23/25], Step [115/119], Loss: 0.2780, Time: 758.8562 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [5/119], Loss: 0.2553, Time: 760.9836 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [10/119], Loss: 0.2423, Time: 761.3468 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [15/119], Loss: 0.2509, Time: 761.7073 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [20/119], Loss: 0.2754, Time: 762.0754 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [25/119], Loss: 0.2367, Time: 762.4389 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [30/119], Loss: 0.2610, Time: 762.8006 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [35/119], Loss: 0.2453, Time: 763.1671 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [40/119], Loss: 0.2520, Time: 763.5366 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [45/119], Loss: 0.2762, Time: 763.9040 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [50/119], Loss: 0.2579, Time: 764.2738 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [55/119], Loss: 0.2699, Time: 764.6541 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [60/119], Loss: 0.2687, Time: 765.0268 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [65/119], Loss: 0.2539, Time: 765.3981 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [70/119], Loss: 0.2851, Time: 765.7758 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [75/119], Loss: 0.2617, Time: 766.1471 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [80/119], Loss: 0.2683, Time: 766.5146 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [85/119], Loss: 0.2572, Time: 766.8793 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [90/119], Loss: 0.2621, Time: 767.2435 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [95/119], Loss: 0.2427, Time: 767.6096 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [100/119], Loss: 0.2631, Time: 767.9742 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [105/119], Loss: 0.2767, Time: 768.3673 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [110/119], Loss: 0.2597, Time: 768.7352 secs, learning rate: 0.0010\n",
      "Epoch [24/25], Step [115/119], Loss: 0.2612, Time: 769.1007 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [5/119], Loss: 0.2649, Time: 771.2129 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [10/119], Loss: 0.2498, Time: 771.5799 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [15/119], Loss: 0.2628, Time: 771.9438 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [20/119], Loss: 0.2760, Time: 772.3181 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [25/119], Loss: 0.2597, Time: 772.6909 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [30/119], Loss: 0.2711, Time: 773.0593 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [35/119], Loss: 0.2791, Time: 773.4247 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [40/119], Loss: 0.2663, Time: 773.8004 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [45/119], Loss: 0.2580, Time: 774.1895 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [50/119], Loss: 0.2571, Time: 774.5562 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [55/119], Loss: 0.2826, Time: 774.9347 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [60/119], Loss: 0.2404, Time: 775.2991 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [65/119], Loss: 0.2586, Time: 775.6703 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [70/119], Loss: 0.2614, Time: 776.0405 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [75/119], Loss: 0.2566, Time: 776.4083 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [80/119], Loss: 0.2386, Time: 776.7721 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [85/119], Loss: 0.2560, Time: 777.1350 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [90/119], Loss: 0.2498, Time: 777.5014 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [95/119], Loss: 0.2910, Time: 777.8617 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [100/119], Loss: 0.2805, Time: 778.2353 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [105/119], Loss: 0.2730, Time: 778.6127 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [110/119], Loss: 0.2622, Time: 778.9826 secs, learning rate: 0.0010\n",
      "Epoch [25/25], Step [115/119], Loss: 0.2625, Time: 779.3457 secs, learning rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(YTrain)\n",
    "# total_step = len(YVal)\n",
    "start_time = time.time()\n",
    "model = model.float()\n",
    "\n",
    "mean_train = []\n",
    "mean_val = []\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "for num_epochs in [5, 10, 15, 20, 25]:\n",
    "    model = state_estimat(d_in=4, num_classes=1).to(device)\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=learning_rate_drop_period, gamma=0.1)\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    loss_tmp = 0\n",
    "    norm = 1\n",
    "    for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i, :, :], YVal[i, :]\n",
    "    \n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "    \n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm * outputs, norm * y.float().reshape(1, 1))\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().reshape(1,1,1))\n",
    "        # loss1 = criterion(norm*outputs, norm*y.float().T)\n",
    "        # loss2 = torch.mean(outputs**2 - y.float().T**2)\n",
    "        # loss = loss1 + loss2\n",
    "    \n",
    "        loss_tmp += loss.item()\n",
    "    loss_val.append(loss_tmp / len(YVal))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        ind = np.arange(int(total_step / batch_size))\n",
    "        random.shuffle(ind)\n",
    "        for i, k in enumerate(ind):\n",
    "            # each i is a batch of 128 samples\n",
    "            x, y = XTrain[k * batch_size:(k + 1) * batch_size, :, :], YTrain[k * batch_size:(k + 1) * batch_size, :]\n",
    "            # x, y = XVal[k*batch_size:(k+1)*batch_size,:,:], YVal[k*batch_size:(k+1)*batch_size,:]\n",
    "    \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "    \n",
    "            # Forward pass\n",
    "            # x = nn.functional.normalize(x.float(), p=1.0, dim = 1)\n",
    "            outputs = model(x.float())\n",
    "            loss = criterion(norm * outputs, norm * y.float().reshape(batch_size, 1))\n",
    "            # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().reshape(batch_size,1,1))\n",
    "            # loss1 = criterion(norm*outputs, norm*y.float().reshape(batch_size,1))\n",
    "            # loss2 = torch.sum(abs(outputs - y.float().reshape(batch_size,1)))\n",
    "            # loss = loss1 + loss2\n",
    "    \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            loss_train.append(loss.item())\n",
    "    \n",
    "            if (i + 1) % 5 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs, learning rate: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, int(total_step / batch_size), loss.item(),\n",
    "                              time.time() - start_time, optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "        loss_tmp = 0\n",
    "        result = []\n",
    "        for i in range(len(YVal)):\n",
    "            # each i is a batch of 128 samples\n",
    "            x, y = XVal[i, :, :], YVal[i, :]\n",
    "    \n",
    "            x = x.unsqueeze(0).to(device)\n",
    "            y = y.unsqueeze(0).to(device)\n",
    "    \n",
    "            # Forward pass val\n",
    "            outputs = model(x.float())\n",
    "            loss = criterion(norm * outputs, norm * y.float().reshape(1, 1))\n",
    "            # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().reshape(1,1,1))\n",
    "            # loss1 = criterion(norm*outputs, norm*y.float().reshape(1,1,1))\n",
    "            # loss2 = torch.mean(outputs**2 - y.float().reshape(1,1,1)**2)\n",
    "            # loss = loss1 + loss2\n",
    "    \n",
    "            loss_tmp += loss.item()\n",
    "            result.append(outputs[0, 0].item())\n",
    "            # result.append(nn.Sigmoid()(outputs[0,0]).item())\n",
    "        loss_val.append(loss_tmp / len(YVal))\n",
    "    \n",
    "        scheduler.step()\n",
    "    \n",
    "    mean_val.append(np.mean(loss_val[-1]))\n",
    "    mean_train.append(np.mean(loss_train[-1]))\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T22:13:13.084310600Z",
     "start_time": "2023-12-27T22:00:11.940261600Z"
    }
   },
   "id": "2aa9f86b4446c50b"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.axis.XTick at 0x1f5f10a6280>,\n <matplotlib.axis.XTick at 0x1f5f10a6250>,\n <matplotlib.axis.XTick at 0x1f5f0e57f70>,\n <matplotlib.axis.XTick at 0x1f5f10e05b0>,\n <matplotlib.axis.XTick at 0x1f5f10e0d00>]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.style.use('seaborn')\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot([5, 10, 15, 20, 25], mean_val, label='val error')\n",
    "plt.plot([5, 10, 15, 20, 25], mean_train, label='Training error')\n",
    "plt.ylabel('loss', fontsize=14)\n",
    "ax.set_xlabel('Number of Epochs', fontsize=14)\n",
    "ax.set_title('Learning curves', fontsize=18, y=1.03) \n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "ax.minorticks_off()\n",
    "ax.set_xticks([5, 10, 15, 20, 25]) \n",
    "# plt.ylim([0, 1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T22:44:25.444274Z",
     "start_time": "2023-12-27T22:44:25.183204900Z"
    }
   },
   "id": "a996da7b150ccdcf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
