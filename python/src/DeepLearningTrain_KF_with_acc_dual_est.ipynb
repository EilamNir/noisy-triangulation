{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation.generate_path import generate_path\n",
    "import matplotlib.pyplot as plt\n",
    "from estimation.distance_sensor import distance_sensors\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from estimation.kalman_filter_from_points_with_acc import kalman_filter_from_points_acc\n",
    "from estimation.dual_iterative_non_iterative_estimator import iter_non_iter_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 1)\n",
      "(4, 3, 10, 569)\n"
     ]
    }
   ],
   "source": [
    "# create test data\n",
    "target_initial_pos = np.array([0, 0, 5000])\n",
    "target_speed_xy = 50\n",
    "target_speed_z = 10\n",
    "target_rot_speed = 3\n",
    "time_res = 0.5\n",
    "\n",
    "path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "path1.add_straight_interval(100)\n",
    "path1.add_xy_turn_interval(90, -np.deg2rad(target_rot_speed))\n",
    "path1.add_straight_interval(100)\n",
    "\n",
    "# create noisy sensors\n",
    "sensors = distance_sensors([[-5000,0,0],[ 400, -7400, 0],[ 800, 800, 0]], 15)\n",
    "sensors.calculate_measurements(path1.path)\n",
    "sigma_a = 1\n",
    "sigma_v = 100\n",
    "kf_acc = kalman_filter_from_points_acc(time_res, sigma_a, sigma_v, non_diag_reduction_ratio=2)\n",
    "dual_est = iter_non_iter_estimator(sensors)\n",
    "estimated_path = dual_est.estimate_path()\n",
    "kf_path_acc = kf_acc.filter_path(estimated_path)\n",
    "\n",
    "sample = 10\n",
    "XTest = []\n",
    "for i in np.arange(len(path1.path) - sample + 1):\n",
    "    tmp = np.concatenate((sensors.sensor_locations, np.reshape(kf_path_acc[i,:], (1,3))), 0)\n",
    "    tmp = tmp.reshape(4,3,1)\n",
    "    for j in np.arange(1,sample):\n",
    "        matrix = np.concatenate((sensors.sensor_locations, np.reshape(kf_path_acc[i+j,:], (1,3))), 0)\n",
    "        matrix = matrix.reshape(4,3,1)\n",
    "        tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "    if i > 0:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = np.concatenate((XTest, tmp), 3)\n",
    "    else:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = tmp\n",
    "\n",
    "YTest = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTest))\n",
    "print(np.shape(XTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207188, 1)\n",
      "(4, 3, 10, 207188)\n"
     ]
    }
   ],
   "source": [
    "# create train data\n",
    "# run_number = 600\n",
    "run_number = 1000\n",
    "XTrain = []\n",
    "YTrain = []\n",
    "for k in np.arange(run_number):\n",
    "    target_initial_pos = np.random.randint(-7000, 7000, size=(1, 3))[0]\n",
    "    sensors_pos = np.random.randint(-7000, 7000, size=(3, 3))[:,:]\n",
    "    target_speed_xy = 50\n",
    "    target_speed_z = 10\n",
    "    target_rot_speed = 3\n",
    "    time_res = 0.5\n",
    "\n",
    "    path1 = generate_path(np.deg2rad(np.random.randint(0,360,size=1)[0]), target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "    path1.add_straight_interval(np.random.randint(10,100,size=1)[0])\n",
    "    path1.add_xy_turn_interval(np.random.randint(10,100,size=1)[0], -random.choice([-1, 1])*np.deg2rad(target_rot_speed))\n",
    "\n",
    "    # create noisy sensors\n",
    "    sensors = distance_sensors(sensors_pos, 20)\n",
    "    sensors.calculate_measurements(path1.path)\n",
    "    sigma_a = 1\n",
    "    sigma_v = 100\n",
    "    kf_acc = kalman_filter_from_points_acc(time_res, sigma_a, sigma_v, non_diag_reduction_ratio=2)\n",
    "    dual_est = iter_non_iter_estimator(sensors)\n",
    "    estimated_path = dual_est.estimate_path()\n",
    "    kf_path_acc = kf_acc.filter_path(estimated_path)\n",
    "\n",
    "    sample = 10\n",
    "    for i in np.arange(len(path1.path) - sample + 1):\n",
    "        tmp = np.concatenate((sensors.sensor_locations, np.reshape(kf_path_acc[i,:], (1,3))), 0)\n",
    "        tmp = tmp.reshape(4,3,1)\n",
    "        for j in np.arange(1,sample):\n",
    "            matrix = np.concatenate((sensors.sensor_locations, np.reshape(kf_path_acc[i+j,:], (1,3))), 0)\n",
    "            matrix = matrix.reshape(4,3,1)\n",
    "            tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "        if len(XTrain):\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = np.concatenate((XTrain, tmp), 3)\n",
    "        else:\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = tmp\n",
    "    if len(YTrain):\n",
    "        YTrain = np.concatenate((YTrain, path1.state_key[sample-1:]), 0)\n",
    "    else:\n",
    "        YTrain = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTrain))\n",
    "print(np.shape(XTrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "ind = np.arange(len(YTrain))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XVal = torch.from_numpy(np.transpose(XTest, (3, 2, 0, 1)))\n",
    "YVal = torch.from_numpy(YTest)\n",
    "\n",
    "XTrain = torch.from_numpy(np.transpose(XTrain[:,:,:,ind], (3, 2, 0, 1)))\n",
    "YTrain = torch.from_numpy(YTrain[ind,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create network\n",
    "class state_estimat(nn.Module):\n",
    "    def __init__(self, d_in, num_classes):\n",
    "        # initialzing the parent object (important!)\n",
    "        super(state_estimat, self).__init__()\n",
    "        # Create a pipeline - a sequence of layers\n",
    "        \n",
    "        self.pipe = torch.nn.Sequential(\n",
    "            nn.Conv2d(d_in, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*3*4, 1))\n",
    "            # nn.Sigmoid())\n",
    "\n",
    "        # self.d_in = d_in\n",
    "        # self.device = device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = nn.Conv2d(self.d_in, 64, kernel_size=3, padding=1, device=self.device)(x)\n",
    "        # x = nn.ReLU()(x)\n",
    "        # x = nn.Conv2d(64, 64, kernel_size=3, padding=1, device=self.device)(x)\n",
    "        # x = nn.ReLU()(x)\n",
    "        # x = nn.Conv2d(64, 64, kernel_size=3, padding=1, device=self.device)(x)\n",
    "        # x = nn.ReLU()(x)\n",
    "        # x = nn.Flatten()(x)\n",
    "        # x = nn.Linear(64*3*4, 1, device=self.device)(x)\n",
    "        # return x\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "state_estimat(\n",
      "  (pipe): Sequential(\n",
      "    (0): Conv2d(10, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters:\n",
    "# num_epochs = 100\n",
    "num_epochs = 10\n",
    "# batch_size = 512\n",
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "learning_rate_drop_period = 10\n",
    "input_shape = [3,4,3]\n",
    "\n",
    "# Device configuration, as before\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(device)\n",
    "# create model\n",
    "model = state_estimat(d_in=10, num_classes=1).to(device)\n",
    "print(model)\n",
    "# Loss and optimizer\n",
    "# criterion = torch.nn.BCELoss()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=learning_rate_drop_period, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [5/809], Loss: 2896598528.0000, Time: 0.1210 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [10/809], Loss: 15224776.0000, Time: 0.1255 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [15/809], Loss: 51340548.0000, Time: 0.1295 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [20/809], Loss: 88009216.0000, Time: 0.1335 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [25/809], Loss: 3780323328.0000, Time: 0.1376 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [30/809], Loss: 38824583168.0000, Time: 0.1416 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [35/809], Loss: 44744130560.0000, Time: 0.1455 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [40/809], Loss: 622433408.0000, Time: 0.1494 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [45/809], Loss: 32404529152.0000, Time: 0.1536 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [50/809], Loss: 162939072.0000, Time: 0.1575 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [55/809], Loss: 149672112.0000, Time: 0.1614 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [60/809], Loss: 5887027200.0000, Time: 0.1654 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [65/809], Loss: 3280787996672.0000, Time: 0.1695 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [70/809], Loss: 120081704.0000, Time: 0.1734 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [75/809], Loss: 3012539392.0000, Time: 0.1774 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [80/809], Loss: 1369342208.0000, Time: 0.1814 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [85/809], Loss: 308083584.0000, Time: 0.1864 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [90/809], Loss: 32310562816.0000, Time: 0.1923 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [95/809], Loss: 181910880.0000, Time: 0.1971 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [100/809], Loss: 34199160.0000, Time: 0.2015 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [105/809], Loss: 396448.1250, Time: 0.2058 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [110/809], Loss: 26738.4375, Time: 0.2102 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [115/809], Loss: 6.8104, Time: 0.2145 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [120/809], Loss: 5.5215, Time: 0.2186 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [125/809], Loss: 30.5440, Time: 0.2226 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [130/809], Loss: 34.6147, Time: 0.2265 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [135/809], Loss: 678497.6250, Time: 0.2305 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [140/809], Loss: 26519.5508, Time: 0.2346 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [145/809], Loss: 925.3493, Time: 0.2385 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [150/809], Loss: 978572544.0000, Time: 0.2424 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [155/809], Loss: 2363.9136, Time: 0.2464 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [160/809], Loss: 23023674.0000, Time: 0.2503 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [165/809], Loss: 1.6701, Time: 0.2544 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [170/809], Loss: 5.8901, Time: 0.2583 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [175/809], Loss: 16.0036, Time: 0.2622 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [180/809], Loss: 5.2546, Time: 0.2662 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [185/809], Loss: 7.0845, Time: 0.2702 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [190/809], Loss: 9.7849, Time: 0.2742 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [195/809], Loss: 174785.9375, Time: 0.2781 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [200/809], Loss: 3.0201, Time: 0.2819 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [205/809], Loss: 9.9200, Time: 0.2857 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [210/809], Loss: 10.4567, Time: 0.2894 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [215/809], Loss: 12.1803, Time: 0.2932 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [220/809], Loss: 5.5640, Time: 0.2969 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [225/809], Loss: 0.5928, Time: 0.3007 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [230/809], Loss: 5.6567, Time: 0.3044 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [235/809], Loss: 0.5030, Time: 0.3082 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [240/809], Loss: 1.7774, Time: 0.3119 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [245/809], Loss: 5010.3335, Time: 0.3156 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [250/809], Loss: 11.2732, Time: 0.3195 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [255/809], Loss: 1.8372, Time: 0.3234 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [260/809], Loss: 0.9025, Time: 0.3273 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [265/809], Loss: 4.4424, Time: 0.3310 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [270/809], Loss: 1.4758, Time: 0.3348 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [275/809], Loss: 1.8758, Time: 0.3386 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [280/809], Loss: 3.8789, Time: 0.3423 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [285/809], Loss: 5.0457, Time: 0.3461 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [290/809], Loss: 0.6402, Time: 0.3498 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [295/809], Loss: 0.5459, Time: 0.3537 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [300/809], Loss: 0.9807, Time: 0.3574 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [305/809], Loss: 0.4479, Time: 0.3612 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [310/809], Loss: 5.5534, Time: 0.3649 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [315/809], Loss: 1.0001, Time: 0.3688 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [320/809], Loss: 1.4456, Time: 0.3725 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [325/809], Loss: 7.2800, Time: 0.3762 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [330/809], Loss: 3.2426, Time: 0.3800 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [335/809], Loss: 2.4328, Time: 0.3839 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [340/809], Loss: 4.0720, Time: 0.3878 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [345/809], Loss: 3.1880, Time: 0.3915 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [350/809], Loss: 3.7995, Time: 0.3953 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [355/809], Loss: 0.5223, Time: 0.3990 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [360/809], Loss: 4.9704, Time: 0.4028 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [365/809], Loss: 1.2870, Time: 0.4066 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [370/809], Loss: 30.5126, Time: 0.4103 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [375/809], Loss: 450.9895, Time: 0.4141 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [380/809], Loss: 4.7480, Time: 0.4180 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [385/809], Loss: 4.0720, Time: 0.4224 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [390/809], Loss: 2.0057, Time: 0.4267 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [395/809], Loss: 2.3342, Time: 0.4305 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [400/809], Loss: 3.9487, Time: 0.4344 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [405/809], Loss: 2.9658, Time: 0.4383 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [410/809], Loss: 0.4591, Time: 0.4420 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [415/809], Loss: 5.9195, Time: 0.4457 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [420/809], Loss: 4.8939, Time: 0.4494 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [425/809], Loss: 3.4220, Time: 0.4533 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [430/809], Loss: 2.2885, Time: 0.4571 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [435/809], Loss: 4.0436, Time: 0.4608 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [440/809], Loss: 2.1602, Time: 0.4646 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [445/809], Loss: 0.5992, Time: 0.4685 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [450/809], Loss: 3.3318, Time: 0.4722 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [455/809], Loss: 3.5923, Time: 0.4760 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [460/809], Loss: 3.0103, Time: 0.4797 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [465/809], Loss: 1.7445, Time: 0.4834 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [470/809], Loss: 1.9361, Time: 0.4873 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [475/809], Loss: 1.9971, Time: 0.4910 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [480/809], Loss: 3.3317, Time: 0.4948 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [485/809], Loss: 0.9848, Time: 0.4986 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [490/809], Loss: 2.7686, Time: 0.5025 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [495/809], Loss: 1.3303, Time: 0.5062 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [500/809], Loss: 0.4442, Time: 0.5100 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [505/809], Loss: 2.2806, Time: 0.5137 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [510/809], Loss: 0.7887, Time: 0.5178 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [515/809], Loss: 1.9547, Time: 0.5216 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [520/809], Loss: 2.6632, Time: 0.5257 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [525/809], Loss: 0.4808, Time: 0.5299 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [530/809], Loss: 6269.4341, Time: 0.5341 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [535/809], Loss: 2080.3740, Time: 0.5383 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [540/809], Loss: 0.5104, Time: 0.5439 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [545/809], Loss: 3.0602, Time: 0.5506 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [550/809], Loss: 2.1695, Time: 0.5572 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [555/809], Loss: 1.8589, Time: 0.5639 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [560/809], Loss: 32603.2109, Time: 0.5705 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [565/809], Loss: 1.2295, Time: 0.5771 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [570/809], Loss: 2.2770, Time: 0.5849 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [575/809], Loss: 2.5555, Time: 0.5966 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [580/809], Loss: 0.5329, Time: 0.6019 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [585/809], Loss: 2.0205, Time: 0.6065 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [590/809], Loss: 2.0274, Time: 0.6109 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [595/809], Loss: 1.9584, Time: 0.6147 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [600/809], Loss: 0.6799, Time: 0.6187 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [605/809], Loss: 1.4579, Time: 0.6225 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [610/809], Loss: 15.3938, Time: 0.6272 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [615/809], Loss: 2.1393, Time: 0.6315 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [620/809], Loss: 2.4605, Time: 0.6355 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [625/809], Loss: 2.0835, Time: 0.6397 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [630/809], Loss: 0.4544, Time: 0.6436 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [635/809], Loss: 2.0330, Time: 0.6474 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [640/809], Loss: 1.2801, Time: 0.6513 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [645/809], Loss: 0.6135, Time: 0.6551 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [650/809], Loss: 0.5435, Time: 0.6589 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [655/809], Loss: 14.6126, Time: 0.6626 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [660/809], Loss: 1.5698, Time: 0.6664 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [665/809], Loss: 1.8854, Time: 0.6702 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [670/809], Loss: 1.8342, Time: 0.6740 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [675/809], Loss: 0.9030, Time: 0.6777 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [680/809], Loss: 0.4810, Time: 0.6814 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [685/809], Loss: 0.5109, Time: 0.6854 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [690/809], Loss: 4.0133, Time: 0.6891 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [695/809], Loss: 1.1268, Time: 0.6929 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [700/809], Loss: 0.7773, Time: 0.6966 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [705/809], Loss: 0.5889, Time: 0.7006 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [710/809], Loss: 1.1117, Time: 0.7043 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [715/809], Loss: 1.2689, Time: 0.7081 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [720/809], Loss: 4.1951, Time: 0.7118 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [725/809], Loss: 0.4551, Time: 0.7156 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [730/809], Loss: 3.5272, Time: 0.7195 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [735/809], Loss: 1.7950, Time: 0.7233 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [740/809], Loss: 1.0808, Time: 0.7273 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [745/809], Loss: 4.0271, Time: 0.7312 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [750/809], Loss: 2.1500, Time: 0.7351 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [755/809], Loss: 2.2426, Time: 0.7389 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [760/809], Loss: 1.1231, Time: 0.7426 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [765/809], Loss: 0.8991, Time: 0.7464 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [770/809], Loss: 0.4994, Time: 0.7501 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [775/809], Loss: 1.4703, Time: 0.7540 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [780/809], Loss: 0.6062, Time: 0.7578 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [785/809], Loss: 2.6161, Time: 0.7615 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [790/809], Loss: 0.6948, Time: 0.7652 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [795/809], Loss: 0.4623, Time: 0.7692 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [800/809], Loss: 1.6752, Time: 0.7730 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [805/809], Loss: 0.5177, Time: 0.7767 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [5/809], Loss: 2.4938, Time: 0.9031 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [10/809], Loss: 0.8498, Time: 0.9079 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [15/809], Loss: 2.1441, Time: 0.9128 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [20/809], Loss: 0.8227, Time: 0.9178 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [25/809], Loss: 0.4881, Time: 0.9220 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [30/809], Loss: 7.7319, Time: 0.9259 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [35/809], Loss: 2.6235, Time: 0.9299 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [40/809], Loss: 1.7431, Time: 0.9339 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [45/809], Loss: 0.8747, Time: 0.9377 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [50/809], Loss: 0.9086, Time: 0.9414 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [55/809], Loss: 0.4762, Time: 0.9452 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [60/809], Loss: 0.9585, Time: 0.9490 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [65/809], Loss: 0.6681, Time: 0.9529 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [70/809], Loss: 0.4696, Time: 0.9566 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [75/809], Loss: 0.7144, Time: 0.9604 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [80/809], Loss: 1.8632, Time: 0.9642 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [85/809], Loss: 0.6671, Time: 0.9680 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [90/809], Loss: 2.3388, Time: 0.9718 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [95/809], Loss: 0.6010, Time: 0.9755 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [100/809], Loss: 0.9809, Time: 0.9793 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [105/809], Loss: 0.7189, Time: 0.9830 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [110/809], Loss: 4.3931, Time: 0.9869 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [115/809], Loss: 0.6301, Time: 0.9907 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [120/809], Loss: 0.9519, Time: 0.9944 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [125/809], Loss: 0.5049, Time: 0.9982 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [130/809], Loss: 0.4621, Time: 1.0021 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [135/809], Loss: 0.9922, Time: 1.0058 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [140/809], Loss: 0.6558, Time: 1.0096 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [145/809], Loss: 0.5290, Time: 1.0134 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [150/809], Loss: 0.5500, Time: 1.0173 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [155/809], Loss: 0.7003, Time: 1.0210 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [160/809], Loss: 2.0915, Time: 1.0248 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [165/809], Loss: 0.8725, Time: 1.0285 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [170/809], Loss: 0.6751, Time: 1.0323 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [175/809], Loss: 0.8070, Time: 1.0361 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [180/809], Loss: 0.7114, Time: 1.0398 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [185/809], Loss: 0.5466, Time: 1.0436 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [190/809], Loss: 0.6396, Time: 1.0474 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [195/809], Loss: 0.5040, Time: 1.0513 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [200/809], Loss: 0.5900, Time: 1.0551 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [205/809], Loss: 0.5912, Time: 1.0589 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [210/809], Loss: 0.4805, Time: 1.0627 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [215/809], Loss: 0.8247, Time: 1.0664 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [220/809], Loss: 0.4657, Time: 1.0702 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [225/809], Loss: 0.8172, Time: 1.0740 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [230/809], Loss: 1.0270, Time: 1.0777 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [235/809], Loss: 5.2460, Time: 1.0815 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [240/809], Loss: 0.9375, Time: 1.0854 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [245/809], Loss: 0.6550, Time: 1.0892 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [250/809], Loss: 0.4620, Time: 1.0929 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [255/809], Loss: 0.5258, Time: 1.0967 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [260/809], Loss: 0.5419, Time: 1.1006 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [265/809], Loss: 0.6562, Time: 1.1044 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [270/809], Loss: 0.5531, Time: 1.1081 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [275/809], Loss: 0.4694, Time: 1.1119 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [280/809], Loss: 0.5404, Time: 1.1156 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [285/809], Loss: 0.5932, Time: 1.1195 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [290/809], Loss: 0.4385, Time: 1.1233 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [295/809], Loss: 0.6298, Time: 1.1270 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [300/809], Loss: 0.5404, Time: 1.1310 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [305/809], Loss: 2.0081, Time: 1.1350 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [310/809], Loss: 0.4199, Time: 1.1388 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [315/809], Loss: 1.0925, Time: 1.1426 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [320/809], Loss: 0.4509, Time: 1.1464 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [325/809], Loss: 0.5782, Time: 1.1501 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [330/809], Loss: 0.8660, Time: 1.1540 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [335/809], Loss: 1.9540, Time: 1.1578 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [340/809], Loss: 0.6241, Time: 1.1615 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [345/809], Loss: 0.4324, Time: 1.1653 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [350/809], Loss: 0.6331, Time: 1.1691 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [355/809], Loss: 0.6475, Time: 1.1729 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [360/809], Loss: 0.8305, Time: 1.1766 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [365/809], Loss: 0.7258, Time: 1.1803 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [370/809], Loss: 4.1118, Time: 1.1843 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [375/809], Loss: 0.4619, Time: 1.1880 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [380/809], Loss: 1.0065, Time: 1.1918 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [385/809], Loss: 0.5372, Time: 1.1956 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [390/809], Loss: 1.5904, Time: 1.1993 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [395/809], Loss: 0.9813, Time: 1.2033 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [400/809], Loss: 0.6367, Time: 1.2070 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [405/809], Loss: 734936.3750, Time: 1.2108 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [410/809], Loss: 0.4802, Time: 1.2145 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [415/809], Loss: 0.6287, Time: 1.2183 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [420/809], Loss: 0.6473, Time: 1.2220 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [425/809], Loss: 2.3792, Time: 1.2258 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [430/809], Loss: 0.4858, Time: 1.2295 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [435/809], Loss: 0.5219, Time: 1.2333 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [440/809], Loss: 0.4674, Time: 1.2371 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [445/809], Loss: 0.4768, Time: 1.2408 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [450/809], Loss: 0.5240, Time: 1.2446 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [455/809], Loss: 0.5810, Time: 1.2483 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [460/809], Loss: 0.8546, Time: 1.2521 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [465/809], Loss: 0.8310, Time: 1.2559 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [470/809], Loss: 0.4801, Time: 1.2596 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [475/809], Loss: 0.4353, Time: 1.2634 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [480/809], Loss: 0.4712, Time: 1.2673 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [485/809], Loss: 0.4945, Time: 1.2710 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [490/809], Loss: 0.5210, Time: 1.2748 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [495/809], Loss: 0.7163, Time: 1.2785 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [500/809], Loss: 0.5891, Time: 1.2823 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [505/809], Loss: 1.5048, Time: 1.2862 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [510/809], Loss: 0.5079, Time: 1.2899 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [515/809], Loss: 0.5081, Time: 1.2937 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [520/809], Loss: 0.4829, Time: 1.2974 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [525/809], Loss: 0.4974, Time: 1.3013 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [530/809], Loss: 0.4694, Time: 1.3051 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [535/809], Loss: 0.5493, Time: 1.3088 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [540/809], Loss: 0.4595, Time: 1.3126 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [545/809], Loss: 0.4761, Time: 1.3163 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [550/809], Loss: 0.5106, Time: 1.3203 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [555/809], Loss: 0.4865, Time: 1.3240 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [560/809], Loss: 0.4394, Time: 1.3277 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [565/809], Loss: 0.5163, Time: 1.3317 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [570/809], Loss: 0.4842, Time: 1.3356 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [575/809], Loss: 0.4468, Time: 1.3394 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [580/809], Loss: 0.5549, Time: 1.3431 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [585/809], Loss: 0.5101, Time: 1.3468 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [590/809], Loss: 0.4387, Time: 1.3506 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [595/809], Loss: 0.4451, Time: 1.3544 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [600/809], Loss: 0.5471, Time: 1.3582 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [605/809], Loss: 1.4710, Time: 1.3619 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [610/809], Loss: 0.5036, Time: 1.3657 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [615/809], Loss: 0.4926, Time: 1.3695 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [620/809], Loss: 0.4467, Time: 1.3732 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [625/809], Loss: 0.5224, Time: 1.3770 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [630/809], Loss: 1.4912, Time: 1.3807 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [635/809], Loss: 0.4886, Time: 1.3847 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [640/809], Loss: 0.4874, Time: 1.3885 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [645/809], Loss: 0.4851, Time: 1.3923 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [650/809], Loss: 0.5135, Time: 1.3961 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [655/809], Loss: 0.5045, Time: 1.3998 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [660/809], Loss: 0.4930, Time: 1.4037 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [665/809], Loss: 0.4504, Time: 1.4074 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [670/809], Loss: 0.5520, Time: 1.4112 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [675/809], Loss: 0.4512, Time: 1.4151 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [680/809], Loss: 0.4791, Time: 1.4192 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [685/809], Loss: 0.5305, Time: 1.4230 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [690/809], Loss: 1.3547, Time: 1.4267 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [695/809], Loss: 0.4128, Time: 1.4305 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [700/809], Loss: 1.9076, Time: 1.4344 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [705/809], Loss: 0.5078, Time: 1.4382 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [710/809], Loss: 0.4687, Time: 1.4420 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [715/809], Loss: 0.5430, Time: 1.4458 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [720/809], Loss: 0.4619, Time: 1.4495 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [725/809], Loss: 0.4522, Time: 1.4535 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [730/809], Loss: 0.4978, Time: 1.4573 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [735/809], Loss: 0.5129, Time: 1.4611 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [740/809], Loss: 0.4756, Time: 1.4648 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [745/809], Loss: 1.2961, Time: 1.4688 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [750/809], Loss: 0.4869, Time: 1.4725 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [755/809], Loss: 0.4407, Time: 1.4763 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [760/809], Loss: 0.4618, Time: 1.4800 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [765/809], Loss: 0.4253, Time: 1.4839 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [770/809], Loss: 0.4694, Time: 1.4877 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [775/809], Loss: 0.4305, Time: 1.4932 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [780/809], Loss: 0.5143, Time: 1.4998 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [785/809], Loss: 0.4907, Time: 1.5066 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [790/809], Loss: 0.5206, Time: 1.5131 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [795/809], Loss: 0.5242, Time: 1.5199 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [800/809], Loss: 0.4640, Time: 1.5266 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [805/809], Loss: 0.4267, Time: 1.5326 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [5/809], Loss: 0.5191, Time: 1.6647 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [10/809], Loss: 1.3020, Time: 1.6701 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [15/809], Loss: 0.4756, Time: 1.6746 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [20/809], Loss: 0.5153, Time: 1.6798 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [25/809], Loss: 0.4790, Time: 1.6843 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [30/809], Loss: 0.5045, Time: 1.6881 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [35/809], Loss: 0.5441, Time: 1.6919 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [40/809], Loss: 0.4382, Time: 1.6957 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [45/809], Loss: 0.4470, Time: 1.6995 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [50/809], Loss: 0.5443, Time: 1.7034 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [55/809], Loss: 0.7917, Time: 1.7078 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [60/809], Loss: 0.4488, Time: 1.7123 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [65/809], Loss: 0.5111, Time: 1.7169 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [70/809], Loss: 0.4781, Time: 1.7213 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [75/809], Loss: 0.4755, Time: 1.7251 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [80/809], Loss: 0.5086, Time: 1.7289 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [85/809], Loss: 0.4858, Time: 1.7327 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [90/809], Loss: 0.5607, Time: 1.7367 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [95/809], Loss: 0.4820, Time: 1.7406 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [100/809], Loss: 732244.5000, Time: 1.7444 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [105/809], Loss: 0.4973, Time: 1.7482 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [110/809], Loss: 0.4749, Time: 1.7521 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [115/809], Loss: 0.5319, Time: 1.7559 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [120/809], Loss: 1.4639, Time: 1.7597 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [125/809], Loss: 0.7854, Time: 1.7634 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [130/809], Loss: 0.4937, Time: 1.7673 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [135/809], Loss: 0.4713, Time: 1.7711 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [140/809], Loss: 0.5084, Time: 1.7748 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [145/809], Loss: 0.4781, Time: 1.7786 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [150/809], Loss: 0.4593, Time: 1.7824 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [155/809], Loss: 0.4843, Time: 1.7862 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [160/809], Loss: 0.4869, Time: 1.7900 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [165/809], Loss: 0.4919, Time: 1.7938 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [170/809], Loss: 0.4865, Time: 1.7976 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [175/809], Loss: 0.4726, Time: 1.8014 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [180/809], Loss: 0.8774, Time: 1.8052 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [185/809], Loss: 0.4124, Time: 1.8090 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [190/809], Loss: 0.5107, Time: 1.8127 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [195/809], Loss: 0.5040, Time: 1.8165 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [200/809], Loss: 0.4607, Time: 1.8203 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [205/809], Loss: 0.4536, Time: 1.8241 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [210/809], Loss: 1.3299, Time: 1.8279 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [215/809], Loss: 0.5257, Time: 1.8317 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [220/809], Loss: 0.5212, Time: 1.8355 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [225/809], Loss: 0.4645, Time: 1.8393 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [230/809], Loss: 0.9530, Time: 1.8431 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [235/809], Loss: 0.5215, Time: 1.8468 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [240/809], Loss: 0.5004, Time: 1.8507 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [245/809], Loss: 0.4882, Time: 1.8545 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [250/809], Loss: 0.4813, Time: 1.8582 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [255/809], Loss: 0.4110, Time: 1.8620 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [260/809], Loss: 0.4875, Time: 1.8657 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [265/809], Loss: 0.4822, Time: 1.8696 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [270/809], Loss: 0.4431, Time: 1.8734 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [275/809], Loss: 0.4448, Time: 1.8771 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [280/809], Loss: 3.0534, Time: 1.8809 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [285/809], Loss: 0.4945, Time: 1.8848 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [290/809], Loss: 0.4287, Time: 1.8885 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [295/809], Loss: 0.4921, Time: 1.8922 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [300/809], Loss: 0.5061, Time: 1.8960 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [305/809], Loss: 0.4726, Time: 1.8998 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [310/809], Loss: 0.4562, Time: 1.9036 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [315/809], Loss: 0.4513, Time: 1.9074 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [320/809], Loss: 0.4196, Time: 1.9112 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [325/809], Loss: 0.5207, Time: 1.9149 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [330/809], Loss: 0.5299, Time: 1.9188 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [335/809], Loss: 0.4741, Time: 1.9226 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [340/809], Loss: 0.4777, Time: 1.9264 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [345/809], Loss: 0.4916, Time: 1.9301 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [350/809], Loss: 1.0774, Time: 1.9340 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [355/809], Loss: 1.9960, Time: 1.9379 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [360/809], Loss: 0.4947, Time: 1.9418 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [365/809], Loss: 0.4847, Time: 1.9455 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [370/809], Loss: 0.4983, Time: 1.9493 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [375/809], Loss: 0.4671, Time: 1.9532 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [380/809], Loss: 1.6256, Time: 1.9570 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [385/809], Loss: 0.4920, Time: 1.9607 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [390/809], Loss: 1.6251, Time: 1.9645 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [395/809], Loss: 0.4370, Time: 1.9684 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [400/809], Loss: 0.4326, Time: 1.9721 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [405/809], Loss: 1.7165, Time: 1.9759 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [410/809], Loss: 0.5076, Time: 1.9797 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [415/809], Loss: 0.4825, Time: 1.9835 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [420/809], Loss: 0.4763, Time: 1.9873 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [425/809], Loss: 0.4301, Time: 1.9911 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [430/809], Loss: 0.5024, Time: 1.9949 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [435/809], Loss: 0.4780, Time: 1.9986 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [440/809], Loss: 0.5135, Time: 2.0025 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [445/809], Loss: 1.2085, Time: 2.0062 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [450/809], Loss: 0.4782, Time: 2.0100 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [455/809], Loss: 0.4262, Time: 2.0138 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [460/809], Loss: 1.6722, Time: 2.0177 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [465/809], Loss: 0.5017, Time: 2.0216 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [470/809], Loss: 0.4836, Time: 2.0258 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [475/809], Loss: 0.4285, Time: 2.0298 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [480/809], Loss: 0.5392, Time: 2.0338 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [485/809], Loss: 0.4428, Time: 2.0388 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [490/809], Loss: 0.4806, Time: 2.0430 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [495/809], Loss: 0.4289, Time: 2.0468 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [500/809], Loss: 0.4740, Time: 2.0507 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [505/809], Loss: 0.4920, Time: 2.0544 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [510/809], Loss: 0.4585, Time: 2.0582 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [515/809], Loss: 0.4644, Time: 2.0619 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [520/809], Loss: 0.4765, Time: 2.0656 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [525/809], Loss: 0.7456, Time: 2.0695 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [530/809], Loss: 0.9841, Time: 2.0733 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [535/809], Loss: 1.3948, Time: 2.0770 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [540/809], Loss: 0.4239, Time: 2.0808 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [545/809], Loss: 0.4950, Time: 2.0847 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [550/809], Loss: 0.5179, Time: 2.0885 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [555/809], Loss: 1.2934, Time: 2.0922 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [560/809], Loss: 0.4840, Time: 2.0960 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [565/809], Loss: 0.5282, Time: 2.0997 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [570/809], Loss: 0.4621, Time: 2.1036 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [575/809], Loss: 0.5128, Time: 2.1074 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [580/809], Loss: 0.5215, Time: 2.1111 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [585/809], Loss: 0.5090, Time: 2.1149 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [590/809], Loss: 0.5325, Time: 2.1188 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [595/809], Loss: 0.5184, Time: 2.1225 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [600/809], Loss: 0.4846, Time: 2.1263 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [605/809], Loss: 0.4701, Time: 2.1300 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [610/809], Loss: 0.4436, Time: 2.1339 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [615/809], Loss: 0.5028, Time: 2.1377 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [620/809], Loss: 0.4602, Time: 2.1417 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [625/809], Loss: 0.8730, Time: 2.1455 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [630/809], Loss: 0.4647, Time: 2.1492 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [635/809], Loss: 0.4031, Time: 2.1532 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [640/809], Loss: 0.4509, Time: 2.1569 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [645/809], Loss: 0.4362, Time: 2.1607 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [650/809], Loss: 0.4767, Time: 2.1644 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [655/809], Loss: 0.4980, Time: 2.1682 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [660/809], Loss: 0.4948, Time: 2.1719 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [665/809], Loss: 0.4801, Time: 2.1757 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [670/809], Loss: 0.4113, Time: 2.1794 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [675/809], Loss: 0.5931, Time: 2.1832 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [680/809], Loss: 1.4363, Time: 2.1870 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [685/809], Loss: 0.4898, Time: 2.1908 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [690/809], Loss: 0.4772, Time: 2.1945 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [695/809], Loss: 0.4822, Time: 2.1983 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [700/809], Loss: 0.4470, Time: 2.2021 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [705/809], Loss: 0.4873, Time: 2.2059 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [710/809], Loss: 0.4955, Time: 2.2097 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [715/809], Loss: 0.4882, Time: 2.2134 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [720/809], Loss: 0.5556, Time: 2.2173 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [725/809], Loss: 0.4270, Time: 2.2211 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [730/809], Loss: 0.5172, Time: 2.2248 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [735/809], Loss: 0.4720, Time: 2.2285 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [740/809], Loss: 0.4771, Time: 2.2323 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [745/809], Loss: 0.7841, Time: 2.2362 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [750/809], Loss: 0.4945, Time: 2.2400 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [755/809], Loss: 0.4588, Time: 2.2437 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [760/809], Loss: 0.5263, Time: 2.2475 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [765/809], Loss: 0.4931, Time: 2.2514 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [770/809], Loss: 1.9574, Time: 2.2551 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [775/809], Loss: 0.4363, Time: 2.2589 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [780/809], Loss: 0.5362, Time: 2.2626 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [785/809], Loss: 0.4825, Time: 2.2664 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [790/809], Loss: 0.4970, Time: 2.2703 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [795/809], Loss: 0.7223, Time: 2.2741 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [800/809], Loss: 0.4423, Time: 2.2778 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [805/809], Loss: 0.5405, Time: 2.2816 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [5/809], Loss: 0.5271, Time: 2.4086 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [10/809], Loss: 0.5172, Time: 2.4132 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [15/809], Loss: 0.5220, Time: 2.4183 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [20/809], Loss: 0.5111, Time: 2.4226 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [25/809], Loss: 0.4403, Time: 2.4264 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [30/809], Loss: 0.4507, Time: 2.4302 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [35/809], Loss: 0.4726, Time: 2.4340 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [40/809], Loss: 0.4513, Time: 2.4378 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [45/809], Loss: 0.4952, Time: 2.4416 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [50/809], Loss: 0.5168, Time: 2.4453 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [55/809], Loss: 0.5263, Time: 2.4491 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [60/809], Loss: 0.5131, Time: 2.4529 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [65/809], Loss: 0.4714, Time: 2.4567 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [70/809], Loss: 0.4833, Time: 2.4604 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [75/809], Loss: 1.5188, Time: 2.4642 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [80/809], Loss: 0.8881, Time: 2.4681 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [85/809], Loss: 0.4688, Time: 2.4718 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [90/809], Loss: 0.4788, Time: 2.4756 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [95/809], Loss: 0.5269, Time: 2.4794 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [100/809], Loss: 0.4214, Time: 2.4831 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [105/809], Loss: 0.4731, Time: 2.4870 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [110/809], Loss: 0.4829, Time: 2.4908 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [115/809], Loss: 1.3169, Time: 2.4945 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [120/809], Loss: 0.4840, Time: 2.4983 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [125/809], Loss: 0.5114, Time: 2.5022 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [130/809], Loss: 0.4605, Time: 2.5059 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [135/809], Loss: 0.5051, Time: 2.5097 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [140/809], Loss: 0.4510, Time: 2.5134 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [145/809], Loss: 0.4998, Time: 2.5173 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [150/809], Loss: 0.4473, Time: 2.5211 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [155/809], Loss: 0.5095, Time: 2.5248 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [160/809], Loss: 0.7221, Time: 2.5285 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [165/809], Loss: 0.4750, Time: 2.5323 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [170/809], Loss: 0.4635, Time: 2.5362 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [175/809], Loss: 0.9307, Time: 2.5400 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [180/809], Loss: 0.4544, Time: 2.5437 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [185/809], Loss: 0.4911, Time: 2.5474 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [190/809], Loss: 0.4532, Time: 2.5514 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [195/809], Loss: 0.8071, Time: 2.5551 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [200/809], Loss: 0.5078, Time: 2.5589 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [205/809], Loss: 0.4860, Time: 2.5626 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [210/809], Loss: 0.5376, Time: 2.5664 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [215/809], Loss: 0.4683, Time: 2.5703 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [220/809], Loss: 0.7452, Time: 2.5740 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [225/809], Loss: 0.4842, Time: 2.5778 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [230/809], Loss: 0.4873, Time: 2.5816 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [235/809], Loss: 1.4777, Time: 2.5855 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [240/809], Loss: 0.4534, Time: 2.5892 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [245/809], Loss: 0.4638, Time: 2.5929 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [250/809], Loss: 0.4919, Time: 2.5967 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [255/809], Loss: 0.4384, Time: 2.6004 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [260/809], Loss: 0.4609, Time: 2.6043 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [265/809], Loss: 0.4444, Time: 2.6080 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [270/809], Loss: 0.4896, Time: 2.6120 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [275/809], Loss: 0.4790, Time: 2.6158 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [280/809], Loss: 0.4908, Time: 2.6196 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [285/809], Loss: 1066706.5000, Time: 2.6234 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [290/809], Loss: 0.5053, Time: 2.6272 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [295/809], Loss: 0.4249, Time: 2.6309 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [300/809], Loss: 0.4482, Time: 2.6348 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [305/809], Loss: 0.4790, Time: 2.6385 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [310/809], Loss: 0.4310, Time: 2.6423 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [315/809], Loss: 0.5077, Time: 2.6461 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [320/809], Loss: 1.2248, Time: 2.6499 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [325/809], Loss: 13911.3066, Time: 2.6536 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [330/809], Loss: 1.0974, Time: 2.6574 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [335/809], Loss: 0.4885, Time: 2.6612 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [340/809], Loss: 0.5123, Time: 2.6649 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [345/809], Loss: 0.4785, Time: 2.6687 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [350/809], Loss: 0.4967, Time: 2.6724 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [355/809], Loss: 0.4705, Time: 2.6762 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [360/809], Loss: 0.4521, Time: 2.6799 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [365/809], Loss: 0.4499, Time: 2.6837 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [370/809], Loss: 0.4625, Time: 2.6874 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [375/809], Loss: 0.4786, Time: 2.6915 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [380/809], Loss: 0.4786, Time: 2.6959 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [385/809], Loss: 0.5028, Time: 2.6998 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [390/809], Loss: 0.4414, Time: 2.7039 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [395/809], Loss: 0.4592, Time: 2.7077 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [400/809], Loss: 0.4610, Time: 2.7116 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [405/809], Loss: 0.4866, Time: 2.7153 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [410/809], Loss: 0.4017, Time: 2.7196 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [415/809], Loss: 0.5084, Time: 2.7241 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [420/809], Loss: 0.4555, Time: 2.7292 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [425/809], Loss: 0.4509, Time: 2.7331 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [430/809], Loss: 0.5260, Time: 2.7370 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [435/809], Loss: 0.7429, Time: 2.7407 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [440/809], Loss: 0.4734, Time: 2.7445 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [445/809], Loss: 0.4457, Time: 2.7482 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [450/809], Loss: 0.4712, Time: 2.7521 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [455/809], Loss: 2.2161, Time: 2.7559 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [460/809], Loss: 0.5140, Time: 2.7597 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [465/809], Loss: 0.4673, Time: 2.7634 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [470/809], Loss: 0.5030, Time: 2.7673 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [475/809], Loss: 0.4567, Time: 2.7711 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [480/809], Loss: 0.4419, Time: 2.7748 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [485/809], Loss: 0.4316, Time: 2.7786 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [490/809], Loss: 0.4354, Time: 2.7823 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [495/809], Loss: 0.4717, Time: 2.7862 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [500/809], Loss: 0.5172, Time: 2.7900 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [505/809], Loss: 0.4416, Time: 2.7937 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [510/809], Loss: 0.4420, Time: 2.7975 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [515/809], Loss: 1.3332, Time: 2.8014 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [520/809], Loss: 0.8839, Time: 2.8051 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [525/809], Loss: 0.4737, Time: 2.8089 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [530/809], Loss: 0.4593, Time: 2.8128 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [535/809], Loss: 0.5027, Time: 2.8167 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [540/809], Loss: 0.4596, Time: 2.8206 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [545/809], Loss: 0.4482, Time: 2.8244 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [550/809], Loss: 0.4816, Time: 2.8281 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [555/809], Loss: 0.5189, Time: 2.8319 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [560/809], Loss: 0.4798, Time: 2.8358 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [565/809], Loss: 0.5189, Time: 2.8395 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [570/809], Loss: 0.4095, Time: 2.8433 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [575/809], Loss: 0.5116, Time: 2.8470 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [580/809], Loss: 0.4889, Time: 2.8510 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [585/809], Loss: 0.4843, Time: 2.8547 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [590/809], Loss: 0.5241, Time: 2.8585 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [595/809], Loss: 1.0226, Time: 2.8623 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [600/809], Loss: 0.4413, Time: 2.8660 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [605/809], Loss: 0.4809, Time: 2.8699 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [610/809], Loss: 0.8402, Time: 2.8736 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [615/809], Loss: 0.5223, Time: 2.8774 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [620/809], Loss: 0.4448, Time: 2.8811 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [625/809], Loss: 0.4910, Time: 2.8848 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [630/809], Loss: 0.5140, Time: 2.8886 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [635/809], Loss: 0.4987, Time: 2.8923 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [640/809], Loss: 0.4998, Time: 2.8961 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [645/809], Loss: 2.1268, Time: 2.8998 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [650/809], Loss: 0.4665, Time: 2.9037 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [655/809], Loss: 0.5438, Time: 2.9074 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [660/809], Loss: 0.4837, Time: 2.9112 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [665/809], Loss: 4.1812, Time: 2.9149 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [670/809], Loss: 0.5039, Time: 2.9188 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [675/809], Loss: 1.6397, Time: 2.9225 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [680/809], Loss: 0.5332, Time: 2.9263 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [685/809], Loss: 0.4624, Time: 2.9300 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [690/809], Loss: 0.4638, Time: 2.9340 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [695/809], Loss: 0.4686, Time: 2.9377 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [700/809], Loss: 1.5612, Time: 2.9414 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [705/809], Loss: 0.4707, Time: 2.9452 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [710/809], Loss: 0.6663, Time: 2.9489 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [715/809], Loss: 0.4715, Time: 2.9529 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [720/809], Loss: 0.4124, Time: 2.9566 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [725/809], Loss: 0.7785, Time: 2.9604 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [730/809], Loss: 0.5216, Time: 2.9641 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [735/809], Loss: 0.4667, Time: 2.9680 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [740/809], Loss: 0.4738, Time: 2.9718 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [745/809], Loss: 0.4708, Time: 2.9755 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [750/809], Loss: 0.9690, Time: 2.9793 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [755/809], Loss: 0.4591, Time: 2.9830 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [760/809], Loss: 0.4953, Time: 2.9870 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [765/809], Loss: 0.7549, Time: 2.9907 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [770/809], Loss: 0.4945, Time: 2.9945 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [775/809], Loss: 712091.5000, Time: 2.9982 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [780/809], Loss: 0.4837, Time: 3.0021 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [785/809], Loss: 0.4990, Time: 3.0059 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [790/809], Loss: 0.4500, Time: 3.0096 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [795/809], Loss: 0.7893, Time: 3.0136 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [800/809], Loss: 0.4652, Time: 3.0174 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [805/809], Loss: 0.4541, Time: 3.0212 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [5/809], Loss: 0.4509, Time: 3.1469 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [10/809], Loss: 0.4723, Time: 3.1518 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [15/809], Loss: 0.4731, Time: 3.1563 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [20/809], Loss: 0.5541, Time: 3.1606 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [25/809], Loss: 0.5114, Time: 3.1645 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [30/809], Loss: 0.4125, Time: 3.1685 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [35/809], Loss: 0.4811, Time: 3.1722 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [40/809], Loss: 0.5126, Time: 3.1760 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [45/809], Loss: 0.4476, Time: 3.1798 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [50/809], Loss: 0.4824, Time: 3.1836 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [55/809], Loss: 0.4689, Time: 3.1874 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [60/809], Loss: 0.4425, Time: 3.1912 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [65/809], Loss: 0.4367, Time: 3.1949 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [70/809], Loss: 0.4502, Time: 3.1987 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [75/809], Loss: 0.5231, Time: 3.2026 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [80/809], Loss: 0.4729, Time: 3.2064 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [85/809], Loss: 0.4397, Time: 3.2101 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [90/809], Loss: 0.4432, Time: 3.2139 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [95/809], Loss: 0.4210, Time: 3.2180 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [100/809], Loss: 0.4601, Time: 3.2219 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [105/809], Loss: 0.5540, Time: 3.2257 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [110/809], Loss: 0.4742, Time: 3.2294 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [115/809], Loss: 0.4688, Time: 3.2333 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [120/809], Loss: 0.9737, Time: 3.2371 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [125/809], Loss: 0.4503, Time: 3.2409 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [130/809], Loss: 0.4177, Time: 3.2447 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [135/809], Loss: 0.5126, Time: 3.2495 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [140/809], Loss: 0.4783, Time: 3.2538 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [145/809], Loss: 0.6446, Time: 3.2576 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [150/809], Loss: 0.4784, Time: 3.2614 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [155/809], Loss: 0.9317, Time: 3.2651 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [160/809], Loss: 0.4207, Time: 3.2689 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [165/809], Loss: 0.4843, Time: 3.2727 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [170/809], Loss: 0.4491, Time: 3.2764 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [175/809], Loss: 0.4384, Time: 3.2802 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [180/809], Loss: 0.4713, Time: 3.2841 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [185/809], Loss: 0.5101, Time: 3.2879 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [190/809], Loss: 0.5531, Time: 3.2920 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [195/809], Loss: 0.5123, Time: 3.2965 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [200/809], Loss: 0.5064, Time: 3.3008 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [205/809], Loss: 0.4971, Time: 3.3054 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [210/809], Loss: 0.5152, Time: 3.3097 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [215/809], Loss: 0.8874, Time: 3.3135 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [220/809], Loss: 0.4671, Time: 3.3174 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [225/809], Loss: 0.4570, Time: 3.3212 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [230/809], Loss: 0.4203, Time: 3.3250 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [235/809], Loss: 1.2706, Time: 3.3287 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [240/809], Loss: 0.4568, Time: 3.3325 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [245/809], Loss: 0.4487, Time: 3.3363 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [250/809], Loss: 1.1268, Time: 3.3401 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [255/809], Loss: 0.4353, Time: 3.3439 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [260/809], Loss: 0.5208, Time: 3.3477 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [265/809], Loss: 0.4611, Time: 3.3515 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [270/809], Loss: 0.4900, Time: 3.3553 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [275/809], Loss: 0.5119, Time: 3.3591 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [280/809], Loss: 0.4569, Time: 3.3628 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [285/809], Loss: 0.4868, Time: 3.3666 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [290/809], Loss: 0.4784, Time: 3.3704 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [295/809], Loss: 0.5046, Time: 3.3742 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [300/809], Loss: 0.4350, Time: 3.3780 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [305/809], Loss: 0.4459, Time: 3.3818 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [310/809], Loss: 0.4538, Time: 3.3856 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [315/809], Loss: 1.1279, Time: 3.3893 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [320/809], Loss: 0.4936, Time: 3.3931 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [325/809], Loss: 0.4814, Time: 3.3969 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [330/809], Loss: 0.4746, Time: 3.4007 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [335/809], Loss: 0.4735, Time: 3.4045 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [340/809], Loss: 0.7022, Time: 3.4082 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [345/809], Loss: 0.5295, Time: 3.4120 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [350/809], Loss: 0.4746, Time: 3.4158 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [355/809], Loss: 0.4845, Time: 3.4200 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [360/809], Loss: 0.5238, Time: 3.4240 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [365/809], Loss: 0.4597, Time: 3.4277 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [370/809], Loss: 0.5493, Time: 3.4315 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [375/809], Loss: 704142.1250, Time: 3.4355 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [380/809], Loss: 0.4986, Time: 3.4393 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [385/809], Loss: 0.4678, Time: 3.4430 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [390/809], Loss: 0.4183, Time: 3.4468 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [395/809], Loss: 0.4272, Time: 3.4507 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [400/809], Loss: 0.4831, Time: 3.4544 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [405/809], Loss: 1023240.2500, Time: 3.4582 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [410/809], Loss: 0.9541, Time: 3.4620 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [415/809], Loss: 0.4817, Time: 3.4658 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [420/809], Loss: 1.1820, Time: 3.4696 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [425/809], Loss: 0.4903, Time: 3.4734 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [430/809], Loss: 0.4611, Time: 3.4771 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [435/809], Loss: 0.4546, Time: 3.4809 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [440/809], Loss: 0.4191, Time: 3.4853 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [445/809], Loss: 0.4461, Time: 3.4895 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [450/809], Loss: 0.4223, Time: 3.4937 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [455/809], Loss: 0.4453, Time: 3.4989 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [460/809], Loss: 0.4688, Time: 3.5041 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [465/809], Loss: 0.4919, Time: 3.5080 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [470/809], Loss: 0.4408, Time: 3.5117 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [475/809], Loss: 0.4597, Time: 3.5155 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [480/809], Loss: 0.4344, Time: 3.5193 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [485/809], Loss: 0.4127, Time: 3.5231 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [490/809], Loss: 0.6428, Time: 3.5269 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [495/809], Loss: 0.4902, Time: 3.5306 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [500/809], Loss: 0.4511, Time: 3.5345 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [505/809], Loss: 0.4451, Time: 3.5383 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [510/809], Loss: 0.4791, Time: 3.5420 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [515/809], Loss: 0.4839, Time: 3.5458 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [520/809], Loss: 0.4811, Time: 3.5495 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [525/809], Loss: 0.4997, Time: 3.5534 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [530/809], Loss: 0.4837, Time: 3.5571 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [535/809], Loss: 0.4873, Time: 3.5609 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [540/809], Loss: 0.5026, Time: 3.5647 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [545/809], Loss: 0.4476, Time: 3.5686 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [550/809], Loss: 0.5044, Time: 3.5723 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [555/809], Loss: 0.4701, Time: 3.5761 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [560/809], Loss: 0.4737, Time: 3.5798 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [565/809], Loss: 0.4470, Time: 3.5836 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [570/809], Loss: 0.4914, Time: 3.5875 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [575/809], Loss: 0.4282, Time: 3.5912 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [580/809], Loss: 0.4897, Time: 3.5950 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [585/809], Loss: 0.5041, Time: 3.5987 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [590/809], Loss: 0.7055, Time: 3.6026 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [595/809], Loss: 0.4426, Time: 3.6064 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [600/809], Loss: 0.5234, Time: 3.6101 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [605/809], Loss: 0.5220, Time: 3.6139 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [610/809], Loss: 0.4747, Time: 3.6178 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [615/809], Loss: 0.4620, Time: 3.6216 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [620/809], Loss: 0.7412, Time: 3.6255 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [625/809], Loss: 0.4391, Time: 3.6293 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [630/809], Loss: 0.4886, Time: 3.6331 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [635/809], Loss: 1.0218, Time: 3.6370 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [640/809], Loss: 0.4387, Time: 3.6408 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [645/809], Loss: 0.7467, Time: 3.6445 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [650/809], Loss: 0.4653, Time: 3.6483 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [655/809], Loss: 0.4464, Time: 3.6521 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [660/809], Loss: 0.6942, Time: 3.6558 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [665/809], Loss: 0.4953, Time: 3.6596 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [670/809], Loss: 0.9933, Time: 3.6633 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [675/809], Loss: 0.4361, Time: 3.6673 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [680/809], Loss: 0.4814, Time: 3.6710 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [685/809], Loss: 0.4576, Time: 3.6747 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [690/809], Loss: 0.4837, Time: 3.6785 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [695/809], Loss: 0.4241, Time: 3.6823 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [700/809], Loss: 0.4431, Time: 3.6860 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [705/809], Loss: 0.4586, Time: 3.6898 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [710/809], Loss: 0.4969, Time: 3.6938 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [715/809], Loss: 0.4169, Time: 3.6982 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [720/809], Loss: 0.4339, Time: 3.7020 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [725/809], Loss: 0.4559, Time: 3.7058 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [730/809], Loss: 0.4753, Time: 3.7103 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [735/809], Loss: 0.4930, Time: 3.7144 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [740/809], Loss: 0.4752, Time: 3.7181 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [745/809], Loss: 0.4770, Time: 3.7218 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [750/809], Loss: 0.9358, Time: 3.7256 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [755/809], Loss: 0.7077, Time: 3.7293 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [760/809], Loss: 0.6446, Time: 3.7331 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [765/809], Loss: 0.5027, Time: 3.7368 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [770/809], Loss: 0.4542, Time: 3.7406 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [775/809], Loss: 0.5033, Time: 3.7445 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [780/809], Loss: 0.5308, Time: 3.7483 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [785/809], Loss: 0.4283, Time: 3.7522 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [790/809], Loss: 0.5023, Time: 3.7560 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [795/809], Loss: 0.4628, Time: 3.7597 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [800/809], Loss: 0.4409, Time: 3.7635 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [805/809], Loss: 0.4624, Time: 3.7674 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [5/809], Loss: 0.5167, Time: 3.8940 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [10/809], Loss: 0.4723, Time: 3.8988 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [15/809], Loss: 0.4599, Time: 3.9039 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [20/809], Loss: 0.4938, Time: 3.9089 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [25/809], Loss: 0.4832, Time: 3.9135 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [30/809], Loss: 0.4818, Time: 3.9174 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [35/809], Loss: 0.4659, Time: 3.9212 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [40/809], Loss: 0.4128, Time: 3.9250 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [45/809], Loss: 0.4804, Time: 3.9287 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [50/809], Loss: 0.7431, Time: 3.9325 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [55/809], Loss: 0.4658, Time: 3.9363 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [60/809], Loss: 0.4518, Time: 3.9401 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [65/809], Loss: 0.4694, Time: 3.9438 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [70/809], Loss: 0.4672, Time: 3.9476 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [75/809], Loss: 0.4687, Time: 3.9514 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [80/809], Loss: 0.9941, Time: 3.9552 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [85/809], Loss: 0.4334, Time: 3.9589 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [90/809], Loss: 0.4818, Time: 3.9627 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [95/809], Loss: 0.4755, Time: 3.9664 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [100/809], Loss: 0.5100, Time: 3.9703 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [105/809], Loss: 0.8954, Time: 3.9741 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [110/809], Loss: 0.5006, Time: 3.9778 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [115/809], Loss: 0.5142, Time: 3.9816 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [120/809], Loss: 0.4868, Time: 3.9855 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [125/809], Loss: 0.8591, Time: 3.9893 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [130/809], Loss: 0.4785, Time: 3.9930 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [135/809], Loss: 0.4616, Time: 3.9967 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [140/809], Loss: 0.4230, Time: 4.0007 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [145/809], Loss: 0.4725, Time: 4.0050 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [150/809], Loss: 0.5017, Time: 4.0093 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [155/809], Loss: 0.5559, Time: 4.0137 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [160/809], Loss: 0.4480, Time: 4.0179 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [165/809], Loss: 0.4324, Time: 4.0217 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [170/809], Loss: 1.4144, Time: 4.0255 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [175/809], Loss: 0.6001, Time: 4.0292 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [180/809], Loss: 0.6960, Time: 4.0329 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [185/809], Loss: 0.4155, Time: 4.0368 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [190/809], Loss: 0.4914, Time: 4.0406 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [195/809], Loss: 0.4621, Time: 4.0444 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [200/809], Loss: 0.4941, Time: 4.0482 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [205/809], Loss: 0.4604, Time: 4.0521 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [210/809], Loss: 0.4966, Time: 4.0559 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [215/809], Loss: 0.4387, Time: 4.0596 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [220/809], Loss: 0.4224, Time: 4.0634 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [225/809], Loss: 0.6171, Time: 4.0673 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [230/809], Loss: 0.4415, Time: 4.0711 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [235/809], Loss: 1.0141, Time: 4.0748 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [240/809], Loss: 0.4970, Time: 4.0786 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [245/809], Loss: 0.4712, Time: 4.0823 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [250/809], Loss: 0.4813, Time: 4.0862 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [255/809], Loss: 0.4252, Time: 4.0900 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [260/809], Loss: 0.5111, Time: 4.0937 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [265/809], Loss: 0.4744, Time: 4.0977 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [270/809], Loss: 0.4539, Time: 4.1017 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [275/809], Loss: 0.4428, Time: 4.1055 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [280/809], Loss: 0.7672, Time: 4.1093 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [285/809], Loss: 0.5615, Time: 4.1131 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [290/809], Loss: 0.4458, Time: 4.1169 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [295/809], Loss: 0.7013, Time: 4.1208 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [300/809], Loss: 0.7749, Time: 4.1246 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [305/809], Loss: 0.4749, Time: 4.1284 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [310/809], Loss: 0.4623, Time: 4.1322 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [315/809], Loss: 0.4347, Time: 4.1361 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [320/809], Loss: 0.4356, Time: 4.1399 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [325/809], Loss: 0.4567, Time: 4.1436 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [330/809], Loss: 0.5063, Time: 4.1474 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [335/809], Loss: 0.4713, Time: 4.1513 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [340/809], Loss: 0.4929, Time: 4.1551 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [345/809], Loss: 0.6247, Time: 4.1588 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [350/809], Loss: 0.4926, Time: 4.1626 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [355/809], Loss: 0.4374, Time: 4.1663 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [360/809], Loss: 0.4571, Time: 4.1703 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [365/809], Loss: 0.5343, Time: 4.1740 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [370/809], Loss: 0.4339, Time: 4.1778 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [375/809], Loss: 0.4547, Time: 4.1815 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [380/809], Loss: 0.4569, Time: 4.1855 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [385/809], Loss: 0.4533, Time: 4.1893 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [390/809], Loss: 0.4195, Time: 4.1931 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [395/809], Loss: 0.4518, Time: 4.1968 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [400/809], Loss: 0.4632, Time: 4.2007 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [405/809], Loss: 0.4631, Time: 4.2045 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [410/809], Loss: 0.9078, Time: 4.2082 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [415/809], Loss: 0.5599, Time: 4.2120 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [420/809], Loss: 0.4627, Time: 4.2158 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [425/809], Loss: 0.5211, Time: 4.2196 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [430/809], Loss: 1.3565, Time: 4.2234 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [435/809], Loss: 0.5229, Time: 4.2271 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [440/809], Loss: 0.4502, Time: 4.2309 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [445/809], Loss: 0.4920, Time: 4.2348 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [450/809], Loss: 0.8118, Time: 4.2385 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [455/809], Loss: 0.4583, Time: 4.2423 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [460/809], Loss: 0.8009, Time: 4.2461 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [465/809], Loss: 0.4918, Time: 4.2498 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [470/809], Loss: 0.4648, Time: 4.2537 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [475/809], Loss: 0.4243, Time: 4.2574 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [480/809], Loss: 0.4875, Time: 4.2611 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [485/809], Loss: 0.4901, Time: 4.2649 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [490/809], Loss: 0.5227, Time: 4.2688 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [495/809], Loss: 0.4609, Time: 4.2726 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [500/809], Loss: 0.4801, Time: 4.2763 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [505/809], Loss: 0.4519, Time: 4.2801 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [510/809], Loss: 0.4377, Time: 4.2840 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [515/809], Loss: 0.4950, Time: 4.2877 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [520/809], Loss: 0.4416, Time: 4.2915 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [525/809], Loss: 0.4829, Time: 4.2953 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [530/809], Loss: 1.7814, Time: 4.2993 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [535/809], Loss: 0.4681, Time: 4.3032 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [540/809], Loss: 0.6972, Time: 4.3071 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [545/809], Loss: 0.5010, Time: 4.3108 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [550/809], Loss: 0.4833, Time: 4.3147 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [555/809], Loss: 0.4692, Time: 4.3186 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [560/809], Loss: 0.6183, Time: 4.3224 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [565/809], Loss: 0.4398, Time: 4.3261 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [570/809], Loss: 0.5245, Time: 4.3299 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [575/809], Loss: 0.4848, Time: 4.3346 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [580/809], Loss: 0.4689, Time: 4.3389 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [585/809], Loss: 0.4742, Time: 4.3431 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [590/809], Loss: 0.6944, Time: 4.3472 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [595/809], Loss: 0.4334, Time: 4.3512 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [600/809], Loss: 0.7802, Time: 4.3549 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [605/809], Loss: 0.9159, Time: 4.3587 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [610/809], Loss: 0.4587, Time: 4.3624 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [615/809], Loss: 0.4962, Time: 4.3662 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [620/809], Loss: 0.4497, Time: 4.3701 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [625/809], Loss: 0.4553, Time: 4.3738 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [630/809], Loss: 0.4685, Time: 4.3776 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [635/809], Loss: 0.4728, Time: 4.3814 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [640/809], Loss: 0.4609, Time: 4.3853 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [645/809], Loss: 0.4643, Time: 4.3890 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [650/809], Loss: 0.4152, Time: 4.3928 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [655/809], Loss: 0.6440, Time: 4.3965 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [660/809], Loss: 0.4331, Time: 4.4003 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [665/809], Loss: 0.7219, Time: 4.4042 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [670/809], Loss: 0.4721, Time: 4.4080 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [675/809], Loss: 0.4474, Time: 4.4118 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [680/809], Loss: 0.4659, Time: 4.4155 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [685/809], Loss: 0.4494, Time: 4.4194 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [690/809], Loss: 0.4155, Time: 4.4232 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [695/809], Loss: 0.4728, Time: 4.4270 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [700/809], Loss: 0.4683, Time: 4.4307 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [705/809], Loss: 0.4466, Time: 4.4346 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [710/809], Loss: 0.4946, Time: 4.4384 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [715/809], Loss: 0.4712, Time: 4.4421 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [720/809], Loss: 0.4715, Time: 4.4459 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [725/809], Loss: 0.4456, Time: 4.4497 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [730/809], Loss: 0.4676, Time: 4.4536 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [735/809], Loss: 0.4499, Time: 4.4574 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [740/809], Loss: 0.4598, Time: 4.4612 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [745/809], Loss: 0.4560, Time: 4.4649 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [750/809], Loss: 0.4572, Time: 4.4688 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [755/809], Loss: 0.4919, Time: 4.4726 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [760/809], Loss: 0.4778, Time: 4.4763 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [765/809], Loss: 0.4733, Time: 4.4801 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [770/809], Loss: 0.4936, Time: 4.4840 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [775/809], Loss: 0.4522, Time: 4.4878 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [780/809], Loss: 0.4408, Time: 4.4915 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [785/809], Loss: 0.4740, Time: 4.4953 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [790/809], Loss: 0.4578, Time: 4.4991 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [795/809], Loss: 0.4547, Time: 4.5030 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [800/809], Loss: 0.4311, Time: 4.5070 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [805/809], Loss: 0.4555, Time: 4.5108 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [5/809], Loss: 0.5070, Time: 4.6377 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [10/809], Loss: 0.5173, Time: 4.6422 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [15/809], Loss: 0.4550, Time: 4.6473 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [20/809], Loss: 0.4733, Time: 4.6521 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [25/809], Loss: 0.4375, Time: 4.6561 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [30/809], Loss: 0.6224, Time: 4.6598 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [35/809], Loss: 0.7042, Time: 4.6636 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [40/809], Loss: 0.4328, Time: 4.6674 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [45/809], Loss: 0.7226, Time: 4.6712 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [50/809], Loss: 0.4613, Time: 4.6753 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [55/809], Loss: 0.4874, Time: 4.6797 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [60/809], Loss: 0.4738, Time: 4.6840 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [65/809], Loss: 0.4714, Time: 4.6882 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [70/809], Loss: 0.5996, Time: 4.6922 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [75/809], Loss: 0.5110, Time: 4.6960 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [80/809], Loss: 0.4511, Time: 4.6999 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [85/809], Loss: 0.4338, Time: 4.7042 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [90/809], Loss: 0.4756, Time: 4.7081 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [95/809], Loss: 0.5082, Time: 4.7119 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [100/809], Loss: 0.6728, Time: 4.7157 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [105/809], Loss: 0.4741, Time: 4.7196 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [110/809], Loss: 0.4640, Time: 4.7233 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [115/809], Loss: 0.4249, Time: 4.7271 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [120/809], Loss: 0.5706, Time: 4.7309 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [125/809], Loss: 0.5218, Time: 4.7348 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [130/809], Loss: 0.3936, Time: 4.7385 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [135/809], Loss: 0.4668, Time: 4.7423 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [140/809], Loss: 0.5311, Time: 4.7461 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [145/809], Loss: 0.4403, Time: 4.7498 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [150/809], Loss: 0.5459, Time: 4.7536 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [155/809], Loss: 0.4559, Time: 4.7574 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [160/809], Loss: 0.3966, Time: 4.7611 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [165/809], Loss: 0.4761, Time: 4.7649 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [170/809], Loss: 0.5032, Time: 4.7686 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [175/809], Loss: 0.6864, Time: 4.7724 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [180/809], Loss: 0.4749, Time: 4.7761 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [185/809], Loss: 0.4539, Time: 4.7799 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [190/809], Loss: 0.4151, Time: 4.7836 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [195/809], Loss: 0.4507, Time: 4.7873 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [200/809], Loss: 0.4480, Time: 4.7911 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [205/809], Loss: 0.4069, Time: 4.7949 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [210/809], Loss: 0.5481, Time: 4.7987 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [215/809], Loss: 0.4337, Time: 4.8026 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [220/809], Loss: 0.5034, Time: 4.8064 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [225/809], Loss: 0.5919, Time: 4.8101 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [230/809], Loss: 0.6147, Time: 4.8139 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [235/809], Loss: 0.5924, Time: 4.8182 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [240/809], Loss: 0.4795, Time: 4.8227 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [245/809], Loss: 0.4685, Time: 4.8269 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [250/809], Loss: 0.5896, Time: 4.8309 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [255/809], Loss: 0.4947, Time: 4.8348 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [260/809], Loss: 0.4088, Time: 4.8386 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [265/809], Loss: 0.4232, Time: 4.8423 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [270/809], Loss: 0.5170, Time: 4.8461 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [275/809], Loss: 0.5031, Time: 4.8498 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [280/809], Loss: 0.4193, Time: 4.8537 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [285/809], Loss: 0.4819, Time: 4.8574 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [290/809], Loss: 0.4126, Time: 4.8612 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [295/809], Loss: 0.4395, Time: 4.8649 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [300/809], Loss: 0.4922, Time: 4.8688 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [305/809], Loss: 0.4853, Time: 4.8726 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [310/809], Loss: 0.5024, Time: 4.8764 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [315/809], Loss: 0.5205, Time: 4.8802 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [320/809], Loss: 0.4337, Time: 4.8840 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [325/809], Loss: 0.4531, Time: 4.8878 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [330/809], Loss: 0.4874, Time: 4.8916 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [335/809], Loss: 0.4702, Time: 4.8954 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [340/809], Loss: 0.5229, Time: 4.8991 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [345/809], Loss: 0.4614, Time: 4.9029 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [350/809], Loss: 0.4114, Time: 4.9069 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [355/809], Loss: 0.4847, Time: 4.9108 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [360/809], Loss: 0.4734, Time: 4.9146 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [365/809], Loss: 0.4916, Time: 4.9185 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [370/809], Loss: 0.4592, Time: 4.9223 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [375/809], Loss: 0.4506, Time: 4.9261 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [380/809], Loss: 0.4395, Time: 4.9299 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [385/809], Loss: 0.4332, Time: 4.9337 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [390/809], Loss: 0.4518, Time: 4.9376 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [395/809], Loss: 0.6316, Time: 4.9413 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [400/809], Loss: 0.4885, Time: 4.9451 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [405/809], Loss: 0.4801, Time: 4.9489 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [410/809], Loss: 0.4010, Time: 4.9527 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [415/809], Loss: 0.4226, Time: 4.9565 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [420/809], Loss: 0.4456, Time: 4.9603 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [425/809], Loss: 0.4430, Time: 4.9641 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [430/809], Loss: 0.4640, Time: 4.9680 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [435/809], Loss: 0.4259, Time: 4.9718 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [440/809], Loss: 0.4993, Time: 4.9756 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [445/809], Loss: 0.4548, Time: 4.9793 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [450/809], Loss: 0.4604, Time: 4.9831 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [455/809], Loss: 0.4456, Time: 4.9870 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [460/809], Loss: 0.4656, Time: 4.9908 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [465/809], Loss: 0.4961, Time: 4.9945 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [470/809], Loss: 0.4779, Time: 4.9983 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [475/809], Loss: 0.4793, Time: 5.0022 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [480/809], Loss: 0.4750, Time: 5.0060 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [485/809], Loss: 0.4575, Time: 5.0098 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [490/809], Loss: 0.5277, Time: 5.0135 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [495/809], Loss: 0.4666, Time: 5.0174 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [500/809], Loss: 0.4993, Time: 5.0211 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [505/809], Loss: 0.4752, Time: 5.0249 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [510/809], Loss: 0.4021, Time: 5.0286 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [515/809], Loss: 0.4804, Time: 5.0324 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [520/809], Loss: 0.3974, Time: 5.0362 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [525/809], Loss: 0.4476, Time: 5.0400 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [530/809], Loss: 0.4861, Time: 5.0438 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [535/809], Loss: 0.4139, Time: 5.0475 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [540/809], Loss: 0.5439, Time: 5.0514 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [545/809], Loss: 0.4863, Time: 5.0552 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [550/809], Loss: 0.4496, Time: 5.0589 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [555/809], Loss: 0.4930, Time: 5.0627 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [560/809], Loss: 0.5960, Time: 5.0664 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [565/809], Loss: 0.4607, Time: 5.0703 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [570/809], Loss: 0.4603, Time: 5.0741 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [575/809], Loss: 0.5217, Time: 5.0779 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [580/809], Loss: 0.4583, Time: 5.0816 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [585/809], Loss: 0.4659, Time: 5.0855 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [590/809], Loss: 0.4485, Time: 5.0893 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [595/809], Loss: 0.4639, Time: 5.0930 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [600/809], Loss: 0.4404, Time: 5.0968 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [605/809], Loss: 0.4563, Time: 5.1007 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [610/809], Loss: 0.4339, Time: 5.1044 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [615/809], Loss: 0.4372, Time: 5.1084 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [620/809], Loss: 0.4920, Time: 5.1122 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [625/809], Loss: 0.6307, Time: 5.1160 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [630/809], Loss: 0.4140, Time: 5.1199 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [635/809], Loss: 0.4680, Time: 5.1237 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [640/809], Loss: 0.4575, Time: 5.1275 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [645/809], Loss: 0.4493, Time: 5.1314 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [650/809], Loss: 0.4927, Time: 5.1353 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [655/809], Loss: 0.4788, Time: 5.1390 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [660/809], Loss: 0.5523, Time: 5.1428 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [665/809], Loss: 0.4443, Time: 5.1466 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [670/809], Loss: 0.4063, Time: 5.1504 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [675/809], Loss: 0.4019, Time: 5.1542 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [680/809], Loss: 0.5850, Time: 5.1580 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [685/809], Loss: 0.4608, Time: 5.1617 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [690/809], Loss: 0.4868, Time: 5.1655 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [695/809], Loss: 0.6103, Time: 5.1694 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [700/809], Loss: 0.4636, Time: 5.1731 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [705/809], Loss: 0.4086, Time: 5.1769 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [710/809], Loss: 0.4813, Time: 5.1807 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [715/809], Loss: 0.5114, Time: 5.1845 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [720/809], Loss: 0.7917, Time: 5.1883 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [725/809], Loss: 0.4189, Time: 5.1920 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [730/809], Loss: 0.4504, Time: 5.1958 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [735/809], Loss: 0.4857, Time: 5.1995 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [740/809], Loss: 0.4496, Time: 5.2037 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [745/809], Loss: 0.4383, Time: 5.2082 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [750/809], Loss: 0.5078, Time: 5.2123 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [755/809], Loss: 0.4187, Time: 5.2166 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [760/809], Loss: 0.4923, Time: 5.2205 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [765/809], Loss: 0.4191, Time: 5.2243 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [770/809], Loss: 0.4465, Time: 5.2281 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [775/809], Loss: 0.4689, Time: 5.2318 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [780/809], Loss: 618273.8750, Time: 5.2356 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [785/809], Loss: 0.4658, Time: 5.2393 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [790/809], Loss: 0.4520, Time: 5.2431 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [795/809], Loss: 0.4422, Time: 5.2469 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [800/809], Loss: 0.4411, Time: 5.2507 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [805/809], Loss: 0.4580, Time: 5.2545 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [5/809], Loss: 0.4526, Time: 5.3812 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [10/809], Loss: 0.4549, Time: 5.3864 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [15/809], Loss: 0.4821, Time: 5.3908 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [20/809], Loss: 0.4357, Time: 5.3949 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [25/809], Loss: 0.5045, Time: 5.3987 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [30/809], Loss: 0.4731, Time: 5.4027 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [35/809], Loss: 0.4551, Time: 5.4064 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [40/809], Loss: 0.4475, Time: 5.4102 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [45/809], Loss: 0.4236, Time: 5.4139 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [50/809], Loss: 0.5391, Time: 5.4178 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [55/809], Loss: 0.4856, Time: 5.4216 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [60/809], Loss: 0.4309, Time: 5.4253 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [65/809], Loss: 0.4029, Time: 5.4291 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [70/809], Loss: 0.4376, Time: 5.4329 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [75/809], Loss: 0.4472, Time: 5.4368 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [80/809], Loss: 0.5163, Time: 5.4405 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [85/809], Loss: 0.4767, Time: 5.4443 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [90/809], Loss: 0.4432, Time: 5.4481 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [95/809], Loss: 0.4287, Time: 5.4520 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [100/809], Loss: 0.4542, Time: 5.4557 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [105/809], Loss: 0.4501, Time: 5.4595 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [110/809], Loss: 0.4457, Time: 5.4632 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [115/809], Loss: 0.4621, Time: 5.4670 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [120/809], Loss: 0.4881, Time: 5.4709 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [125/809], Loss: 0.4526, Time: 5.4746 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [130/809], Loss: 0.4775, Time: 5.4783 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [135/809], Loss: 0.5456, Time: 5.4821 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [140/809], Loss: 0.4795, Time: 5.4860 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [145/809], Loss: 0.4555, Time: 5.4897 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [150/809], Loss: 0.4842, Time: 5.4935 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [155/809], Loss: 0.4179, Time: 5.4972 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [160/809], Loss: 0.4579, Time: 5.5012 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [165/809], Loss: 0.4453, Time: 5.5049 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [170/809], Loss: 0.4621, Time: 5.5087 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [175/809], Loss: 0.5028, Time: 5.5125 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [180/809], Loss: 0.4376, Time: 5.5162 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [185/809], Loss: 0.4687, Time: 5.5201 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [190/809], Loss: 0.4846, Time: 5.5239 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [195/809], Loss: 0.4414, Time: 5.5276 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [200/809], Loss: 0.4222, Time: 5.5314 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [205/809], Loss: 0.5116, Time: 5.5353 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [210/809], Loss: 0.4271, Time: 5.5390 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [215/809], Loss: 0.4123, Time: 5.5428 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [220/809], Loss: 0.4666, Time: 5.5465 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [225/809], Loss: 0.4155, Time: 5.5503 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [230/809], Loss: 0.4516, Time: 5.5541 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [235/809], Loss: 0.4623, Time: 5.5579 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [240/809], Loss: 0.4463, Time: 5.5616 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [245/809], Loss: 0.4629, Time: 5.5654 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [250/809], Loss: 0.4464, Time: 5.5693 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [255/809], Loss: 0.4358, Time: 5.5730 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [260/809], Loss: 0.4683, Time: 5.5768 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [265/809], Loss: 0.4876, Time: 5.5805 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [270/809], Loss: 0.4531, Time: 5.5847 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [275/809], Loss: 0.4868, Time: 5.5885 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [280/809], Loss: 0.3976, Time: 5.5923 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [285/809], Loss: 0.4950, Time: 5.5961 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [290/809], Loss: 0.5206, Time: 5.5998 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [295/809], Loss: 0.4245, Time: 5.6037 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [300/809], Loss: 0.4244, Time: 5.6074 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [305/809], Loss: 0.4586, Time: 5.6112 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [310/809], Loss: 0.3849, Time: 5.6149 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [315/809], Loss: 0.4627, Time: 5.6188 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [320/809], Loss: 0.4264, Time: 5.6226 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [325/809], Loss: 0.4843, Time: 5.6264 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [330/809], Loss: 0.4211, Time: 5.6301 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [335/809], Loss: 0.4843, Time: 5.6340 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [340/809], Loss: 0.4576, Time: 5.6378 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [345/809], Loss: 0.3983, Time: 5.6415 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [350/809], Loss: 0.4517, Time: 5.6453 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [355/809], Loss: 0.4665, Time: 5.6490 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [360/809], Loss: 0.4417, Time: 5.6529 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [365/809], Loss: 0.4310, Time: 5.6567 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [370/809], Loss: 0.4907, Time: 5.6604 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [375/809], Loss: 0.4105, Time: 5.6642 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [380/809], Loss: 0.4626, Time: 5.6681 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [385/809], Loss: 0.4711, Time: 5.6719 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [390/809], Loss: 16.3783, Time: 5.6757 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [395/809], Loss: 0.4526, Time: 5.6795 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [400/809], Loss: 0.4707, Time: 5.6833 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [405/809], Loss: 0.3938, Time: 5.6871 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [410/809], Loss: 0.4445, Time: 5.6908 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [415/809], Loss: 0.4560, Time: 5.6946 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [420/809], Loss: 0.5533, Time: 5.6983 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [425/809], Loss: 0.4190, Time: 5.7022 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [430/809], Loss: 0.4103, Time: 5.7060 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [435/809], Loss: 0.3997, Time: 5.7097 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [440/809], Loss: 0.3998, Time: 5.7135 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [445/809], Loss: 0.4554, Time: 5.7174 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [450/809], Loss: 0.4406, Time: 5.7211 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [455/809], Loss: 0.4179, Time: 5.7248 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [460/809], Loss: 0.4159, Time: 5.7286 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [465/809], Loss: 0.4530, Time: 5.7324 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [470/809], Loss: 0.4133, Time: 5.7363 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [475/809], Loss: 0.4264, Time: 5.7400 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [480/809], Loss: 0.5155, Time: 5.7438 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [485/809], Loss: 0.4263, Time: 5.7475 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [490/809], Loss: 0.4525, Time: 5.7514 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [495/809], Loss: 0.4511, Time: 5.7552 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [500/809], Loss: 0.4598, Time: 5.7589 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [505/809], Loss: 0.4591, Time: 5.7627 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [510/809], Loss: 0.4628, Time: 5.7664 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [515/809], Loss: 0.4566, Time: 5.7703 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [520/809], Loss: 0.5029, Time: 5.7741 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [525/809], Loss: 0.4255, Time: 5.7778 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [530/809], Loss: 0.4118, Time: 5.7816 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [535/809], Loss: 0.4574, Time: 5.7857 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [540/809], Loss: 0.4481, Time: 5.7895 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [545/809], Loss: 0.4510, Time: 5.7932 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [550/809], Loss: 0.4838, Time: 5.7970 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [555/809], Loss: 0.4587, Time: 5.8010 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [560/809], Loss: 0.4457, Time: 5.8047 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [565/809], Loss: 0.4302, Time: 5.8085 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [570/809], Loss: 834864.7500, Time: 5.8123 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [575/809], Loss: 0.4553, Time: 5.8160 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [580/809], Loss: 0.5145, Time: 5.8197 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [585/809], Loss: 0.5876, Time: 5.8235 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [590/809], Loss: 0.4308, Time: 5.8272 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [595/809], Loss: 0.4211, Time: 5.8310 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [600/809], Loss: 0.4885, Time: 5.8347 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [605/809], Loss: 0.4992, Time: 5.8384 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [610/809], Loss: 0.4127, Time: 5.8428 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [615/809], Loss: 0.4920, Time: 5.8474 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [620/809], Loss: 0.4395, Time: 5.8520 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [625/809], Loss: 0.4221, Time: 5.8558 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [630/809], Loss: 0.4333, Time: 5.8595 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [635/809], Loss: 0.4875, Time: 5.8634 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [640/809], Loss: 0.4053, Time: 5.8671 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [645/809], Loss: 0.4127, Time: 5.8710 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [650/809], Loss: 0.4076, Time: 5.8748 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [655/809], Loss: 0.4479, Time: 5.8785 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [660/809], Loss: 0.3891, Time: 5.8823 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [665/809], Loss: 0.4281, Time: 5.8862 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [670/809], Loss: 0.4147, Time: 5.8900 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [675/809], Loss: 0.4317, Time: 5.8937 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [680/809], Loss: 0.4014, Time: 5.8975 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [685/809], Loss: 0.3911, Time: 5.9014 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [690/809], Loss: 0.4427, Time: 5.9052 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [695/809], Loss: 0.4347, Time: 5.9090 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [700/809], Loss: 0.4577, Time: 5.9127 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [705/809], Loss: 0.4207, Time: 5.9165 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [710/809], Loss: 0.4015, Time: 5.9203 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [715/809], Loss: 0.4338, Time: 5.9241 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [720/809], Loss: 0.4446, Time: 5.9278 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [725/809], Loss: 0.4364, Time: 5.9316 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [730/809], Loss: 101.7756, Time: 5.9355 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [735/809], Loss: 0.4670, Time: 5.9392 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [740/809], Loss: 0.4567, Time: 5.9430 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [745/809], Loss: 0.4138, Time: 5.9468 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [750/809], Loss: 0.4201, Time: 5.9507 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [755/809], Loss: 0.4490, Time: 5.9544 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [760/809], Loss: 0.4384, Time: 5.9582 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [765/809], Loss: 0.4298, Time: 5.9619 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [770/809], Loss: 0.4490, Time: 5.9657 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [775/809], Loss: 0.3799, Time: 5.9696 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [780/809], Loss: 0.4099, Time: 5.9733 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [785/809], Loss: 0.3968, Time: 5.9771 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [790/809], Loss: 0.4386, Time: 5.9809 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [795/809], Loss: 0.4030, Time: 5.9848 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [800/809], Loss: 0.4134, Time: 5.9889 secs, learning rate: 0.0100\n",
      "Epoch [8/10], Step [805/809], Loss: 0.4287, Time: 5.9928 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [5/809], Loss: 0.4642, Time: 6.1187 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [10/809], Loss: 0.3913, Time: 6.1237 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [15/809], Loss: 0.4041, Time: 6.1288 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [20/809], Loss: 0.4111, Time: 6.1337 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [25/809], Loss: 0.4478, Time: 6.1380 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [30/809], Loss: 0.4508, Time: 6.1418 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [35/809], Loss: 0.4594, Time: 6.1455 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [40/809], Loss: 0.4479, Time: 6.1493 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [45/809], Loss: 0.4119, Time: 6.1533 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [50/809], Loss: 0.4547, Time: 6.1571 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [55/809], Loss: 0.4451, Time: 6.1608 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [60/809], Loss: 0.3889, Time: 6.1646 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [65/809], Loss: 0.4370, Time: 6.1684 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [70/809], Loss: 0.4403, Time: 6.1722 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [75/809], Loss: 0.3976, Time: 6.1759 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [80/809], Loss: 0.4015, Time: 6.1796 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [85/809], Loss: 0.4413, Time: 6.1834 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [90/809], Loss: 0.4373, Time: 6.1873 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [95/809], Loss: 0.5015, Time: 6.1914 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [100/809], Loss: 0.3968, Time: 6.1953 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [105/809], Loss: 0.4631, Time: 6.1991 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [110/809], Loss: 0.3817, Time: 6.2030 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [115/809], Loss: 0.4097, Time: 6.2069 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [120/809], Loss: 0.4263, Time: 6.2108 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [125/809], Loss: 0.3721, Time: 6.2145 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [130/809], Loss: 0.4418, Time: 6.2184 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [135/809], Loss: 0.4144, Time: 6.2222 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [140/809], Loss: 0.4492, Time: 6.2259 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [145/809], Loss: 0.4175, Time: 6.2297 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [150/809], Loss: 0.4585, Time: 6.2335 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [155/809], Loss: 0.4139, Time: 6.2374 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [160/809], Loss: 0.3879, Time: 6.2412 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [165/809], Loss: 0.3997, Time: 6.2449 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [170/809], Loss: 0.3864, Time: 6.2487 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [175/809], Loss: 0.3904, Time: 6.2526 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [180/809], Loss: 0.4513, Time: 6.2564 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [185/809], Loss: 0.3609, Time: 6.2602 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [190/809], Loss: 0.4070, Time: 6.2640 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [195/809], Loss: 0.4419, Time: 6.2679 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [200/809], Loss: 0.4458, Time: 6.2717 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [205/809], Loss: 0.4295, Time: 6.2754 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [210/809], Loss: 0.4118, Time: 6.2792 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [215/809], Loss: 0.4546, Time: 6.2830 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [220/809], Loss: 0.4286, Time: 6.2868 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [225/809], Loss: 0.4351, Time: 6.2906 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [230/809], Loss: 0.3920, Time: 6.2944 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [235/809], Loss: 0.4443, Time: 6.2981 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [240/809], Loss: 0.4377, Time: 6.3020 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [245/809], Loss: 0.4508, Time: 6.3058 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [250/809], Loss: 0.3909, Time: 6.3095 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [255/809], Loss: 0.4278, Time: 6.3133 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [260/809], Loss: 0.4329, Time: 6.3171 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [265/809], Loss: 0.4150, Time: 6.3209 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [270/809], Loss: 0.3887, Time: 6.3247 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [275/809], Loss: 0.4641, Time: 6.3285 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [280/809], Loss: 0.4569, Time: 6.3322 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [285/809], Loss: 0.3995, Time: 6.3361 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [290/809], Loss: 0.4242, Time: 6.3399 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [295/809], Loss: 0.4115, Time: 6.3436 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [300/809], Loss: 0.4496, Time: 6.3474 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [305/809], Loss: 0.4275, Time: 6.3513 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [310/809], Loss: 0.4049, Time: 6.3551 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [315/809], Loss: 0.3794, Time: 6.3589 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [320/809], Loss: 0.3732, Time: 6.3626 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [325/809], Loss: 0.4291, Time: 6.3664 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [330/809], Loss: 0.4243, Time: 6.3703 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [335/809], Loss: 0.4301, Time: 6.3741 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [340/809], Loss: 0.4089, Time: 6.3779 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [345/809], Loss: 0.4045, Time: 6.3817 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [350/809], Loss: 0.4491, Time: 6.3855 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [355/809], Loss: 0.4136, Time: 6.3893 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [360/809], Loss: 0.4808, Time: 6.3933 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [365/809], Loss: 0.4204, Time: 6.3971 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [370/809], Loss: 0.4618, Time: 6.4010 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [375/809], Loss: 0.4583, Time: 6.4049 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [380/809], Loss: 0.4418, Time: 6.4087 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [385/809], Loss: 0.3945, Time: 6.4125 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [390/809], Loss: 0.4288, Time: 6.4163 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [395/809], Loss: 0.4410, Time: 6.4202 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [400/809], Loss: 0.4191, Time: 6.4240 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [405/809], Loss: 0.4317, Time: 6.4278 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [410/809], Loss: 0.3747, Time: 6.4315 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [415/809], Loss: 0.4405, Time: 6.4355 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [420/809], Loss: 0.4112, Time: 6.4392 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [425/809], Loss: 0.4155, Time: 6.4430 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [430/809], Loss: 0.4732, Time: 6.4468 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [435/809], Loss: 0.4047, Time: 6.4507 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [440/809], Loss: 0.4366, Time: 6.4544 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [445/809], Loss: 0.4198, Time: 6.4582 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [450/809], Loss: 0.3962, Time: 6.4619 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [455/809], Loss: 0.4569, Time: 6.4657 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [460/809], Loss: 0.3987, Time: 6.4696 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [465/809], Loss: 0.4343, Time: 6.4733 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [470/809], Loss: 520871.6875, Time: 6.4771 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [475/809], Loss: 0.4176, Time: 6.4808 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [480/809], Loss: 0.3839, Time: 6.4848 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [485/809], Loss: 0.3944, Time: 6.4885 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [490/809], Loss: 0.4622, Time: 6.4923 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [495/809], Loss: 0.4350, Time: 6.4960 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [500/809], Loss: 0.4223, Time: 6.4998 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [505/809], Loss: 0.3881, Time: 6.5037 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [510/809], Loss: 0.4229, Time: 6.5074 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [515/809], Loss: 0.3968, Time: 6.5112 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [520/809], Loss: 0.3895, Time: 6.5149 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [525/809], Loss: 0.3852, Time: 6.5188 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [530/809], Loss: 0.4123, Time: 6.5226 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [535/809], Loss: 0.4500, Time: 6.5264 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [540/809], Loss: 0.4435, Time: 6.5301 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [545/809], Loss: 0.4123, Time: 6.5340 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [550/809], Loss: 0.4182, Time: 6.5378 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [555/809], Loss: 0.4187, Time: 6.5416 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [560/809], Loss: 0.4500, Time: 6.5453 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [565/809], Loss: 0.4261, Time: 6.5491 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [570/809], Loss: 0.4234, Time: 6.5529 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [575/809], Loss: 0.3980, Time: 6.5567 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [580/809], Loss: 0.4053, Time: 6.5605 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [585/809], Loss: 0.3820, Time: 6.5643 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [590/809], Loss: 0.3669, Time: 6.5681 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [595/809], Loss: 0.4165, Time: 6.5719 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [600/809], Loss: 0.4589, Time: 6.5757 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [605/809], Loss: 0.4271, Time: 6.5794 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [610/809], Loss: 0.4326, Time: 6.5832 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [615/809], Loss: 0.4294, Time: 6.5870 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [620/809], Loss: 0.4325, Time: 6.5908 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [625/809], Loss: 0.3734, Time: 6.5948 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [630/809], Loss: 0.3887, Time: 6.5986 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [635/809], Loss: 0.4383, Time: 6.6025 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [640/809], Loss: 0.4473, Time: 6.6064 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [645/809], Loss: 21.0733, Time: 6.6102 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [650/809], Loss: 0.4277, Time: 6.6141 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [655/809], Loss: 0.4167, Time: 6.6180 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [660/809], Loss: 0.4256, Time: 6.6218 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [665/809], Loss: 0.4007, Time: 6.6256 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [670/809], Loss: 0.3900, Time: 6.6294 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [675/809], Loss: 0.4468, Time: 6.6332 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [680/809], Loss: 0.4099, Time: 6.6371 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [685/809], Loss: 0.4144, Time: 6.6409 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [690/809], Loss: 0.4881, Time: 6.6446 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [695/809], Loss: 0.5000, Time: 6.6484 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [700/809], Loss: 0.3876, Time: 6.6523 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [705/809], Loss: 0.5619, Time: 6.6561 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [710/809], Loss: 0.4208, Time: 6.6599 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [715/809], Loss: 0.5191, Time: 6.6636 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [720/809], Loss: 0.4396, Time: 6.6675 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [725/809], Loss: 0.4698, Time: 6.6712 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [730/809], Loss: 0.4336, Time: 6.6750 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [735/809], Loss: 0.3894, Time: 6.6788 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [740/809], Loss: 0.4485, Time: 6.6825 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [745/809], Loss: 0.4235, Time: 6.6864 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [750/809], Loss: 0.3991, Time: 6.6901 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [755/809], Loss: 0.4574, Time: 6.6939 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [760/809], Loss: 0.4206, Time: 6.6979 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [765/809], Loss: 0.3918, Time: 6.7022 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [770/809], Loss: 0.3925, Time: 6.7066 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [775/809], Loss: 0.4708, Time: 6.7110 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [780/809], Loss: 0.3661, Time: 6.7147 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [785/809], Loss: 0.4147, Time: 6.7187 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [790/809], Loss: 0.4333, Time: 6.7224 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [795/809], Loss: 0.4043, Time: 6.7262 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [800/809], Loss: 0.4144, Time: 6.7300 secs, learning rate: 0.0100\n",
      "Epoch [9/10], Step [805/809], Loss: 0.4458, Time: 6.7340 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [5/809], Loss: 0.4585, Time: 6.8599 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [10/809], Loss: 0.3616, Time: 6.8645 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [15/809], Loss: 0.4139, Time: 6.8682 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [20/809], Loss: 0.4387, Time: 6.8720 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [25/809], Loss: 0.4080, Time: 6.8757 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [30/809], Loss: 0.4479, Time: 6.8795 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [35/809], Loss: 0.4256, Time: 6.8832 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [40/809], Loss: 0.4827, Time: 6.8870 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [45/809], Loss: 0.4476, Time: 6.8907 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [50/809], Loss: 0.3819, Time: 6.8944 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [55/809], Loss: 0.4401, Time: 6.8982 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [60/809], Loss: 0.4140, Time: 6.9021 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [65/809], Loss: 0.4000, Time: 6.9059 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [70/809], Loss: 0.4457, Time: 6.9096 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [75/809], Loss: 0.4675, Time: 6.9134 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [80/809], Loss: 0.3990, Time: 6.9171 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [85/809], Loss: 0.3726, Time: 6.9210 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [90/809], Loss: 0.3910, Time: 6.9248 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [95/809], Loss: 0.4219, Time: 6.9285 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [100/809], Loss: 0.4017, Time: 6.9322 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [105/809], Loss: 0.3907, Time: 6.9361 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [110/809], Loss: 0.4355, Time: 6.9399 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [115/809], Loss: 0.3964, Time: 6.9437 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [120/809], Loss: 0.4696, Time: 6.9474 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [125/809], Loss: 0.4181, Time: 6.9513 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [130/809], Loss: 0.4272, Time: 6.9551 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [135/809], Loss: 0.4545, Time: 6.9588 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [140/809], Loss: 0.4074, Time: 6.9626 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [145/809], Loss: 0.3932, Time: 6.9663 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [150/809], Loss: 0.4141, Time: 6.9702 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [155/809], Loss: 0.4501, Time: 6.9739 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [160/809], Loss: 0.3893, Time: 6.9777 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [165/809], Loss: 0.3683, Time: 6.9814 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [170/809], Loss: 0.4403, Time: 6.9854 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [175/809], Loss: 0.3948, Time: 6.9895 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [180/809], Loss: 0.3922, Time: 6.9935 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [185/809], Loss: 0.4102, Time: 6.9976 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [190/809], Loss: 0.4334, Time: 7.0019 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [195/809], Loss: 0.4338, Time: 7.0060 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [200/809], Loss: 0.4013, Time: 7.0099 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [205/809], Loss: 0.4405, Time: 7.0137 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [210/809], Loss: 0.4035, Time: 7.0176 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [215/809], Loss: 0.3973, Time: 7.0214 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [220/809], Loss: 0.4600, Time: 7.0251 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [225/809], Loss: 0.4304, Time: 7.0289 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [230/809], Loss: 0.3880, Time: 7.0327 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [235/809], Loss: 0.4366, Time: 7.0366 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [240/809], Loss: 0.4228, Time: 7.0403 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [245/809], Loss: 0.4292, Time: 7.0441 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [250/809], Loss: 0.4303, Time: 7.0479 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [255/809], Loss: 0.4120, Time: 7.0518 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [260/809], Loss: 0.3932, Time: 7.0555 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [265/809], Loss: 0.4013, Time: 7.0593 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [270/809], Loss: 0.4014, Time: 7.0633 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [275/809], Loss: 0.4163, Time: 7.0671 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [280/809], Loss: 0.4365, Time: 7.0710 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [285/809], Loss: 0.3888, Time: 7.0748 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [290/809], Loss: 0.3835, Time: 7.0785 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [295/809], Loss: 0.3924, Time: 7.0823 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [300/809], Loss: 0.4313, Time: 7.0862 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [305/809], Loss: 0.4280, Time: 7.0900 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [310/809], Loss: 0.4222, Time: 7.0938 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [315/809], Loss: 0.3741, Time: 7.0975 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [320/809], Loss: 542418.3125, Time: 7.1014 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [325/809], Loss: 0.3733, Time: 7.1052 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [330/809], Loss: 0.3842, Time: 7.1090 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [335/809], Loss: 0.4434, Time: 7.1127 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [340/809], Loss: 0.4459, Time: 7.1165 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [345/809], Loss: 0.4586, Time: 7.1203 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [350/809], Loss: 0.4168, Time: 7.1241 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [355/809], Loss: 0.4210, Time: 7.1278 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [360/809], Loss: 0.4241, Time: 7.1316 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [365/809], Loss: 0.4160, Time: 7.1355 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [370/809], Loss: 0.3845, Time: 7.1393 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [375/809], Loss: 0.4032, Time: 7.1430 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [380/809], Loss: 0.4096, Time: 7.1468 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [385/809], Loss: 0.4422, Time: 7.1507 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [390/809], Loss: 0.4008, Time: 7.1544 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [395/809], Loss: 0.4302, Time: 7.1582 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [400/809], Loss: 0.3999, Time: 7.1619 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [405/809], Loss: 0.4083, Time: 7.1657 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [410/809], Loss: 0.3808, Time: 7.1696 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [415/809], Loss: 0.3965, Time: 7.1734 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [420/809], Loss: 0.4179, Time: 7.1772 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [425/809], Loss: 0.3852, Time: 7.1809 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [430/809], Loss: 0.4236, Time: 7.1848 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [435/809], Loss: 0.4114, Time: 7.1885 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [440/809], Loss: 0.4083, Time: 7.1923 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [445/809], Loss: 0.3876, Time: 7.1960 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [450/809], Loss: 0.4290, Time: 7.1998 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [455/809], Loss: 0.4078, Time: 7.2037 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [460/809], Loss: 0.4050, Time: 7.2075 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [465/809], Loss: 0.3993, Time: 7.2112 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [470/809], Loss: 0.3862, Time: 7.2150 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [475/809], Loss: 0.3950, Time: 7.2189 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [480/809], Loss: 0.3568, Time: 7.2226 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [485/809], Loss: 0.4216, Time: 7.2263 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [490/809], Loss: 0.3480, Time: 7.2301 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [495/809], Loss: 0.4002, Time: 7.2340 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [500/809], Loss: 0.4057, Time: 7.2377 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [505/809], Loss: 0.4094, Time: 7.2415 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [510/809], Loss: 0.3619, Time: 7.2452 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [515/809], Loss: 0.3854, Time: 7.2490 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [520/809], Loss: 0.4005, Time: 7.2529 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [525/809], Loss: 0.3733, Time: 7.2567 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [530/809], Loss: 0.3793, Time: 7.2604 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [535/809], Loss: 0.3972, Time: 7.2644 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [540/809], Loss: 0.3790, Time: 7.2684 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [545/809], Loss: 0.3959, Time: 7.2722 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [550/809], Loss: 0.3610, Time: 7.2759 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [555/809], Loss: 0.4050, Time: 7.2796 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [560/809], Loss: 0.4247, Time: 7.2840 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [565/809], Loss: 0.3667, Time: 7.2882 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [570/809], Loss: 0.3919, Time: 7.2920 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [575/809], Loss: 0.3757, Time: 7.2966 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [580/809], Loss: 0.4625, Time: 7.3013 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [585/809], Loss: 0.4067, Time: 7.3051 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [590/809], Loss: 0.3626, Time: 7.3089 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [595/809], Loss: 0.3842, Time: 7.3127 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [600/809], Loss: 0.4107, Time: 7.3164 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [605/809], Loss: 0.3576, Time: 7.3207 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [610/809], Loss: 0.4110, Time: 7.3252 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [615/809], Loss: 0.3996, Time: 7.3294 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [620/809], Loss: 0.4143, Time: 7.3340 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [625/809], Loss: 0.4202, Time: 7.3378 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [630/809], Loss: 0.3649, Time: 7.3416 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [635/809], Loss: 18.4083, Time: 7.3453 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [640/809], Loss: 0.4244, Time: 7.3491 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [645/809], Loss: 0.4038, Time: 7.3530 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [650/809], Loss: 0.3720, Time: 7.3567 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [655/809], Loss: 0.4022, Time: 7.3605 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [660/809], Loss: 0.5174, Time: 7.3643 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [665/809], Loss: 0.4038, Time: 7.3681 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [670/809], Loss: 0.3628, Time: 7.3719 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [675/809], Loss: 0.4127, Time: 7.3756 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [680/809], Loss: 0.5000, Time: 7.3794 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [685/809], Loss: 0.3662, Time: 7.3831 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [690/809], Loss: 0.5209, Time: 7.3869 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [695/809], Loss: 0.3978, Time: 7.3907 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [700/809], Loss: 0.4362, Time: 7.3945 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [705/809], Loss: 0.3970, Time: 7.3982 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [710/809], Loss: 0.5097, Time: 7.4021 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [715/809], Loss: 0.4228, Time: 7.4059 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [720/809], Loss: 0.3513, Time: 7.4097 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [725/809], Loss: 0.4113, Time: 7.4135 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [730/809], Loss: 0.4237, Time: 7.4172 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [735/809], Loss: 0.4050, Time: 7.4210 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [740/809], Loss: 0.3875, Time: 7.4248 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [745/809], Loss: 0.3932, Time: 7.4285 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [750/809], Loss: 0.4065, Time: 7.4323 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [755/809], Loss: 0.3872, Time: 7.4363 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [760/809], Loss: 0.4600, Time: 7.4400 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [765/809], Loss: 0.3858, Time: 7.4438 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [770/809], Loss: 0.3842, Time: 7.4476 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [775/809], Loss: 0.3881, Time: 7.4513 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [780/809], Loss: 0.3824, Time: 7.4551 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [785/809], Loss: 0.3615, Time: 7.4588 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [790/809], Loss: 0.4077, Time: 7.4626 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [795/809], Loss: 0.3756, Time: 7.4666 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [800/809], Loss: 0.3566, Time: 7.4705 secs, learning rate: 0.0100\n",
      "Epoch [10/10], Step [805/809], Loss: 0.4305, Time: 7.4742 secs, learning rate: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(YTrain)\n",
    "start_time = time.time()\n",
    "model = model.float()\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "loss_tmp = 0\n",
    "norm = 1\n",
    "for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), nn.Sigmoid()(norm*y.float().T))\n",
    "        # print(\"#1\")\n",
    "        # print(norm*y.float().T)\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().T)\n",
    "        loss = criterion(norm*outputs, norm*y.float().T)\n",
    "        # print(f\"{loss=}\")\n",
    "        loss_tmp += loss.item()\n",
    "loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ind = np.arange(int(total_step/batch_size))\n",
    "    random.shuffle(ind)\n",
    "    for i,k in enumerate(ind):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XTrain[k*batch_size:(k+1)*batch_size,:,:,:], YTrain[k*batch_size:(k+1)*batch_size,:]\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x.float())\n",
    "        # loss = criterion(nn.Sigmoid()(norm*y.float()), nn.Sigmoid()(norm*outputs))\n",
    "        # print(\"#2\")\n",
    "        # print(norm*y.float().T)\n",
    "        # loss = criterion(norm*y.float(), nn.Sigmoid()(norm*outputs))\n",
    "        loss = criterion(norm*outputs, norm*y.float().T)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 5== 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs, learning rate: {:.4f}'\n",
    "                    .format(epoch + 1, num_epochs, i + 1, int(total_step/batch_size), loss.item(), time.time() - start_time, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    loss_tmp = 0\n",
    "    result = []\n",
    "    for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        # print(f\"{x.float()=},\")\n",
    "        outputs = model(x.float())\n",
    "        # print(f\"{outputs=},\")\n",
    "        # print(f\"{nn.Sigmoid()(outputs)=},\")\n",
    "        # print(f\"{y.float().T=},\")\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), nn.Sigmoid()(norm*y.float().T))\n",
    "        # print(\"#3\")\n",
    "        # print(f\"{norm*y.float().T=}\")\n",
    "        # print(f\"{nn.Sigmoid()(norm*outputs)=}\")\n",
    "        # print(f\"{outputs=},\")\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().T)\n",
    "        loss = criterion(norm*outputs, norm*y.float().T)\n",
    "        # print(f\"{loss=},\")\n",
    "        loss_tmp += loss.item()\n",
    "        # result.append(nn.Sigmoid()(outputs[0,0]).item())\n",
    "        result.append(outputs[0,0].item())\n",
    "    loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(loss_train)), loss_train, label = 'Training error')\n",
    "plt.plot(np.arange(0, len(loss_train)+1, int(total_step/batch_size)), loss_val, label = 'Validation error')\n",
    "plt.ylabel('loss', fontsize = 14)\n",
    "plt.xlabel('steps', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim([0,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa221ca9de0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(result)), YVal, label = 'Validation')\n",
    "plt.plot(np.arange(len(result)), result, label = 'Training')\n",
    "plt.ylabel('state', fontsize = 14)\n",
    "plt.xlabel('time', fontsize = 14)\n",
    "plt.legend()\n",
    "# plt.ylim([-0.5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
