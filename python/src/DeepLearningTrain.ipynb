{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation.generate_path import generate_path\n",
    "import matplotlib.pyplot as plt\n",
    "from estimation.distance_sensor import distance_sensors\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 1)\n",
      "(4, 3, 3, 576)\n"
     ]
    }
   ],
   "source": [
    "# create test data\n",
    "target_initial_pos = np.array([0, 0, 5000])\n",
    "target_speed_xy = 50\n",
    "target_speed_z = 10\n",
    "target_rot_speed = 3\n",
    "time_res = 0.5\n",
    "\n",
    "path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "path1.add_straight_interval(100)\n",
    "path1.add_xy_turn_interval(90, -np.deg2rad(target_rot_speed))\n",
    "path1.add_straight_interval(100)\n",
    "\n",
    "# create noisy sensors\n",
    "sensors = distance_sensors([[-5000,0,0],[ 400, -7400, 0],[ 800, 800, 0]], 15)\n",
    "sensors.calculate_measurements(path1.path)\n",
    "\n",
    "sample = 3\n",
    "XTest = []\n",
    "for i in np.arange(len(path1.path) - sample + 1):\n",
    "    tmp = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i,:], (1,3))), 0)\n",
    "    tmp = tmp.reshape(4,3,1)\n",
    "    for j in np.arange(1,sample):\n",
    "        matrix = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i+j,:], (1,3))), 0)\n",
    "        matrix = matrix.reshape(4,3,1)\n",
    "        tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "    if i > 0:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = np.concatenate((XTest, tmp), 3)\n",
    "    else:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = tmp\n",
    "\n",
    "YTest = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTest))\n",
    "print(np.shape(XTest))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118784, 1)\n",
      "(4, 3, 3, 118784)\n"
     ]
    }
   ],
   "source": [
    "# create train data\n",
    "run_number = 600\n",
    "XTrain = []\n",
    "YTrain = []\n",
    "for k in np.arange(run_number):\n",
    "    target_initial_pos = np.random.randint(-7000, 7000, size=(1, 3))[0]\n",
    "    sensors_pos = np.random.randint(-7000, 7000, size=(3, 3))[:,:]\n",
    "    target_speed_xy = 50\n",
    "    target_speed_z = 10\n",
    "    target_rot_speed = 3\n",
    "    time_res = 0.5\n",
    "\n",
    "    path1 = generate_path(np.deg2rad(np.random.randint(0,360,size=1)[0]), target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "    path1.add_straight_interval(np.random.randint(0,100,size=1)[0])\n",
    "    path1.add_xy_turn_interval(np.random.randint(0,100,size=1)[0], -random.choice([-1, 1])*np.deg2rad(target_rot_speed))\n",
    "\n",
    "    # create noisy sensors\n",
    "    sensors = distance_sensors(sensors_pos, 20)\n",
    "    sensors.calculate_measurements(path1.path)\n",
    "\n",
    "    sample = 3\n",
    "    for i in np.arange(len(path1.path) - sample + 1):\n",
    "        tmp = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i,:], (1,3))), 0)\n",
    "        tmp = tmp.reshape(4,3,1)\n",
    "        for j in np.arange(1,sample):\n",
    "            matrix = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i+j,:], (1,3))), 0)\n",
    "            matrix = matrix.reshape(4,3,1)\n",
    "            tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "        if len(XTrain):\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = np.concatenate((XTrain, tmp), 3)\n",
    "        else:\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = tmp\n",
    "    if len(YTrain):\n",
    "        YTrain = np.concatenate((YTrain, path1.state_key[sample-1:]), 0)\n",
    "    else:\n",
    "        YTrain = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTrain))\n",
    "print(np.shape(XTrain))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "ind = np.arange(len(YTrain))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XVal = torch.from_numpy(np.transpose(XTest, (3, 2, 0, 1)))\n",
    "YVal = torch.from_numpy(YTest)\n",
    "\n",
    "XTrain = torch.from_numpy(np.transpose(XTrain[:,:,:,ind], (3, 2, 0, 1)))\n",
    "YTrain = torch.from_numpy(YTrain[ind,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "# create network\n",
    "class state_estimat(nn.Module):\n",
    "    def __init__(self, d_in, num_classes):\n",
    "        # initialzing the parent object (important!)\n",
    "        super(state_estimat, self).__init__()\n",
    "        # Create a pipeline - a sequence of layers\n",
    "        self.pipe = torch.nn.Sequential(\n",
    "            nn.Conv2d(d_in, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*3*4, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_estimat(\n",
      "  (pipe): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters:\n",
    "num_epochs = 30\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "learning_rate_drop_period = 10\n",
    "input_shape = [3,4,3]\n",
    "\n",
    "# Device configuration, as before\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# create model\n",
    "model = state_estimat(d_in=3, num_classes=1).to(device)\n",
    "print(model)\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=learning_rate_drop_period, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [5/232], Loss: 17104.2559, Time: 0.6386 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [10/232], Loss: 536.0326, Time: 0.9434 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [15/232], Loss: 2450.6135, Time: 1.2662 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [20/232], Loss: 220.1350, Time: 1.5720 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [25/232], Loss: 594.5405, Time: 1.8698 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [30/232], Loss: 178.4730, Time: 2.1757 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [35/232], Loss: 68.0186, Time: 2.4815 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [40/232], Loss: 111.8276, Time: 2.7883 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [45/232], Loss: 49.3105, Time: 3.0911 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [50/232], Loss: 31.7189, Time: 3.3849 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [55/232], Loss: 38.1998, Time: 3.6787 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [60/232], Loss: 33.1240, Time: 3.9755 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [65/232], Loss: 22.3332, Time: 4.2824 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [70/232], Loss: 23.9548, Time: 4.6201 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [75/232], Loss: 24.6171, Time: 4.9489 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [80/232], Loss: 17.7792, Time: 5.2528 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [85/232], Loss: 17.7094, Time: 5.5406 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [90/232], Loss: 16.0886, Time: 5.8294 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [95/232], Loss: 16.2756, Time: 6.2302 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [100/232], Loss: 13.8871, Time: 6.5380 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [105/232], Loss: 14.6149, Time: 6.8308 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [110/232], Loss: 13.2746, Time: 7.1186 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [115/232], Loss: 13.7611, Time: 7.4144 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [120/232], Loss: 12.0209, Time: 7.7402 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [125/232], Loss: 11.4211, Time: 8.0290 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [130/232], Loss: 13.8774, Time: 8.3119 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [135/232], Loss: 12.0531, Time: 8.6087 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [140/232], Loss: 9.9491, Time: 8.8985 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [145/232], Loss: 11.2366, Time: 9.1973 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [150/232], Loss: 10.6685, Time: 9.4931 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [155/232], Loss: 10.3067, Time: 9.7960 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [160/232], Loss: 11.5204, Time: 10.0808 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [165/232], Loss: 8.6675, Time: 10.3666 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [170/232], Loss: 10.2914, Time: 10.6734 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [175/232], Loss: 8.8521, Time: 10.9642 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [180/232], Loss: 7.4755, Time: 11.2631 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [185/232], Loss: 9.1604, Time: 11.5469 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [190/232], Loss: 8.5097, Time: 11.8407 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [195/232], Loss: 7.8244, Time: 12.1235 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [200/232], Loss: 7.4059, Time: 12.4203 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [205/232], Loss: 7.2147, Time: 12.7082 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [210/232], Loss: 7.4978, Time: 13.0090 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [215/232], Loss: 7.4393, Time: 13.3098 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [220/232], Loss: 7.0074, Time: 13.6006 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [225/232], Loss: 6.3527, Time: 13.8974 secs, learning rate: 0.0010\n",
      "Epoch [1/30], Step [230/232], Loss: 6.3065, Time: 14.1803 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [5/232], Loss: 6.2362, Time: 14.9218 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [10/232], Loss: 6.2059, Time: 15.2306 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [15/232], Loss: 5.8615, Time: 15.5294 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [20/232], Loss: 6.2742, Time: 15.8172 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [25/232], Loss: 5.8705, Time: 16.1091 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [30/232], Loss: 5.8331, Time: 16.4149 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [35/232], Loss: 5.2329, Time: 16.7167 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [40/232], Loss: 5.1832, Time: 17.0145 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [45/232], Loss: 5.5236, Time: 17.3083 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [50/232], Loss: 5.3129, Time: 17.5911 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [55/232], Loss: 5.1967, Time: 17.8840 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [60/232], Loss: 5.1442, Time: 18.1728 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [65/232], Loss: 5.0716, Time: 18.4706 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [70/232], Loss: 4.9153, Time: 18.8024 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [75/232], Loss: 4.9690, Time: 19.1092 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [80/232], Loss: 4.8813, Time: 19.4120 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [85/232], Loss: 4.4674, Time: 19.7138 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [90/232], Loss: 4.3093, Time: 20.0007 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [95/232], Loss: 4.7101, Time: 20.2885 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [100/232], Loss: 4.3540, Time: 20.5963 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [105/232], Loss: 4.1580, Time: 20.8851 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [110/232], Loss: 4.2008, Time: 21.1719 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [115/232], Loss: 4.3140, Time: 21.4608 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [120/232], Loss: 4.2622, Time: 21.7586 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [125/232], Loss: 3.8507, Time: 22.0584 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [130/232], Loss: 4.1070, Time: 22.3512 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [135/232], Loss: 3.9659, Time: 22.6480 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [140/232], Loss: 3.3886, Time: 22.9418 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [145/232], Loss: 3.7998, Time: 23.2357 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [150/232], Loss: 3.6130, Time: 23.5455 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [155/232], Loss: 3.8666, Time: 23.8473 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [160/232], Loss: 3.8383, Time: 24.1291 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [165/232], Loss: 3.5596, Time: 24.4169 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [170/232], Loss: 3.5294, Time: 24.7257 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [175/232], Loss: 3.1385, Time: 25.0296 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [180/232], Loss: 3.4966, Time: 25.3703 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [185/232], Loss: 3.2037, Time: 25.7641 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [190/232], Loss: 3.1160, Time: 26.0639 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [195/232], Loss: 3.0094, Time: 26.3577 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [200/232], Loss: 3.6123, Time: 26.6615 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [205/232], Loss: 3.5912, Time: 26.9584 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [210/232], Loss: 3.7473, Time: 27.2472 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [215/232], Loss: 3.4397, Time: 27.5330 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [220/232], Loss: 3.3969, Time: 27.8498 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [225/232], Loss: 2.9313, Time: 28.1686 secs, learning rate: 0.0010\n",
      "Epoch [2/30], Step [230/232], Loss: 3.0709, Time: 28.4644 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [5/232], Loss: 3.1676, Time: 29.1890 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [10/232], Loss: 2.9090, Time: 29.5088 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [15/232], Loss: 2.6811, Time: 29.8306 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [20/232], Loss: 2.9555, Time: 30.1224 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [25/232], Loss: 2.8625, Time: 30.4102 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [30/232], Loss: 3.1364, Time: 30.7460 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [35/232], Loss: 2.5269, Time: 31.0668 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [40/232], Loss: 2.9718, Time: 31.3676 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [45/232], Loss: 2.7000, Time: 31.6705 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [50/232], Loss: 2.6911, Time: 31.9623 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [55/232], Loss: 2.6589, Time: 32.2421 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [60/232], Loss: 2.5118, Time: 32.5349 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [65/232], Loss: 2.3193, Time: 32.8337 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [70/232], Loss: 2.4399, Time: 33.1376 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [75/232], Loss: 2.8391, Time: 33.4464 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [80/232], Loss: 2.5891, Time: 33.7452 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [85/232], Loss: 2.4407, Time: 34.0480 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [90/232], Loss: 2.3837, Time: 34.3468 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [95/232], Loss: 2.5400, Time: 34.6446 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [100/232], Loss: 2.3602, Time: 34.9484 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [105/232], Loss: 2.4115, Time: 35.2502 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [110/232], Loss: 2.2028, Time: 35.5591 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [115/232], Loss: 2.3570, Time: 35.8559 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [120/232], Loss: 2.1706, Time: 36.1777 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [125/232], Loss: 2.2057, Time: 36.4855 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [130/232], Loss: 2.1259, Time: 36.7823 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [135/232], Loss: 2.0217, Time: 37.0791 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [140/232], Loss: 2.1661, Time: 37.3629 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [145/232], Loss: 2.1357, Time: 37.6498 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [150/232], Loss: 2.2880, Time: 37.9596 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [155/232], Loss: 1.8426, Time: 38.2604 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [160/232], Loss: 2.1517, Time: 38.5732 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [165/232], Loss: 1.8861, Time: 38.8760 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [170/232], Loss: 2.2059, Time: 39.1818 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [175/232], Loss: 1.9135, Time: 39.4796 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [180/232], Loss: 2.0379, Time: 39.8044 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [185/232], Loss: 1.9234, Time: 40.1063 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [190/232], Loss: 1.7180, Time: 40.3971 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [195/232], Loss: 1.9769, Time: 40.6929 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [200/232], Loss: 2.0016, Time: 41.0327 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [205/232], Loss: 2.0103, Time: 41.4234 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [210/232], Loss: 1.8145, Time: 41.7492 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [215/232], Loss: 1.8927, Time: 42.1820 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [220/232], Loss: 1.9884, Time: 42.6397 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [225/232], Loss: 1.8603, Time: 42.9645 secs, learning rate: 0.0010\n",
      "Epoch [3/30], Step [230/232], Loss: 1.7176, Time: 43.4052 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [5/232], Loss: 1.6524, Time: 44.3416 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [10/232], Loss: 1.8659, Time: 44.6465 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [15/232], Loss: 1.5864, Time: 44.9543 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [20/232], Loss: 1.6526, Time: 45.3420 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [25/232], Loss: 1.6956, Time: 45.6388 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [30/232], Loss: 1.6995, Time: 45.9357 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [35/232], Loss: 1.7294, Time: 46.2235 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [40/232], Loss: 1.5860, Time: 46.6032 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [45/232], Loss: 1.7864, Time: 46.9091 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [50/232], Loss: 1.6979, Time: 47.3658 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [55/232], Loss: 1.4733, Time: 47.8355 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [60/232], Loss: 1.4874, Time: 48.1693 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [65/232], Loss: 1.6641, Time: 48.6190 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [70/232], Loss: 1.6764, Time: 49.0457 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [75/232], Loss: 1.5502, Time: 49.3745 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [80/232], Loss: 1.6459, Time: 49.7073 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [85/232], Loss: 1.4730, Time: 50.0061 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [90/232], Loss: 1.4086, Time: 50.3000 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [95/232], Loss: 1.4153, Time: 50.5948 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [100/232], Loss: 1.6786, Time: 50.9026 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [105/232], Loss: 1.4685, Time: 51.2154 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [110/232], Loss: 1.5065, Time: 51.5922 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [115/232], Loss: 1.3339, Time: 51.9210 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [120/232], Loss: 1.2241, Time: 52.3257 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [125/232], Loss: 1.4949, Time: 52.8184 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [130/232], Loss: 1.5962, Time: 53.1972 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [135/232], Loss: 1.6751, Time: 53.6259 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [140/232], Loss: 1.3939, Time: 54.0616 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [145/232], Loss: 1.3133, Time: 54.4054 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [150/232], Loss: 1.4946, Time: 54.7962 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [155/232], Loss: 1.4067, Time: 55.1030 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [160/232], Loss: 1.3173, Time: 55.4068 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [165/232], Loss: 1.5357, Time: 55.6996 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [170/232], Loss: 1.3452, Time: 55.9895 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [175/232], Loss: 1.2487, Time: 56.2893 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [180/232], Loss: 1.4097, Time: 56.5781 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [185/232], Loss: 1.3225, Time: 56.9678 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [190/232], Loss: 1.2934, Time: 57.3046 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [195/232], Loss: 1.4522, Time: 57.7694 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [200/232], Loss: 1.3261, Time: 58.2151 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [205/232], Loss: 1.2647, Time: 58.5329 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [210/232], Loss: 1.2893, Time: 58.8507 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [215/232], Loss: 1.4353, Time: 59.1495 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [220/232], Loss: 1.2159, Time: 59.4553 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [225/232], Loss: 1.2808, Time: 59.7711 secs, learning rate: 0.0010\n",
      "Epoch [4/30], Step [230/232], Loss: 1.4199, Time: 60.0739 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [5/232], Loss: 1.2274, Time: 60.8255 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [10/232], Loss: 1.2351, Time: 61.1383 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [15/232], Loss: 1.0850, Time: 61.4421 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [20/232], Loss: 1.1233, Time: 61.7479 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [25/232], Loss: 1.2101, Time: 62.0587 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [30/232], Loss: 1.2401, Time: 62.3535 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [35/232], Loss: 1.1730, Time: 62.6523 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [40/232], Loss: 1.2307, Time: 62.9751 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [45/232], Loss: 1.0461, Time: 63.2680 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [50/232], Loss: 1.1339, Time: 63.5688 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [55/232], Loss: 1.2553, Time: 63.8756 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [60/232], Loss: 1.1809, Time: 64.1704 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [65/232], Loss: 1.0299, Time: 64.4592 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [70/232], Loss: 1.0589, Time: 64.8620 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [75/232], Loss: 1.1388, Time: 65.1518 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [80/232], Loss: 1.1705, Time: 65.4476 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [85/232], Loss: 1.1195, Time: 65.7424 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [90/232], Loss: 0.9538, Time: 66.0672 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [95/232], Loss: 1.0787, Time: 66.3820 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [100/232], Loss: 1.1281, Time: 66.7008 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [105/232], Loss: 1.0029, Time: 67.0127 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [110/232], Loss: 1.0431, Time: 67.3005 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [115/232], Loss: 1.0867, Time: 67.5993 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [120/232], Loss: 1.1214, Time: 67.9011 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [125/232], Loss: 1.1447, Time: 68.2259 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [130/232], Loss: 0.9503, Time: 68.5167 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [135/232], Loss: 0.8683, Time: 68.8135 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [140/232], Loss: 0.9978, Time: 69.1134 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [145/232], Loss: 0.9894, Time: 69.4122 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [150/232], Loss: 0.9761, Time: 69.7150 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [155/232], Loss: 1.0642, Time: 70.0188 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [160/232], Loss: 0.8062, Time: 70.3226 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [165/232], Loss: 0.9609, Time: 70.6284 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [170/232], Loss: 0.9400, Time: 70.9462 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [175/232], Loss: 0.9715, Time: 71.2720 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [180/232], Loss: 0.9183, Time: 71.5718 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [185/232], Loss: 0.9021, Time: 71.8687 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [190/232], Loss: 0.9787, Time: 72.1725 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [195/232], Loss: 0.8691, Time: 72.4683 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [200/232], Loss: 0.9873, Time: 72.7611 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [205/232], Loss: 0.9546, Time: 73.0619 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [210/232], Loss: 0.8523, Time: 73.3667 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [215/232], Loss: 0.9696, Time: 73.6655 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [220/232], Loss: 0.8478, Time: 73.9664 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [225/232], Loss: 0.8413, Time: 74.2632 secs, learning rate: 0.0010\n",
      "Epoch [5/30], Step [230/232], Loss: 1.0705, Time: 74.5660 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [5/232], Loss: 0.8875, Time: 75.3265 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [10/232], Loss: 0.9852, Time: 75.6213 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [15/232], Loss: 0.8283, Time: 75.9212 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [20/232], Loss: 0.8710, Time: 76.2140 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [25/232], Loss: 0.9875, Time: 76.5288 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [30/232], Loss: 0.7786, Time: 76.8266 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [35/232], Loss: 0.8764, Time: 77.1294 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [40/232], Loss: 0.8012, Time: 77.4332 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [45/232], Loss: 0.8108, Time: 77.7240 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [50/232], Loss: 0.8129, Time: 78.0179 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [55/232], Loss: 0.7973, Time: 78.3317 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [60/232], Loss: 0.8608, Time: 78.6285 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [65/232], Loss: 0.8213, Time: 78.9483 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [70/232], Loss: 0.8350, Time: 79.2551 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [75/232], Loss: 0.9084, Time: 79.5509 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [80/232], Loss: 0.7620, Time: 79.8467 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [85/232], Loss: 0.7949, Time: 80.1715 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [90/232], Loss: 0.7960, Time: 80.4673 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [95/232], Loss: 0.7445, Time: 80.7782 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [100/232], Loss: 0.7636, Time: 81.0900 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [105/232], Loss: 0.7801, Time: 81.3878 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [110/232], Loss: 0.8198, Time: 81.6846 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [115/232], Loss: 0.8297, Time: 81.9814 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [120/232], Loss: 0.7892, Time: 82.2832 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [125/232], Loss: 0.9054, Time: 82.5850 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [130/232], Loss: 0.7397, Time: 82.8978 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [135/232], Loss: 0.7926, Time: 83.2017 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [140/232], Loss: 0.7351, Time: 83.4985 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [145/232], Loss: 0.6697, Time: 83.8133 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [150/232], Loss: 0.7929, Time: 84.1111 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [155/232], Loss: 0.7435, Time: 84.5129 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [160/232], Loss: 0.7122, Time: 84.8087 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [165/232], Loss: 0.6879, Time: 85.1075 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [170/232], Loss: 0.8051, Time: 85.4113 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [175/232], Loss: 0.6822, Time: 85.7081 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [180/232], Loss: 0.6291, Time: 86.0359 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [185/232], Loss: 0.6877, Time: 86.3437 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [190/232], Loss: 0.7013, Time: 86.6395 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [195/232], Loss: 0.7699, Time: 86.9344 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [200/232], Loss: 0.7402, Time: 87.2372 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [205/232], Loss: 0.6878, Time: 87.5350 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [210/232], Loss: 0.6694, Time: 87.8508 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [215/232], Loss: 0.6696, Time: 88.1726 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [220/232], Loss: 0.7280, Time: 88.4654 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [225/232], Loss: 0.6946, Time: 88.7532 secs, learning rate: 0.0010\n",
      "Epoch [6/30], Step [230/232], Loss: 0.7264, Time: 89.0481 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [5/232], Loss: 0.7846, Time: 89.8086 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [10/232], Loss: 0.7165, Time: 90.1264 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [15/232], Loss: 0.8118, Time: 90.4202 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [20/232], Loss: 0.6314, Time: 90.7130 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [25/232], Loss: 0.8205, Time: 91.0148 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [30/232], Loss: 0.6252, Time: 91.3446 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [35/232], Loss: 0.6173, Time: 91.6504 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [40/232], Loss: 0.6272, Time: 91.9563 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [45/232], Loss: 0.6423, Time: 92.2511 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [50/232], Loss: 0.6102, Time: 92.5519 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [55/232], Loss: 0.6627, Time: 92.8727 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [60/232], Loss: 0.7050, Time: 93.1945 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [65/232], Loss: 0.6517, Time: 93.5003 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [70/232], Loss: 0.6775, Time: 93.8121 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [75/232], Loss: 0.6783, Time: 94.1169 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [80/232], Loss: 0.7277, Time: 94.4097 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [85/232], Loss: 0.6505, Time: 94.7056 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [90/232], Loss: 0.6167, Time: 95.0214 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [95/232], Loss: 0.6531, Time: 95.3422 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [100/232], Loss: 0.5861, Time: 95.6460 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [105/232], Loss: 0.5675, Time: 95.9668 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [110/232], Loss: 0.5777, Time: 96.2846 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [115/232], Loss: 0.6096, Time: 96.5944 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [120/232], Loss: 0.5869, Time: 96.9032 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [125/232], Loss: 0.6698, Time: 97.1960 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [130/232], Loss: 0.5949, Time: 97.4958 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [135/232], Loss: 0.5584, Time: 97.7887 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [140/232], Loss: 0.6266, Time: 98.0785 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [145/232], Loss: 0.5491, Time: 98.3893 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [150/232], Loss: 0.6059, Time: 98.7021 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [155/232], Loss: 0.5216, Time: 99.0049 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [160/232], Loss: 0.6243, Time: 99.3187 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [165/232], Loss: 0.5920, Time: 99.6095 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [170/232], Loss: 0.6498, Time: 99.8984 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [175/232], Loss: 0.6298, Time: 100.1922 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [180/232], Loss: 0.5976, Time: 100.4840 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [185/232], Loss: 0.6176, Time: 100.7868 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [190/232], Loss: 0.6164, Time: 101.0886 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [195/232], Loss: 0.5041, Time: 101.3924 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [200/232], Loss: 0.6176, Time: 101.6962 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [205/232], Loss: 0.5910, Time: 101.9841 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [210/232], Loss: 0.5668, Time: 102.2799 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [215/232], Loss: 0.6247, Time: 102.5767 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [220/232], Loss: 0.5393, Time: 102.8655 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [225/232], Loss: 0.5077, Time: 103.1843 secs, learning rate: 0.0010\n",
      "Epoch [7/30], Step [230/232], Loss: 0.5482, Time: 103.5711 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [5/232], Loss: 0.5082, Time: 104.3136 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [10/232], Loss: 0.5731, Time: 104.6085 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [15/232], Loss: 0.5301, Time: 104.9023 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [20/232], Loss: 0.4900, Time: 105.2261 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [25/232], Loss: 0.4973, Time: 105.5429 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [30/232], Loss: 0.5315, Time: 105.8487 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [35/232], Loss: 0.5328, Time: 106.1545 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [40/232], Loss: 0.5739, Time: 106.4473 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [45/232], Loss: 0.5951, Time: 106.7371 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [50/232], Loss: 0.5099, Time: 107.0400 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [55/232], Loss: 0.5367, Time: 107.3578 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [60/232], Loss: 0.5760, Time: 107.6606 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [65/232], Loss: 0.4803, Time: 107.9754 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [70/232], Loss: 0.4716, Time: 108.2772 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [75/232], Loss: 0.4841, Time: 108.5830 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [80/232], Loss: 0.4945, Time: 108.9128 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [85/232], Loss: 0.5145, Time: 109.3895 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [90/232], Loss: 0.5601, Time: 109.9432 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [95/232], Loss: 0.5300, Time: 110.2969 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [100/232], Loss: 0.5119, Time: 110.6008 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [105/232], Loss: 0.4517, Time: 110.9116 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [110/232], Loss: 0.5134, Time: 111.2324 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [115/232], Loss: 0.4932, Time: 111.5432 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [120/232], Loss: 0.4828, Time: 111.8480 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [125/232], Loss: 0.5286, Time: 112.1548 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [130/232], Loss: 0.5256, Time: 112.4466 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [135/232], Loss: 0.4571, Time: 112.7474 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [140/232], Loss: 0.4807, Time: 113.0712 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [145/232], Loss: 0.4752, Time: 113.3710 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [150/232], Loss: 0.5240, Time: 113.6729 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [155/232], Loss: 0.4893, Time: 113.9707 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [160/232], Loss: 0.4743, Time: 114.2765 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [165/232], Loss: 0.4514, Time: 114.5723 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [170/232], Loss: 0.4699, Time: 114.8661 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [175/232], Loss: 0.4882, Time: 115.1709 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [180/232], Loss: 0.5211, Time: 115.4767 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [185/232], Loss: 0.4619, Time: 115.7796 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [190/232], Loss: 0.4747, Time: 116.0834 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [195/232], Loss: 0.4526, Time: 116.3972 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [200/232], Loss: 0.4322, Time: 116.6950 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [205/232], Loss: 0.4468, Time: 116.9898 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [210/232], Loss: 0.4547, Time: 117.2866 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [215/232], Loss: 0.4879, Time: 117.5864 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [220/232], Loss: 0.5084, Time: 117.9003 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [225/232], Loss: 0.5271, Time: 118.1991 secs, learning rate: 0.0010\n",
      "Epoch [8/30], Step [230/232], Loss: 0.4645, Time: 118.5049 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [5/232], Loss: 0.4486, Time: 119.2264 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [10/232], Loss: 0.4518, Time: 119.5322 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [15/232], Loss: 0.4630, Time: 119.8391 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [20/232], Loss: 0.4456, Time: 120.1579 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [25/232], Loss: 0.5634, Time: 120.4637 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [30/232], Loss: 0.4718, Time: 120.7665 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [35/232], Loss: 0.4652, Time: 121.0593 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [40/232], Loss: 0.4394, Time: 121.3501 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [45/232], Loss: 0.5047, Time: 121.6599 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [50/232], Loss: 0.4703, Time: 121.9617 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [55/232], Loss: 0.4181, Time: 122.2776 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [60/232], Loss: 0.4636, Time: 122.5734 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [65/232], Loss: 0.4869, Time: 122.9581 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [70/232], Loss: 0.4576, Time: 123.2559 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [75/232], Loss: 0.3437, Time: 123.5748 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [80/232], Loss: 0.4268, Time: 123.8676 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [85/232], Loss: 0.4307, Time: 124.1794 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [90/232], Loss: 0.4341, Time: 124.4772 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [95/232], Loss: 0.4277, Time: 124.7750 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [100/232], Loss: 0.4336, Time: 125.0758 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [105/232], Loss: 0.4235, Time: 125.3726 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [110/232], Loss: 0.3924, Time: 125.6735 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [115/232], Loss: 0.4754, Time: 125.9713 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [120/232], Loss: 0.3846, Time: 126.2671 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [125/232], Loss: 0.3842, Time: 126.5699 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [130/232], Loss: 0.4075, Time: 126.8707 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [135/232], Loss: 0.4332, Time: 127.1725 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [140/232], Loss: 0.4315, Time: 127.4793 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [145/232], Loss: 0.4166, Time: 127.7702 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [150/232], Loss: 0.3972, Time: 128.0700 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [155/232], Loss: 0.4020, Time: 128.3688 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [160/232], Loss: 0.3871, Time: 128.6726 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [165/232], Loss: 0.4362, Time: 128.9794 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [170/232], Loss: 0.3886, Time: 129.2732 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [175/232], Loss: 0.3706, Time: 129.5641 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [180/232], Loss: 0.4571, Time: 129.8679 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [185/232], Loss: 0.4464, Time: 130.1787 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [190/232], Loss: 0.3944, Time: 130.4735 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [195/232], Loss: 0.3804, Time: 130.7643 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [200/232], Loss: 0.3842, Time: 131.0641 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [205/232], Loss: 0.3797, Time: 131.3689 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [210/232], Loss: 0.4146, Time: 131.6658 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [215/232], Loss: 0.4267, Time: 131.9646 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [220/232], Loss: 0.3861, Time: 132.2704 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [225/232], Loss: 0.3888, Time: 132.5702 secs, learning rate: 0.0010\n",
      "Epoch [9/30], Step [230/232], Loss: 0.3744, Time: 132.8660 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [5/232], Loss: 0.4070, Time: 133.6176 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [10/232], Loss: 0.3925, Time: 133.9224 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [15/232], Loss: 0.4419, Time: 134.2312 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [20/232], Loss: 0.3453, Time: 134.5240 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [25/232], Loss: 0.3659, Time: 134.8268 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [30/232], Loss: 0.3431, Time: 135.1476 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [35/232], Loss: 0.3747, Time: 135.4564 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [40/232], Loss: 0.3034, Time: 135.7592 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [45/232], Loss: 0.4255, Time: 136.0570 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [50/232], Loss: 0.3521, Time: 136.3439 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [55/232], Loss: 0.3688, Time: 136.6377 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [60/232], Loss: 0.3607, Time: 136.9505 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [65/232], Loss: 0.3689, Time: 137.2503 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [70/232], Loss: 0.3693, Time: 137.5511 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [75/232], Loss: 0.3862, Time: 137.8449 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [80/232], Loss: 0.3439, Time: 138.1478 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [85/232], Loss: 0.3864, Time: 138.4556 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [90/232], Loss: 0.3949, Time: 138.7754 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [95/232], Loss: 0.3717, Time: 139.0722 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [100/232], Loss: 0.3529, Time: 139.3720 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [105/232], Loss: 0.3627, Time: 139.6848 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [110/232], Loss: 0.3427, Time: 139.9936 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [115/232], Loss: 0.3490, Time: 140.3044 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [120/232], Loss: 0.3591, Time: 140.6172 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [125/232], Loss: 0.3798, Time: 140.9131 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [130/232], Loss: 0.3436, Time: 141.2149 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [135/232], Loss: 0.3635, Time: 141.5097 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [140/232], Loss: 0.3787, Time: 141.8145 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [145/232], Loss: 0.3702, Time: 142.1103 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [150/232], Loss: 0.3181, Time: 142.4981 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [155/232], Loss: 0.3159, Time: 142.8029 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [160/232], Loss: 0.3639, Time: 143.1117 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [165/232], Loss: 0.3507, Time: 143.4005 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [170/232], Loss: 0.3574, Time: 143.7143 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [175/232], Loss: 0.3368, Time: 144.0161 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [180/232], Loss: 0.3885, Time: 144.3130 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [185/232], Loss: 0.3300, Time: 144.6268 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [190/232], Loss: 0.3770, Time: 144.9266 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [195/232], Loss: 0.3618, Time: 145.2294 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [200/232], Loss: 0.3332, Time: 145.5212 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [205/232], Loss: 0.3569, Time: 145.8310 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [210/232], Loss: 0.3788, Time: 146.1488 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [215/232], Loss: 0.3347, Time: 146.4466 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [220/232], Loss: 0.3597, Time: 146.7515 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [225/232], Loss: 0.3545, Time: 147.0413 secs, learning rate: 0.0010\n",
      "Epoch [10/30], Step [230/232], Loss: 0.3146, Time: 147.3451 secs, learning rate: 0.0010\n",
      "Epoch [11/30], Step [5/232], Loss: 0.3355, Time: 148.0846 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [10/232], Loss: 0.3242, Time: 148.3804 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [15/232], Loss: 0.3256, Time: 148.6773 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [20/232], Loss: 0.3180, Time: 148.9681 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [25/232], Loss: 0.3655, Time: 149.2589 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [30/232], Loss: 0.3199, Time: 149.5677 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [35/232], Loss: 0.3193, Time: 149.8835 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [40/232], Loss: 0.3484, Time: 150.1733 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [45/232], Loss: 0.3000, Time: 150.4692 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [50/232], Loss: 0.3480, Time: 150.7770 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [55/232], Loss: 0.3410, Time: 151.0698 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [60/232], Loss: 0.3208, Time: 151.3666 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [65/232], Loss: 0.3487, Time: 151.6764 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [70/232], Loss: 0.3929, Time: 151.9862 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [75/232], Loss: 0.3617, Time: 152.2880 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [80/232], Loss: 0.3157, Time: 152.5868 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [85/232], Loss: 0.3415, Time: 152.8957 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [90/232], Loss: 0.3648, Time: 153.2085 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [95/232], Loss: 0.2982, Time: 153.5123 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [100/232], Loss: 0.3110, Time: 153.8111 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [105/232], Loss: 0.2557, Time: 154.1009 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [110/232], Loss: 0.3560, Time: 154.3977 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [115/232], Loss: 0.3122, Time: 154.7405 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [120/232], Loss: 0.3232, Time: 155.0583 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [125/232], Loss: 0.3521, Time: 155.3681 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [130/232], Loss: 0.3277, Time: 155.6989 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [135/232], Loss: 0.3390, Time: 155.9987 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [140/232], Loss: 0.3309, Time: 156.2876 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [145/232], Loss: 0.3265, Time: 156.6164 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [150/232], Loss: 0.3258, Time: 156.9352 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [155/232], Loss: 0.3415, Time: 157.2420 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [160/232], Loss: 0.3292, Time: 157.5368 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [165/232], Loss: 0.3267, Time: 157.8466 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [170/232], Loss: 0.3540, Time: 158.1414 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [175/232], Loss: 0.3733, Time: 158.4402 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [180/232], Loss: 0.2997, Time: 158.7401 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [185/232], Loss: 0.2867, Time: 159.0469 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [190/232], Loss: 0.3329, Time: 159.3467 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [195/232], Loss: 0.3704, Time: 159.6475 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [200/232], Loss: 0.3445, Time: 159.9553 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [205/232], Loss: 0.3168, Time: 160.2751 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [210/232], Loss: 0.3218, Time: 160.5709 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [215/232], Loss: 0.2948, Time: 160.8747 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [220/232], Loss: 0.3512, Time: 161.1676 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [225/232], Loss: 0.3150, Time: 161.4604 secs, learning rate: 0.0001\n",
      "Epoch [11/30], Step [230/232], Loss: 0.3186, Time: 161.7592 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [5/232], Loss: 0.3249, Time: 162.5987 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [10/232], Loss: 0.3198, Time: 162.9025 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [15/232], Loss: 0.3258, Time: 163.2223 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [20/232], Loss: 0.3058, Time: 163.5281 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [25/232], Loss: 0.3048, Time: 163.8489 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [30/232], Loss: 0.3179, Time: 164.1457 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [35/232], Loss: 0.3164, Time: 164.4405 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [40/232], Loss: 0.3353, Time: 164.7443 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [45/232], Loss: 0.3210, Time: 165.0472 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [50/232], Loss: 0.3219, Time: 165.3580 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [55/232], Loss: 0.3620, Time: 165.6708 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [60/232], Loss: 0.3117, Time: 165.9706 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [65/232], Loss: 0.4047, Time: 166.2584 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [70/232], Loss: 0.3187, Time: 166.5532 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [75/232], Loss: 0.3538, Time: 166.8880 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [80/232], Loss: 0.3192, Time: 167.3128 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [85/232], Loss: 0.3400, Time: 167.6176 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [90/232], Loss: 0.3480, Time: 167.9354 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [95/232], Loss: 0.3131, Time: 168.2582 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [100/232], Loss: 0.3185, Time: 168.5980 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [105/232], Loss: 0.3275, Time: 168.9198 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [110/232], Loss: 0.3344, Time: 169.2186 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [115/232], Loss: 0.3600, Time: 169.5284 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [120/232], Loss: 0.3275, Time: 169.8262 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [125/232], Loss: 0.3493, Time: 170.1590 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [130/232], Loss: 0.3151, Time: 170.4548 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [135/232], Loss: 0.3083, Time: 170.7466 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [140/232], Loss: 0.3133, Time: 171.0475 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [145/232], Loss: 0.2835, Time: 171.3593 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [150/232], Loss: 0.3595, Time: 171.6731 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [155/232], Loss: 0.2967, Time: 171.9679 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [160/232], Loss: 0.3113, Time: 172.2557 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [165/232], Loss: 0.3190, Time: 172.5505 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [170/232], Loss: 0.3196, Time: 172.8603 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [175/232], Loss: 0.3208, Time: 173.1632 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [180/232], Loss: 0.2989, Time: 173.4590 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [185/232], Loss: 0.2812, Time: 173.7548 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [190/232], Loss: 0.3149, Time: 174.0476 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [195/232], Loss: 0.3288, Time: 174.3644 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [200/232], Loss: 0.3662, Time: 174.6572 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [205/232], Loss: 0.3730, Time: 174.9600 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [210/232], Loss: 0.3497, Time: 175.2499 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [215/232], Loss: 0.3524, Time: 175.5427 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [220/232], Loss: 0.3427, Time: 175.8475 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [225/232], Loss: 0.2987, Time: 176.1493 secs, learning rate: 0.0001\n",
      "Epoch [12/30], Step [230/232], Loss: 0.3307, Time: 176.4411 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [5/232], Loss: 0.3132, Time: 177.1867 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [10/232], Loss: 0.3138, Time: 177.4865 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [15/232], Loss: 0.3044, Time: 177.7843 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [20/232], Loss: 0.3533, Time: 178.0841 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [25/232], Loss: 0.3437, Time: 178.3829 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [30/232], Loss: 0.3157, Time: 178.6748 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [35/232], Loss: 0.3509, Time: 178.9926 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [40/232], Loss: 0.2982, Time: 179.3064 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [45/232], Loss: 0.3474, Time: 179.6052 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [50/232], Loss: 0.3474, Time: 179.9170 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [55/232], Loss: 0.3239, Time: 180.2368 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [60/232], Loss: 0.3421, Time: 180.5476 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [65/232], Loss: 0.2875, Time: 180.8464 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [70/232], Loss: 0.3044, Time: 181.1372 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [75/232], Loss: 0.2875, Time: 181.5230 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [80/232], Loss: 0.3285, Time: 181.8218 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [85/232], Loss: 0.3108, Time: 182.1346 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [90/232], Loss: 0.2904, Time: 182.4354 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [95/232], Loss: 0.2796, Time: 182.7283 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [100/232], Loss: 0.3726, Time: 183.0211 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [105/232], Loss: 0.3005, Time: 183.3239 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [110/232], Loss: 0.3258, Time: 183.6347 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [115/232], Loss: 0.4067, Time: 183.9495 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [120/232], Loss: 0.3059, Time: 184.2453 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [125/232], Loss: 0.3054, Time: 184.5371 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [130/232], Loss: 0.3083, Time: 184.8370 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [135/232], Loss: 0.3446, Time: 185.1458 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [140/232], Loss: 0.3604, Time: 185.4456 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [145/232], Loss: 0.3352, Time: 185.7574 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [150/232], Loss: 0.3046, Time: 186.0572 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [155/232], Loss: 0.2997, Time: 186.3610 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [160/232], Loss: 0.3414, Time: 186.6608 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [165/232], Loss: 0.3457, Time: 186.9736 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [170/232], Loss: 0.3286, Time: 187.2794 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [175/232], Loss: 0.3063, Time: 187.5793 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [180/232], Loss: 0.3945, Time: 187.8881 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [185/232], Loss: 0.3010, Time: 188.1959 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [190/232], Loss: 0.3125, Time: 188.4867 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [195/232], Loss: 0.3374, Time: 188.7855 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [200/232], Loss: 0.3185, Time: 189.0743 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [205/232], Loss: 0.3153, Time: 189.3851 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [210/232], Loss: 0.3273, Time: 189.6920 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [215/232], Loss: 0.2470, Time: 189.9808 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [220/232], Loss: 0.3335, Time: 190.2846 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [225/232], Loss: 0.3258, Time: 190.5764 secs, learning rate: 0.0001\n",
      "Epoch [13/30], Step [230/232], Loss: 0.3575, Time: 190.8662 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [5/232], Loss: 0.3204, Time: 191.6138 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [10/232], Loss: 0.3066, Time: 191.9326 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [15/232], Loss: 0.3489, Time: 192.2264 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [20/232], Loss: 0.3413, Time: 192.5212 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [25/232], Loss: 0.3017, Time: 192.8250 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [30/232], Loss: 0.2778, Time: 193.1388 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [35/232], Loss: 0.2986, Time: 193.4356 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [40/232], Loss: 0.2998, Time: 193.7375 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [45/232], Loss: 0.3389, Time: 194.0353 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [50/232], Loss: 0.3369, Time: 194.3401 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [55/232], Loss: 0.3328, Time: 194.6589 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [60/232], Loss: 0.3443, Time: 194.9597 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [65/232], Loss: 0.2920, Time: 195.2765 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [70/232], Loss: 0.3198, Time: 195.5803 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [75/232], Loss: 0.3395, Time: 195.9031 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [80/232], Loss: 0.3610, Time: 196.1969 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [85/232], Loss: 0.3027, Time: 196.5247 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [90/232], Loss: 0.3400, Time: 196.8535 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [95/232], Loss: 0.2907, Time: 197.1693 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [100/232], Loss: 0.3102, Time: 197.4712 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [105/232], Loss: 0.3237, Time: 197.7710 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [110/232], Loss: 0.3129, Time: 198.0728 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [115/232], Loss: 0.3086, Time: 198.3746 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [120/232], Loss: 0.2889, Time: 198.6684 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [125/232], Loss: 0.3212, Time: 198.9662 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [130/232], Loss: 0.3063, Time: 199.2670 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [135/232], Loss: 0.3107, Time: 199.5699 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [140/232], Loss: 0.3377, Time: 199.8887 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [145/232], Loss: 0.2911, Time: 200.1825 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [150/232], Loss: 0.2966, Time: 200.4803 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [155/232], Loss: 0.3079, Time: 200.8471 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [160/232], Loss: 0.3090, Time: 201.1569 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [165/232], Loss: 0.2817, Time: 201.4547 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [170/232], Loss: 0.3351, Time: 201.7495 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [175/232], Loss: 0.2808, Time: 202.0503 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [180/232], Loss: 0.2773, Time: 202.3581 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [185/232], Loss: 0.2979, Time: 202.6580 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [190/232], Loss: 0.2994, Time: 202.9548 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [195/232], Loss: 0.3101, Time: 203.2576 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [200/232], Loss: 0.3170, Time: 203.5694 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [205/232], Loss: 0.3065, Time: 203.8712 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [210/232], Loss: 0.3513, Time: 204.1780 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [215/232], Loss: 0.3026, Time: 204.4758 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [220/232], Loss: 0.3296, Time: 204.7786 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [225/232], Loss: 0.3082, Time: 205.0685 secs, learning rate: 0.0001\n",
      "Epoch [14/30], Step [230/232], Loss: 0.3314, Time: 205.3663 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [5/232], Loss: 0.3324, Time: 206.1068 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [10/232], Loss: 0.3079, Time: 206.3966 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [15/232], Loss: 0.3496, Time: 206.8144 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [20/232], Loss: 0.2980, Time: 207.2801 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [25/232], Loss: 0.3133, Time: 207.7248 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [30/232], Loss: 0.2417, Time: 208.1216 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [35/232], Loss: 0.3814, Time: 208.4254 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [40/232], Loss: 0.3001, Time: 208.7642 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [45/232], Loss: 0.3397, Time: 209.0750 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [50/232], Loss: 0.3563, Time: 209.3778 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [55/232], Loss: 0.3093, Time: 209.6936 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [60/232], Loss: 0.3690, Time: 209.9834 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [65/232], Loss: 0.2940, Time: 210.2803 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [70/232], Loss: 0.3304, Time: 210.6140 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [75/232], Loss: 0.3090, Time: 210.9139 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [80/232], Loss: 0.2939, Time: 211.2067 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [85/232], Loss: 0.3252, Time: 211.5085 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [90/232], Loss: 0.2920, Time: 211.8223 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [95/232], Loss: 0.3006, Time: 212.1351 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [100/232], Loss: 0.3006, Time: 212.4309 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [105/232], Loss: 0.3300, Time: 212.7267 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [110/232], Loss: 0.3029, Time: 213.0256 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [115/232], Loss: 0.3415, Time: 213.3394 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [120/232], Loss: 0.2892, Time: 213.6352 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [125/232], Loss: 0.2902, Time: 213.9420 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [130/232], Loss: 0.2914, Time: 214.2428 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [135/232], Loss: 0.2997, Time: 214.5456 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [140/232], Loss: 0.2883, Time: 214.8484 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [145/232], Loss: 0.3241, Time: 215.1452 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [150/232], Loss: 0.3289, Time: 215.4501 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [155/232], Loss: 0.3311, Time: 215.7559 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [160/232], Loss: 0.2907, Time: 216.0667 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [165/232], Loss: 0.3000, Time: 216.3805 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [170/232], Loss: 0.3167, Time: 216.6853 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [175/232], Loss: 0.2705, Time: 216.9831 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [180/232], Loss: 0.3027, Time: 217.2739 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [185/232], Loss: 0.3027, Time: 217.5728 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [190/232], Loss: 0.3238, Time: 217.8806 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [195/232], Loss: 0.3008, Time: 218.1894 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [200/232], Loss: 0.2638, Time: 218.4902 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [205/232], Loss: 0.2985, Time: 218.7810 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [210/232], Loss: 0.3394, Time: 219.0808 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [215/232], Loss: 0.3147, Time: 219.3876 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [220/232], Loss: 0.3424, Time: 219.7014 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [225/232], Loss: 0.3276, Time: 220.0152 secs, learning rate: 0.0001\n",
      "Epoch [15/30], Step [230/232], Loss: 0.2813, Time: 220.4110 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [5/232], Loss: 0.2823, Time: 221.1475 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [10/232], Loss: 0.3389, Time: 221.4414 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [15/232], Loss: 0.3358, Time: 221.7482 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [20/232], Loss: 0.2909, Time: 222.0500 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [25/232], Loss: 0.3153, Time: 222.3408 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [30/232], Loss: 0.3077, Time: 222.6546 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [35/232], Loss: 0.2872, Time: 222.9644 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [40/232], Loss: 0.3614, Time: 223.2672 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [45/232], Loss: 0.2924, Time: 223.5591 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [50/232], Loss: 0.3231, Time: 223.8649 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [55/232], Loss: 0.2918, Time: 224.1777 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [60/232], Loss: 0.2766, Time: 224.4785 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [65/232], Loss: 0.2888, Time: 224.7773 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [70/232], Loss: 0.3172, Time: 225.0891 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [75/232], Loss: 0.2988, Time: 225.4199 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [80/232], Loss: 0.3329, Time: 225.7247 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [85/232], Loss: 0.2883, Time: 226.0525 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [90/232], Loss: 0.2865, Time: 226.3693 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [95/232], Loss: 0.2837, Time: 226.6841 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [100/232], Loss: 0.3381, Time: 226.9749 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [105/232], Loss: 0.3324, Time: 227.2778 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [110/232], Loss: 0.3480, Time: 227.5886 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [115/232], Loss: 0.3104, Time: 227.8944 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [120/232], Loss: 0.2956, Time: 228.2052 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [125/232], Loss: 0.3029, Time: 228.4980 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [130/232], Loss: 0.2940, Time: 228.8378 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [135/232], Loss: 0.2879, Time: 229.1386 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [140/232], Loss: 0.3355, Time: 229.4434 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [145/232], Loss: 0.2919, Time: 229.7372 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [150/232], Loss: 0.3256, Time: 230.0580 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [155/232], Loss: 0.2873, Time: 230.5417 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [160/232], Loss: 0.2911, Time: 231.0874 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [165/232], Loss: 0.2946, Time: 231.4592 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [170/232], Loss: 0.2815, Time: 231.7800 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [175/232], Loss: 0.3691, Time: 232.0808 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [180/232], Loss: 0.3212, Time: 232.3796 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [185/232], Loss: 0.2872, Time: 232.6784 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [190/232], Loss: 0.2933, Time: 232.9842 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [195/232], Loss: 0.3401, Time: 233.2881 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [200/232], Loss: 0.2948, Time: 233.5809 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [205/232], Loss: 0.2886, Time: 233.8817 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [210/232], Loss: 0.3184, Time: 234.1795 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [215/232], Loss: 0.2769, Time: 234.4793 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [220/232], Loss: 0.2994, Time: 234.7801 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [225/232], Loss: 0.2913, Time: 235.0789 secs, learning rate: 0.0001\n",
      "Epoch [16/30], Step [230/232], Loss: 0.2786, Time: 235.3888 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [5/232], Loss: 0.2878, Time: 236.1363 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [10/232], Loss: 0.2922, Time: 236.4411 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [15/232], Loss: 0.2920, Time: 236.7479 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [20/232], Loss: 0.2869, Time: 237.0407 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [25/232], Loss: 0.3332, Time: 237.3296 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [30/232], Loss: 0.3040, Time: 237.6474 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [35/232], Loss: 0.2750, Time: 237.9582 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [40/232], Loss: 0.2828, Time: 238.2520 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [45/232], Loss: 0.2984, Time: 238.5488 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [50/232], Loss: 0.2974, Time: 238.8476 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [55/232], Loss: 0.2633, Time: 239.1384 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [60/232], Loss: 0.2735, Time: 239.4303 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [65/232], Loss: 0.3273, Time: 239.7321 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [70/232], Loss: 0.2956, Time: 240.1128 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [75/232], Loss: 0.2850, Time: 240.4366 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [80/232], Loss: 0.3192, Time: 240.7524 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [85/232], Loss: 0.3246, Time: 241.0473 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [90/232], Loss: 0.3781, Time: 241.3401 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [95/232], Loss: 0.3092, Time: 241.6379 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [100/232], Loss: 0.3243, Time: 241.9367 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [105/232], Loss: 0.3328, Time: 242.2405 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [110/232], Loss: 0.2828, Time: 242.5483 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [115/232], Loss: 0.2926, Time: 242.8731 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [120/232], Loss: 0.3076, Time: 243.1650 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [125/232], Loss: 0.2765, Time: 243.4548 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [130/232], Loss: 0.2866, Time: 243.7616 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [135/232], Loss: 0.2891, Time: 244.0624 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [140/232], Loss: 0.2848, Time: 244.3782 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [145/232], Loss: 0.3248, Time: 244.6720 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [150/232], Loss: 0.2932, Time: 244.9678 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [155/232], Loss: 0.3041, Time: 245.2617 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [160/232], Loss: 0.2788, Time: 245.5685 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [165/232], Loss: 0.2608, Time: 245.8733 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [170/232], Loss: 0.2905, Time: 246.1731 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [175/232], Loss: 0.2807, Time: 246.4639 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [180/232], Loss: 0.2943, Time: 246.7587 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [185/232], Loss: 0.2875, Time: 247.0636 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [190/232], Loss: 0.3173, Time: 247.3714 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [195/232], Loss: 0.2989, Time: 247.6782 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [200/232], Loss: 0.2898, Time: 247.9930 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [205/232], Loss: 0.3086, Time: 248.2988 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [210/232], Loss: 0.2883, Time: 248.6006 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [215/232], Loss: 0.2731, Time: 248.9054 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [220/232], Loss: 0.2236, Time: 249.2062 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [225/232], Loss: 0.3239, Time: 249.4981 secs, learning rate: 0.0001\n",
      "Epoch [17/30], Step [230/232], Loss: 0.2617, Time: 249.8059 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [5/232], Loss: 0.3109, Time: 250.5434 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [10/232], Loss: 0.2602, Time: 250.8432 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [15/232], Loss: 0.2502, Time: 251.1520 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [20/232], Loss: 0.2899, Time: 251.4588 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [25/232], Loss: 0.3013, Time: 251.7577 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [30/232], Loss: 0.2677, Time: 252.0645 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [35/232], Loss: 0.2688, Time: 252.3773 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [40/232], Loss: 0.2857, Time: 252.6761 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [45/232], Loss: 0.2940, Time: 252.9679 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [50/232], Loss: 0.3182, Time: 253.2667 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [55/232], Loss: 0.3005, Time: 253.5695 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [60/232], Loss: 0.2831, Time: 253.8664 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [65/232], Loss: 0.2728, Time: 254.1572 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [70/232], Loss: 0.3087, Time: 254.4590 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [75/232], Loss: 0.2970, Time: 254.7618 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [80/232], Loss: 0.2840, Time: 255.0566 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [85/232], Loss: 0.2767, Time: 255.3714 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [90/232], Loss: 0.2747, Time: 255.7062 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [95/232], Loss: 0.2884, Time: 256.0100 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [100/232], Loss: 0.3067, Time: 256.3188 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [105/232], Loss: 0.2747, Time: 256.6227 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [110/232], Loss: 0.2615, Time: 256.9515 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [115/232], Loss: 0.3017, Time: 257.2523 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [120/232], Loss: 0.2385, Time: 257.5401 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [125/232], Loss: 0.2903, Time: 257.8459 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [130/232], Loss: 0.2886, Time: 258.1677 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [135/232], Loss: 0.2819, Time: 258.4645 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [140/232], Loss: 0.2833, Time: 258.7763 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [145/232], Loss: 0.2842, Time: 259.0821 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [150/232], Loss: 0.3016, Time: 259.4569 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [155/232], Loss: 0.2828, Time: 259.7727 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [160/232], Loss: 0.2671, Time: 260.0745 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [165/232], Loss: 0.2837, Time: 260.3973 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [170/232], Loss: 0.2505, Time: 260.6941 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [175/232], Loss: 0.2971, Time: 260.9920 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [180/232], Loss: 0.3202, Time: 261.2848 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [185/232], Loss: 0.2833, Time: 261.5736 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [190/232], Loss: 0.2756, Time: 261.8724 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [195/232], Loss: 0.3014, Time: 262.1632 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [200/232], Loss: 0.2768, Time: 262.4631 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [205/232], Loss: 0.2863, Time: 262.7599 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [210/232], Loss: 0.2623, Time: 263.0607 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [215/232], Loss: 0.2913, Time: 263.3565 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [220/232], Loss: 0.2846, Time: 263.6753 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [225/232], Loss: 0.2621, Time: 263.9781 secs, learning rate: 0.0001\n",
      "Epoch [18/30], Step [230/232], Loss: 0.2663, Time: 264.2789 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [5/232], Loss: 0.2887, Time: 265.0205 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [10/232], Loss: 0.2473, Time: 265.3143 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [15/232], Loss: 0.2721, Time: 265.6121 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [20/232], Loss: 0.2940, Time: 265.9439 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [25/232], Loss: 0.2826, Time: 266.2477 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [30/232], Loss: 0.2796, Time: 266.5395 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [35/232], Loss: 0.3044, Time: 266.8473 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [40/232], Loss: 0.2805, Time: 267.1562 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [45/232], Loss: 0.2987, Time: 267.4540 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [50/232], Loss: 0.2847, Time: 267.7638 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [55/232], Loss: 0.2939, Time: 268.0616 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [60/232], Loss: 0.2653, Time: 268.3774 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [65/232], Loss: 0.3135, Time: 268.6902 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [70/232], Loss: 0.2801, Time: 268.9920 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [75/232], Loss: 0.2686, Time: 269.2858 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [80/232], Loss: 0.2897, Time: 269.5777 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [85/232], Loss: 0.2724, Time: 269.9115 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [90/232], Loss: 0.2650, Time: 270.2093 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [95/232], Loss: 0.2838, Time: 270.5770 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [100/232], Loss: 0.2991, Time: 270.9568 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [105/232], Loss: 0.3012, Time: 271.3236 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [110/232], Loss: 0.2802, Time: 271.6884 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [115/232], Loss: 0.3152, Time: 272.0541 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [120/232], Loss: 0.2923, Time: 272.4179 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [125/232], Loss: 0.2695, Time: 272.7897 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [130/232], Loss: 0.2972, Time: 273.1375 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [135/232], Loss: 0.2840, Time: 273.4553 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [140/232], Loss: 0.2630, Time: 273.7621 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [145/232], Loss: 0.2802, Time: 274.0939 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [150/232], Loss: 0.2578, Time: 274.3937 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [155/232], Loss: 0.2768, Time: 274.7125 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [160/232], Loss: 0.2751, Time: 275.0193 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [165/232], Loss: 0.2673, Time: 275.3141 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [170/232], Loss: 0.3106, Time: 275.6139 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [175/232], Loss: 0.2685, Time: 275.9327 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [180/232], Loss: 0.2557, Time: 276.2306 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [185/232], Loss: 0.2728, Time: 276.5664 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [190/232], Loss: 0.2693, Time: 276.8792 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [195/232], Loss: 0.2667, Time: 277.2000 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [200/232], Loss: 0.2731, Time: 277.5108 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [205/232], Loss: 0.2703, Time: 277.8126 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [210/232], Loss: 0.2675, Time: 278.1154 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [215/232], Loss: 0.2709, Time: 278.4312 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [220/232], Loss: 0.2804, Time: 278.7360 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [225/232], Loss: 0.2555, Time: 279.1368 secs, learning rate: 0.0001\n",
      "Epoch [19/30], Step [230/232], Loss: 0.2772, Time: 279.4396 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [5/232], Loss: 0.2370, Time: 280.1931 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [10/232], Loss: 0.2108, Time: 280.4929 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [15/232], Loss: 0.2600, Time: 280.8197 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [20/232], Loss: 0.2532, Time: 281.1455 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [25/232], Loss: 0.2680, Time: 281.4543 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [30/232], Loss: 0.2969, Time: 281.7591 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [35/232], Loss: 0.2965, Time: 282.0600 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [40/232], Loss: 0.2980, Time: 282.3698 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [45/232], Loss: 0.2515, Time: 282.6836 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [50/232], Loss: 0.2697, Time: 282.9934 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [55/232], Loss: 0.2900, Time: 283.2932 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [60/232], Loss: 0.2636, Time: 283.6070 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [65/232], Loss: 0.2787, Time: 283.9318 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [70/232], Loss: 0.2885, Time: 284.2356 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [75/232], Loss: 0.2717, Time: 284.5444 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [80/232], Loss: 0.2973, Time: 284.8512 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [85/232], Loss: 0.2677, Time: 285.1511 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [90/232], Loss: 0.3030, Time: 285.4519 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [95/232], Loss: 0.2667, Time: 285.7697 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [100/232], Loss: 0.2690, Time: 286.0705 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [105/232], Loss: 0.2822, Time: 286.3753 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [110/232], Loss: 0.2443, Time: 286.6811 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [115/232], Loss: 0.2638, Time: 286.9919 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [120/232], Loss: 0.2756, Time: 287.2977 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [125/232], Loss: 0.2845, Time: 287.6075 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [130/232], Loss: 0.3036, Time: 287.9233 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [135/232], Loss: 0.2628, Time: 288.2302 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [140/232], Loss: 0.2556, Time: 288.5370 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [145/232], Loss: 0.2689, Time: 288.8558 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [150/232], Loss: 0.2863, Time: 289.1676 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [155/232], Loss: 0.2747, Time: 289.4604 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [160/232], Loss: 0.2647, Time: 289.7622 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [165/232], Loss: 0.2776, Time: 290.0780 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [170/232], Loss: 0.2659, Time: 290.3768 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [175/232], Loss: 0.2727, Time: 290.6846 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [180/232], Loss: 0.2553, Time: 290.9895 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [185/232], Loss: 0.2488, Time: 291.3033 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [190/232], Loss: 0.2807, Time: 291.6071 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [195/232], Loss: 0.2742, Time: 291.9119 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [200/232], Loss: 0.2613, Time: 292.2107 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [205/232], Loss: 0.2556, Time: 292.5265 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [210/232], Loss: 0.2813, Time: 292.8393 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [215/232], Loss: 0.2931, Time: 293.1561 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [220/232], Loss: 0.3045, Time: 293.4499 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [225/232], Loss: 0.2709, Time: 293.8057 secs, learning rate: 0.0001\n",
      "Epoch [20/30], Step [230/232], Loss: 0.2723, Time: 294.2784 secs, learning rate: 0.0001\n",
      "Epoch [21/30], Step [5/232], Loss: 0.2466, Time: 295.0979 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [10/232], Loss: 0.2871, Time: 295.3857 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [15/232], Loss: 0.2697, Time: 295.6906 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [20/232], Loss: 0.2596, Time: 295.9984 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [25/232], Loss: 0.2394, Time: 296.2962 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [30/232], Loss: 0.2895, Time: 296.5980 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [35/232], Loss: 0.2687, Time: 296.9038 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [40/232], Loss: 0.2670, Time: 297.1996 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [45/232], Loss: 0.2835, Time: 297.4934 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [50/232], Loss: 0.2470, Time: 297.7943 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [55/232], Loss: 0.2943, Time: 298.1001 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [60/232], Loss: 0.3068, Time: 298.3989 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [65/232], Loss: 0.2618, Time: 298.8386 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [70/232], Loss: 0.2811, Time: 299.1874 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [75/232], Loss: 0.3255, Time: 299.5002 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [80/232], Loss: 0.2767, Time: 299.8030 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [85/232], Loss: 0.2582, Time: 300.1188 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [90/232], Loss: 0.2684, Time: 300.4446 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [95/232], Loss: 0.2523, Time: 300.7704 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [100/232], Loss: 0.2799, Time: 301.0712 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [105/232], Loss: 0.2494, Time: 301.3780 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [110/232], Loss: 0.2614, Time: 301.6938 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [115/232], Loss: 0.2576, Time: 302.0146 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [120/232], Loss: 0.2809, Time: 302.3235 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [125/232], Loss: 0.2862, Time: 302.6213 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [130/232], Loss: 0.2599, Time: 302.9311 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [135/232], Loss: 0.2721, Time: 303.2399 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [140/232], Loss: 0.3196, Time: 303.5517 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [145/232], Loss: 0.2659, Time: 303.8485 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [150/232], Loss: 0.2630, Time: 304.1403 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [155/232], Loss: 0.2635, Time: 304.4491 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [160/232], Loss: 0.2369, Time: 304.7540 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [165/232], Loss: 0.2479, Time: 305.1047 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [170/232], Loss: 0.2799, Time: 305.4195 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [175/232], Loss: 0.2626, Time: 305.7214 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [180/232], Loss: 0.2479, Time: 306.0312 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [185/232], Loss: 0.2624, Time: 306.3480 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [190/232], Loss: 0.3002, Time: 306.6548 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [195/232], Loss: 0.2385, Time: 306.9626 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [200/232], Loss: 0.2714, Time: 307.2634 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [205/232], Loss: 0.2877, Time: 307.5562 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [210/232], Loss: 0.2506, Time: 307.8510 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [215/232], Loss: 0.2675, Time: 308.1509 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [220/232], Loss: 0.2879, Time: 308.4587 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [225/232], Loss: 0.2608, Time: 308.7695 secs, learning rate: 0.0000\n",
      "Epoch [21/30], Step [230/232], Loss: 0.2656, Time: 309.0693 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [5/232], Loss: 0.2617, Time: 309.8108 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [10/232], Loss: 0.2470, Time: 310.1117 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [15/232], Loss: 0.2742, Time: 310.4105 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [20/232], Loss: 0.2589, Time: 310.7163 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [25/232], Loss: 0.2563, Time: 311.0211 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [30/232], Loss: 0.2342, Time: 311.3149 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [35/232], Loss: 0.2612, Time: 311.6117 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [40/232], Loss: 0.2445, Time: 311.9185 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [45/232], Loss: 0.2549, Time: 312.2144 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [50/232], Loss: 0.2798, Time: 312.5102 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [55/232], Loss: 0.2532, Time: 312.8170 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [60/232], Loss: 0.2824, Time: 313.1198 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [65/232], Loss: 0.2654, Time: 313.4126 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [70/232], Loss: 0.2615, Time: 313.7124 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [75/232], Loss: 0.2629, Time: 314.0142 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [80/232], Loss: 0.2526, Time: 314.3191 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [85/232], Loss: 0.2229, Time: 314.6389 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [90/232], Loss: 0.2046, Time: 314.9497 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [95/232], Loss: 0.2489, Time: 315.2525 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [100/232], Loss: 0.2872, Time: 315.5733 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [105/232], Loss: 0.2570, Time: 315.8901 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [110/232], Loss: 0.2035, Time: 316.2039 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [115/232], Loss: 0.2655, Time: 316.5117 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [120/232], Loss: 0.2606, Time: 316.8135 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [125/232], Loss: 0.2630, Time: 317.1353 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [130/232], Loss: 0.2671, Time: 317.4441 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [135/232], Loss: 0.2872, Time: 317.7459 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [140/232], Loss: 0.2602, Time: 318.1427 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [145/232], Loss: 0.2695, Time: 318.4485 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [150/232], Loss: 0.2966, Time: 318.7603 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [155/232], Loss: 0.2644, Time: 319.0831 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [160/232], Loss: 0.2649, Time: 319.3869 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [165/232], Loss: 0.2823, Time: 319.6967 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [170/232], Loss: 0.2111, Time: 319.9946 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [175/232], Loss: 0.2517, Time: 320.3134 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [180/232], Loss: 0.2966, Time: 320.6521 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [185/232], Loss: 0.2774, Time: 321.1319 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [190/232], Loss: 0.2988, Time: 321.6815 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [195/232], Loss: 0.2626, Time: 322.0183 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [200/232], Loss: 0.3153, Time: 322.3091 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [205/232], Loss: 0.2569, Time: 322.6019 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [210/232], Loss: 0.2946, Time: 322.9068 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [215/232], Loss: 0.2704, Time: 323.2286 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [220/232], Loss: 0.2858, Time: 323.5594 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [225/232], Loss: 0.2559, Time: 323.9121 secs, learning rate: 0.0000\n",
      "Epoch [22/30], Step [230/232], Loss: 0.2583, Time: 324.2160 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [5/232], Loss: 0.2625, Time: 324.9725 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [10/232], Loss: 0.2648, Time: 325.2713 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [15/232], Loss: 0.2570, Time: 325.6131 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [20/232], Loss: 0.2556, Time: 325.9089 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [25/232], Loss: 0.2842, Time: 326.2127 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [30/232], Loss: 0.2404, Time: 326.5245 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [35/232], Loss: 0.2548, Time: 326.8313 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [40/232], Loss: 0.2682, Time: 327.1232 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [45/232], Loss: 0.2961, Time: 327.4180 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [50/232], Loss: 0.2469, Time: 327.7148 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [55/232], Loss: 0.2816, Time: 328.0086 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [60/232], Loss: 0.2810, Time: 328.3554 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [65/232], Loss: 0.2632, Time: 328.6972 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [70/232], Loss: 0.2656, Time: 329.0210 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [75/232], Loss: 0.2557, Time: 329.3478 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [80/232], Loss: 0.2446, Time: 329.6736 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [85/232], Loss: 0.2629, Time: 329.9744 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [90/232], Loss: 0.2595, Time: 330.2862 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [95/232], Loss: 0.2865, Time: 330.5810 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [100/232], Loss: 0.2660, Time: 330.8898 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [105/232], Loss: 0.2599, Time: 331.1986 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [110/232], Loss: 0.2022, Time: 331.5015 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [115/232], Loss: 0.2553, Time: 331.8043 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [120/232], Loss: 0.2607, Time: 332.1081 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [125/232], Loss: 0.2835, Time: 332.4249 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [130/232], Loss: 0.3412, Time: 332.7327 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [135/232], Loss: 0.2772, Time: 333.0335 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [140/232], Loss: 0.2543, Time: 333.3413 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [145/232], Loss: 0.2869, Time: 333.6531 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [150/232], Loss: 0.2566, Time: 333.9789 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [155/232], Loss: 0.2802, Time: 334.2857 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [160/232], Loss: 0.2991, Time: 334.5895 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [165/232], Loss: 0.2646, Time: 334.8854 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [170/232], Loss: 0.2679, Time: 335.1772 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [175/232], Loss: 0.2666, Time: 335.4790 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [180/232], Loss: 0.2484, Time: 335.7908 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [185/232], Loss: 0.2526, Time: 336.0956 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [190/232], Loss: 0.2758, Time: 336.4004 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [195/232], Loss: 0.2595, Time: 336.7122 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [200/232], Loss: 0.2716, Time: 337.0191 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [205/232], Loss: 0.2539, Time: 337.3129 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [210/232], Loss: 0.2554, Time: 337.7046 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [215/232], Loss: 0.2610, Time: 338.0164 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [220/232], Loss: 0.2638, Time: 338.3133 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [225/232], Loss: 0.2786, Time: 338.6111 secs, learning rate: 0.0000\n",
      "Epoch [23/30], Step [230/232], Loss: 0.2536, Time: 338.9079 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [5/232], Loss: 0.2643, Time: 339.6414 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [10/232], Loss: 0.2673, Time: 339.9492 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [15/232], Loss: 0.2370, Time: 340.2511 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [20/232], Loss: 0.2661, Time: 340.5609 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [25/232], Loss: 0.2990, Time: 340.8647 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [30/232], Loss: 0.2835, Time: 341.1785 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [35/232], Loss: 0.2556, Time: 341.4783 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [40/232], Loss: 0.2812, Time: 341.7721 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [45/232], Loss: 0.2645, Time: 342.0689 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [50/232], Loss: 0.2511, Time: 342.3687 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [55/232], Loss: 0.2575, Time: 342.6726 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [60/232], Loss: 0.2099, Time: 342.9704 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [65/232], Loss: 0.3089, Time: 343.2702 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [70/232], Loss: 0.2559, Time: 343.5690 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [75/232], Loss: 0.2324, Time: 343.8698 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [80/232], Loss: 0.2436, Time: 344.1686 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [85/232], Loss: 0.2914, Time: 344.4695 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [90/232], Loss: 0.2808, Time: 344.7853 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [95/232], Loss: 0.2700, Time: 345.0911 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [100/232], Loss: 0.2801, Time: 345.3939 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [105/232], Loss: 0.2373, Time: 345.6927 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [110/232], Loss: 0.2512, Time: 345.9915 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [115/232], Loss: 0.2775, Time: 346.3043 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [120/232], Loss: 0.2851, Time: 346.5961 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [125/232], Loss: 0.2460, Time: 346.8910 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [130/232], Loss: 0.3010, Time: 347.1908 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [135/232], Loss: 0.2790, Time: 347.4956 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [140/232], Loss: 0.3120, Time: 347.7984 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [145/232], Loss: 0.2716, Time: 348.0942 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [150/232], Loss: 0.2532, Time: 348.3870 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [155/232], Loss: 0.2422, Time: 348.6928 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [160/232], Loss: 0.2686, Time: 349.0047 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [165/232], Loss: 0.2560, Time: 349.3095 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [170/232], Loss: 0.2588, Time: 349.6073 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [175/232], Loss: 0.2690, Time: 349.9291 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [180/232], Loss: 0.2829, Time: 350.2329 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [185/232], Loss: 0.2853, Time: 350.5357 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [190/232], Loss: 0.2505, Time: 350.8455 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [195/232], Loss: 0.2361, Time: 351.1523 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [200/232], Loss: 0.2459, Time: 351.4501 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [205/232], Loss: 0.2526, Time: 351.7460 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [210/232], Loss: 0.2761, Time: 352.0398 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [215/232], Loss: 0.2845, Time: 352.3436 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [220/232], Loss: 0.2621, Time: 352.6424 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [225/232], Loss: 0.2543, Time: 352.9392 secs, learning rate: 0.0000\n",
      "Epoch [24/30], Step [230/232], Loss: 0.2849, Time: 353.2430 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [5/232], Loss: 0.2554, Time: 353.9786 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [10/232], Loss: 0.2626, Time: 354.2784 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [15/232], Loss: 0.2581, Time: 354.5762 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [20/232], Loss: 0.2692, Time: 354.8750 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [25/232], Loss: 0.2902, Time: 355.1669 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [30/232], Loss: 0.3003, Time: 355.4757 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [35/232], Loss: 0.2492, Time: 355.7715 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [40/232], Loss: 0.2690, Time: 356.0673 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [45/232], Loss: 0.2567, Time: 356.3741 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [50/232], Loss: 0.2450, Time: 356.6889 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [55/232], Loss: 0.2543, Time: 357.0027 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [60/232], Loss: 0.2595, Time: 357.3875 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [65/232], Loss: 0.2612, Time: 357.6933 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [70/232], Loss: 0.2538, Time: 358.0071 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [75/232], Loss: 0.2624, Time: 358.3149 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [80/232], Loss: 0.2975, Time: 358.6137 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [85/232], Loss: 0.2638, Time: 358.9055 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [90/232], Loss: 0.2652, Time: 359.2154 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [95/232], Loss: 0.2873, Time: 359.5172 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [100/232], Loss: 0.2625, Time: 359.8170 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [105/232], Loss: 0.2728, Time: 360.1168 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [110/232], Loss: 0.2648, Time: 360.4226 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [115/232], Loss: 0.2514, Time: 360.7334 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [120/232], Loss: 0.2538, Time: 361.0402 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [125/232], Loss: 0.2349, Time: 361.3480 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [130/232], Loss: 0.2860, Time: 361.6519 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [135/232], Loss: 0.2642, Time: 361.9487 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [140/232], Loss: 0.2428, Time: 362.2605 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [145/232], Loss: 0.2087, Time: 362.5523 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [150/232], Loss: 0.2031, Time: 362.8521 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [155/232], Loss: 0.2852, Time: 363.1529 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [160/232], Loss: 0.2741, Time: 363.4607 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [165/232], Loss: 0.2423, Time: 363.7635 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [170/232], Loss: 0.2443, Time: 364.0554 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [175/232], Loss: 0.2412, Time: 364.3522 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [180/232], Loss: 0.2579, Time: 364.6520 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [185/232], Loss: 0.2517, Time: 364.9638 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [190/232], Loss: 0.2493, Time: 365.2816 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [195/232], Loss: 0.2589, Time: 365.5764 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [200/232], Loss: 0.2520, Time: 365.8742 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [205/232], Loss: 0.2583, Time: 366.1741 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [210/232], Loss: 0.2634, Time: 366.4669 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [215/232], Loss: 0.2553, Time: 366.7787 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [220/232], Loss: 0.2735, Time: 367.0725 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [225/232], Loss: 0.2848, Time: 367.3663 secs, learning rate: 0.0000\n",
      "Epoch [25/30], Step [230/232], Loss: 0.2615, Time: 367.6611 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [5/232], Loss: 0.2484, Time: 368.4047 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [10/232], Loss: 0.2304, Time: 368.7035 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [15/232], Loss: 0.2609, Time: 368.9993 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [20/232], Loss: 0.2542, Time: 369.3101 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [25/232], Loss: 0.2529, Time: 369.6109 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [30/232], Loss: 0.2537, Time: 369.9118 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [35/232], Loss: 0.2435, Time: 370.2106 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [40/232], Loss: 0.2604, Time: 370.5304 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [45/232], Loss: 0.2525, Time: 370.8412 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [50/232], Loss: 0.2740, Time: 371.1440 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [55/232], Loss: 0.2400, Time: 371.4398 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [60/232], Loss: 0.2937, Time: 371.7716 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [65/232], Loss: 0.2580, Time: 372.0724 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [70/232], Loss: 0.2940, Time: 372.3892 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [75/232], Loss: 0.2819, Time: 372.6990 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [80/232], Loss: 0.2953, Time: 373.0198 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [85/232], Loss: 0.2810, Time: 373.3316 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [90/232], Loss: 0.2601, Time: 373.6325 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [95/232], Loss: 0.2442, Time: 373.9453 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [100/232], Loss: 0.2435, Time: 374.2481 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [105/232], Loss: 0.2297, Time: 374.5549 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [110/232], Loss: 0.2957, Time: 374.8567 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [115/232], Loss: 0.2534, Time: 375.1665 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [120/232], Loss: 0.2888, Time: 375.4713 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [125/232], Loss: 0.2830, Time: 375.7791 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [130/232], Loss: 0.2445, Time: 376.0799 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [135/232], Loss: 0.2577, Time: 376.3778 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [140/232], Loss: 0.2599, Time: 376.6876 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [145/232], Loss: 0.2398, Time: 377.0773 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [150/232], Loss: 0.2639, Time: 377.3791 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [155/232], Loss: 0.2411, Time: 377.6710 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [160/232], Loss: 0.2592, Time: 377.9728 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [165/232], Loss: 0.2563, Time: 378.2736 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [170/232], Loss: 0.2609, Time: 378.5734 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [175/232], Loss: 0.2758, Time: 378.8922 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [180/232], Loss: 0.2800, Time: 379.1930 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [185/232], Loss: 0.2940, Time: 379.4878 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [190/232], Loss: 0.2737, Time: 379.7887 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [195/232], Loss: 0.2569, Time: 380.1055 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [200/232], Loss: 0.2568, Time: 380.4063 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [205/232], Loss: 0.2569, Time: 380.7141 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [210/232], Loss: 0.2502, Time: 381.0329 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [215/232], Loss: 0.2431, Time: 381.3457 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [220/232], Loss: 0.2541, Time: 381.6535 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [225/232], Loss: 0.2476, Time: 381.9563 secs, learning rate: 0.0000\n",
      "Epoch [26/30], Step [230/232], Loss: 0.2628, Time: 382.2521 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [5/232], Loss: 0.2573, Time: 382.9887 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [10/232], Loss: 0.2519, Time: 383.2805 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [15/232], Loss: 0.2910, Time: 383.5823 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [20/232], Loss: 0.2321, Time: 383.8941 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [25/232], Loss: 0.2595, Time: 384.1999 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [30/232], Loss: 0.2405, Time: 384.4958 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [35/232], Loss: 0.2499, Time: 384.7896 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [40/232], Loss: 0.2542, Time: 385.1184 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [45/232], Loss: 0.2796, Time: 385.4332 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [50/232], Loss: 0.2567, Time: 385.7450 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [55/232], Loss: 0.2809, Time: 386.0518 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [60/232], Loss: 0.2415, Time: 386.3506 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [65/232], Loss: 0.2652, Time: 386.6574 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [70/232], Loss: 0.2477, Time: 386.9592 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [75/232], Loss: 0.2622, Time: 387.2630 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [80/232], Loss: 0.3347, Time: 387.5699 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [85/232], Loss: 0.2517, Time: 387.8657 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [90/232], Loss: 0.2717, Time: 388.1765 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [95/232], Loss: 0.2857, Time: 388.4953 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [100/232], Loss: 0.2433, Time: 388.8051 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [105/232], Loss: 0.2514, Time: 389.1129 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [110/232], Loss: 0.2764, Time: 389.4137 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [115/232], Loss: 0.2725, Time: 389.7485 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [120/232], Loss: 0.2650, Time: 390.0593 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [125/232], Loss: 0.2511, Time: 390.3681 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [130/232], Loss: 0.2562, Time: 390.7149 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [135/232], Loss: 0.2476, Time: 391.1946 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [140/232], Loss: 0.2840, Time: 391.6044 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [145/232], Loss: 0.2813, Time: 391.9522 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [150/232], Loss: 0.2551, Time: 392.3049 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [155/232], Loss: 0.2619, Time: 392.6827 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [160/232], Loss: 0.2526, Time: 393.0475 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [165/232], Loss: 0.2589, Time: 393.3993 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [170/232], Loss: 0.2821, Time: 393.7780 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [175/232], Loss: 0.2730, Time: 394.1138 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [180/232], Loss: 0.3078, Time: 394.4746 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [185/232], Loss: 0.2483, Time: 394.8424 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [190/232], Loss: 0.2655, Time: 395.1662 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [195/232], Loss: 0.2494, Time: 395.4670 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [200/232], Loss: 0.2539, Time: 395.8128 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [205/232], Loss: 0.2592, Time: 396.1216 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [210/232], Loss: 0.2419, Time: 396.5203 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [215/232], Loss: 0.2582, Time: 396.8192 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [220/232], Loss: 0.2595, Time: 397.1200 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [225/232], Loss: 0.2427, Time: 397.4278 secs, learning rate: 0.0000\n",
      "Epoch [27/30], Step [230/232], Loss: 0.2636, Time: 397.7226 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [5/232], Loss: 0.2525, Time: 398.4751 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [10/232], Loss: 0.2978, Time: 398.7749 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [15/232], Loss: 0.2483, Time: 399.0758 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [20/232], Loss: 0.2383, Time: 399.3826 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [25/232], Loss: 0.2779, Time: 399.6764 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [30/232], Loss: 0.2630, Time: 400.0072 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [35/232], Loss: 0.2675, Time: 400.4909 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [40/232], Loss: 0.2461, Time: 401.0435 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [45/232], Loss: 0.2850, Time: 401.4183 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [50/232], Loss: 0.2445, Time: 401.7311 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [55/232], Loss: 0.2514, Time: 402.0429 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [60/232], Loss: 0.3065, Time: 402.3417 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [65/232], Loss: 0.2818, Time: 402.6456 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [70/232], Loss: 0.2602, Time: 402.9484 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [75/232], Loss: 0.2538, Time: 403.2462 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [80/232], Loss: 0.2418, Time: 403.5580 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [85/232], Loss: 0.2278, Time: 403.8558 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [90/232], Loss: 0.2810, Time: 404.1586 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [95/232], Loss: 0.2572, Time: 404.5694 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [100/232], Loss: 0.2279, Time: 405.0341 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [105/232], Loss: 0.2799, Time: 405.5098 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [110/232], Loss: 0.2792, Time: 405.9805 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [115/232], Loss: 0.2405, Time: 406.3912 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [120/232], Loss: 0.2302, Time: 406.6911 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [125/232], Loss: 0.2921, Time: 406.9879 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [130/232], Loss: 0.2395, Time: 407.3087 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [135/232], Loss: 0.2853, Time: 407.6555 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [140/232], Loss: 0.2682, Time: 407.9783 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [145/232], Loss: 0.2906, Time: 408.2891 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [150/232], Loss: 0.2415, Time: 408.5939 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [155/232], Loss: 0.2733, Time: 408.9077 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [160/232], Loss: 0.2570, Time: 409.2325 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [165/232], Loss: 0.2565, Time: 409.5423 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [170/232], Loss: 0.2581, Time: 409.8551 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [175/232], Loss: 0.2536, Time: 410.1549 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [180/232], Loss: 0.2569, Time: 410.4837 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [185/232], Loss: 0.2734, Time: 410.7885 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [190/232], Loss: 0.2584, Time: 411.0893 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [195/232], Loss: 0.2635, Time: 411.4871 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [200/232], Loss: 0.2652, Time: 411.8019 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [205/232], Loss: 0.2769, Time: 412.1037 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [210/232], Loss: 0.2773, Time: 412.4085 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [215/232], Loss: 0.2574, Time: 412.7163 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [220/232], Loss: 0.2392, Time: 413.0152 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [225/232], Loss: 0.2365, Time: 413.3280 secs, learning rate: 0.0000\n",
      "Epoch [28/30], Step [230/232], Loss: 0.2849, Time: 413.6358 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [5/232], Loss: 0.2669, Time: 414.3673 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [10/232], Loss: 0.2554, Time: 414.6631 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [15/232], Loss: 0.2532, Time: 414.9600 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [20/232], Loss: 0.2519, Time: 415.2718 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [25/232], Loss: 0.2304, Time: 415.5766 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [30/232], Loss: 0.2490, Time: 415.8714 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [35/232], Loss: 0.2789, Time: 416.1692 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [40/232], Loss: 0.2537, Time: 416.4890 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [45/232], Loss: 0.2930, Time: 416.7958 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [50/232], Loss: 0.2293, Time: 417.0906 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [55/232], Loss: 0.2712, Time: 417.3945 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [60/232], Loss: 0.2783, Time: 417.7083 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [65/232], Loss: 0.2410, Time: 418.0071 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [70/232], Loss: 0.2369, Time: 418.3159 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [75/232], Loss: 0.2400, Time: 418.6247 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [80/232], Loss: 0.2847, Time: 418.9225 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [85/232], Loss: 0.2442, Time: 419.2303 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [90/232], Loss: 0.2515, Time: 419.5421 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [95/232], Loss: 0.2745, Time: 419.8429 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [100/232], Loss: 0.2847, Time: 420.1607 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [105/232], Loss: 0.2590, Time: 420.4646 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [110/232], Loss: 0.2530, Time: 420.7664 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [115/232], Loss: 0.2759, Time: 421.0792 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [120/232], Loss: 0.2264, Time: 421.3750 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [125/232], Loss: 0.2472, Time: 421.6778 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [130/232], Loss: 0.3035, Time: 421.9846 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [135/232], Loss: 0.2501, Time: 422.2814 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [140/232], Loss: 0.2550, Time: 422.5833 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [145/232], Loss: 0.2498, Time: 422.8811 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [150/232], Loss: 0.2511, Time: 423.2149 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [155/232], Loss: 0.2392, Time: 423.5487 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [160/232], Loss: 0.2552, Time: 423.9064 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [165/232], Loss: 0.2591, Time: 424.2083 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [170/232], Loss: 0.2495, Time: 424.5111 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [175/232], Loss: 0.2781, Time: 424.8209 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [180/232], Loss: 0.2786, Time: 425.1976 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [185/232], Loss: 0.2594, Time: 425.5244 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [190/232], Loss: 0.2521, Time: 425.8263 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [195/232], Loss: 0.2493, Time: 426.1411 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [200/232], Loss: 0.2619, Time: 426.4609 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [205/232], Loss: 0.2647, Time: 426.9066 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [210/232], Loss: 0.2387, Time: 427.2604 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [215/232], Loss: 0.2578, Time: 427.5792 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [220/232], Loss: 0.2883, Time: 427.8920 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [225/232], Loss: 0.2793, Time: 428.1988 secs, learning rate: 0.0000\n",
      "Epoch [29/30], Step [230/232], Loss: 0.2516, Time: 428.5106 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [5/232], Loss: 0.2489, Time: 429.2411 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [10/232], Loss: 0.2648, Time: 429.5570 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [15/232], Loss: 0.2585, Time: 429.8608 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [20/232], Loss: 0.2520, Time: 430.1716 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [25/232], Loss: 0.2454, Time: 430.4814 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [30/232], Loss: 0.2431, Time: 430.7892 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [35/232], Loss: 0.2241, Time: 431.1080 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [40/232], Loss: 0.2526, Time: 431.4038 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [45/232], Loss: 0.2437, Time: 431.7006 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [50/232], Loss: 0.2281, Time: 432.0054 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [55/232], Loss: 0.2501, Time: 432.3932 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [60/232], Loss: 0.2676, Time: 432.6960 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [65/232], Loss: 0.2506, Time: 432.9928 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [70/232], Loss: 0.2532, Time: 433.2896 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [75/232], Loss: 0.2679, Time: 433.5995 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [80/232], Loss: 0.2631, Time: 433.9033 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [85/232], Loss: 0.2609, Time: 434.2141 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [90/232], Loss: 0.2505, Time: 434.5149 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [95/232], Loss: 0.2339, Time: 434.8047 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [100/232], Loss: 0.2398, Time: 435.1235 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [105/232], Loss: 0.2817, Time: 435.4243 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [110/232], Loss: 0.2378, Time: 435.7291 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [115/232], Loss: 0.2544, Time: 436.0380 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [120/232], Loss: 0.2640, Time: 436.3498 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [125/232], Loss: 0.2427, Time: 436.6616 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [130/232], Loss: 0.2836, Time: 436.9704 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [135/232], Loss: 0.2438, Time: 437.2772 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [140/232], Loss: 0.3061, Time: 437.6080 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [145/232], Loss: 0.2754, Time: 437.9118 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [150/232], Loss: 0.2535, Time: 438.2136 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [155/232], Loss: 0.2657, Time: 438.5454 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [160/232], Loss: 0.2464, Time: 438.8562 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [165/232], Loss: 0.2589, Time: 439.1580 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [170/232], Loss: 0.2516, Time: 439.4548 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [175/232], Loss: 0.2515, Time: 439.7647 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [180/232], Loss: 0.2537, Time: 440.0805 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [185/232], Loss: 0.2531, Time: 440.3993 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [190/232], Loss: 0.2823, Time: 440.7031 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [195/232], Loss: 0.2539, Time: 441.0019 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [200/232], Loss: 0.2754, Time: 441.3027 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [205/232], Loss: 0.2985, Time: 441.6175 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [210/232], Loss: 0.2565, Time: 441.9383 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [215/232], Loss: 0.2672, Time: 442.2371 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [220/232], Loss: 0.2544, Time: 442.5409 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [225/232], Loss: 0.2752, Time: 442.8507 secs, learning rate: 0.0000\n",
      "Epoch [30/30], Step [230/232], Loss: 0.2493, Time: 443.1596 secs, learning rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(YTrain)\n",
    "start_time = time.time()\n",
    "model = model.float()\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "loss_tmp = 0\n",
    "norm = 1\n",
    "for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm*outputs, norm*y.float().T)\n",
    "        loss_tmp += loss.item()\n",
    "loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ind = np.arange(int(total_step/batch_size))\n",
    "    random.shuffle(ind)\n",
    "    for i,k in enumerate(ind):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XTrain[k*batch_size:(k+1)*batch_size,:,:,:], YTrain[k*batch_size:(k+1)*batch_size,:]\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm*y.float(), norm*outputs)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 5== 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs, learning rate: {:.4f}'\n",
    "                    .format(epoch + 1, num_epochs, i + 1, int(total_step/batch_size), loss.item(), time.time() - start_time, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    loss_tmp = 0\n",
    "    result = []\n",
    "    for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm*outputs, norm*y.float().T)\n",
    "        loss_tmp += loss.item()\n",
    "        result.append(outputs)\n",
    "    loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 20.0)"
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x396 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(loss_train)), loss_train, label = 'Training error')\n",
    "plt.plot(np.arange(0, len(loss_train)+1, int(total_step/batch_size)), loss_val, label = 'Validation error')\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim([0,20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [
    {
     "data": {
      "text/plain": "(-10.0, 10.0)"
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x396 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(result)), YVal, label = 'Validation')\n",
    "plt.plot(np.arange(len(result)), result, label = 'Training')\n",
    "plt.ylabel('state', fontsize = 14)\n",
    "plt.xlabel('time', fontsize = 14)\n",
    "plt.legend()\n",
    "plt.ylim([-10,10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}