{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation.generate_path import generate_path\n",
    "import matplotlib.pyplot as plt\n",
    "from estimation.distance_sensor import distance_sensors\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575, 1)\n",
      "(4, 3, 4, 575)\n"
     ]
    }
   ],
   "source": [
    "# create test data\n",
    "target_initial_pos = np.array([0, 0, 5000])\n",
    "target_speed_xy = 50\n",
    "target_speed_z = 10\n",
    "target_rot_speed = 3\n",
    "time_res = 0.5\n",
    "\n",
    "path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "path1.add_straight_interval(100)\n",
    "path1.add_xy_turn_interval(90, -np.deg2rad(target_rot_speed))\n",
    "path1.add_straight_interval(100)\n",
    "\n",
    "# create noisy sensors\n",
    "sensors = distance_sensors([[-5000,0,0],[ 400, -7400, 0],[ 800, 800, 0]], 15)\n",
    "sensors.calculate_measurements(path1.path)\n",
    "\n",
    "sample = 4\n",
    "XTest = []\n",
    "for i in np.arange(len(path1.path) - sample + 1):\n",
    "    tmp = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i,:], (1,3))), 0)\n",
    "    tmp = tmp.reshape(4,3,1)\n",
    "    for j in np.arange(1,sample):\n",
    "        matrix = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i+j,:], (1,3))), 0)\n",
    "        matrix = matrix.reshape(4,3,1)\n",
    "        tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "    if i > 0:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = np.concatenate((XTest, tmp), 3)\n",
    "    else:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = tmp\n",
    "\n",
    "YTest = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTest))\n",
    "print(np.shape(XTest))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117733, 1)\n",
      "(4, 3, 4, 117733)\n"
     ]
    }
   ],
   "source": [
    "# create train data\n",
    "run_number = 600\n",
    "XTrain = []\n",
    "YTrain = []\n",
    "for k in np.arange(run_number):\n",
    "    target_initial_pos = np.random.randint(-7000, 7000, size=(1, 3))[0]\n",
    "    sensors_pos = np.random.randint(-7000, 7000, size=(3, 3))[:,:]\n",
    "    target_speed_xy = 50\n",
    "    target_speed_z = 10\n",
    "    target_rot_speed = 3\n",
    "    time_res = 0.5\n",
    "\n",
    "    path1 = generate_path(np.deg2rad(np.random.randint(0,360,size=1)[0]), target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "    path1.add_straight_interval(np.random.randint(0,100,size=1)[0])\n",
    "    path1.add_xy_turn_interval(np.random.randint(0,100,size=1)[0], -random.choice([-1, 1])*np.deg2rad(target_rot_speed))\n",
    "\n",
    "    # create noisy sensors\n",
    "    sensors = distance_sensors(sensors_pos, 20)\n",
    "    sensors.calculate_measurements(path1.path)\n",
    "\n",
    "    sample = 4\n",
    "    for i in np.arange(len(path1.path) - sample + 1):\n",
    "        tmp = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i,:], (1,3))), 0)\n",
    "        tmp = tmp.reshape(4,3,1)\n",
    "        for j in np.arange(1,sample):\n",
    "            matrix = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i+j,:], (1,3))), 0)\n",
    "            matrix = matrix.reshape(4,3,1)\n",
    "            tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "        if len(XTrain):\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = np.concatenate((XTrain, tmp), 3)\n",
    "        else:\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = tmp\n",
    "    if len(YTrain):\n",
    "        YTrain = np.concatenate((YTrain, path1.state_key[sample-1:]), 0)\n",
    "    else:\n",
    "        YTrain = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTrain))\n",
    "print(np.shape(XTrain))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "ind = np.arange(len(YTrain))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XVal = torch.from_numpy(np.transpose(XTest, (3, 2, 0, 1)))\n",
    "YVal = torch.from_numpy(YTest)\n",
    "\n",
    "XTrain = torch.from_numpy(np.transpose(XTrain[:,:,:,ind], (3, 2, 0, 1)))\n",
    "YTrain = torch.from_numpy(YTrain[ind,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# create network\n",
    "class state_estimat(nn.Module):\n",
    "    def __init__(self, d_in, num_classes):\n",
    "        # initialzing the parent object (important!)\n",
    "        super(state_estimat, self).__init__()\n",
    "        # Create a pipeline - a sequence of layers\n",
    "        self.pipe = torch.nn.Sequential(\n",
    "            nn.Conv2d(d_in, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*3*4, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_estimat(\n",
      "  (pipe): Sequential(\n",
      "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters:\n",
    "num_epochs = 60\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "learning_rate_drop_period = 10\n",
    "input_shape = [3,4,3]\n",
    "\n",
    "# Device configuration, as before\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# create model\n",
    "model = state_estimat(d_in=4, num_classes=1).to(device)\n",
    "print(model)\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=learning_rate_drop_period, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def my_loss(target, output):\n",
    "    loss = torch.mean(math.exp(output) - math.exp(target))\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Step [5/229], Loss: 52685.8750, Time: 1.3072 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [10/229], Loss: 1503.5280, Time: 1.7479 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [15/229], Loss: 3560.8777, Time: 2.2052 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [20/229], Loss: 588.9982, Time: 2.6764 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [25/229], Loss: 1062.9678, Time: 3.2010 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [30/229], Loss: 154.9467, Time: 3.7242 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [35/229], Loss: 167.4223, Time: 4.0870 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [40/229], Loss: 203.5834, Time: 4.4553 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [45/229], Loss: 86.3059, Time: 4.9120 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [50/229], Loss: 55.4759, Time: 5.2683 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [55/229], Loss: 68.2989, Time: 5.6531 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [60/229], Loss: 46.4460, Time: 6.0323 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [65/229], Loss: 32.6892, Time: 6.3871 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [70/229], Loss: 37.5682, Time: 6.7439 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [75/229], Loss: 30.1498, Time: 7.0952 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [80/229], Loss: 28.7244, Time: 7.4659 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [85/229], Loss: 25.3392, Time: 7.8192 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [90/229], Loss: 27.1268, Time: 8.1780 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [95/229], Loss: 23.3729, Time: 8.5313 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [100/229], Loss: 22.6067, Time: 8.8861 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [105/229], Loss: 22.3128, Time: 9.3403 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [110/229], Loss: 20.6278, Time: 9.7561 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [115/229], Loss: 19.3705, Time: 10.1293 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [120/229], Loss: 22.7392, Time: 10.4881 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [125/229], Loss: 19.9653, Time: 10.8579 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [130/229], Loss: 17.3227, Time: 11.2152 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [135/229], Loss: 18.8169, Time: 11.5889 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [140/229], Loss: 18.4438, Time: 11.9532 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [145/229], Loss: 15.1837, Time: 12.3380 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [150/229], Loss: 16.2665, Time: 12.7792 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [155/229], Loss: 17.4241, Time: 13.1470 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [160/229], Loss: 15.5693, Time: 13.4943 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [165/229], Loss: 14.7070, Time: 13.8840 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [170/229], Loss: 13.7869, Time: 14.3502 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [175/229], Loss: 14.0046, Time: 14.7220 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [180/229], Loss: 14.7834, Time: 15.0943 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [185/229], Loss: 13.5870, Time: 15.4531 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [190/229], Loss: 13.4970, Time: 15.8698 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [195/229], Loss: 12.4176, Time: 16.2521 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [200/229], Loss: 11.9438, Time: 16.7018 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [205/229], Loss: 12.1653, Time: 17.1500 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [210/229], Loss: 13.4389, Time: 17.7312 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [215/229], Loss: 11.6376, Time: 18.1259 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [220/229], Loss: 12.4027, Time: 18.5332 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [225/229], Loss: 10.8870, Time: 18.8990 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [5/229], Loss: 10.9483, Time: 19.9658 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [10/229], Loss: 10.6573, Time: 20.4530 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [15/229], Loss: 10.2552, Time: 20.8328 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [20/229], Loss: 10.5513, Time: 21.3170 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [25/229], Loss: 10.3478, Time: 21.6848 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [30/229], Loss: 10.9610, Time: 22.3159 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [35/229], Loss: 10.1446, Time: 22.7381 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [40/229], Loss: 9.3105, Time: 23.2278 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [45/229], Loss: 9.7936, Time: 23.7050 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [50/229], Loss: 9.0330, Time: 24.1168 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [55/229], Loss: 9.0346, Time: 24.4601 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [60/229], Loss: 9.3107, Time: 24.8778 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [65/229], Loss: 8.8510, Time: 25.2331 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [70/229], Loss: 7.8030, Time: 25.5569 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [75/229], Loss: 8.7229, Time: 25.8547 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [80/229], Loss: 8.1373, Time: 26.1869 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [85/229], Loss: 8.2468, Time: 26.5077 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [90/229], Loss: 8.3183, Time: 27.0089 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [95/229], Loss: 7.8508, Time: 27.4771 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [100/229], Loss: 7.8033, Time: 27.8839 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [105/229], Loss: 6.5345, Time: 28.2107 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [110/229], Loss: 7.9845, Time: 28.5250 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [115/229], Loss: 7.4709, Time: 28.8148 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [120/229], Loss: 7.6342, Time: 29.1241 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [125/229], Loss: 6.7671, Time: 29.4289 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [130/229], Loss: 6.5428, Time: 29.7238 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [135/229], Loss: 8.0340, Time: 30.0131 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [140/229], Loss: 6.8243, Time: 30.3009 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [145/229], Loss: 7.0457, Time: 30.7511 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [150/229], Loss: 6.8896, Time: 31.7235 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [155/229], Loss: 6.5117, Time: 32.5730 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [160/229], Loss: 7.0379, Time: 33.0357 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [165/229], Loss: 6.0815, Time: 33.3805 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [170/229], Loss: 5.9861, Time: 33.6763 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [175/229], Loss: 6.0348, Time: 33.9881 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [180/229], Loss: 5.4313, Time: 34.2870 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [185/229], Loss: 6.2308, Time: 34.5748 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [190/229], Loss: 5.9664, Time: 34.8936 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [195/229], Loss: 5.8548, Time: 35.1844 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [200/229], Loss: 5.5634, Time: 35.5482 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [205/229], Loss: 5.6616, Time: 35.8510 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [210/229], Loss: 5.9667, Time: 36.1418 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [215/229], Loss: 5.5799, Time: 36.4326 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [220/229], Loss: 5.4512, Time: 36.7215 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [225/229], Loss: 5.7096, Time: 37.0043 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [5/229], Loss: 5.3971, Time: 37.8877 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [10/229], Loss: 5.3948, Time: 38.1826 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [15/229], Loss: 5.5855, Time: 38.4704 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [20/229], Loss: 4.4378, Time: 38.7562 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [25/229], Loss: 4.9933, Time: 39.0560 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [30/229], Loss: 4.5176, Time: 39.3408 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [35/229], Loss: 4.8114, Time: 39.6427 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [40/229], Loss: 4.9426, Time: 39.9285 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [45/229], Loss: 5.0889, Time: 40.2193 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [50/229], Loss: 4.6661, Time: 40.5201 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [55/229], Loss: 4.5814, Time: 40.8289 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [60/229], Loss: 4.9158, Time: 41.1277 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [65/229], Loss: 4.3949, Time: 41.4186 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [70/229], Loss: 4.3183, Time: 41.7224 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [75/229], Loss: 4.2472, Time: 42.0102 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [80/229], Loss: 4.6890, Time: 42.3100 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [85/229], Loss: 4.1081, Time: 42.6108 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [90/229], Loss: 4.4386, Time: 42.8966 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [95/229], Loss: 4.1895, Time: 43.2145 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [100/229], Loss: 3.7652, Time: 43.5253 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [105/229], Loss: 4.3319, Time: 43.8351 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [110/229], Loss: 4.4680, Time: 44.1289 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [115/229], Loss: 4.0368, Time: 44.4187 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [120/229], Loss: 3.9423, Time: 44.7145 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [125/229], Loss: 3.9107, Time: 45.0123 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [130/229], Loss: 3.3682, Time: 45.2982 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [135/229], Loss: 3.8357, Time: 45.5890 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [140/229], Loss: 4.0199, Time: 45.8738 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [145/229], Loss: 3.7805, Time: 46.1656 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [150/229], Loss: 3.7241, Time: 46.4525 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [155/229], Loss: 3.5316, Time: 46.7573 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [160/229], Loss: 3.3880, Time: 47.0521 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [165/229], Loss: 3.4812, Time: 47.3699 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [170/229], Loss: 3.5218, Time: 47.6707 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [175/229], Loss: 3.5613, Time: 47.9615 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [180/229], Loss: 3.1385, Time: 48.2553 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [185/229], Loss: 3.5364, Time: 48.5412 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [190/229], Loss: 3.3083, Time: 48.8280 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [195/229], Loss: 3.2296, Time: 49.1148 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [200/229], Loss: 3.5244, Time: 49.4136 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [205/229], Loss: 3.5756, Time: 49.7424 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [210/229], Loss: 3.2020, Time: 50.0592 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [215/229], Loss: 3.5061, Time: 50.3501 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [220/229], Loss: 2.9072, Time: 50.6489 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [225/229], Loss: 3.3366, Time: 50.9367 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [5/229], Loss: 2.8328, Time: 51.8082 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [10/229], Loss: 2.9583, Time: 52.0870 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [15/229], Loss: 3.0146, Time: 52.3878 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [20/229], Loss: 3.1009, Time: 52.6876 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [25/229], Loss: 2.9212, Time: 52.9784 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [30/229], Loss: 2.7268, Time: 53.2613 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [35/229], Loss: 3.0397, Time: 53.5461 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [40/229], Loss: 3.4643, Time: 53.8489 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [45/229], Loss: 3.2691, Time: 54.1797 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [50/229], Loss: 2.7996, Time: 54.4735 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [55/229], Loss: 2.5945, Time: 54.7733 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [60/229], Loss: 2.8462, Time: 55.0681 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [65/229], Loss: 2.7419, Time: 55.3730 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [70/229], Loss: 2.7404, Time: 55.6718 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [75/229], Loss: 2.5807, Time: 55.9806 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [80/229], Loss: 3.1743, Time: 56.2894 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [85/229], Loss: 2.6061, Time: 56.5812 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [90/229], Loss: 2.2981, Time: 56.8880 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [95/229], Loss: 2.9242, Time: 57.1888 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [100/229], Loss: 2.6377, Time: 57.4856 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [105/229], Loss: 2.6657, Time: 57.8174 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [110/229], Loss: 2.1984, Time: 58.1143 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [115/229], Loss: 2.4677, Time: 58.4361 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [120/229], Loss: 2.6327, Time: 58.7309 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [125/229], Loss: 2.4070, Time: 59.0227 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [130/229], Loss: 2.5880, Time: 59.3135 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [135/229], Loss: 2.5279, Time: 59.6193 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [140/229], Loss: 2.1310, Time: 59.9421 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [145/229], Loss: 2.2507, Time: 60.2340 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [150/229], Loss: 2.2386, Time: 60.5328 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [155/229], Loss: 2.4740, Time: 60.8576 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [160/229], Loss: 2.2326, Time: 61.1594 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [165/229], Loss: 1.9598, Time: 61.4672 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [170/229], Loss: 2.0446, Time: 61.7690 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [175/229], Loss: 2.3494, Time: 62.0638 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [180/229], Loss: 2.0195, Time: 62.3746 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [185/229], Loss: 1.8662, Time: 62.6934 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [190/229], Loss: 1.9006, Time: 62.9873 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [195/229], Loss: 1.8495, Time: 63.2741 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [200/229], Loss: 2.1348, Time: 63.5689 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [205/229], Loss: 2.4530, Time: 63.8747 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [210/229], Loss: 1.8824, Time: 64.2245 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [215/229], Loss: 1.9205, Time: 64.5253 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [220/229], Loss: 2.1084, Time: 64.8151 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [225/229], Loss: 1.8896, Time: 65.1219 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [5/229], Loss: 1.9974, Time: 65.9954 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [10/229], Loss: 1.7698, Time: 66.2852 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [15/229], Loss: 1.8583, Time: 66.5780 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [20/229], Loss: 1.8780, Time: 66.8749 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [25/229], Loss: 1.9088, Time: 67.1617 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [30/229], Loss: 1.9200, Time: 67.4665 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [35/229], Loss: 1.8036, Time: 67.7773 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [40/229], Loss: 1.6810, Time: 68.0891 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [45/229], Loss: 1.7062, Time: 68.3809 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [50/229], Loss: 1.8634, Time: 68.6727 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [55/229], Loss: 1.8434, Time: 68.9656 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [60/229], Loss: 2.0853, Time: 69.2544 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [65/229], Loss: 1.7046, Time: 69.5442 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [70/229], Loss: 1.9187, Time: 69.8450 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [75/229], Loss: 1.8498, Time: 70.1358 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [80/229], Loss: 1.5915, Time: 70.4217 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [85/229], Loss: 1.7536, Time: 70.7095 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [90/229], Loss: 1.7979, Time: 70.9963 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [95/229], Loss: 1.5528, Time: 71.3051 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [100/229], Loss: 1.7511, Time: 71.6089 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [105/229], Loss: 1.6837, Time: 71.8968 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [110/229], Loss: 1.7024, Time: 72.1836 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [115/229], Loss: 1.4100, Time: 72.4934 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [120/229], Loss: 1.7179, Time: 72.7922 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [125/229], Loss: 1.4155, Time: 73.0790 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [130/229], Loss: 1.5834, Time: 73.3768 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [135/229], Loss: 1.3696, Time: 73.6787 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [140/229], Loss: 1.7289, Time: 73.9785 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [145/229], Loss: 1.5830, Time: 74.2643 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [150/229], Loss: 1.5152, Time: 74.5481 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [155/229], Loss: 1.4421, Time: 74.8329 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [160/229], Loss: 1.4707, Time: 75.1378 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [165/229], Loss: 1.5967, Time: 75.4306 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [170/229], Loss: 1.2893, Time: 75.7154 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [175/229], Loss: 1.4027, Time: 76.0202 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [180/229], Loss: 1.3848, Time: 76.3040 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [185/229], Loss: 1.5148, Time: 76.5909 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [190/229], Loss: 1.4117, Time: 76.8757 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [195/229], Loss: 1.3526, Time: 77.1895 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [200/229], Loss: 1.5221, Time: 77.4813 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [205/229], Loss: 1.5189, Time: 77.7671 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [210/229], Loss: 1.5650, Time: 78.0610 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [215/229], Loss: 1.2850, Time: 78.3478 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [220/229], Loss: 1.3406, Time: 78.6486 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [225/229], Loss: 1.3346, Time: 78.9364 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [5/229], Loss: 1.3874, Time: 79.8119 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [10/229], Loss: 1.3005, Time: 80.1057 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [15/229], Loss: 1.1312, Time: 80.3925 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [20/229], Loss: 1.3766, Time: 80.6853 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [25/229], Loss: 1.2632, Time: 80.9792 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [30/229], Loss: 1.3340, Time: 81.2640 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [35/229], Loss: 1.2778, Time: 81.6078 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [40/229], Loss: 1.2438, Time: 81.9026 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [45/229], Loss: 1.2998, Time: 82.1964 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [50/229], Loss: 1.2064, Time: 82.4892 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [55/229], Loss: 1.2496, Time: 82.7950 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [60/229], Loss: 1.2760, Time: 83.0978 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [65/229], Loss: 1.1534, Time: 83.3937 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [70/229], Loss: 1.2189, Time: 83.6775 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [75/229], Loss: 1.2006, Time: 83.9683 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [80/229], Loss: 1.1850, Time: 84.2681 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [85/229], Loss: 1.0511, Time: 84.5550 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [90/229], Loss: 1.2130, Time: 84.8518 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [95/229], Loss: 1.1326, Time: 85.1386 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [100/229], Loss: 1.1803, Time: 85.4284 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [105/229], Loss: 1.1613, Time: 85.7312 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [110/229], Loss: 1.0250, Time: 86.0280 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [115/229], Loss: 1.0934, Time: 86.3249 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [120/229], Loss: 1.2791, Time: 86.6107 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [125/229], Loss: 1.0849, Time: 86.9155 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [130/229], Loss: 0.9853, Time: 87.2133 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [135/229], Loss: 1.2406, Time: 87.5331 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [140/229], Loss: 1.1793, Time: 87.8279 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [145/229], Loss: 0.9426, Time: 88.1237 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [150/229], Loss: 1.0123, Time: 88.4086 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [155/229], Loss: 0.9943, Time: 88.7044 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [160/229], Loss: 1.0296, Time: 88.9942 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [165/229], Loss: 1.1082, Time: 89.2810 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [170/229], Loss: 1.0038, Time: 89.5709 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [175/229], Loss: 0.9958, Time: 89.8607 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [180/229], Loss: 1.1959, Time: 90.1515 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [185/229], Loss: 0.9779, Time: 90.4403 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [190/229], Loss: 1.3389, Time: 90.7441 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [195/229], Loss: 0.9445, Time: 91.0449 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [200/229], Loss: 0.9447, Time: 91.3278 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [205/229], Loss: 1.0088, Time: 91.6346 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [210/229], Loss: 1.0073, Time: 91.9344 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [215/229], Loss: 0.9933, Time: 92.2292 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [220/229], Loss: 1.0873, Time: 92.5140 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [225/229], Loss: 0.9709, Time: 92.7999 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [5/229], Loss: 0.8605, Time: 93.7073 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [10/229], Loss: 0.8684, Time: 93.9971 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [15/229], Loss: 0.9557, Time: 94.2909 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [20/229], Loss: 0.8319, Time: 94.5928 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [25/229], Loss: 0.9469, Time: 94.8926 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [30/229], Loss: 1.0796, Time: 95.1864 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [35/229], Loss: 0.8047, Time: 95.4742 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [40/229], Loss: 0.8554, Time: 95.7650 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [45/229], Loss: 0.8207, Time: 96.0529 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [50/229], Loss: 0.8808, Time: 96.3447 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [55/229], Loss: 1.0068, Time: 96.6395 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [60/229], Loss: 0.8928, Time: 96.9413 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [65/229], Loss: 0.8202, Time: 97.2411 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [70/229], Loss: 0.8514, Time: 97.5279 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [75/229], Loss: 0.9297, Time: 97.8667 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [80/229], Loss: 0.8184, Time: 98.1556 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [85/229], Loss: 0.8121, Time: 98.4634 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [90/229], Loss: 0.8219, Time: 98.7492 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [95/229], Loss: 0.8896, Time: 99.0840 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [100/229], Loss: 0.8515, Time: 99.3688 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [105/229], Loss: 0.8657, Time: 99.6866 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [110/229], Loss: 0.8124, Time: 99.9834 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [115/229], Loss: 0.8495, Time: 100.2832 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [120/229], Loss: 0.9126, Time: 100.5721 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [125/229], Loss: 0.8148, Time: 100.8649 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [130/229], Loss: 0.7109, Time: 101.1547 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [135/229], Loss: 0.9137, Time: 101.4525 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [140/229], Loss: 0.7850, Time: 101.7563 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [145/229], Loss: 0.8446, Time: 102.0552 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [150/229], Loss: 0.7292, Time: 102.3460 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [155/229], Loss: 0.7444, Time: 102.6368 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [160/229], Loss: 0.7855, Time: 102.9226 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [165/229], Loss: 0.7937, Time: 103.2154 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [170/229], Loss: 0.7862, Time: 103.5272 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [175/229], Loss: 0.7216, Time: 103.8450 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [180/229], Loss: 0.8150, Time: 104.2098 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [185/229], Loss: 0.7794, Time: 104.4946 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [190/229], Loss: 0.7555, Time: 104.7915 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [195/229], Loss: 0.7836, Time: 105.0933 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [200/229], Loss: 0.9888, Time: 105.3871 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [205/229], Loss: 0.6635, Time: 105.6769 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [210/229], Loss: 0.7006, Time: 105.9637 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [215/229], Loss: 0.6774, Time: 106.2526 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [220/229], Loss: 0.6968, Time: 106.5364 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [225/229], Loss: 0.7162, Time: 106.8342 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [5/229], Loss: 0.8198, Time: 107.7287 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [10/229], Loss: 0.7609, Time: 108.0225 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [15/229], Loss: 0.7021, Time: 108.3413 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [20/229], Loss: 0.6515, Time: 108.6271 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [25/229], Loss: 0.6493, Time: 108.9129 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [30/229], Loss: 0.7757, Time: 109.2357 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [35/229], Loss: 0.6184, Time: 109.5355 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [40/229], Loss: 0.8515, Time: 109.8254 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [45/229], Loss: 0.7238, Time: 110.1122 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [50/229], Loss: 0.6780, Time: 110.4000 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [55/229], Loss: 0.5986, Time: 110.7018 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [60/229], Loss: 0.6997, Time: 110.9996 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [65/229], Loss: 0.6682, Time: 111.2865 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [70/229], Loss: 0.5437, Time: 111.5723 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [75/229], Loss: 0.5558, Time: 111.8651 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [80/229], Loss: 0.6193, Time: 112.1639 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [85/229], Loss: 0.6701, Time: 112.4517 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [90/229], Loss: 0.6322, Time: 112.7356 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [95/229], Loss: 0.6255, Time: 113.0204 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [100/229], Loss: 0.5128, Time: 113.3032 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [105/229], Loss: 0.5249, Time: 113.6080 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [110/229], Loss: 0.5787, Time: 113.8968 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [115/229], Loss: 0.6954, Time: 114.1897 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [120/229], Loss: 0.6138, Time: 114.4835 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [125/229], Loss: 0.5164, Time: 114.7703 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [130/229], Loss: 0.5545, Time: 115.1191 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [135/229], Loss: 0.5736, Time: 115.4159 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [140/229], Loss: 0.5325, Time: 115.7057 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [145/229], Loss: 0.5756, Time: 115.9956 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [150/229], Loss: 0.6378, Time: 116.2874 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [155/229], Loss: 0.5420, Time: 116.5862 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [160/229], Loss: 0.7053, Time: 116.9490 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [165/229], Loss: 0.5567, Time: 117.3637 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [170/229], Loss: 0.6403, Time: 117.7795 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [175/229], Loss: 0.6577, Time: 118.0743 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [180/229], Loss: 0.5885, Time: 118.3701 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [185/229], Loss: 0.6511, Time: 118.6629 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [190/229], Loss: 0.5256, Time: 118.9497 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [195/229], Loss: 0.5601, Time: 119.2396 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [200/229], Loss: 0.5463, Time: 119.5424 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [205/229], Loss: 0.5293, Time: 119.8302 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [210/229], Loss: 0.5449, Time: 120.1182 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [215/229], Loss: 0.5990, Time: 120.4092 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [220/229], Loss: 0.5157, Time: 120.7152 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [225/229], Loss: 0.6194, Time: 121.0163 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [5/229], Loss: 0.6008, Time: 121.9373 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [10/229], Loss: 0.5772, Time: 122.2323 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [15/229], Loss: 0.4921, Time: 122.5283 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [20/229], Loss: 0.4928, Time: 122.8303 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [25/229], Loss: 0.4898, Time: 123.1253 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [30/229], Loss: 0.4860, Time: 123.4173 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [35/229], Loss: 0.4774, Time: 123.7293 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [40/229], Loss: 0.5685, Time: 124.0193 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [45/229], Loss: 0.4449, Time: 124.3213 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [50/229], Loss: 0.4824, Time: 124.6173 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [55/229], Loss: 0.4944, Time: 124.9183 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [60/229], Loss: 0.4695, Time: 125.2283 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [65/229], Loss: 0.4990, Time: 125.5223 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [70/229], Loss: 0.5381, Time: 125.8303 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [75/229], Loss: 0.4649, Time: 126.1183 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [80/229], Loss: 0.4778, Time: 126.4203 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [85/229], Loss: 0.5135, Time: 126.7143 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [90/229], Loss: 0.4316, Time: 127.0033 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [95/229], Loss: 0.5350, Time: 127.3033 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [100/229], Loss: 0.5129, Time: 127.6083 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [105/229], Loss: 0.4356, Time: 127.8993 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [110/229], Loss: 0.5212, Time: 128.1923 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [115/229], Loss: 0.4141, Time: 128.5053 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [120/229], Loss: 0.4584, Time: 128.8003 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [125/229], Loss: 0.5075, Time: 129.1043 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [130/229], Loss: 0.4534, Time: 129.3963 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [135/229], Loss: 0.4271, Time: 129.6863 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [140/229], Loss: 0.3877, Time: 129.9793 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [145/229], Loss: 0.5118, Time: 130.2693 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [150/229], Loss: 0.4251, Time: 130.5612 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [155/229], Loss: 0.4250, Time: 130.8623 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [160/229], Loss: 0.4363, Time: 131.1693 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [165/229], Loss: 0.4469, Time: 131.4562 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [170/229], Loss: 0.5169, Time: 131.7473 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [175/229], Loss: 0.4604, Time: 132.0962 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [180/229], Loss: 0.4450, Time: 132.3932 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [185/229], Loss: 0.4725, Time: 132.6912 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [190/229], Loss: 0.4200, Time: 132.9813 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [195/229], Loss: 0.3912, Time: 133.2722 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [200/229], Loss: 0.3573, Time: 133.5632 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [205/229], Loss: 0.4062, Time: 133.8522 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [210/229], Loss: 0.4284, Time: 134.1592 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [215/229], Loss: 0.3729, Time: 134.4552 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [220/229], Loss: 0.4330, Time: 134.7462 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [225/229], Loss: 0.3654, Time: 135.0462 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [5/229], Loss: 0.4208, Time: 135.9473 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [10/229], Loss: 0.4034, Time: 136.2492 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [15/229], Loss: 0.4201, Time: 136.5342 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [20/229], Loss: 0.4216, Time: 136.8222 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [25/229], Loss: 0.3816, Time: 137.1242 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [30/229], Loss: 0.3906, Time: 137.4220 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [35/229], Loss: 0.3582, Time: 137.7288 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [40/229], Loss: 0.3994, Time: 138.0197 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [45/229], Loss: 0.3550, Time: 138.3075 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [50/229], Loss: 0.4342, Time: 138.5963 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [55/229], Loss: 0.3855, Time: 138.8831 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [60/229], Loss: 0.4414, Time: 139.1790 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [65/229], Loss: 0.3886, Time: 139.4608 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [70/229], Loss: 0.3306, Time: 139.7496 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [75/229], Loss: 0.3500, Time: 140.0484 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [80/229], Loss: 0.4384, Time: 140.3782 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [85/229], Loss: 0.3226, Time: 140.9149 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [90/229], Loss: 0.3757, Time: 141.2457 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [95/229], Loss: 0.3332, Time: 141.5305 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [100/229], Loss: 0.3729, Time: 141.8303 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [105/229], Loss: 0.3078, Time: 142.1181 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [110/229], Loss: 0.3267, Time: 142.4080 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [115/229], Loss: 0.4945, Time: 142.7138 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [120/229], Loss: 0.3208, Time: 143.0076 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [125/229], Loss: 0.3615, Time: 143.2954 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [130/229], Loss: 0.3843, Time: 143.5882 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [135/229], Loss: 0.4073, Time: 143.8890 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [140/229], Loss: 0.3416, Time: 144.1859 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [145/229], Loss: 0.3197, Time: 144.4757 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [150/229], Loss: 0.3217, Time: 144.7615 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [155/229], Loss: 0.3958, Time: 145.0603 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [160/229], Loss: 0.3323, Time: 145.3461 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [165/229], Loss: 0.3232, Time: 145.6320 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [170/229], Loss: 0.3689, Time: 145.9248 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [175/229], Loss: 0.2675, Time: 146.2076 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [180/229], Loss: 0.3972, Time: 146.5074 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [185/229], Loss: 0.3751, Time: 146.8102 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [190/229], Loss: 0.2958, Time: 147.1051 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [195/229], Loss: 0.3723, Time: 147.4079 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [200/229], Loss: 0.3131, Time: 147.6927 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [205/229], Loss: 0.3055, Time: 147.9895 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [210/229], Loss: 0.3061, Time: 148.2883 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [215/229], Loss: 0.3095, Time: 148.5961 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [220/229], Loss: 0.2637, Time: 148.9559 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [225/229], Loss: 0.2822, Time: 149.2487 secs, learning rate: 0.0010\n",
      "Epoch [11/60], Step [5/229], Loss: 0.3109, Time: 150.1352 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [10/229], Loss: 0.2702, Time: 150.4220 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [15/229], Loss: 0.3698, Time: 150.7128 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [20/229], Loss: 0.2718, Time: 150.9977 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [25/229], Loss: 0.2509, Time: 151.2955 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [30/229], Loss: 0.2574, Time: 151.5833 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [35/229], Loss: 0.3696, Time: 151.8851 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [40/229], Loss: 0.3388, Time: 152.1809 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [45/229], Loss: 0.3458, Time: 152.4797 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [50/229], Loss: 0.2869, Time: 152.7696 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [55/229], Loss: 0.2947, Time: 153.0624 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [60/229], Loss: 0.2882, Time: 153.3472 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [65/229], Loss: 0.2887, Time: 153.6400 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [70/229], Loss: 0.2600, Time: 153.9428 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [75/229], Loss: 0.2495, Time: 154.2337 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [80/229], Loss: 0.3032, Time: 154.5155 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [85/229], Loss: 0.3159, Time: 154.8113 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [90/229], Loss: 0.3160, Time: 155.1021 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [95/229], Loss: 0.2985, Time: 155.3889 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [100/229], Loss: 0.3105, Time: 155.6738 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [105/229], Loss: 0.3063, Time: 155.9756 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [110/229], Loss: 0.2489, Time: 156.2674 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [115/229], Loss: 0.3118, Time: 156.5522 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [120/229], Loss: 0.3101, Time: 156.8401 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [125/229], Loss: 0.2751, Time: 157.1349 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [130/229], Loss: 0.2906, Time: 157.4287 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [135/229], Loss: 0.2990, Time: 157.7345 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [140/229], Loss: 0.3624, Time: 158.0263 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [145/229], Loss: 0.2527, Time: 158.3211 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [150/229], Loss: 0.2375, Time: 158.6379 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [155/229], Loss: 0.2815, Time: 158.9288 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [160/229], Loss: 0.2872, Time: 159.2146 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [165/229], Loss: 0.2906, Time: 159.5064 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [170/229], Loss: 0.3628, Time: 159.7982 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [175/229], Loss: 0.3342, Time: 160.0881 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [180/229], Loss: 0.3232, Time: 160.3849 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [185/229], Loss: 0.2842, Time: 160.6757 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [190/229], Loss: 0.3197, Time: 160.9625 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [195/229], Loss: 0.2605, Time: 161.2783 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [200/229], Loss: 0.3130, Time: 161.5751 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [205/229], Loss: 0.2499, Time: 161.8630 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [210/229], Loss: 0.2865, Time: 162.1528 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [215/229], Loss: 0.3141, Time: 162.4466 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [220/229], Loss: 0.3214, Time: 162.7514 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [225/229], Loss: 0.3236, Time: 163.0452 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [5/229], Loss: 0.2929, Time: 163.9307 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [10/229], Loss: 0.2719, Time: 164.2335 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [15/229], Loss: 0.4106, Time: 164.5193 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [20/229], Loss: 0.2909, Time: 164.8161 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [25/229], Loss: 0.2539, Time: 165.1159 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [30/229], Loss: 0.3091, Time: 165.3978 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [35/229], Loss: 0.3568, Time: 165.6966 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [40/229], Loss: 0.3406, Time: 166.0404 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [45/229], Loss: 0.2429, Time: 166.3352 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [50/229], Loss: 0.3324, Time: 166.6720 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [55/229], Loss: 0.2784, Time: 166.9848 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [60/229], Loss: 0.3053, Time: 167.2806 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [65/229], Loss: 0.2878, Time: 167.5794 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [70/229], Loss: 0.3535, Time: 167.8702 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [75/229], Loss: 0.2778, Time: 168.1531 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [80/229], Loss: 0.3012, Time: 168.4409 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [85/229], Loss: 0.3211, Time: 168.7427 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [90/229], Loss: 0.3165, Time: 169.0455 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [95/229], Loss: 0.3072, Time: 169.3463 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [100/229], Loss: 0.2455, Time: 169.6352 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [105/229], Loss: 0.3548, Time: 169.9190 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [110/229], Loss: 0.2813, Time: 170.2348 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [115/229], Loss: 0.2954, Time: 170.5236 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [120/229], Loss: 0.2624, Time: 170.8194 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [125/229], Loss: 0.3046, Time: 171.1182 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [130/229], Loss: 0.2994, Time: 171.4111 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [135/229], Loss: 0.2908, Time: 171.6989 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [140/229], Loss: 0.2887, Time: 171.9847 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [145/229], Loss: 0.2572, Time: 172.2865 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [150/229], Loss: 0.2953, Time: 172.5843 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [155/229], Loss: 0.3022, Time: 172.8752 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [160/229], Loss: 0.2790, Time: 173.1630 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [165/229], Loss: 0.2852, Time: 173.4878 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [170/229], Loss: 0.3651, Time: 173.7836 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [175/229], Loss: 0.2991, Time: 174.0744 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [180/229], Loss: 0.3148, Time: 174.3682 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [185/229], Loss: 0.2895, Time: 174.6711 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [190/229], Loss: 0.2719, Time: 174.9649 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [195/229], Loss: 0.2622, Time: 175.2487 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [200/229], Loss: 0.3304, Time: 175.5415 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [205/229], Loss: 0.2690, Time: 175.8313 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [210/229], Loss: 0.3608, Time: 176.1372 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [215/229], Loss: 0.3068, Time: 176.4500 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [220/229], Loss: 0.3502, Time: 176.7538 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [225/229], Loss: 0.2623, Time: 177.0586 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [5/229], Loss: 0.3603, Time: 177.9490 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [10/229], Loss: 0.2568, Time: 178.2369 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [15/229], Loss: 0.2354, Time: 178.5247 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [20/229], Loss: 0.2408, Time: 178.8365 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [25/229], Loss: 0.3040, Time: 179.1423 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [30/229], Loss: 0.3775, Time: 179.4371 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [35/229], Loss: 0.2959, Time: 179.7359 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [40/229], Loss: 0.2848, Time: 180.0347 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [45/229], Loss: 0.2418, Time: 180.3376 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [50/229], Loss: 0.2695, Time: 180.6274 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [55/229], Loss: 0.3438, Time: 180.9162 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [60/229], Loss: 0.3109, Time: 181.2210 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [65/229], Loss: 0.3417, Time: 181.5068 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [70/229], Loss: 0.2746, Time: 181.7927 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [75/229], Loss: 0.2609, Time: 182.0895 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [80/229], Loss: 0.3086, Time: 182.3903 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [85/229], Loss: 0.2983, Time: 182.7421 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [90/229], Loss: 0.2471, Time: 183.0339 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [95/229], Loss: 0.2792, Time: 183.3307 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [100/229], Loss: 0.2683, Time: 183.6185 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [105/229], Loss: 0.3343, Time: 183.9034 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [110/229], Loss: 0.3051, Time: 184.2002 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [115/229], Loss: 0.2730, Time: 184.4940 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [120/229], Loss: 0.2747, Time: 184.7828 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [125/229], Loss: 0.2861, Time: 185.0766 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [130/229], Loss: 0.3208, Time: 185.3685 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [135/229], Loss: 0.2811, Time: 185.6573 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [140/229], Loss: 0.2955, Time: 185.9681 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [145/229], Loss: 0.2742, Time: 186.2689 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [150/229], Loss: 0.2972, Time: 186.5577 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [155/229], Loss: 0.2803, Time: 186.8455 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [160/229], Loss: 0.3318, Time: 187.1454 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [165/229], Loss: 0.2852, Time: 187.4322 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [170/229], Loss: 0.3159, Time: 187.7190 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [175/229], Loss: 0.2343, Time: 188.0088 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [180/229], Loss: 0.2961, Time: 188.2947 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [185/229], Loss: 0.2940, Time: 188.6105 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [190/229], Loss: 0.2311, Time: 188.9133 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [195/229], Loss: 0.2661, Time: 189.2051 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [200/229], Loss: 0.2974, Time: 189.4949 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [205/229], Loss: 0.3302, Time: 189.7917 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [210/229], Loss: 0.3293, Time: 190.1045 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [215/229], Loss: 0.2485, Time: 190.3934 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [220/229], Loss: 0.3389, Time: 190.6882 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [225/229], Loss: 0.2910, Time: 190.9860 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [5/229], Loss: 0.3278, Time: 191.8515 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [10/229], Loss: 0.2695, Time: 192.1583 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [15/229], Loss: 0.3003, Time: 192.4451 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [20/229], Loss: 0.2764, Time: 192.7399 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [25/229], Loss: 0.2456, Time: 193.0317 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [30/229], Loss: 0.3268, Time: 193.3196 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [35/229], Loss: 0.2557, Time: 193.6014 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [40/229], Loss: 0.2404, Time: 193.9012 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [45/229], Loss: 0.3095, Time: 194.1980 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [50/229], Loss: 0.2293, Time: 194.4868 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [55/229], Loss: 0.2959, Time: 194.7727 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [60/229], Loss: 0.2893, Time: 195.0895 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [65/229], Loss: 0.2904, Time: 195.3833 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [70/229], Loss: 0.2641, Time: 195.6751 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [75/229], Loss: 0.2683, Time: 195.9629 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [80/229], Loss: 0.2668, Time: 196.2527 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [85/229], Loss: 0.2767, Time: 196.5436 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [90/229], Loss: 0.3055, Time: 196.8344 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [95/229], Loss: 0.2364, Time: 197.1372 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [100/229], Loss: 0.3323, Time: 197.4340 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [105/229], Loss: 0.3114, Time: 197.7278 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [110/229], Loss: 0.2960, Time: 198.0426 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [115/229], Loss: 0.2732, Time: 198.3325 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [120/229], Loss: 0.2925, Time: 198.6223 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [125/229], Loss: 0.3299, Time: 198.9111 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [130/229], Loss: 0.2478, Time: 199.2029 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [135/229], Loss: 0.2175, Time: 199.4897 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [140/229], Loss: 0.3246, Time: 199.7766 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [145/229], Loss: 0.2903, Time: 200.1154 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [150/229], Loss: 0.2363, Time: 200.4062 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [155/229], Loss: 0.2841, Time: 200.6950 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [160/229], Loss: 0.3577, Time: 200.9888 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [165/229], Loss: 0.2719, Time: 201.3036 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [170/229], Loss: 0.2511, Time: 201.5974 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [175/229], Loss: 0.2464, Time: 201.8863 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [180/229], Loss: 0.2713, Time: 202.1951 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [185/229], Loss: 0.3798, Time: 202.4809 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [190/229], Loss: 0.2875, Time: 202.7737 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [195/229], Loss: 0.2885, Time: 203.0575 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [200/229], Loss: 0.2659, Time: 203.3464 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [205/229], Loss: 0.2628, Time: 203.6412 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [210/229], Loss: 0.2645, Time: 203.9290 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [215/229], Loss: 0.2453, Time: 204.2568 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [220/229], Loss: 0.2626, Time: 204.5566 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [225/229], Loss: 0.3282, Time: 204.8594 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [5/229], Loss: 0.2423, Time: 205.7439 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [10/229], Loss: 0.2806, Time: 206.0287 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [15/229], Loss: 0.2265, Time: 206.3155 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [20/229], Loss: 0.2732, Time: 206.6024 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [25/229], Loss: 0.2143, Time: 206.9052 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [30/229], Loss: 0.3050, Time: 207.2170 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [35/229], Loss: 0.3058, Time: 207.5298 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [40/229], Loss: 0.2285, Time: 207.8246 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [45/229], Loss: 0.2780, Time: 208.1184 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [50/229], Loss: 0.2477, Time: 208.4062 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [55/229], Loss: 0.2809, Time: 208.7001 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [60/229], Loss: 0.2920, Time: 209.0159 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [65/229], Loss: 0.2671, Time: 209.3167 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [70/229], Loss: 0.2584, Time: 209.6245 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [75/229], Loss: 0.2247, Time: 209.9193 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [80/229], Loss: 0.2579, Time: 210.2071 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [85/229], Loss: 0.2802, Time: 210.5020 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [90/229], Loss: 0.3224, Time: 210.7948 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [95/229], Loss: 0.2081, Time: 211.0996 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [100/229], Loss: 0.2833, Time: 211.3904 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [105/229], Loss: 0.2822, Time: 211.6892 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [110/229], Loss: 0.2887, Time: 211.9830 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [115/229], Loss: 0.2388, Time: 212.2729 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [120/229], Loss: 0.2783, Time: 212.5607 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [125/229], Loss: 0.3289, Time: 212.8515 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [130/229], Loss: 0.2474, Time: 213.1553 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [135/229], Loss: 0.3227, Time: 213.4481 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [140/229], Loss: 0.2433, Time: 213.7440 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [145/229], Loss: 0.2667, Time: 214.0608 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [150/229], Loss: 0.2169, Time: 214.3506 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [155/229], Loss: 0.2463, Time: 214.6404 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [160/229], Loss: 0.2666, Time: 214.9262 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [165/229], Loss: 0.2754, Time: 215.2270 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [170/229], Loss: 0.2735, Time: 215.5209 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [175/229], Loss: 0.2658, Time: 215.8087 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [180/229], Loss: 0.2831, Time: 216.1235 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [185/229], Loss: 0.2946, Time: 216.4203 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [190/229], Loss: 0.3004, Time: 216.7131 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [195/229], Loss: 0.2228, Time: 217.0459 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [200/229], Loss: 0.2763, Time: 217.3437 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [205/229], Loss: 0.2481, Time: 217.6346 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [210/229], Loss: 0.2385, Time: 217.9274 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [215/229], Loss: 0.2540, Time: 218.2252 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [220/229], Loss: 0.2535, Time: 218.5240 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [225/229], Loss: 0.2562, Time: 218.8128 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [5/229], Loss: 0.3119, Time: 219.6893 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [10/229], Loss: 0.2205, Time: 219.9851 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [15/229], Loss: 0.2665, Time: 220.2799 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [20/229], Loss: 0.2519, Time: 220.5797 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [25/229], Loss: 0.2856, Time: 220.8696 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [30/229], Loss: 0.2339, Time: 221.1824 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [35/229], Loss: 0.2709, Time: 221.4762 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [40/229], Loss: 0.2397, Time: 221.7850 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [45/229], Loss: 0.2499, Time: 222.0718 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [50/229], Loss: 0.2449, Time: 222.3736 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [55/229], Loss: 0.2893, Time: 222.6684 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [60/229], Loss: 0.2088, Time: 222.9673 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [65/229], Loss: 0.2063, Time: 223.2551 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [70/229], Loss: 0.3194, Time: 223.5429 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [75/229], Loss: 0.3035, Time: 223.8437 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [80/229], Loss: 0.2972, Time: 224.1375 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [85/229], Loss: 0.3357, Time: 224.4254 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [90/229], Loss: 0.2214, Time: 224.7312 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [95/229], Loss: 0.2848, Time: 225.0390 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [100/229], Loss: 0.3120, Time: 225.3388 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [105/229], Loss: 0.2535, Time: 225.6326 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [110/229], Loss: 0.2535, Time: 225.9224 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [115/229], Loss: 0.2341, Time: 226.2163 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [120/229], Loss: 0.2257, Time: 226.5041 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [125/229], Loss: 0.2709, Time: 226.7929 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [130/229], Loss: 0.2246, Time: 227.0857 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [135/229], Loss: 0.2456, Time: 227.3925 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [140/229], Loss: 0.3329, Time: 227.6804 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [145/229], Loss: 0.2585, Time: 227.9702 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [150/229], Loss: 0.2154, Time: 228.2760 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [155/229], Loss: 0.2400, Time: 228.5658 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [160/229], Loss: 0.2118, Time: 228.8546 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [165/229], Loss: 0.2973, Time: 229.1494 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [170/229], Loss: 0.3043, Time: 229.4463 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [175/229], Loss: 0.2595, Time: 229.7371 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [180/229], Loss: 0.2396, Time: 230.0239 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [185/229], Loss: 0.2656, Time: 230.3247 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [190/229], Loss: 0.2504, Time: 230.6175 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [195/229], Loss: 0.2724, Time: 230.9034 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [200/229], Loss: 0.3039, Time: 231.1922 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [205/229], Loss: 0.2145, Time: 231.4790 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [210/229], Loss: 0.3090, Time: 231.7708 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [215/229], Loss: 0.2651, Time: 232.0646 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [220/229], Loss: 0.2577, Time: 232.3595 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [225/229], Loss: 0.2623, Time: 232.6493 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [5/229], Loss: 0.2769, Time: 233.5297 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [10/229], Loss: 0.2578, Time: 233.8186 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [15/229], Loss: 0.3469, Time: 234.1614 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [20/229], Loss: 0.2620, Time: 234.4512 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [25/229], Loss: 0.2674, Time: 234.7420 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [30/229], Loss: 0.2410, Time: 235.0418 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [35/229], Loss: 0.2848, Time: 235.3346 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [40/229], Loss: 0.2556, Time: 235.6195 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [45/229], Loss: 0.2072, Time: 235.9213 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [50/229], Loss: 0.2297, Time: 236.2131 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [55/229], Loss: 0.2475, Time: 236.5099 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [60/229], Loss: 0.2400, Time: 236.7987 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [65/229], Loss: 0.2196, Time: 237.0925 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [70/229], Loss: 0.2248, Time: 237.3934 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [75/229], Loss: 0.2423, Time: 237.6892 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [80/229], Loss: 0.2234, Time: 237.9840 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [85/229], Loss: 0.3076, Time: 238.2728 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [90/229], Loss: 0.2274, Time: 238.5906 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [95/229], Loss: 0.2399, Time: 238.8984 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [100/229], Loss: 0.2826, Time: 239.1952 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [105/229], Loss: 0.2156, Time: 239.4901 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [110/229], Loss: 0.3413, Time: 239.7879 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [115/229], Loss: 0.2002, Time: 240.0817 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [120/229], Loss: 0.2362, Time: 240.3915 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [125/229], Loss: 0.2346, Time: 240.6883 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [130/229], Loss: 0.2965, Time: 240.9801 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [135/229], Loss: 0.2841, Time: 241.2780 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [140/229], Loss: 0.1993, Time: 241.5738 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [145/229], Loss: 0.2238, Time: 241.8626 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [150/229], Loss: 0.2844, Time: 242.1554 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [155/229], Loss: 0.2504, Time: 242.4502 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [160/229], Loss: 0.2486, Time: 242.7471 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [165/229], Loss: 0.2328, Time: 243.0399 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [170/229], Loss: 0.2291, Time: 243.3347 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [175/229], Loss: 0.2110, Time: 243.6295 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [180/229], Loss: 0.2535, Time: 243.9343 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [185/229], Loss: 0.3069, Time: 244.2301 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [190/229], Loss: 0.2351, Time: 244.5270 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [195/229], Loss: 0.2252, Time: 244.8358 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [200/229], Loss: 0.2462, Time: 245.1316 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [205/229], Loss: 0.2496, Time: 245.4164 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [210/229], Loss: 0.2149, Time: 245.6982 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [215/229], Loss: 0.2206, Time: 246.0570 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [220/229], Loss: 0.2106, Time: 246.4378 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [225/229], Loss: 0.2529, Time: 246.7326 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [5/229], Loss: 0.2101, Time: 247.6061 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [10/229], Loss: 0.2233, Time: 247.9039 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [15/229], Loss: 0.2895, Time: 248.2087 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [20/229], Loss: 0.2176, Time: 248.5025 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [25/229], Loss: 0.2304, Time: 248.7963 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [30/229], Loss: 0.2768, Time: 249.0802 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [35/229], Loss: 0.2276, Time: 249.3750 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [40/229], Loss: 0.2156, Time: 249.6718 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [45/229], Loss: 0.2811, Time: 249.9606 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [50/229], Loss: 0.2279, Time: 250.2984 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [55/229], Loss: 0.2890, Time: 250.5932 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [60/229], Loss: 0.2319, Time: 250.8940 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [65/229], Loss: 0.2466, Time: 251.1839 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [70/229], Loss: 0.2298, Time: 251.4797 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [75/229], Loss: 0.2291, Time: 251.7695 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [80/229], Loss: 0.2615, Time: 252.0593 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [85/229], Loss: 0.2745, Time: 252.3521 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [90/229], Loss: 0.2779, Time: 252.6569 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [95/229], Loss: 0.2418, Time: 252.9488 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [100/229], Loss: 0.2755, Time: 253.2416 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [105/229], Loss: 0.2553, Time: 253.5504 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [110/229], Loss: 0.2364, Time: 253.8362 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [115/229], Loss: 0.2511, Time: 254.1270 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [120/229], Loss: 0.2570, Time: 254.4249 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [125/229], Loss: 0.2513, Time: 254.7257 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [130/229], Loss: 0.2075, Time: 255.0265 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [135/229], Loss: 0.2976, Time: 255.3193 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [140/229], Loss: 0.1787, Time: 255.6111 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [145/229], Loss: 0.2066, Time: 255.8999 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [150/229], Loss: 0.2231, Time: 256.2028 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [155/229], Loss: 0.2391, Time: 256.5026 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [160/229], Loss: 0.2812, Time: 256.7944 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [165/229], Loss: 0.2611, Time: 257.0912 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [170/229], Loss: 0.2682, Time: 257.3890 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [175/229], Loss: 0.2699, Time: 257.6928 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [180/229], Loss: 0.2380, Time: 257.9957 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [185/229], Loss: 0.2125, Time: 258.2985 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [190/229], Loss: 0.2855, Time: 258.5913 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [195/229], Loss: 0.2363, Time: 258.8911 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [200/229], Loss: 0.2596, Time: 259.1889 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [205/229], Loss: 0.2115, Time: 259.4847 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [210/229], Loss: 0.2295, Time: 259.7875 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [215/229], Loss: 0.2069, Time: 260.1044 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [220/229], Loss: 0.2525, Time: 260.4042 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [225/229], Loss: 0.2133, Time: 260.7020 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [5/229], Loss: 0.2082, Time: 261.5654 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [10/229], Loss: 0.2379, Time: 261.8603 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [15/229], Loss: 0.2405, Time: 262.1611 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [20/229], Loss: 0.2401, Time: 262.4549 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [25/229], Loss: 0.2753, Time: 262.7487 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [30/229], Loss: 0.2558, Time: 263.0405 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [35/229], Loss: 0.2373, Time: 263.3364 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [40/229], Loss: 0.2040, Time: 263.6212 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [45/229], Loss: 0.2163, Time: 263.9080 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [50/229], Loss: 0.2134, Time: 264.2048 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [55/229], Loss: 0.2279, Time: 264.4956 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [60/229], Loss: 0.2267, Time: 264.7855 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [65/229], Loss: 0.2079, Time: 265.0853 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [70/229], Loss: 0.2594, Time: 265.3821 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [75/229], Loss: 0.1797, Time: 265.6719 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [80/229], Loss: 0.2695, Time: 265.9587 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [85/229], Loss: 0.2490, Time: 266.2486 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [90/229], Loss: 0.2483, Time: 266.5494 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [95/229], Loss: 0.2268, Time: 266.8572 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [100/229], Loss: 0.2067, Time: 267.1650 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [105/229], Loss: 0.2263, Time: 267.4538 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [110/229], Loss: 0.2241, Time: 267.7936 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [115/229], Loss: 0.2744, Time: 268.0974 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [120/229], Loss: 0.2489, Time: 268.3942 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [125/229], Loss: 0.2067, Time: 268.6961 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [130/229], Loss: 0.1704, Time: 269.0039 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [135/229], Loss: 0.2115, Time: 269.2937 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [140/229], Loss: 0.2266, Time: 269.5795 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [145/229], Loss: 0.1972, Time: 269.8803 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [150/229], Loss: 0.2371, Time: 270.1821 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [155/229], Loss: 0.1763, Time: 270.5039 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [160/229], Loss: 0.2203, Time: 271.0266 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [165/229], Loss: 0.1820, Time: 271.3614 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [170/229], Loss: 0.2933, Time: 271.6502 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [175/229], Loss: 0.2115, Time: 271.9381 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [180/229], Loss: 0.2540, Time: 272.2329 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [185/229], Loss: 0.1724, Time: 272.5297 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [190/229], Loss: 0.1918, Time: 272.8205 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [195/229], Loss: 0.3010, Time: 273.2103 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [200/229], Loss: 0.1893, Time: 273.5750 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [205/229], Loss: 0.2427, Time: 273.9438 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [210/229], Loss: 0.2120, Time: 274.4175 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [215/229], Loss: 0.2591, Time: 274.8602 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [220/229], Loss: 0.1888, Time: 275.2030 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [225/229], Loss: 0.2535, Time: 275.5178 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [5/229], Loss: 0.1657, Time: 276.4283 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [10/229], Loss: 0.2575, Time: 276.7331 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [15/229], Loss: 0.2188, Time: 277.0309 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [20/229], Loss: 0.2306, Time: 277.3217 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [25/229], Loss: 0.2256, Time: 277.6245 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [30/229], Loss: 0.2302, Time: 277.9204 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [35/229], Loss: 0.1970, Time: 278.2192 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [40/229], Loss: 0.2380, Time: 278.5170 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [45/229], Loss: 0.2031, Time: 278.8068 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [50/229], Loss: 0.2362, Time: 279.0926 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [55/229], Loss: 0.2242, Time: 279.3825 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [60/229], Loss: 0.1941, Time: 279.6803 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [65/229], Loss: 0.1799, Time: 279.9751 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [70/229], Loss: 0.2103, Time: 280.2699 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [75/229], Loss: 0.2022, Time: 280.5757 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [80/229], Loss: 0.2170, Time: 280.8705 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [85/229], Loss: 0.1844, Time: 281.1644 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [90/229], Loss: 0.2298, Time: 281.4542 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [95/229], Loss: 0.2053, Time: 281.7480 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [100/229], Loss: 0.1687, Time: 282.0468 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [105/229], Loss: 0.1824, Time: 282.3426 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [110/229], Loss: 0.2167, Time: 282.6325 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [115/229], Loss: 0.1968, Time: 282.9323 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [120/229], Loss: 0.2130, Time: 283.2311 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [125/229], Loss: 0.2952, Time: 283.5289 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [130/229], Loss: 0.2319, Time: 283.8187 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [135/229], Loss: 0.2123, Time: 284.1115 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [140/229], Loss: 0.1923, Time: 284.4064 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [145/229], Loss: 0.1874, Time: 284.7521 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [150/229], Loss: 0.2099, Time: 285.0450 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [155/229], Loss: 0.1984, Time: 285.3348 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [160/229], Loss: 0.2019, Time: 285.6266 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [165/229], Loss: 0.2870, Time: 285.9234 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [170/229], Loss: 0.1894, Time: 286.2232 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [175/229], Loss: 0.1790, Time: 286.5211 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [180/229], Loss: 0.1893, Time: 286.8199 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [185/229], Loss: 0.2143, Time: 287.1087 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [190/229], Loss: 0.2116, Time: 287.4055 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [195/229], Loss: 0.2300, Time: 287.7063 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [200/229], Loss: 0.1976, Time: 288.0061 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [205/229], Loss: 0.1958, Time: 288.2970 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [210/229], Loss: 0.2411, Time: 288.5968 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [215/229], Loss: 0.1964, Time: 288.9016 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [220/229], Loss: 0.1873, Time: 289.1934 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [225/229], Loss: 0.2091, Time: 289.4912 secs, learning rate: 0.0001\n",
      "Epoch [21/60], Step [5/229], Loss: 0.1690, Time: 290.3707 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [10/229], Loss: 0.2227, Time: 290.6605 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [15/229], Loss: 0.1558, Time: 290.9613 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [20/229], Loss: 0.1814, Time: 291.2501 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [25/229], Loss: 0.2061, Time: 291.5410 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [30/229], Loss: 0.2269, Time: 291.8278 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [35/229], Loss: 0.2469, Time: 292.1216 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [40/229], Loss: 0.2206, Time: 292.4204 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [45/229], Loss: 0.1671, Time: 292.7092 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [50/229], Loss: 0.1852, Time: 293.0061 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [55/229], Loss: 0.2374, Time: 293.3199 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [60/229], Loss: 0.1975, Time: 293.6067 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [65/229], Loss: 0.1948, Time: 293.9165 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [70/229], Loss: 0.2425, Time: 294.2143 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [75/229], Loss: 0.1701, Time: 294.5151 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [80/229], Loss: 0.1965, Time: 294.8069 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [85/229], Loss: 0.2207, Time: 295.1018 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [90/229], Loss: 0.2135, Time: 295.4026 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [95/229], Loss: 0.1992, Time: 295.6994 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [100/229], Loss: 0.2233, Time: 295.9972 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [105/229], Loss: 0.1862, Time: 296.2910 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [110/229], Loss: 0.1758, Time: 296.6128 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [115/229], Loss: 0.2374, Time: 296.9186 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [120/229], Loss: 0.2355, Time: 297.2115 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [125/229], Loss: 0.2109, Time: 297.4993 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [130/229], Loss: 0.1797, Time: 297.8311 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [135/229], Loss: 0.2126, Time: 298.1459 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [140/229], Loss: 0.2133, Time: 298.4597 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [145/229], Loss: 0.2344, Time: 298.7475 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [150/229], Loss: 0.2155, Time: 299.0433 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [155/229], Loss: 0.2196, Time: 299.3322 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [160/229], Loss: 0.2152, Time: 299.6180 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [165/229], Loss: 0.1722, Time: 299.9068 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [170/229], Loss: 0.2773, Time: 300.2016 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [175/229], Loss: 0.2246, Time: 300.4944 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [180/229], Loss: 0.2329, Time: 300.8032 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [185/229], Loss: 0.1691, Time: 301.1071 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [190/229], Loss: 0.2313, Time: 301.4019 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [195/229], Loss: 0.1911, Time: 301.6917 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [200/229], Loss: 0.2221, Time: 302.0355 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [205/229], Loss: 0.1915, Time: 302.3333 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [210/229], Loss: 0.2085, Time: 302.6351 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [215/229], Loss: 0.2067, Time: 302.9279 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [220/229], Loss: 0.2030, Time: 303.2307 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [225/229], Loss: 0.2008, Time: 303.5585 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [5/229], Loss: 0.1988, Time: 304.4400 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [10/229], Loss: 0.2170, Time: 304.7418 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [15/229], Loss: 0.1965, Time: 305.0316 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [20/229], Loss: 0.1748, Time: 305.3364 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [25/229], Loss: 0.2075, Time: 305.6343 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [30/229], Loss: 0.1936, Time: 305.9181 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [35/229], Loss: 0.2338, Time: 306.2129 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [40/229], Loss: 0.1869, Time: 306.5037 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [45/229], Loss: 0.1651, Time: 306.7915 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [50/229], Loss: 0.2072, Time: 307.0844 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [55/229], Loss: 0.2179, Time: 307.3892 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [60/229], Loss: 0.1969, Time: 307.6880 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [65/229], Loss: 0.1897, Time: 307.9848 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [70/229], Loss: 0.2094, Time: 308.2886 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [75/229], Loss: 0.1811, Time: 308.5774 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [80/229], Loss: 0.1787, Time: 308.8743 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [85/229], Loss: 0.2132, Time: 309.1731 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [90/229], Loss: 0.2364, Time: 309.4709 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [95/229], Loss: 0.1646, Time: 309.7627 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [100/229], Loss: 0.1545, Time: 310.0505 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [105/229], Loss: 0.2090, Time: 310.3643 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [110/229], Loss: 0.1664, Time: 310.6532 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [115/229], Loss: 0.2402, Time: 310.9390 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [120/229], Loss: 0.2068, Time: 311.2468 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [125/229], Loss: 0.2145, Time: 311.5416 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [130/229], Loss: 0.2053, Time: 311.8304 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [135/229], Loss: 0.1675, Time: 312.1243 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [140/229], Loss: 0.2459, Time: 312.4351 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [145/229], Loss: 0.1803, Time: 312.7239 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [150/229], Loss: 0.1763, Time: 313.0147 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [155/229], Loss: 0.1591, Time: 313.3125 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [160/229], Loss: 0.1865, Time: 313.6063 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [165/229], Loss: 0.1860, Time: 313.9022 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [170/229], Loss: 0.2696, Time: 314.1880 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [175/229], Loss: 0.1754, Time: 314.4888 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [180/229], Loss: 0.2045, Time: 314.7796 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [185/229], Loss: 0.2522, Time: 315.0904 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [190/229], Loss: 0.1976, Time: 315.3902 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [195/229], Loss: 0.2030, Time: 315.6851 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [200/229], Loss: 0.2006, Time: 315.9699 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [205/229], Loss: 0.1669, Time: 316.2577 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [210/229], Loss: 0.2286, Time: 316.5475 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [215/229], Loss: 0.2361, Time: 316.8403 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [220/229], Loss: 0.1979, Time: 317.1382 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [225/229], Loss: 0.2105, Time: 317.4300 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [5/229], Loss: 0.2076, Time: 318.3124 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [10/229], Loss: 0.2315, Time: 318.6073 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [15/229], Loss: 0.2175, Time: 318.9510 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [20/229], Loss: 0.2064, Time: 319.2449 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [25/229], Loss: 0.2370, Time: 319.5547 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [30/229], Loss: 0.2402, Time: 319.8485 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [35/229], Loss: 0.1958, Time: 320.1513 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [40/229], Loss: 0.1711, Time: 320.4381 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [45/229], Loss: 0.2042, Time: 320.7329 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [50/229], Loss: 0.1879, Time: 321.0408 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [55/229], Loss: 0.1647, Time: 321.3296 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [60/229], Loss: 0.2046, Time: 321.6234 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [65/229], Loss: 0.2339, Time: 321.9132 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [70/229], Loss: 0.2068, Time: 322.2100 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [75/229], Loss: 0.1703, Time: 322.4979 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [80/229], Loss: 0.2152, Time: 322.8217 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [85/229], Loss: 0.1527, Time: 323.1315 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [90/229], Loss: 0.2126, Time: 323.4163 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [95/229], Loss: 0.1856, Time: 323.7041 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [100/229], Loss: 0.1909, Time: 323.9949 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [105/229], Loss: 0.2070, Time: 324.3007 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [110/229], Loss: 0.1793, Time: 324.5976 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [115/229], Loss: 0.2212, Time: 324.8954 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [120/229], Loss: 0.2006, Time: 325.1882 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [125/229], Loss: 0.2377, Time: 325.4780 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [130/229], Loss: 0.2158, Time: 325.7708 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [135/229], Loss: 0.2057, Time: 326.0677 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [140/229], Loss: 0.1746, Time: 326.3575 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [145/229], Loss: 0.1514, Time: 326.6503 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [150/229], Loss: 0.2237, Time: 326.9691 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [155/229], Loss: 0.2212, Time: 327.2809 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [160/229], Loss: 0.1827, Time: 327.5767 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [165/229], Loss: 0.1728, Time: 327.8735 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [170/229], Loss: 0.2101, Time: 328.1634 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [175/229], Loss: 0.2432, Time: 328.4612 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [180/229], Loss: 0.2067, Time: 328.7630 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [185/229], Loss: 0.2190, Time: 329.0558 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [190/229], Loss: 0.1959, Time: 329.3506 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [195/229], Loss: 0.2101, Time: 329.6474 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [200/229], Loss: 0.2028, Time: 329.9453 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [205/229], Loss: 0.1683, Time: 330.2421 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [210/229], Loss: 0.2136, Time: 330.5279 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [215/229], Loss: 0.2177, Time: 330.8217 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [220/229], Loss: 0.2241, Time: 331.1165 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [225/229], Loss: 0.2129, Time: 331.4044 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [5/229], Loss: 0.2718, Time: 332.2798 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [10/229], Loss: 0.2055, Time: 332.5676 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [15/229], Loss: 0.1757, Time: 332.8705 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [20/229], Loss: 0.1974, Time: 333.1653 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [25/229], Loss: 0.1878, Time: 333.4521 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [30/229], Loss: 0.2051, Time: 333.7439 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [35/229], Loss: 0.1688, Time: 334.0317 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [40/229], Loss: 0.1738, Time: 334.3236 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [45/229], Loss: 0.2167, Time: 334.6224 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [50/229], Loss: 0.2052, Time: 334.9242 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [55/229], Loss: 0.2304, Time: 335.2180 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [60/229], Loss: 0.2087, Time: 335.5108 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [65/229], Loss: 0.2290, Time: 335.7997 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [70/229], Loss: 0.2161, Time: 336.0975 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [75/229], Loss: 0.1637, Time: 336.4383 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [80/229], Loss: 0.2204, Time: 336.7311 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [85/229], Loss: 0.1513, Time: 337.0309 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [90/229], Loss: 0.2099, Time: 337.3377 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [95/229], Loss: 0.1931, Time: 337.6355 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [100/229], Loss: 0.2294, Time: 337.9233 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [105/229], Loss: 0.1983, Time: 338.2262 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [110/229], Loss: 0.2015, Time: 338.5180 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [115/229], Loss: 0.2363, Time: 338.8108 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [120/229], Loss: 0.1692, Time: 339.1066 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [125/229], Loss: 0.2069, Time: 339.4054 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [130/229], Loss: 0.1974, Time: 339.6982 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [135/229], Loss: 0.2018, Time: 340.0001 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [140/229], Loss: 0.2084, Time: 340.2929 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [145/229], Loss: 0.1863, Time: 340.5967 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [150/229], Loss: 0.2312, Time: 340.9015 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [155/229], Loss: 0.1742, Time: 341.2093 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [160/229], Loss: 0.1966, Time: 341.5081 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [165/229], Loss: 0.2011, Time: 341.7950 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [170/229], Loss: 0.2023, Time: 342.1048 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [175/229], Loss: 0.1635, Time: 342.3926 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [180/229], Loss: 0.1874, Time: 342.6944 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [185/229], Loss: 0.1622, Time: 342.9932 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [190/229], Loss: 0.2048, Time: 343.3050 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [195/229], Loss: 0.1838, Time: 343.6068 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [200/229], Loss: 0.1926, Time: 343.9007 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [205/229], Loss: 0.2315, Time: 344.1925 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [210/229], Loss: 0.2210, Time: 344.4873 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [215/229], Loss: 0.1846, Time: 344.7871 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [220/229], Loss: 0.1820, Time: 345.0739 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [225/229], Loss: 0.2005, Time: 345.3877 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [5/229], Loss: 0.2036, Time: 346.2682 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [10/229], Loss: 0.1651, Time: 346.5680 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [15/229], Loss: 0.1875, Time: 346.8568 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [20/229], Loss: 0.1566, Time: 347.1556 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [25/229], Loss: 0.1813, Time: 347.4515 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [30/229], Loss: 0.1684, Time: 347.7503 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [35/229], Loss: 0.1866, Time: 348.0461 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [40/229], Loss: 0.1846, Time: 348.3409 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [45/229], Loss: 0.1895, Time: 348.6277 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [50/229], Loss: 0.1715, Time: 348.9276 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [55/229], Loss: 0.2268, Time: 349.2224 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [60/229], Loss: 0.2075, Time: 349.5312 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [65/229], Loss: 0.1811, Time: 349.8270 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [70/229], Loss: 0.1716, Time: 350.1168 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [75/229], Loss: 0.1801, Time: 350.4176 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [80/229], Loss: 0.1913, Time: 350.7224 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [85/229], Loss: 0.1548, Time: 351.0223 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [90/229], Loss: 0.1957, Time: 351.3181 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [95/229], Loss: 0.2030, Time: 351.6109 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [100/229], Loss: 0.1772, Time: 351.9057 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [105/229], Loss: 0.2063, Time: 352.1985 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [110/229], Loss: 0.1689, Time: 352.5023 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [115/229], Loss: 0.1946, Time: 352.7912 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [120/229], Loss: 0.1824, Time: 353.0960 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [125/229], Loss: 0.1926, Time: 353.4418 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [130/229], Loss: 0.2468, Time: 353.7316 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [135/229], Loss: 0.2051, Time: 354.0274 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [140/229], Loss: 0.2011, Time: 354.3562 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [145/229], Loss: 0.2162, Time: 354.6500 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [150/229], Loss: 0.1648, Time: 354.9488 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [155/229], Loss: 0.2252, Time: 355.2437 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [160/229], Loss: 0.1936, Time: 355.5395 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [165/229], Loss: 0.1997, Time: 355.8323 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [170/229], Loss: 0.2061, Time: 356.1251 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [175/229], Loss: 0.2206, Time: 356.4119 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [180/229], Loss: 0.1988, Time: 356.7028 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [185/229], Loss: 0.2153, Time: 357.0036 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [190/229], Loss: 0.2013, Time: 357.2934 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [195/229], Loss: 0.2167, Time: 357.5902 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [200/229], Loss: 0.1778, Time: 357.8830 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [205/229], Loss: 0.2068, Time: 358.2008 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [210/229], Loss: 0.1763, Time: 358.4957 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [215/229], Loss: 0.1937, Time: 358.7845 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [220/229], Loss: 0.1832, Time: 359.0823 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [225/229], Loss: 0.1489, Time: 359.3861 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [5/229], Loss: 0.1789, Time: 360.2696 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [10/229], Loss: 0.1883, Time: 360.5564 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [15/229], Loss: 0.1520, Time: 360.8462 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [20/229], Loss: 0.1613, Time: 361.1540 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [25/229], Loss: 0.2279, Time: 361.4538 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [30/229], Loss: 0.1846, Time: 361.7636 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [35/229], Loss: 0.2153, Time: 362.0734 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [40/229], Loss: 0.1497, Time: 362.3743 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [45/229], Loss: 0.1985, Time: 362.6611 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [50/229], Loss: 0.2323, Time: 362.9699 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [55/229], Loss: 0.1941, Time: 363.2757 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [60/229], Loss: 0.2195, Time: 363.5695 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [65/229], Loss: 0.1694, Time: 363.8593 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [70/229], Loss: 0.1600, Time: 364.1652 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [75/229], Loss: 0.1725, Time: 364.4690 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [80/229], Loss: 0.2094, Time: 364.7778 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [85/229], Loss: 0.1458, Time: 365.0746 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [90/229], Loss: 0.2113, Time: 365.3704 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [95/229], Loss: 0.2027, Time: 365.6622 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [100/229], Loss: 0.2030, Time: 365.9840 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [105/229], Loss: 0.1972, Time: 366.2808 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [110/229], Loss: 0.2149, Time: 366.5797 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [115/229], Loss: 0.1894, Time: 366.8745 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [120/229], Loss: 0.1648, Time: 367.1683 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [125/229], Loss: 0.2043, Time: 367.4551 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [130/229], Loss: 0.2048, Time: 367.7549 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [135/229], Loss: 0.1636, Time: 368.0458 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [140/229], Loss: 0.1795, Time: 368.3516 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [145/229], Loss: 0.2379, Time: 368.6694 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [150/229], Loss: 0.2318, Time: 368.9622 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [155/229], Loss: 0.1987, Time: 369.2590 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [160/229], Loss: 0.1668, Time: 369.5508 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [165/229], Loss: 0.1915, Time: 369.8526 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [170/229], Loss: 0.2009, Time: 370.1525 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [175/229], Loss: 0.2148, Time: 370.4493 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [180/229], Loss: 0.1846, Time: 370.8161 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [185/229], Loss: 0.1794, Time: 371.1069 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [190/229], Loss: 0.1876, Time: 371.4197 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [195/229], Loss: 0.1915, Time: 371.7075 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [200/229], Loss: 0.1801, Time: 372.0103 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [205/229], Loss: 0.2015, Time: 372.3121 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [210/229], Loss: 0.2152, Time: 372.6109 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [215/229], Loss: 0.1883, Time: 372.9068 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [220/229], Loss: 0.1968, Time: 373.2006 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [225/229], Loss: 0.1814, Time: 373.5094 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [5/229], Loss: 0.2235, Time: 374.3908 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [10/229], Loss: 0.2132, Time: 374.6787 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [15/229], Loss: 0.2156, Time: 374.9935 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [20/229], Loss: 0.1720, Time: 375.2923 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [25/229], Loss: 0.1796, Time: 375.5871 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [30/229], Loss: 0.1984, Time: 375.8829 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [35/229], Loss: 0.1669, Time: 376.1867 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [40/229], Loss: 0.1507, Time: 376.4866 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [45/229], Loss: 0.2101, Time: 376.7944 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [50/229], Loss: 0.1997, Time: 377.3230 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [55/229], Loss: 0.1873, Time: 377.6888 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [60/229], Loss: 0.2437, Time: 378.0406 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [65/229], Loss: 0.1627, Time: 378.3364 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [70/229], Loss: 0.1848, Time: 378.6412 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [75/229], Loss: 0.1881, Time: 378.9360 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [80/229], Loss: 0.1574, Time: 379.3378 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [85/229], Loss: 0.2290, Time: 379.8045 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [90/229], Loss: 0.1809, Time: 380.2662 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [95/229], Loss: 0.1953, Time: 380.7379 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [100/229], Loss: 0.1980, Time: 381.0397 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [105/229], Loss: 0.2129, Time: 381.3356 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [110/229], Loss: 0.1885, Time: 381.6344 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [115/229], Loss: 0.2133, Time: 381.9382 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [120/229], Loss: 0.1859, Time: 382.2300 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [125/229], Loss: 0.2156, Time: 382.5308 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [130/229], Loss: 0.1701, Time: 382.8236 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [135/229], Loss: 0.2420, Time: 383.1155 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [140/229], Loss: 0.1998, Time: 383.4173 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [145/229], Loss: 0.2584, Time: 383.7231 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [150/229], Loss: 0.1775, Time: 384.0139 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [155/229], Loss: 0.1627, Time: 384.3237 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [160/229], Loss: 0.2038, Time: 384.6225 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [165/229], Loss: 0.2046, Time: 384.9134 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [170/229], Loss: 0.2619, Time: 385.2122 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [175/229], Loss: 0.1680, Time: 385.5280 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [180/229], Loss: 0.1712, Time: 385.8308 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [185/229], Loss: 0.1686, Time: 386.1346 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [190/229], Loss: 0.1931, Time: 386.4234 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [195/229], Loss: 0.2270, Time: 386.7202 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [200/229], Loss: 0.2118, Time: 387.0271 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [205/229], Loss: 0.1560, Time: 387.4218 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [210/229], Loss: 0.1867, Time: 387.7096 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [215/229], Loss: 0.2175, Time: 388.0484 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [220/229], Loss: 0.2602, Time: 388.3462 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [225/229], Loss: 0.2075, Time: 388.6391 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [5/229], Loss: 0.2161, Time: 389.5285 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [10/229], Loss: 0.2128, Time: 389.8173 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [15/229], Loss: 0.1704, Time: 390.1221 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [20/229], Loss: 0.1563, Time: 390.4190 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [25/229], Loss: 0.1468, Time: 390.7198 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [30/229], Loss: 0.1925, Time: 391.0326 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [35/229], Loss: 0.2154, Time: 391.3204 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [40/229], Loss: 0.1943, Time: 391.6172 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [45/229], Loss: 0.2231, Time: 391.9130 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [50/229], Loss: 0.2117, Time: 392.2109 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [55/229], Loss: 0.2175, Time: 392.5107 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [60/229], Loss: 0.1747, Time: 392.7975 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [65/229], Loss: 0.2037, Time: 393.0903 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [70/229], Loss: 0.1941, Time: 393.3861 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [75/229], Loss: 0.1811, Time: 393.6839 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [80/229], Loss: 0.1511, Time: 393.9828 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [85/229], Loss: 0.1447, Time: 394.2726 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [90/229], Loss: 0.1890, Time: 394.5694 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [95/229], Loss: 0.2109, Time: 394.8572 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [100/229], Loss: 0.2245, Time: 395.1570 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [105/229], Loss: 0.2371, Time: 395.4499 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [110/229], Loss: 0.1646, Time: 395.7527 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [115/229], Loss: 0.1608, Time: 396.0745 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [120/229], Loss: 0.2224, Time: 396.3803 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [125/229], Loss: 0.2097, Time: 396.6711 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [130/229], Loss: 0.1748, Time: 396.9619 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [135/229], Loss: 0.1959, Time: 397.2797 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [140/229], Loss: 0.1928, Time: 397.5865 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [145/229], Loss: 0.1755, Time: 397.8754 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [150/229], Loss: 0.2015, Time: 398.1672 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [155/229], Loss: 0.1989, Time: 398.4590 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [160/229], Loss: 0.1440, Time: 398.7518 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [165/229], Loss: 0.1612, Time: 399.0446 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [170/229], Loss: 0.1914, Time: 399.3415 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [175/229], Loss: 0.1853, Time: 399.6403 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [180/229], Loss: 0.1775, Time: 399.9301 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [185/229], Loss: 0.1816, Time: 400.2239 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [190/229], Loss: 0.1911, Time: 400.5187 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [195/229], Loss: 0.1892, Time: 400.8125 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [200/229], Loss: 0.1838, Time: 401.1024 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [205/229], Loss: 0.1877, Time: 401.3982 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [210/229], Loss: 0.1684, Time: 401.7020 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [215/229], Loss: 0.1909, Time: 401.9948 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [220/229], Loss: 0.2034, Time: 402.2866 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [225/229], Loss: 0.1915, Time: 402.5795 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [5/229], Loss: 0.1948, Time: 403.4619 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [10/229], Loss: 0.1944, Time: 403.7527 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [15/229], Loss: 0.1643, Time: 404.0575 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [20/229], Loss: 0.2554, Time: 404.3524 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [25/229], Loss: 0.1548, Time: 404.6532 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [30/229], Loss: 0.1836, Time: 404.9940 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [35/229], Loss: 0.1613, Time: 405.2868 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [40/229], Loss: 0.1792, Time: 405.5956 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [45/229], Loss: 0.2175, Time: 405.8904 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [50/229], Loss: 0.2066, Time: 406.1792 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [55/229], Loss: 0.1852, Time: 406.4701 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [60/229], Loss: 0.1602, Time: 406.7609 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [65/229], Loss: 0.1905, Time: 407.0587 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [70/229], Loss: 0.1724, Time: 407.4425 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [75/229], Loss: 0.1857, Time: 407.9102 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [80/229], Loss: 0.1517, Time: 408.3759 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [85/229], Loss: 0.1519, Time: 408.8246 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [90/229], Loss: 0.1824, Time: 409.2923 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [95/229], Loss: 0.1770, Time: 409.7540 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [100/229], Loss: 0.1816, Time: 410.2337 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [105/229], Loss: 0.1869, Time: 410.6425 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [110/229], Loss: 0.1860, Time: 410.9343 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [115/229], Loss: 0.2396, Time: 411.2421 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [120/229], Loss: 0.2241, Time: 411.5449 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [125/229], Loss: 0.1999, Time: 411.8357 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [130/229], Loss: 0.1537, Time: 412.1276 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [135/229], Loss: 0.1416, Time: 412.4224 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [140/229], Loss: 0.1944, Time: 412.7192 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [145/229], Loss: 0.1747, Time: 413.0100 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [150/229], Loss: 0.1681, Time: 413.3108 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [155/229], Loss: 0.1561, Time: 413.6097 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [160/229], Loss: 0.1800, Time: 413.8985 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [165/229], Loss: 0.1813, Time: 414.1933 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [170/229], Loss: 0.1963, Time: 414.4861 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [175/229], Loss: 0.1609, Time: 414.7809 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [180/229], Loss: 0.1937, Time: 415.0747 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [185/229], Loss: 0.2054, Time: 415.3646 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [190/229], Loss: 0.1725, Time: 415.6514 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [195/229], Loss: 0.1593, Time: 415.9512 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [200/229], Loss: 0.1876, Time: 416.2420 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [205/229], Loss: 0.1648, Time: 416.5358 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [210/229], Loss: 0.2058, Time: 416.8367 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [215/229], Loss: 0.2117, Time: 417.1405 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [220/229], Loss: 0.2062, Time: 417.4403 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [225/229], Loss: 0.1971, Time: 417.7231 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [5/229], Loss: 0.2027, Time: 418.5996 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [10/229], Loss: 0.1812, Time: 418.8904 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [15/229], Loss: 0.1743, Time: 419.1862 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [20/229], Loss: 0.1491, Time: 419.4800 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [25/229], Loss: 0.1878, Time: 419.7788 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [30/229], Loss: 0.1808, Time: 420.0797 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [35/229], Loss: 0.1772, Time: 420.3735 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [40/229], Loss: 0.2064, Time: 420.6833 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [45/229], Loss: 0.2028, Time: 420.9891 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [50/229], Loss: 0.1820, Time: 421.2809 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [55/229], Loss: 0.2065, Time: 421.5797 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [60/229], Loss: 0.1927, Time: 421.8686 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [65/229], Loss: 0.2249, Time: 422.2343 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [70/229], Loss: 0.1608, Time: 422.5311 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [75/229], Loss: 0.1717, Time: 422.8320 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [80/229], Loss: 0.1635, Time: 423.1408 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [85/229], Loss: 0.1834, Time: 423.4416 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [90/229], Loss: 0.1399, Time: 423.7344 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [95/229], Loss: 0.2167, Time: 424.0242 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [100/229], Loss: 0.1904, Time: 424.3490 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [105/229], Loss: 0.1878, Time: 424.8837 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [110/229], Loss: 0.1860, Time: 425.2195 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [115/229], Loss: 0.1402, Time: 425.5113 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [120/229], Loss: 0.1592, Time: 425.8111 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [125/229], Loss: 0.1610, Time: 426.1039 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [130/229], Loss: 0.2008, Time: 426.4028 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [135/229], Loss: 0.2074, Time: 426.7076 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [140/229], Loss: 0.1952, Time: 426.9974 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [145/229], Loss: 0.1630, Time: 427.2942 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [150/229], Loss: 0.1693, Time: 427.5880 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [155/229], Loss: 0.1744, Time: 427.8769 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [160/229], Loss: 0.2152, Time: 428.1907 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [165/229], Loss: 0.2079, Time: 428.4875 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [170/229], Loss: 0.1915, Time: 428.7803 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [175/229], Loss: 0.1486, Time: 429.0701 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [180/229], Loss: 0.1690, Time: 429.3639 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [185/229], Loss: 0.2260, Time: 429.6667 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [190/229], Loss: 0.1511, Time: 429.9566 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [195/229], Loss: 0.1919, Time: 430.2474 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [200/229], Loss: 0.1853, Time: 430.5382 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [205/229], Loss: 0.2144, Time: 430.8480 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [210/229], Loss: 0.1716, Time: 431.1408 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [215/229], Loss: 0.2184, Time: 431.4307 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [220/229], Loss: 0.2128, Time: 431.7225 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [225/229], Loss: 0.2309, Time: 432.0103 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [5/229], Loss: 0.1807, Time: 432.8988 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [10/229], Loss: 0.1914, Time: 433.2006 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [15/229], Loss: 0.2107, Time: 433.5214 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [20/229], Loss: 0.1681, Time: 433.8172 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [25/229], Loss: 0.1900, Time: 434.1240 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [30/229], Loss: 0.1668, Time: 434.4218 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [35/229], Loss: 0.1882, Time: 434.7276 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [40/229], Loss: 0.2113, Time: 435.0564 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [45/229], Loss: 0.1712, Time: 435.3762 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [50/229], Loss: 0.1469, Time: 435.7340 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [55/229], Loss: 0.2037, Time: 436.0938 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [60/229], Loss: 0.1672, Time: 436.4386 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [65/229], Loss: 0.1438, Time: 436.8133 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [70/229], Loss: 0.1991, Time: 437.2830 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [75/229], Loss: 0.2029, Time: 437.7538 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [80/229], Loss: 0.2230, Time: 438.2035 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [85/229], Loss: 0.1561, Time: 438.6492 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [90/229], Loss: 0.1476, Time: 439.1069 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [95/229], Loss: 0.1720, Time: 439.6376 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [100/229], Loss: 0.1594, Time: 440.0983 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [105/229], Loss: 0.1638, Time: 440.5550 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [110/229], Loss: 0.1962, Time: 441.0187 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [115/229], Loss: 0.1767, Time: 441.3975 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [120/229], Loss: 0.1839, Time: 441.8093 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [125/229], Loss: 0.2201, Time: 442.1371 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [130/229], Loss: 0.1909, Time: 442.4429 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [135/229], Loss: 0.1831, Time: 442.7557 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [140/229], Loss: 0.1375, Time: 443.0575 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [145/229], Loss: 0.1670, Time: 443.3733 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [150/229], Loss: 0.2306, Time: 443.6661 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [155/229], Loss: 0.1885, Time: 443.9599 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [160/229], Loss: 0.2279, Time: 444.2647 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [165/229], Loss: 0.1623, Time: 444.5566 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [170/229], Loss: 0.1839, Time: 444.9573 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [175/229], Loss: 0.1502, Time: 445.2881 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [180/229], Loss: 0.1829, Time: 445.5819 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [185/229], Loss: 0.1547, Time: 445.8797 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [190/229], Loss: 0.1939, Time: 446.1756 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [195/229], Loss: 0.1771, Time: 446.4704 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [200/229], Loss: 0.1800, Time: 446.7812 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [205/229], Loss: 0.1819, Time: 447.0830 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [210/229], Loss: 0.1871, Time: 447.3818 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [215/229], Loss: 0.2127, Time: 447.6686 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [220/229], Loss: 0.1413, Time: 447.9605 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [225/229], Loss: 0.2063, Time: 448.2503 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [5/229], Loss: 0.1810, Time: 449.1317 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [10/229], Loss: 0.1504, Time: 449.4306 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [15/229], Loss: 0.1997, Time: 449.7274 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [20/229], Loss: 0.1841, Time: 450.0232 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [25/229], Loss: 0.1559, Time: 450.3250 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [30/229], Loss: 0.2116, Time: 450.6208 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [35/229], Loss: 0.1499, Time: 450.9096 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [40/229], Loss: 0.1991, Time: 451.2005 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [45/229], Loss: 0.1730, Time: 451.4923 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [50/229], Loss: 0.2186, Time: 451.7931 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [55/229], Loss: 0.2026, Time: 452.0839 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [60/229], Loss: 0.1828, Time: 452.3737 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [65/229], Loss: 0.1616, Time: 452.6766 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [70/229], Loss: 0.1543, Time: 452.9754 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [75/229], Loss: 0.1607, Time: 453.2732 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [80/229], Loss: 0.1664, Time: 453.5720 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [85/229], Loss: 0.1625, Time: 453.8668 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [90/229], Loss: 0.1881, Time: 454.1576 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [95/229], Loss: 0.1799, Time: 454.4525 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [100/229], Loss: 0.1834, Time: 454.7523 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [105/229], Loss: 0.1919, Time: 455.0531 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [110/229], Loss: 0.1804, Time: 455.3499 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [115/229], Loss: 0.2337, Time: 455.6397 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [120/229], Loss: 0.1938, Time: 455.9415 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [125/229], Loss: 0.2173, Time: 456.2424 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [130/229], Loss: 0.1473, Time: 456.5891 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [135/229], Loss: 0.2096, Time: 456.8770 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [140/229], Loss: 0.2292, Time: 457.1708 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [145/229], Loss: 0.1770, Time: 457.4726 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [150/229], Loss: 0.1933, Time: 457.7694 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [155/229], Loss: 0.1593, Time: 458.0572 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [160/229], Loss: 0.1979, Time: 458.3521 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [165/229], Loss: 0.1905, Time: 458.6519 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [170/229], Loss: 0.2125, Time: 458.9507 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [175/229], Loss: 0.1574, Time: 459.2455 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [180/229], Loss: 0.2163, Time: 459.5343 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [185/229], Loss: 0.1690, Time: 459.8341 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [190/229], Loss: 0.1367, Time: 460.1350 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [195/229], Loss: 0.1584, Time: 460.4358 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [200/229], Loss: 0.1936, Time: 460.7416 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [205/229], Loss: 0.2057, Time: 461.0434 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [210/229], Loss: 0.1825, Time: 461.3512 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [215/229], Loss: 0.1546, Time: 461.6680 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [220/229], Loss: 0.2181, Time: 462.0378 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [225/229], Loss: 0.1517, Time: 462.3906 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [5/229], Loss: 0.1814, Time: 463.2990 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [10/229], Loss: 0.2123, Time: 463.5938 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [15/229], Loss: 0.2276, Time: 463.8826 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [20/229], Loss: 0.1406, Time: 464.1805 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [25/229], Loss: 0.1366, Time: 464.4803 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [30/229], Loss: 0.1722, Time: 464.7881 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [35/229], Loss: 0.2433, Time: 465.0829 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [40/229], Loss: 0.1747, Time: 465.3837 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [45/229], Loss: 0.1788, Time: 465.6805 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [50/229], Loss: 0.1602, Time: 465.9833 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [55/229], Loss: 0.1969, Time: 466.2742 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [60/229], Loss: 0.1758, Time: 466.5670 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [65/229], Loss: 0.1915, Time: 466.8618 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [70/229], Loss: 0.1360, Time: 467.1526 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [75/229], Loss: 0.1673, Time: 467.4924 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [80/229], Loss: 0.1983, Time: 467.8072 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [85/229], Loss: 0.1670, Time: 468.0960 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [90/229], Loss: 0.1892, Time: 468.3829 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [95/229], Loss: 0.1932, Time: 468.6827 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [100/229], Loss: 0.1757, Time: 468.9915 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [105/229], Loss: 0.1847, Time: 469.2883 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [110/229], Loss: 0.1516, Time: 469.6051 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [115/229], Loss: 0.2057, Time: 470.1298 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [120/229], Loss: 0.1927, Time: 470.4716 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [125/229], Loss: 0.2127, Time: 470.7804 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [130/229], Loss: 0.1771, Time: 471.0782 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [135/229], Loss: 0.1922, Time: 471.3730 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [140/229], Loss: 0.1924, Time: 471.6608 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [145/229], Loss: 0.1686, Time: 471.9547 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [150/229], Loss: 0.1711, Time: 472.2525 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [155/229], Loss: 0.1838, Time: 472.5393 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [160/229], Loss: 0.2109, Time: 472.8491 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [165/229], Loss: 0.2043, Time: 473.1389 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [170/229], Loss: 0.1736, Time: 473.4477 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [175/229], Loss: 0.1897, Time: 473.7995 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [180/229], Loss: 0.1375, Time: 474.1053 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [185/229], Loss: 0.1555, Time: 474.3952 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [190/229], Loss: 0.1835, Time: 474.6830 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [195/229], Loss: 0.2286, Time: 474.9858 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [200/229], Loss: 0.1834, Time: 475.3036 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [205/229], Loss: 0.1506, Time: 475.5934 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [210/229], Loss: 0.2197, Time: 475.8992 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [215/229], Loss: 0.1612, Time: 476.1900 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [220/229], Loss: 0.1781, Time: 476.4799 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [225/229], Loss: 0.2077, Time: 476.7797 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [5/229], Loss: 0.2453, Time: 477.6711 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [10/229], Loss: 0.1539, Time: 477.9650 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [15/229], Loss: 0.1366, Time: 478.2558 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [20/229], Loss: 0.1943, Time: 478.5576 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [25/229], Loss: 0.1767, Time: 478.8584 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [30/229], Loss: 0.1792, Time: 479.1492 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [35/229], Loss: 0.1902, Time: 479.4470 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [40/229], Loss: 0.1921, Time: 479.7429 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [45/229], Loss: 0.1473, Time: 480.0427 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [50/229], Loss: 0.2096, Time: 480.3405 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [55/229], Loss: 0.2266, Time: 480.6313 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [60/229], Loss: 0.1581, Time: 480.9241 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [65/229], Loss: 0.1902, Time: 481.2259 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [70/229], Loss: 0.2049, Time: 481.5248 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [75/229], Loss: 0.1584, Time: 481.8286 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [80/229], Loss: 0.1885, Time: 482.1174 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [85/229], Loss: 0.1695, Time: 482.4082 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [90/229], Loss: 0.1767, Time: 482.6970 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [95/229], Loss: 0.1406, Time: 482.9879 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [100/229], Loss: 0.1831, Time: 483.2807 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [105/229], Loss: 0.2044, Time: 483.5775 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [110/229], Loss: 0.2016, Time: 483.8823 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [115/229], Loss: 0.1690, Time: 484.1961 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [120/229], Loss: 0.1978, Time: 484.5009 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [125/229], Loss: 0.1333, Time: 484.8007 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [130/229], Loss: 0.1918, Time: 485.0985 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [135/229], Loss: 0.2453, Time: 485.3884 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [140/229], Loss: 0.2152, Time: 485.6802 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [145/229], Loss: 0.1832, Time: 485.9730 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [150/229], Loss: 0.1712, Time: 486.2698 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [155/229], Loss: 0.2121, Time: 486.5587 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [160/229], Loss: 0.1853, Time: 486.8605 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [165/229], Loss: 0.1781, Time: 487.1483 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [170/229], Loss: 0.2418, Time: 487.4401 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [175/229], Loss: 0.2073, Time: 487.7489 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [180/229], Loss: 0.1368, Time: 488.0437 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [185/229], Loss: 0.1655, Time: 488.3405 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [190/229], Loss: 0.1842, Time: 488.6314 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [195/229], Loss: 0.1964, Time: 488.9342 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [200/229], Loss: 0.1553, Time: 489.2430 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [205/229], Loss: 0.1461, Time: 489.5508 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [210/229], Loss: 0.1823, Time: 489.8506 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [215/229], Loss: 0.1828, Time: 490.1434 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [220/229], Loss: 0.1821, Time: 490.4393 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [225/229], Loss: 0.1846, Time: 490.7341 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [5/229], Loss: 0.2201, Time: 491.6515 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [10/229], Loss: 0.1680, Time: 491.9523 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [15/229], Loss: 0.1869, Time: 492.2531 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [20/229], Loss: 0.2012, Time: 492.5460 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [25/229], Loss: 0.1691, Time: 492.8378 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [30/229], Loss: 0.2076, Time: 493.1266 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [35/229], Loss: 0.1978, Time: 493.4244 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [40/229], Loss: 0.2136, Time: 493.7302 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [45/229], Loss: 0.1889, Time: 494.0420 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [50/229], Loss: 0.2115, Time: 494.3478 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [55/229], Loss: 0.1837, Time: 494.6337 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [60/229], Loss: 0.1880, Time: 494.9565 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [65/229], Loss: 0.1605, Time: 495.2543 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [70/229], Loss: 0.1556, Time: 495.5491 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [75/229], Loss: 0.1403, Time: 495.8389 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [80/229], Loss: 0.1549, Time: 496.1397 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [85/229], Loss: 0.1607, Time: 496.4356 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [90/229], Loss: 0.1746, Time: 496.7234 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [95/229], Loss: 0.1843, Time: 497.0202 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [100/229], Loss: 0.1735, Time: 497.3170 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [105/229], Loss: 0.2164, Time: 497.6258 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [110/229], Loss: 0.1612, Time: 497.9186 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [115/229], Loss: 0.1661, Time: 498.2155 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [120/229], Loss: 0.1882, Time: 498.5103 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [125/229], Loss: 0.2001, Time: 498.9020 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [130/229], Loss: 0.2373, Time: 499.3188 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [135/229], Loss: 0.1554, Time: 499.6796 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [140/229], Loss: 0.2011, Time: 500.0563 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [145/229], Loss: 0.1663, Time: 500.4341 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [150/229], Loss: 0.1780, Time: 500.7749 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [155/229], Loss: 0.1468, Time: 501.1197 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [160/229], Loss: 0.1418, Time: 501.4255 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [165/229], Loss: 0.1835, Time: 501.7143 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [170/229], Loss: 0.1914, Time: 502.0111 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [175/229], Loss: 0.1875, Time: 502.3129 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [180/229], Loss: 0.1576, Time: 502.6327 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [185/229], Loss: 0.1488, Time: 502.9246 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [190/229], Loss: 0.1711, Time: 503.2324 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [195/229], Loss: 0.1656, Time: 503.5252 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [200/229], Loss: 0.1591, Time: 503.8140 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [205/229], Loss: 0.1590, Time: 504.1018 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [210/229], Loss: 0.1975, Time: 504.4166 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [215/229], Loss: 0.2110, Time: 504.7404 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [220/229], Loss: 0.1476, Time: 505.0323 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [225/229], Loss: 0.1573, Time: 505.3361 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [5/229], Loss: 0.1655, Time: 506.2365 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [10/229], Loss: 0.1759, Time: 506.5283 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [15/229], Loss: 0.1791, Time: 506.8421 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [20/229], Loss: 0.1482, Time: 507.1459 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [25/229], Loss: 0.2195, Time: 507.4438 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [30/229], Loss: 0.1742, Time: 507.7486 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [35/229], Loss: 0.1592, Time: 508.0364 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [40/229], Loss: 0.1859, Time: 508.3972 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [45/229], Loss: 0.2318, Time: 508.6980 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [50/229], Loss: 0.1858, Time: 508.9978 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [55/229], Loss: 0.1943, Time: 509.2976 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [60/229], Loss: 0.1976, Time: 509.5944 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [65/229], Loss: 0.1748, Time: 509.8973 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [70/229], Loss: 0.1453, Time: 510.1901 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [75/229], Loss: 0.1530, Time: 510.4909 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [80/229], Loss: 0.1831, Time: 510.8227 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [85/229], Loss: 0.1820, Time: 511.3374 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [90/229], Loss: 0.1654, Time: 511.6802 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [95/229], Loss: 0.1764, Time: 511.9690 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [100/229], Loss: 0.1872, Time: 512.2558 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [105/229], Loss: 0.1529, Time: 512.5486 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [110/229], Loss: 0.1476, Time: 512.8414 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [115/229], Loss: 0.1820, Time: 513.1403 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [120/229], Loss: 0.1355, Time: 513.4371 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [125/229], Loss: 0.1575, Time: 513.7339 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [130/229], Loss: 0.1745, Time: 514.0417 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [135/229], Loss: 0.2436, Time: 514.3545 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [140/229], Loss: 0.1739, Time: 514.6533 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [145/229], Loss: 0.1551, Time: 514.9431 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [150/229], Loss: 0.2028, Time: 515.2470 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [155/229], Loss: 0.2024, Time: 515.5408 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [160/229], Loss: 0.1648, Time: 515.8336 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [165/229], Loss: 0.2001, Time: 516.1274 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [170/229], Loss: 0.2189, Time: 516.4212 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [175/229], Loss: 0.2034, Time: 516.7130 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [180/229], Loss: 0.1445, Time: 517.0219 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [185/229], Loss: 0.1647, Time: 517.3157 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [190/229], Loss: 0.1907, Time: 517.6115 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [195/229], Loss: 0.1622, Time: 517.9093 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [200/229], Loss: 0.1800, Time: 518.2131 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [205/229], Loss: 0.1718, Time: 518.5149 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [210/229], Loss: 0.1926, Time: 518.8078 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [215/229], Loss: 0.2407, Time: 519.1136 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [220/229], Loss: 0.2030, Time: 519.4044 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [225/229], Loss: 0.1862, Time: 519.6982 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [5/229], Loss: 0.1355, Time: 520.5807 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [10/229], Loss: 0.1933, Time: 520.8695 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [15/229], Loss: 0.1393, Time: 521.1753 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [20/229], Loss: 0.1911, Time: 521.4681 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [25/229], Loss: 0.1932, Time: 521.7669 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [30/229], Loss: 0.1808, Time: 522.0597 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [35/229], Loss: 0.1783, Time: 522.3476 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [40/229], Loss: 0.1810, Time: 522.6484 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [45/229], Loss: 0.1621, Time: 522.9362 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [50/229], Loss: 0.1628, Time: 523.2440 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [55/229], Loss: 0.2395, Time: 523.5488 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [60/229], Loss: 0.2140, Time: 523.8546 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [65/229], Loss: 0.1815, Time: 524.1515 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [70/229], Loss: 0.1814, Time: 524.4483 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [75/229], Loss: 0.1649, Time: 524.7491 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [80/229], Loss: 0.1663, Time: 525.0429 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [85/229], Loss: 0.1830, Time: 525.3917 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [90/229], Loss: 0.1566, Time: 525.6995 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [95/229], Loss: 0.1815, Time: 525.9973 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [100/229], Loss: 0.1782, Time: 526.2911 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [105/229], Loss: 0.1538, Time: 526.5900 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [110/229], Loss: 0.1434, Time: 526.8778 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [115/229], Loss: 0.1692, Time: 527.1856 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [120/229], Loss: 0.1741, Time: 527.4944 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [125/229], Loss: 0.1540, Time: 527.7842 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [130/229], Loss: 0.1806, Time: 528.0710 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [135/229], Loss: 0.1762, Time: 528.3649 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [140/229], Loss: 0.1557, Time: 528.6707 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [145/229], Loss: 0.1963, Time: 528.9625 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [150/229], Loss: 0.1900, Time: 529.2533 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [155/229], Loss: 0.1673, Time: 529.5491 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [160/229], Loss: 0.1667, Time: 529.8489 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [165/229], Loss: 0.2143, Time: 530.1438 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [170/229], Loss: 0.1615, Time: 530.4336 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [175/229], Loss: 0.1855, Time: 530.7304 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [180/229], Loss: 0.1535, Time: 531.0282 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [185/229], Loss: 0.1451, Time: 531.3210 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [190/229], Loss: 0.1601, Time: 531.6139 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [195/229], Loss: 0.1744, Time: 531.9047 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [200/229], Loss: 0.2122, Time: 532.1985 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [205/229], Loss: 0.1799, Time: 532.4873 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [210/229], Loss: 0.1667, Time: 532.7951 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [215/229], Loss: 0.1568, Time: 533.1039 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [220/229], Loss: 0.1895, Time: 533.3958 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [225/229], Loss: 0.2126, Time: 533.6906 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [5/229], Loss: 0.1986, Time: 534.5640 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [10/229], Loss: 0.1880, Time: 534.8569 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [15/229], Loss: 0.1652, Time: 535.1597 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [20/229], Loss: 0.1311, Time: 535.4495 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [25/229], Loss: 0.1814, Time: 535.7403 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [30/229], Loss: 0.2102, Time: 536.0411 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [35/229], Loss: 0.2253, Time: 536.3299 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [40/229], Loss: 0.1342, Time: 536.6198 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [45/229], Loss: 0.2136, Time: 536.9196 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [50/229], Loss: 0.1879, Time: 537.2314 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [55/229], Loss: 0.1579, Time: 537.5312 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [60/229], Loss: 0.1806, Time: 537.8250 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [65/229], Loss: 0.1647, Time: 538.1258 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [70/229], Loss: 0.1487, Time: 538.4237 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [75/229], Loss: 0.1597, Time: 538.7145 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [80/229], Loss: 0.1869, Time: 539.0093 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [85/229], Loss: 0.1641, Time: 539.3071 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [90/229], Loss: 0.1855, Time: 539.5989 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [95/229], Loss: 0.1787, Time: 539.9017 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [100/229], Loss: 0.1927, Time: 540.1966 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [105/229], Loss: 0.2137, Time: 540.4864 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [110/229], Loss: 0.2140, Time: 540.7922 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [115/229], Loss: 0.1727, Time: 541.0930 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [120/229], Loss: 0.1891, Time: 541.3838 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [125/229], Loss: 0.1641, Time: 541.6926 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [130/229], Loss: 0.1644, Time: 541.9905 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [135/229], Loss: 0.1773, Time: 542.2833 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [140/229], Loss: 0.1582, Time: 542.6191 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [145/229], Loss: 0.2030, Time: 542.9189 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [150/229], Loss: 0.1939, Time: 543.2177 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [155/229], Loss: 0.2237, Time: 543.5125 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [160/229], Loss: 0.1967, Time: 543.8073 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [165/229], Loss: 0.2136, Time: 544.1101 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [170/229], Loss: 0.1843, Time: 544.4020 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [175/229], Loss: 0.1440, Time: 544.7178 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [180/229], Loss: 0.1800, Time: 545.0296 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [185/229], Loss: 0.1767, Time: 545.3274 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [190/229], Loss: 0.1822, Time: 545.6302 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [195/229], Loss: 0.1540, Time: 545.9380 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [200/229], Loss: 0.1613, Time: 546.2398 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [205/229], Loss: 0.1544, Time: 546.5386 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [210/229], Loss: 0.1843, Time: 546.8315 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [215/229], Loss: 0.2405, Time: 547.1203 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [220/229], Loss: 0.1342, Time: 547.4121 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [225/229], Loss: 0.2380, Time: 547.7269 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [5/229], Loss: 0.1704, Time: 548.6164 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [10/229], Loss: 0.2339, Time: 548.9142 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [15/229], Loss: 0.1815, Time: 549.2060 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [20/229], Loss: 0.1556, Time: 549.5048 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [25/229], Loss: 0.1836, Time: 549.8516 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [30/229], Loss: 0.1532, Time: 550.3923 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [35/229], Loss: 0.2009, Time: 550.7271 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [40/229], Loss: 0.1847, Time: 551.0419 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [45/229], Loss: 0.2109, Time: 551.3437 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [50/229], Loss: 0.1608, Time: 551.6375 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [55/229], Loss: 0.1859, Time: 551.9283 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [60/229], Loss: 0.1886, Time: 552.2411 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [65/229], Loss: 0.2048, Time: 552.5300 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [70/229], Loss: 0.1943, Time: 552.8997 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [75/229], Loss: 0.1789, Time: 553.3504 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [80/229], Loss: 0.1478, Time: 553.7192 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [85/229], Loss: 0.2075, Time: 554.0810 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [90/229], Loss: 0.1987, Time: 554.4208 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [95/229], Loss: 0.2083, Time: 554.7926 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [100/229], Loss: 0.1381, Time: 555.1693 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [105/229], Loss: 0.1547, Time: 555.5251 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [110/229], Loss: 0.1447, Time: 555.8749 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [115/229], Loss: 0.1433, Time: 556.2317 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [120/229], Loss: 0.2005, Time: 556.5874 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [125/229], Loss: 0.1701, Time: 556.9362 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [130/229], Loss: 0.2285, Time: 557.2291 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [135/229], Loss: 0.1658, Time: 557.5339 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [140/229], Loss: 0.2095, Time: 557.8277 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [145/229], Loss: 0.1950, Time: 558.1195 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [150/229], Loss: 0.1813, Time: 558.4273 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [155/229], Loss: 0.1939, Time: 558.7151 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [160/229], Loss: 0.1445, Time: 559.0140 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [165/229], Loss: 0.1541, Time: 559.3118 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [170/229], Loss: 0.1720, Time: 559.6566 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [175/229], Loss: 0.1632, Time: 559.9534 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [180/229], Loss: 0.1322, Time: 560.2432 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [185/229], Loss: 0.2034, Time: 560.5350 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [190/229], Loss: 0.1866, Time: 560.8268 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [195/229], Loss: 0.1763, Time: 561.1217 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [200/229], Loss: 0.1568, Time: 561.4225 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [205/229], Loss: 0.2411, Time: 561.7213 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [210/229], Loss: 0.1716, Time: 562.0171 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [215/229], Loss: 0.1575, Time: 562.3199 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [220/229], Loss: 0.1931, Time: 562.6217 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [225/229], Loss: 0.2225, Time: 562.9205 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [5/229], Loss: 0.2283, Time: 563.8360 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [10/229], Loss: 0.1602, Time: 564.1398 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [15/229], Loss: 0.1822, Time: 564.4276 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [20/229], Loss: 0.2046, Time: 564.7294 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [25/229], Loss: 0.1506, Time: 565.0372 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [30/229], Loss: 0.1731, Time: 565.3371 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [35/229], Loss: 0.1805, Time: 565.6379 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [40/229], Loss: 0.2041, Time: 565.9327 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [45/229], Loss: 0.1854, Time: 566.2335 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [50/229], Loss: 0.1767, Time: 566.5293 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [55/229], Loss: 0.1715, Time: 566.8391 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [60/229], Loss: 0.1437, Time: 567.1369 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [65/229], Loss: 0.2161, Time: 567.4448 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [70/229], Loss: 0.1629, Time: 567.7466 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [75/229], Loss: 0.1634, Time: 568.0454 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [80/229], Loss: 0.1659, Time: 568.3402 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [85/229], Loss: 0.1549, Time: 568.6300 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [90/229], Loss: 0.1365, Time: 568.9198 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [95/229], Loss: 0.1867, Time: 569.2356 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [100/229], Loss: 0.1840, Time: 569.5285 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [105/229], Loss: 0.2122, Time: 569.8343 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [110/229], Loss: 0.1707, Time: 570.1381 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [115/229], Loss: 0.1977, Time: 570.4369 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [120/229], Loss: 0.1633, Time: 570.7377 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [125/229], Loss: 0.1821, Time: 571.0325 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [130/229], Loss: 0.1860, Time: 571.3204 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [135/229], Loss: 0.1788, Time: 571.6222 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [140/229], Loss: 0.1595, Time: 571.9190 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [145/229], Loss: 0.1670, Time: 572.2218 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [150/229], Loss: 0.1743, Time: 572.5096 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [155/229], Loss: 0.2039, Time: 572.8094 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [160/229], Loss: 0.1952, Time: 573.0983 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [165/229], Loss: 0.2074, Time: 573.4111 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [170/229], Loss: 0.1621, Time: 573.7159 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [175/229], Loss: 0.1325, Time: 574.0377 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [180/229], Loss: 0.1707, Time: 574.3345 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [185/229], Loss: 0.1453, Time: 574.6403 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [190/229], Loss: 0.1613, Time: 574.9371 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [195/229], Loss: 0.1925, Time: 575.2389 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [200/229], Loss: 0.2389, Time: 575.5428 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [205/229], Loss: 0.2126, Time: 575.8416 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [210/229], Loss: 0.1731, Time: 576.1414 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [215/229], Loss: 0.1886, Time: 576.4502 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [220/229], Loss: 0.1716, Time: 576.7450 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [225/229], Loss: 0.1534, Time: 577.0828 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [5/229], Loss: 0.1680, Time: 577.9723 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [10/229], Loss: 0.1625, Time: 578.2911 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [15/229], Loss: 0.1533, Time: 578.5879 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [20/229], Loss: 0.2224, Time: 578.8827 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [25/229], Loss: 0.1586, Time: 579.1945 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [30/229], Loss: 0.1918, Time: 579.4913 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [35/229], Loss: 0.1760, Time: 579.7911 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [40/229], Loss: 0.1945, Time: 580.0880 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [45/229], Loss: 0.2094, Time: 580.3848 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [50/229], Loss: 0.1486, Time: 580.6826 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [55/229], Loss: 0.1940, Time: 580.9714 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [60/229], Loss: 0.1820, Time: 581.2732 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [65/229], Loss: 0.1433, Time: 581.5970 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [70/229], Loss: 0.1755, Time: 581.8948 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [75/229], Loss: 0.2077, Time: 582.1897 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [80/229], Loss: 0.1449, Time: 582.4895 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [85/229], Loss: 0.1960, Time: 582.8043 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [90/229], Loss: 0.1842, Time: 583.1051 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [95/229], Loss: 0.1917, Time: 583.3989 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [100/229], Loss: 0.1950, Time: 583.6927 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [105/229], Loss: 0.1857, Time: 584.0015 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [110/229], Loss: 0.1555, Time: 584.3004 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [115/229], Loss: 0.2026, Time: 584.5992 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [120/229], Loss: 0.1791, Time: 584.8950 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [125/229], Loss: 0.1327, Time: 585.2108 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [130/229], Loss: 0.1422, Time: 585.5136 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [135/229], Loss: 0.2112, Time: 585.8134 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [140/229], Loss: 0.1719, Time: 586.1052 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [145/229], Loss: 0.1799, Time: 586.3971 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [150/229], Loss: 0.1708, Time: 586.6889 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [155/229], Loss: 0.1288, Time: 586.9817 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [160/229], Loss: 0.1993, Time: 587.2815 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [165/229], Loss: 0.1930, Time: 587.7212 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [170/229], Loss: 0.1853, Time: 588.1570 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [175/229], Loss: 0.1779, Time: 588.4698 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [180/229], Loss: 0.1990, Time: 588.7686 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [185/229], Loss: 0.1626, Time: 589.0774 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [190/229], Loss: 0.1815, Time: 589.3712 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [195/229], Loss: 0.1865, Time: 589.6640 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [200/229], Loss: 0.1965, Time: 589.9808 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [205/229], Loss: 0.1552, Time: 590.2827 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [210/229], Loss: 0.1971, Time: 590.5775 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [215/229], Loss: 0.1562, Time: 590.8663 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [220/229], Loss: 0.2138, Time: 591.1591 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [225/229], Loss: 0.2053, Time: 591.4579 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [5/229], Loss: 0.1780, Time: 592.3414 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [10/229], Loss: 0.1851, Time: 592.6382 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [15/229], Loss: 0.2315, Time: 592.9510 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [20/229], Loss: 0.1863, Time: 593.2448 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [25/229], Loss: 0.1544, Time: 593.5367 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [30/229], Loss: 0.1551, Time: 593.8395 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [35/229], Loss: 0.1814, Time: 594.1823 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [40/229], Loss: 0.1709, Time: 594.4701 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [45/229], Loss: 0.1857, Time: 594.7609 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [50/229], Loss: 0.1503, Time: 595.0607 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [55/229], Loss: 0.2049, Time: 595.3515 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [60/229], Loss: 0.2151, Time: 595.6563 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [65/229], Loss: 0.1802, Time: 595.9512 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [70/229], Loss: 0.2149, Time: 596.2510 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [75/229], Loss: 0.1726, Time: 596.5468 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [80/229], Loss: 0.1782, Time: 596.8526 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [85/229], Loss: 0.1625, Time: 597.1524 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [90/229], Loss: 0.1570, Time: 597.4522 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [95/229], Loss: 0.1632, Time: 597.7620 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [100/229], Loss: 0.1777, Time: 598.0659 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [105/229], Loss: 0.1458, Time: 598.3607 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [110/229], Loss: 0.1789, Time: 598.6535 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [115/229], Loss: 0.1313, Time: 598.9423 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [120/229], Loss: 0.2086, Time: 599.2511 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [125/229], Loss: 0.1318, Time: 599.5519 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [130/229], Loss: 0.2212, Time: 599.8498 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [135/229], Loss: 0.1382, Time: 600.1426 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [140/229], Loss: 0.2062, Time: 600.4454 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [145/229], Loss: 0.1829, Time: 600.7352 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [150/229], Loss: 0.1428, Time: 601.0280 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [155/229], Loss: 0.1683, Time: 601.3258 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [160/229], Loss: 0.1586, Time: 601.6267 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [165/229], Loss: 0.1620, Time: 601.9255 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [170/229], Loss: 0.2123, Time: 602.2183 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [175/229], Loss: 0.1635, Time: 602.5261 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [180/229], Loss: 0.1901, Time: 602.8159 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [185/229], Loss: 0.1594, Time: 603.1097 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [190/229], Loss: 0.1725, Time: 603.3996 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [195/229], Loss: 0.1831, Time: 603.7034 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [200/229], Loss: 0.1767, Time: 603.9992 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [205/229], Loss: 0.1712, Time: 604.2960 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [210/229], Loss: 0.1563, Time: 604.5908 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [215/229], Loss: 0.1623, Time: 604.8916 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [220/229], Loss: 0.1640, Time: 605.1895 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [225/229], Loss: 0.1929, Time: 605.4873 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [5/229], Loss: 0.1418, Time: 606.3817 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [10/229], Loss: 0.1781, Time: 606.6805 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [15/229], Loss: 0.1381, Time: 606.9864 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [20/229], Loss: 0.1366, Time: 607.2912 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [25/229], Loss: 0.1843, Time: 607.5840 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [30/229], Loss: 0.2378, Time: 607.8828 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [35/229], Loss: 0.1423, Time: 608.1766 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [40/229], Loss: 0.1718, Time: 608.4694 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [45/229], Loss: 0.1956, Time: 608.7623 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [50/229], Loss: 0.1446, Time: 609.0711 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [55/229], Loss: 0.1753, Time: 609.3689 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [60/229], Loss: 0.2175, Time: 609.6607 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [65/229], Loss: 0.1964, Time: 609.9685 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [70/229], Loss: 0.2396, Time: 610.2763 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [75/229], Loss: 0.1899, Time: 610.5851 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [80/229], Loss: 0.1331, Time: 610.8870 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [85/229], Loss: 0.2085, Time: 611.2347 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [90/229], Loss: 0.1769, Time: 611.5286 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [95/229], Loss: 0.1777, Time: 611.8204 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [100/229], Loss: 0.1702, Time: 612.1142 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [105/229], Loss: 0.1419, Time: 612.4090 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [110/229], Loss: 0.1644, Time: 612.7038 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [115/229], Loss: 0.1893, Time: 612.9996 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [120/229], Loss: 0.1701, Time: 613.2975 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [125/229], Loss: 0.1656, Time: 613.6063 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [130/229], Loss: 0.2062, Time: 613.9071 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [135/229], Loss: 0.1429, Time: 614.2029 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [140/229], Loss: 0.1989, Time: 614.4997 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [145/229], Loss: 0.1361, Time: 614.8055 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [150/229], Loss: 0.2149, Time: 615.1223 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [155/229], Loss: 0.1994, Time: 615.4232 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [160/229], Loss: 0.2031, Time: 615.7180 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [165/229], Loss: 0.1857, Time: 616.0168 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [170/229], Loss: 0.1757, Time: 616.3166 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [175/229], Loss: 0.1441, Time: 616.6074 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [180/229], Loss: 0.1534, Time: 616.9002 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [185/229], Loss: 0.1857, Time: 617.1951 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [190/229], Loss: 0.1770, Time: 617.5049 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [195/229], Loss: 0.1465, Time: 617.8117 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [200/229], Loss: 0.1324, Time: 618.1065 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [205/229], Loss: 0.2090, Time: 618.4063 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [210/229], Loss: 0.1733, Time: 618.7211 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [215/229], Loss: 0.1840, Time: 619.0159 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [220/229], Loss: 0.2074, Time: 619.3207 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [225/229], Loss: 0.1753, Time: 619.6276 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [5/229], Loss: 0.1711, Time: 620.5090 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [10/229], Loss: 0.1614, Time: 620.8048 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [15/229], Loss: 0.1549, Time: 621.1016 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [20/229], Loss: 0.1762, Time: 621.3935 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [25/229], Loss: 0.2026, Time: 621.7003 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [30/229], Loss: 0.1959, Time: 621.9981 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [35/229], Loss: 0.1811, Time: 622.3239 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [40/229], Loss: 0.1561, Time: 622.8386 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [45/229], Loss: 0.1362, Time: 623.1984 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [50/229], Loss: 0.1985, Time: 623.4952 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [55/229], Loss: 0.1954, Time: 623.7910 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [60/229], Loss: 0.1427, Time: 624.0838 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [65/229], Loss: 0.1485, Time: 624.3906 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [70/229], Loss: 0.1530, Time: 624.6864 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [75/229], Loss: 0.1779, Time: 624.9833 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [80/229], Loss: 0.1420, Time: 625.2881 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [85/229], Loss: 0.1847, Time: 625.5839 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [90/229], Loss: 0.2218, Time: 625.8777 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [95/229], Loss: 0.2376, Time: 626.1885 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [100/229], Loss: 0.1891, Time: 626.4953 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [105/229], Loss: 0.1310, Time: 626.8011 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [110/229], Loss: 0.1541, Time: 627.0989 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [115/229], Loss: 0.1509, Time: 627.3998 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [120/229], Loss: 0.2312, Time: 627.7036 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [125/229], Loss: 0.1787, Time: 628.0044 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [130/229], Loss: 0.1658, Time: 628.4481 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [135/229], Loss: 0.1752, Time: 628.7749 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [140/229], Loss: 0.1837, Time: 629.0757 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [145/229], Loss: 0.1652, Time: 629.3765 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [150/229], Loss: 0.1632, Time: 629.6754 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [155/229], Loss: 0.1624, Time: 629.9842 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [160/229], Loss: 0.1795, Time: 630.2810 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [165/229], Loss: 0.1770, Time: 630.5758 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [170/229], Loss: 0.1611, Time: 630.8656 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [175/229], Loss: 0.1510, Time: 631.1654 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [180/229], Loss: 0.1442, Time: 631.4653 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [185/229], Loss: 0.1938, Time: 631.7551 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [190/229], Loss: 0.1393, Time: 632.0499 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [195/229], Loss: 0.1315, Time: 632.3457 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [200/229], Loss: 0.1721, Time: 632.6375 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [205/229], Loss: 0.1891, Time: 632.9433 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [210/229], Loss: 0.2389, Time: 633.2472 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [215/229], Loss: 0.1857, Time: 633.6959 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [220/229], Loss: 0.1704, Time: 634.1426 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [225/229], Loss: 0.1573, Time: 634.4464 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [5/229], Loss: 0.1945, Time: 635.3748 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [10/229], Loss: 0.1422, Time: 635.6707 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [15/229], Loss: 0.2234, Time: 635.9565 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [20/229], Loss: 0.2102, Time: 636.2453 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [25/229], Loss: 0.1828, Time: 636.5251 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [30/229], Loss: 0.2350, Time: 636.8180 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [35/229], Loss: 0.1625, Time: 637.0958 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [40/229], Loss: 0.1679, Time: 637.3816 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [45/229], Loss: 0.1557, Time: 637.6784 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [50/229], Loss: 0.1637, Time: 637.9692 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [55/229], Loss: 0.1953, Time: 638.2541 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [60/229], Loss: 0.1585, Time: 638.5449 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [65/229], Loss: 0.2050, Time: 638.8307 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [70/229], Loss: 0.1657, Time: 639.1085 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [75/229], Loss: 0.1723, Time: 639.3934 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [80/229], Loss: 0.1563, Time: 639.6762 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [85/229], Loss: 0.1786, Time: 639.9580 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [90/229], Loss: 0.1699, Time: 640.2398 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [95/229], Loss: 0.1741, Time: 640.5357 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [100/229], Loss: 0.1960, Time: 640.8285 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [105/229], Loss: 0.1988, Time: 641.1053 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [110/229], Loss: 0.1774, Time: 641.4021 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [115/229], Loss: 0.1565, Time: 641.6979 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [120/229], Loss: 0.1652, Time: 641.9788 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [125/229], Loss: 0.1377, Time: 642.2766 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [130/229], Loss: 0.1775, Time: 642.5544 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [135/229], Loss: 0.1391, Time: 642.8362 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [140/229], Loss: 0.1285, Time: 643.1311 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [145/229], Loss: 0.2024, Time: 643.4239 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [150/229], Loss: 0.1548, Time: 643.7127 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [155/229], Loss: 0.1826, Time: 643.9955 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [160/229], Loss: 0.2046, Time: 644.2764 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [165/229], Loss: 0.1756, Time: 644.5582 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [170/229], Loss: 0.1991, Time: 644.8500 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [175/229], Loss: 0.1767, Time: 645.1488 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [180/229], Loss: 0.1539, Time: 645.4336 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [185/229], Loss: 0.1707, Time: 645.7155 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [190/229], Loss: 0.1637, Time: 646.0752 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [195/229], Loss: 0.1684, Time: 646.4980 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [200/229], Loss: 0.1854, Time: 646.9597 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [205/229], Loss: 0.1429, Time: 647.3774 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [210/229], Loss: 0.1677, Time: 647.8541 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [215/229], Loss: 0.1363, Time: 648.2889 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [220/229], Loss: 0.1915, Time: 648.7316 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [225/229], Loss: 0.1707, Time: 649.1903 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [5/229], Loss: 0.1785, Time: 650.4266 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [10/229], Loss: 0.1282, Time: 650.8563 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [15/229], Loss: 0.1621, Time: 651.3030 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [20/229], Loss: 0.1808, Time: 651.6988 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [25/229], Loss: 0.1517, Time: 652.0985 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [30/229], Loss: 0.1413, Time: 652.4543 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [35/229], Loss: 0.1306, Time: 652.7351 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [40/229], Loss: 0.1982, Time: 653.0330 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [45/229], Loss: 0.1565, Time: 653.3528 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [50/229], Loss: 0.1990, Time: 653.6875 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [55/229], Loss: 0.2106, Time: 653.9714 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [60/229], Loss: 0.1811, Time: 654.2622 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [65/229], Loss: 0.1952, Time: 654.5400 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [70/229], Loss: 0.1714, Time: 654.8578 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [75/229], Loss: 0.1734, Time: 655.1476 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [80/229], Loss: 0.2045, Time: 655.4335 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [85/229], Loss: 0.1589, Time: 655.7133 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [90/229], Loss: 0.2168, Time: 656.0041 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [95/229], Loss: 0.1923, Time: 656.3079 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [100/229], Loss: 0.1522, Time: 656.5918 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [105/229], Loss: 0.1635, Time: 656.8776 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [110/229], Loss: 0.1892, Time: 657.1724 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [115/229], Loss: 0.1988, Time: 657.6951 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [120/229], Loss: 0.1376, Time: 658.0349 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [125/229], Loss: 0.1759, Time: 658.3457 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [130/229], Loss: 0.1910, Time: 658.6275 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [135/229], Loss: 0.2372, Time: 658.9113 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [140/229], Loss: 0.1766, Time: 659.1922 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [145/229], Loss: 0.1447, Time: 659.4830 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [150/229], Loss: 0.2022, Time: 659.7648 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [155/229], Loss: 0.1776, Time: 660.0486 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [160/229], Loss: 0.1420, Time: 660.3514 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [165/229], Loss: 0.1775, Time: 660.6373 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [170/229], Loss: 0.1767, Time: 660.9421 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [175/229], Loss: 0.1721, Time: 661.2339 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [180/229], Loss: 0.1651, Time: 661.5217 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [185/229], Loss: 0.1618, Time: 661.8065 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [190/229], Loss: 0.1796, Time: 662.0864 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [195/229], Loss: 0.1765, Time: 662.3742 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [200/229], Loss: 0.1794, Time: 662.6500 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [205/229], Loss: 0.1655, Time: 662.9418 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [210/229], Loss: 0.1459, Time: 663.2327 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [215/229], Loss: 0.2083, Time: 663.5205 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [220/229], Loss: 0.1452, Time: 663.8003 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [225/229], Loss: 0.1423, Time: 664.0851 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [5/229], Loss: 0.1640, Time: 664.9466 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [10/229], Loss: 0.2066, Time: 665.2324 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [15/229], Loss: 0.1729, Time: 665.5192 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [20/229], Loss: 0.1414, Time: 665.7971 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [25/229], Loss: 0.2141, Time: 666.0759 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [30/229], Loss: 0.1646, Time: 666.3697 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [35/229], Loss: 0.2371, Time: 666.6535 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [40/229], Loss: 0.2045, Time: 666.9454 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [45/229], Loss: 0.2306, Time: 667.2482 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [50/229], Loss: 0.2343, Time: 667.5290 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [55/229], Loss: 0.1618, Time: 667.8178 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [60/229], Loss: 0.1775, Time: 668.1027 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [65/229], Loss: 0.1849, Time: 668.3905 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [70/229], Loss: 0.1416, Time: 668.6693 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [75/229], Loss: 0.1610, Time: 668.9541 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [80/229], Loss: 0.1514, Time: 669.2330 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [85/229], Loss: 0.1988, Time: 669.5118 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [90/229], Loss: 0.1650, Time: 669.7986 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [95/229], Loss: 0.1739, Time: 670.0894 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [100/229], Loss: 0.1771, Time: 670.3832 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [105/229], Loss: 0.2025, Time: 670.6721 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [110/229], Loss: 0.1451, Time: 670.9599 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [115/229], Loss: 0.2052, Time: 671.2767 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [120/229], Loss: 0.1816, Time: 671.5775 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [125/229], Loss: 0.2101, Time: 671.8663 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [130/229], Loss: 0.1695, Time: 672.1562 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [135/229], Loss: 0.1495, Time: 672.4340 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [140/229], Loss: 0.1494, Time: 672.7318 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [145/229], Loss: 0.1732, Time: 673.0126 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [150/229], Loss: 0.1580, Time: 673.3134 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [155/229], Loss: 0.1788, Time: 673.6033 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [160/229], Loss: 0.1823, Time: 673.8911 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [165/229], Loss: 0.1712, Time: 674.1849 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [170/229], Loss: 0.1692, Time: 674.4657 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [175/229], Loss: 0.1548, Time: 674.7436 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [180/229], Loss: 0.1438, Time: 675.0434 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [185/229], Loss: 0.1679, Time: 675.3222 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [190/229], Loss: 0.1857, Time: 675.6140 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [195/229], Loss: 0.1455, Time: 675.9018 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [200/229], Loss: 0.1811, Time: 676.1997 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [205/229], Loss: 0.2204, Time: 676.4975 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [210/229], Loss: 0.2055, Time: 676.7803 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [215/229], Loss: 0.1832, Time: 677.0641 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [220/229], Loss: 0.1952, Time: 677.3599 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [225/229], Loss: 0.1931, Time: 677.6528 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [5/229], Loss: 0.1406, Time: 678.5312 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [10/229], Loss: 0.1745, Time: 678.8100 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [15/229], Loss: 0.1969, Time: 679.0899 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [20/229], Loss: 0.1915, Time: 679.3807 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [25/229], Loss: 0.1887, Time: 679.6735 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [30/229], Loss: 0.1493, Time: 679.9563 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [35/229], Loss: 0.1936, Time: 680.2442 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [40/229], Loss: 0.1397, Time: 680.5300 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [45/229], Loss: 0.1934, Time: 680.8268 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [50/229], Loss: 0.1672, Time: 681.1036 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [55/229], Loss: 0.1540, Time: 681.4034 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [60/229], Loss: 0.2061, Time: 681.6983 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [65/229], Loss: 0.1514, Time: 681.9781 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [70/229], Loss: 0.2384, Time: 682.2889 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [75/229], Loss: 0.1814, Time: 682.5707 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [80/229], Loss: 0.2226, Time: 682.8556 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [85/229], Loss: 0.1524, Time: 683.1394 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [90/229], Loss: 0.1921, Time: 683.4432 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [95/229], Loss: 0.2057, Time: 683.7200 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [100/229], Loss: 0.1311, Time: 684.0068 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [105/229], Loss: 0.1938, Time: 684.2987 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [110/229], Loss: 0.1359, Time: 684.5775 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [115/229], Loss: 0.1914, Time: 684.8853 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [120/229], Loss: 0.1415, Time: 685.1661 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [125/229], Loss: 0.1481, Time: 685.4440 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [130/229], Loss: 0.1554, Time: 685.7348 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [135/229], Loss: 0.2203, Time: 686.0206 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [140/229], Loss: 0.1905, Time: 686.3274 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [145/229], Loss: 0.1879, Time: 686.6222 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [150/229], Loss: 0.1837, Time: 686.9220 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [155/229], Loss: 0.2165, Time: 687.2249 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [160/229], Loss: 0.1644, Time: 687.5057 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [165/229], Loss: 0.1543, Time: 687.8265 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [170/229], Loss: 0.1664, Time: 688.3432 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [175/229], Loss: 0.1759, Time: 688.6740 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [180/229], Loss: 0.1899, Time: 688.9658 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [185/229], Loss: 0.1781, Time: 689.2806 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [190/229], Loss: 0.1986, Time: 689.5664 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [195/229], Loss: 0.1631, Time: 689.8512 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [200/229], Loss: 0.1954, Time: 690.1351 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [205/229], Loss: 0.1854, Time: 690.4249 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [210/229], Loss: 0.1731, Time: 690.7087 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [215/229], Loss: 0.1830, Time: 690.9935 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [220/229], Loss: 0.1518, Time: 691.2923 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [225/229], Loss: 0.2013, Time: 691.5752 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [5/229], Loss: 0.1586, Time: 692.4356 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [10/229], Loss: 0.1918, Time: 692.7235 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [15/229], Loss: 0.1826, Time: 693.0093 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [20/229], Loss: 0.1787, Time: 693.3061 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [25/229], Loss: 0.1525, Time: 693.5899 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [30/229], Loss: 0.2100, Time: 693.8867 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [35/229], Loss: 0.1900, Time: 694.1676 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [40/229], Loss: 0.1671, Time: 694.4484 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [45/229], Loss: 0.1576, Time: 694.7382 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [50/229], Loss: 0.1822, Time: 695.0280 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [55/229], Loss: 0.1699, Time: 695.3079 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [60/229], Loss: 0.1357, Time: 695.5887 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [65/229], Loss: 0.1645, Time: 695.8805 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [70/229], Loss: 0.1960, Time: 696.1733 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [75/229], Loss: 0.1717, Time: 696.4562 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [80/229], Loss: 0.2005, Time: 696.7420 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [85/229], Loss: 0.1441, Time: 697.0328 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [90/229], Loss: 0.1846, Time: 697.3226 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [95/229], Loss: 0.1860, Time: 697.6164 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [100/229], Loss: 0.1763, Time: 697.9113 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [105/229], Loss: 0.1773, Time: 698.2061 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [110/229], Loss: 0.1519, Time: 698.4949 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [115/229], Loss: 0.1533, Time: 698.7807 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [120/229], Loss: 0.1409, Time: 699.0765 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [125/229], Loss: 0.1322, Time: 699.3644 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [130/229], Loss: 0.2381, Time: 699.6482 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [135/229], Loss: 0.2049, Time: 699.9320 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [140/229], Loss: 0.1741, Time: 700.2348 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [145/229], Loss: 0.2099, Time: 700.5286 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [150/229], Loss: 0.1920, Time: 700.8225 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [155/229], Loss: 0.1742, Time: 701.1103 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [160/229], Loss: 0.1821, Time: 701.4101 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [165/229], Loss: 0.2097, Time: 701.7199 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [170/229], Loss: 0.1481, Time: 702.0187 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [175/229], Loss: 0.1851, Time: 702.3036 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [180/229], Loss: 0.1533, Time: 702.5994 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [185/229], Loss: 0.1672, Time: 702.8992 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [190/229], Loss: 0.1912, Time: 703.1890 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [195/229], Loss: 0.1758, Time: 703.4808 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [200/229], Loss: 0.1837, Time: 703.7697 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [205/229], Loss: 0.1615, Time: 704.0625 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [210/229], Loss: 0.2300, Time: 704.3543 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [215/229], Loss: 0.1880, Time: 704.6481 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [220/229], Loss: 0.1452, Time: 704.9369 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [225/229], Loss: 0.1734, Time: 705.2337 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [5/229], Loss: 0.2005, Time: 706.1242 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [10/229], Loss: 0.1908, Time: 706.4250 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [15/229], Loss: 0.2204, Time: 706.7278 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [20/229], Loss: 0.1575, Time: 707.0137 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [25/229], Loss: 0.2034, Time: 707.3075 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [30/229], Loss: 0.2198, Time: 707.6053 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [35/229], Loss: 0.1632, Time: 707.8981 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [40/229], Loss: 0.2365, Time: 708.1959 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [45/229], Loss: 0.1776, Time: 708.4897 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [50/229], Loss: 0.1699, Time: 708.7866 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [55/229], Loss: 0.1829, Time: 709.0734 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [60/229], Loss: 0.2338, Time: 709.3622 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [65/229], Loss: 0.1884, Time: 709.6520 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [70/229], Loss: 0.1670, Time: 709.9548 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [75/229], Loss: 0.2081, Time: 710.2447 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [80/229], Loss: 0.2093, Time: 710.5415 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [85/229], Loss: 0.2074, Time: 710.8133 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [90/229], Loss: 0.2036, Time: 711.3210 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [95/229], Loss: 0.1534, Time: 711.7947 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [100/229], Loss: 0.1808, Time: 712.2094 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [105/229], Loss: 0.2017, Time: 712.5602 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [110/229], Loss: 0.1835, Time: 712.8580 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [115/229], Loss: 0.1441, Time: 713.1709 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [120/229], Loss: 0.1875, Time: 713.4907 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [125/229], Loss: 0.1707, Time: 713.8205 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [130/229], Loss: 0.1727, Time: 714.1273 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [135/229], Loss: 0.2107, Time: 714.4281 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [140/229], Loss: 0.2073, Time: 714.7229 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [145/229], Loss: 0.1353, Time: 715.0437 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [150/229], Loss: 0.1741, Time: 715.3415 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [155/229], Loss: 0.1757, Time: 715.6513 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [160/229], Loss: 0.1844, Time: 715.9511 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [165/229], Loss: 0.1906, Time: 716.2699 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [170/229], Loss: 0.1613, Time: 716.5827 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [175/229], Loss: 0.1946, Time: 716.8856 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [180/229], Loss: 0.1766, Time: 717.1824 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [185/229], Loss: 0.1538, Time: 717.4962 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [190/229], Loss: 0.1611, Time: 717.8150 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [195/229], Loss: 0.2056, Time: 718.1178 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [200/229], Loss: 0.1528, Time: 718.4546 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [205/229], Loss: 0.2135, Time: 718.9733 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [210/229], Loss: 0.1605, Time: 719.3021 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [215/229], Loss: 0.1670, Time: 719.6089 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [220/229], Loss: 0.1479, Time: 719.9177 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [225/229], Loss: 0.1450, Time: 720.2265 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [5/229], Loss: 0.1529, Time: 721.1599 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [10/229], Loss: 0.1552, Time: 721.4597 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [15/229], Loss: 0.1976, Time: 721.7765 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [20/229], Loss: 0.1441, Time: 722.0804 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [25/229], Loss: 0.1843, Time: 722.3702 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [30/229], Loss: 0.1825, Time: 722.6870 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [35/229], Loss: 0.1880, Time: 722.9738 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [40/229], Loss: 0.1906, Time: 723.2806 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [45/229], Loss: 0.1499, Time: 723.5834 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [50/229], Loss: 0.1497, Time: 723.8932 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [55/229], Loss: 0.1522, Time: 724.1931 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [60/229], Loss: 0.1842, Time: 724.4929 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [65/229], Loss: 0.1578, Time: 724.7967 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [70/229], Loss: 0.1272, Time: 725.0985 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [75/229], Loss: 0.1730, Time: 725.3903 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [80/229], Loss: 0.2073, Time: 725.6911 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [85/229], Loss: 0.1528, Time: 725.9889 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [90/229], Loss: 0.1519, Time: 726.3037 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [95/229], Loss: 0.1863, Time: 726.6056 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [100/229], Loss: 0.1619, Time: 726.8994 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [105/229], Loss: 0.2376, Time: 727.2162 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [110/229], Loss: 0.2043, Time: 727.5140 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [115/229], Loss: 0.2072, Time: 727.8208 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [120/229], Loss: 0.1612, Time: 728.1206 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [125/229], Loss: 0.2053, Time: 728.4254 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [130/229], Loss: 0.1761, Time: 728.7223 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [135/229], Loss: 0.1486, Time: 729.0251 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [140/229], Loss: 0.1520, Time: 729.3299 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [145/229], Loss: 0.1828, Time: 729.6407 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [150/229], Loss: 0.2093, Time: 729.9415 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [155/229], Loss: 0.1609, Time: 730.2513 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [160/229], Loss: 0.2296, Time: 730.5631 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [165/229], Loss: 0.1571, Time: 730.8609 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [170/229], Loss: 0.1830, Time: 731.1638 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [175/229], Loss: 0.1665, Time: 731.4616 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [180/229], Loss: 0.1817, Time: 731.7664 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [185/229], Loss: 0.1517, Time: 732.0662 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [190/229], Loss: 0.2107, Time: 732.3750 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [195/229], Loss: 0.1816, Time: 732.6758 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [200/229], Loss: 0.1636, Time: 732.9826 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [205/229], Loss: 0.2358, Time: 733.2844 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [210/229], Loss: 0.2096, Time: 733.5953 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [215/229], Loss: 0.2090, Time: 733.8931 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [220/229], Loss: 0.1761, Time: 734.1939 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [225/229], Loss: 0.1978, Time: 734.4947 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [5/229], Loss: 0.1765, Time: 735.3951 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [10/229], Loss: 0.2361, Time: 735.6920 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [15/229], Loss: 0.1753, Time: 735.9898 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [20/229], Loss: 0.1929, Time: 736.2836 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [25/229], Loss: 0.1533, Time: 736.5894 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [30/229], Loss: 0.1354, Time: 736.8862 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [35/229], Loss: 0.1612, Time: 737.1840 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [40/229], Loss: 0.1497, Time: 737.4898 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [45/229], Loss: 0.1760, Time: 737.8077 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [50/229], Loss: 0.1717, Time: 738.1704 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [55/229], Loss: 0.1313, Time: 738.4762 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [60/229], Loss: 0.1810, Time: 738.7801 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [65/229], Loss: 0.1725, Time: 739.0809 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [70/229], Loss: 0.1947, Time: 739.3897 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [75/229], Loss: 0.1571, Time: 739.6805 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [80/229], Loss: 0.1739, Time: 739.9923 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [85/229], Loss: 0.1710, Time: 740.2831 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [90/229], Loss: 0.1632, Time: 740.5809 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [95/229], Loss: 0.1909, Time: 740.8778 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [100/229], Loss: 0.1401, Time: 741.1906 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [105/229], Loss: 0.2003, Time: 741.4894 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [110/229], Loss: 0.1904, Time: 741.8162 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [115/229], Loss: 0.1368, Time: 742.1230 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [120/229], Loss: 0.1914, Time: 742.4168 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [125/229], Loss: 0.2057, Time: 742.7176 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [130/229], Loss: 0.1834, Time: 743.0254 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [135/229], Loss: 0.1670, Time: 743.3382 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [140/229], Loss: 0.1430, Time: 743.6471 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [145/229], Loss: 0.1528, Time: 743.9609 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [150/229], Loss: 0.1784, Time: 744.2747 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [155/229], Loss: 0.1553, Time: 744.5785 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [160/229], Loss: 0.1851, Time: 744.8873 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [165/229], Loss: 0.1860, Time: 745.1831 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [170/229], Loss: 0.1517, Time: 745.4799 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [175/229], Loss: 0.1927, Time: 745.7957 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [180/229], Loss: 0.1686, Time: 746.1145 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [185/229], Loss: 0.1642, Time: 746.4243 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [190/229], Loss: 0.2252, Time: 746.7341 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [195/229], Loss: 0.2158, Time: 747.0440 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [200/229], Loss: 0.1704, Time: 747.3538 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [205/229], Loss: 0.2357, Time: 747.6526 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [210/229], Loss: 0.1981, Time: 747.9544 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [215/229], Loss: 0.1942, Time: 748.2582 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [220/229], Loss: 0.1434, Time: 748.7889 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [225/229], Loss: 0.1382, Time: 749.1596 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [5/229], Loss: 0.1981, Time: 750.0541 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [10/229], Loss: 0.1641, Time: 750.3479 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [15/229], Loss: 0.1536, Time: 750.6417 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [20/229], Loss: 0.1619, Time: 750.9356 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [25/229], Loss: 0.1570, Time: 751.2374 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [30/229], Loss: 0.2158, Time: 751.5332 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [35/229], Loss: 0.1517, Time: 751.8330 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [40/229], Loss: 0.1546, Time: 752.1328 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [45/229], Loss: 0.2011, Time: 752.4306 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [50/229], Loss: 0.1518, Time: 752.7334 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [55/229], Loss: 0.1612, Time: 753.0233 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [60/229], Loss: 0.1907, Time: 753.3161 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [65/229], Loss: 0.1479, Time: 753.6099 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [70/229], Loss: 0.1552, Time: 753.9087 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [75/229], Loss: 0.1529, Time: 754.2135 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [80/229], Loss: 0.1408, Time: 754.5133 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [85/229], Loss: 0.1699, Time: 754.8152 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [90/229], Loss: 0.1421, Time: 755.1599 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [95/229], Loss: 0.1787, Time: 755.4538 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [100/229], Loss: 0.1367, Time: 755.7546 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [105/229], Loss: 0.2252, Time: 756.0674 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [110/229], Loss: 0.1903, Time: 756.3672 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [115/229], Loss: 0.1598, Time: 756.6820 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [120/229], Loss: 0.1312, Time: 756.9898 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [125/229], Loss: 0.1879, Time: 757.3026 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [130/229], Loss: 0.2071, Time: 757.6044 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [135/229], Loss: 0.1703, Time: 757.9083 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [140/229], Loss: 0.1810, Time: 758.2011 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [145/229], Loss: 0.1842, Time: 758.5029 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [150/229], Loss: 0.1689, Time: 758.8127 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [155/229], Loss: 0.1764, Time: 759.1085 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [160/229], Loss: 0.1764, Time: 759.4163 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [165/229], Loss: 0.1562, Time: 759.7331 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [170/229], Loss: 0.1408, Time: 760.0349 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [175/229], Loss: 0.1686, Time: 760.3358 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [180/229], Loss: 0.2086, Time: 760.6416 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [185/229], Loss: 0.1975, Time: 760.9414 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [190/229], Loss: 0.1817, Time: 761.2502 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [195/229], Loss: 0.1508, Time: 761.5580 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [200/229], Loss: 0.2034, Time: 761.8608 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [205/229], Loss: 0.1496, Time: 762.1606 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [210/229], Loss: 0.1665, Time: 762.4505 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [215/229], Loss: 0.2130, Time: 762.7493 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [220/229], Loss: 0.1720, Time: 763.0511 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [225/229], Loss: 0.1541, Time: 763.3509 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [5/229], Loss: 0.1522, Time: 764.2443 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [10/229], Loss: 0.1803, Time: 764.5522 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [15/229], Loss: 0.1319, Time: 764.8470 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [20/229], Loss: 0.1975, Time: 765.1458 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [25/229], Loss: 0.1981, Time: 765.4396 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [30/229], Loss: 0.1841, Time: 765.7454 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [35/229], Loss: 0.1913, Time: 766.0422 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [40/229], Loss: 0.1914, Time: 766.3510 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [45/229], Loss: 0.1754, Time: 766.6559 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [50/229], Loss: 0.1786, Time: 766.9457 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [55/229], Loss: 0.2095, Time: 767.2455 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [60/229], Loss: 0.2045, Time: 767.5583 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [65/229], Loss: 0.1469, Time: 767.8521 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [70/229], Loss: 0.2200, Time: 768.1559 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [75/229], Loss: 0.1760, Time: 768.4507 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [80/229], Loss: 0.1816, Time: 768.7596 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [85/229], Loss: 0.1906, Time: 769.0594 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [90/229], Loss: 0.1682, Time: 769.3542 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [95/229], Loss: 0.2252, Time: 769.6630 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [100/229], Loss: 0.1882, Time: 769.9668 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [105/229], Loss: 0.1631, Time: 770.2686 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [110/229], Loss: 0.1797, Time: 770.5694 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [115/229], Loss: 0.1764, Time: 770.8633 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [120/229], Loss: 0.1610, Time: 771.2041 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [125/229], Loss: 0.2157, Time: 771.5588 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [130/229], Loss: 0.1832, Time: 771.8507 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [135/229], Loss: 0.1528, Time: 772.1595 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [140/229], Loss: 0.2002, Time: 772.4633 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [145/229], Loss: 0.1796, Time: 772.7681 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [150/229], Loss: 0.1435, Time: 773.0599 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [155/229], Loss: 0.1978, Time: 773.3527 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [160/229], Loss: 0.1741, Time: 773.6515 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [165/229], Loss: 0.1884, Time: 773.9574 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [170/229], Loss: 0.1381, Time: 774.2522 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [175/229], Loss: 0.1562, Time: 774.5670 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [180/229], Loss: 0.1928, Time: 774.8678 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [185/229], Loss: 0.1486, Time: 775.1626 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [190/229], Loss: 0.2031, Time: 775.4654 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [195/229], Loss: 0.1406, Time: 775.7682 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [200/229], Loss: 0.1695, Time: 776.0661 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [205/229], Loss: 0.1577, Time: 776.3649 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [210/229], Loss: 0.1903, Time: 776.6717 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [215/229], Loss: 0.1562, Time: 776.9665 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [220/229], Loss: 0.1669, Time: 777.3483 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [225/229], Loss: 0.1724, Time: 777.8669 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [5/229], Loss: 0.1577, Time: 778.7694 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [10/229], Loss: 0.1755, Time: 779.0742 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [15/229], Loss: 0.1860, Time: 779.3810 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [20/229], Loss: 0.1405, Time: 779.6728 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [25/229], Loss: 0.1352, Time: 779.9726 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [30/229], Loss: 0.1967, Time: 780.2864 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [35/229], Loss: 0.1978, Time: 780.6003 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [40/229], Loss: 0.2106, Time: 780.9021 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [45/229], Loss: 0.1294, Time: 781.1959 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [50/229], Loss: 0.1948, Time: 781.5147 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [55/229], Loss: 0.2050, Time: 781.8215 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [60/229], Loss: 0.2081, Time: 782.1173 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [65/229], Loss: 0.1609, Time: 782.4191 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [70/229], Loss: 0.1640, Time: 782.7319 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [75/229], Loss: 0.1602, Time: 783.0308 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [80/229], Loss: 0.2087, Time: 783.3286 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [85/229], Loss: 0.1921, Time: 783.6254 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [90/229], Loss: 0.1767, Time: 783.9182 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [95/229], Loss: 0.1390, Time: 784.2140 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [100/229], Loss: 0.2035, Time: 784.5208 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [105/229], Loss: 0.1570, Time: 784.8266 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [110/229], Loss: 0.1761, Time: 785.1265 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [115/229], Loss: 0.1312, Time: 785.4233 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [120/229], Loss: 0.1831, Time: 785.7171 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [125/229], Loss: 0.1848, Time: 786.0099 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [130/229], Loss: 0.1820, Time: 786.3107 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [135/229], Loss: 0.1560, Time: 786.6135 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [140/229], Loss: 0.2045, Time: 786.9194 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [145/229], Loss: 0.1758, Time: 787.2352 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [150/229], Loss: 0.1609, Time: 787.5340 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [155/229], Loss: 0.1828, Time: 787.8428 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [160/229], Loss: 0.1447, Time: 788.1466 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [165/229], Loss: 0.1771, Time: 788.4594 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [170/229], Loss: 0.1765, Time: 788.8102 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [175/229], Loss: 0.1509, Time: 789.1170 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [180/229], Loss: 0.1486, Time: 789.4238 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [185/229], Loss: 0.1905, Time: 789.7336 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [190/229], Loss: 0.1403, Time: 790.0474 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [195/229], Loss: 0.1797, Time: 790.3572 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [200/229], Loss: 0.1980, Time: 790.6501 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [205/229], Loss: 0.1765, Time: 790.9489 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [210/229], Loss: 0.1519, Time: 791.2537 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [215/229], Loss: 0.1774, Time: 791.5595 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [220/229], Loss: 0.1895, Time: 791.8583 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [225/229], Loss: 0.1942, Time: 792.1601 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [5/229], Loss: 0.1926, Time: 793.0426 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [10/229], Loss: 0.1704, Time: 793.3494 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [15/229], Loss: 0.1843, Time: 793.6542 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [20/229], Loss: 0.1947, Time: 793.9510 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [25/229], Loss: 0.1954, Time: 794.2528 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [30/229], Loss: 0.1752, Time: 794.5526 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [35/229], Loss: 0.1906, Time: 794.8495 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [40/229], Loss: 0.2092, Time: 795.1553 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [45/229], Loss: 0.1434, Time: 795.4681 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [50/229], Loss: 0.1879, Time: 795.7799 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [55/229], Loss: 0.1405, Time: 796.0737 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [60/229], Loss: 0.1631, Time: 796.3685 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [65/229], Loss: 0.1449, Time: 796.6603 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [70/229], Loss: 0.1911, Time: 796.9612 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [75/229], Loss: 0.1908, Time: 797.2530 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [80/229], Loss: 0.1598, Time: 797.5438 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [85/229], Loss: 0.1706, Time: 797.8436 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [90/229], Loss: 0.1640, Time: 798.1384 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [95/229], Loss: 0.1551, Time: 798.4333 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [100/229], Loss: 0.1832, Time: 798.7361 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [105/229], Loss: 0.1478, Time: 799.0349 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [110/229], Loss: 0.1896, Time: 799.3337 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [115/229], Loss: 0.1561, Time: 799.6305 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [120/229], Loss: 0.1495, Time: 799.9293 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [125/229], Loss: 0.1738, Time: 800.2251 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [130/229], Loss: 0.1441, Time: 800.5210 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [135/229], Loss: 0.1978, Time: 800.8158 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [140/229], Loss: 0.1939, Time: 801.1236 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [145/229], Loss: 0.1709, Time: 801.4234 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [150/229], Loss: 0.1732, Time: 801.7232 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [155/229], Loss: 0.1924, Time: 802.0210 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [160/229], Loss: 0.2070, Time: 802.3318 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [165/229], Loss: 0.1545, Time: 802.6287 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [170/229], Loss: 0.1806, Time: 802.9295 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [175/229], Loss: 0.1668, Time: 803.2563 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [180/229], Loss: 0.1663, Time: 803.5511 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [185/229], Loss: 0.1400, Time: 803.8569 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [190/229], Loss: 0.1390, Time: 804.1567 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [195/229], Loss: 0.2050, Time: 804.4515 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [200/229], Loss: 0.1438, Time: 804.7733 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [205/229], Loss: 0.2044, Time: 805.0762 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [210/229], Loss: 0.1312, Time: 805.3980 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [215/229], Loss: 0.1550, Time: 805.9826 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [220/229], Loss: 0.1528, Time: 806.3034 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [225/229], Loss: 0.1842, Time: 806.6002 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [5/229], Loss: 0.1764, Time: 807.4937 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [10/229], Loss: 0.1429, Time: 807.7975 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [15/229], Loss: 0.2091, Time: 808.1013 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [20/229], Loss: 0.1512, Time: 808.4011 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [25/229], Loss: 0.1778, Time: 808.6919 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [30/229], Loss: 0.1807, Time: 809.0007 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [35/229], Loss: 0.2053, Time: 809.3105 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [40/229], Loss: 0.1977, Time: 809.6024 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [45/229], Loss: 0.2130, Time: 809.9042 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [50/229], Loss: 0.1446, Time: 810.1980 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [55/229], Loss: 0.1692, Time: 810.4978 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [60/229], Loss: 0.1850, Time: 810.8066 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [65/229], Loss: 0.1540, Time: 811.1044 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [70/229], Loss: 0.1527, Time: 811.4003 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [75/229], Loss: 0.1696, Time: 811.7261 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [80/229], Loss: 0.1905, Time: 812.0209 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [85/229], Loss: 0.1407, Time: 812.3227 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [90/229], Loss: 0.2359, Time: 812.6165 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [95/229], Loss: 0.2013, Time: 812.9243 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [100/229], Loss: 0.2326, Time: 813.2221 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [105/229], Loss: 0.1400, Time: 813.5209 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [110/229], Loss: 0.1763, Time: 813.8228 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [115/229], Loss: 0.1507, Time: 814.1246 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [120/229], Loss: 0.1912, Time: 814.4334 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [125/229], Loss: 0.1367, Time: 814.7242 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [130/229], Loss: 0.1764, Time: 815.0280 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [135/229], Loss: 0.1719, Time: 815.3288 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [140/229], Loss: 0.1799, Time: 815.6306 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [145/229], Loss: 0.1403, Time: 815.9395 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [150/229], Loss: 0.1640, Time: 816.2473 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [155/229], Loss: 0.2044, Time: 816.5621 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [160/229], Loss: 0.1907, Time: 816.8539 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [165/229], Loss: 0.1742, Time: 817.1517 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [170/229], Loss: 0.1611, Time: 817.4515 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [175/229], Loss: 0.1783, Time: 817.7583 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [180/229], Loss: 0.1531, Time: 818.0541 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [185/229], Loss: 0.1828, Time: 818.3460 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [190/229], Loss: 0.1958, Time: 818.6498 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [195/229], Loss: 0.1767, Time: 818.9516 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [200/229], Loss: 0.1498, Time: 819.2464 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [205/229], Loss: 0.1521, Time: 819.5602 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [210/229], Loss: 0.1560, Time: 819.8560 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [215/229], Loss: 0.1485, Time: 820.1519 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [220/229], Loss: 0.1739, Time: 820.4517 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [225/229], Loss: 0.1317, Time: 820.7485 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [5/229], Loss: 0.1637, Time: 821.6479 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [10/229], Loss: 0.1662, Time: 821.9597 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [15/229], Loss: 0.1742, Time: 822.2705 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [20/229], Loss: 0.1544, Time: 822.5624 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [25/229], Loss: 0.2129, Time: 822.8712 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [30/229], Loss: 0.1471, Time: 823.2180 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [35/229], Loss: 0.1484, Time: 823.5278 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [40/229], Loss: 0.2043, Time: 823.8386 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [45/229], Loss: 0.1685, Time: 824.1354 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [50/229], Loss: 0.1576, Time: 824.4252 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [55/229], Loss: 0.1719, Time: 824.7340 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [60/229], Loss: 0.1597, Time: 825.0388 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [65/229], Loss: 0.1958, Time: 825.3457 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [70/229], Loss: 0.1477, Time: 825.6525 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [75/229], Loss: 0.1546, Time: 825.9533 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [80/229], Loss: 0.2051, Time: 826.2531 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [85/229], Loss: 0.1402, Time: 826.5489 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [90/229], Loss: 0.2156, Time: 826.8457 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [95/229], Loss: 0.1561, Time: 827.1555 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [100/229], Loss: 0.1271, Time: 827.4633 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [105/229], Loss: 0.1600, Time: 827.7612 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [110/229], Loss: 0.1754, Time: 828.0710 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [115/229], Loss: 0.2079, Time: 828.3788 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [120/229], Loss: 0.1819, Time: 828.6786 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [125/229], Loss: 0.1785, Time: 828.9824 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [130/229], Loss: 0.1400, Time: 829.2892 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [135/229], Loss: 0.1601, Time: 829.5860 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [140/229], Loss: 0.1707, Time: 829.8829 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [145/229], Loss: 0.1601, Time: 830.1787 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [150/229], Loss: 0.1429, Time: 830.4825 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [155/229], Loss: 0.1366, Time: 830.7763 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [160/229], Loss: 0.1816, Time: 831.0901 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [165/229], Loss: 0.1380, Time: 831.3949 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [170/229], Loss: 0.1763, Time: 831.7017 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [175/229], Loss: 0.1755, Time: 831.9985 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [180/229], Loss: 0.1807, Time: 832.2984 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [185/229], Loss: 0.1920, Time: 832.5922 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [190/229], Loss: 0.1446, Time: 832.8970 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [195/229], Loss: 0.1814, Time: 833.3247 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [200/229], Loss: 0.2043, Time: 833.7735 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [205/229], Loss: 0.1520, Time: 834.0843 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [210/229], Loss: 0.1635, Time: 834.3931 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [215/229], Loss: 0.2093, Time: 834.6839 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [220/229], Loss: 0.1553, Time: 834.9867 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [225/229], Loss: 0.2198, Time: 835.2935 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [5/229], Loss: 0.1706, Time: 836.1840 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [10/229], Loss: 0.1389, Time: 836.4958 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [15/229], Loss: 0.1938, Time: 836.7906 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [20/229], Loss: 0.1979, Time: 837.1024 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [25/229], Loss: 0.1610, Time: 837.3962 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [30/229], Loss: 0.1708, Time: 837.6890 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [35/229], Loss: 0.1604, Time: 837.9968 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [40/229], Loss: 0.1869, Time: 838.3027 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [45/229], Loss: 0.1484, Time: 838.6045 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [50/229], Loss: 0.1352, Time: 838.9013 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [55/229], Loss: 0.1415, Time: 839.2001 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [60/229], Loss: 0.1737, Time: 839.5049 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [65/229], Loss: 0.1703, Time: 839.8067 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [70/229], Loss: 0.1301, Time: 840.0995 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [75/229], Loss: 0.1815, Time: 840.4513 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [80/229], Loss: 0.1754, Time: 840.7471 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [85/229], Loss: 0.1812, Time: 841.0570 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [90/229], Loss: 0.2092, Time: 841.3628 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [95/229], Loss: 0.1999, Time: 841.6746 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [100/229], Loss: 0.1691, Time: 841.9784 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [105/229], Loss: 0.1514, Time: 842.3222 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [110/229], Loss: 0.1739, Time: 842.6240 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [115/229], Loss: 0.1829, Time: 842.9188 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [120/229], Loss: 0.1696, Time: 843.2176 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [125/229], Loss: 0.1911, Time: 843.5154 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [130/229], Loss: 0.2069, Time: 843.8143 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [135/229], Loss: 0.1608, Time: 844.1161 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [140/229], Loss: 0.1535, Time: 844.4139 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [145/229], Loss: 0.1621, Time: 844.7117 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [150/229], Loss: 0.1599, Time: 845.0195 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [155/229], Loss: 0.1667, Time: 845.3213 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [160/229], Loss: 0.1573, Time: 845.6191 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [165/229], Loss: 0.1795, Time: 845.9260 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [170/229], Loss: 0.1882, Time: 846.2308 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [175/229], Loss: 0.1549, Time: 846.5306 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [180/229], Loss: 0.1433, Time: 846.8484 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [185/229], Loss: 0.1624, Time: 847.1562 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [190/229], Loss: 0.1511, Time: 847.4670 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [195/229], Loss: 0.1520, Time: 847.7698 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [200/229], Loss: 0.1840, Time: 848.0616 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [205/229], Loss: 0.2028, Time: 848.3704 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [210/229], Loss: 0.2089, Time: 848.6703 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [215/229], Loss: 0.1294, Time: 848.9801 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [220/229], Loss: 0.1516, Time: 849.2759 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [225/229], Loss: 0.1550, Time: 849.5767 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [5/229], Loss: 0.1351, Time: 850.4692 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [10/229], Loss: 0.1601, Time: 850.7630 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [15/229], Loss: 0.2193, Time: 851.0678 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [20/229], Loss: 0.1701, Time: 851.3726 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [25/229], Loss: 0.1517, Time: 851.6774 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [30/229], Loss: 0.1607, Time: 851.9712 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [35/229], Loss: 0.1768, Time: 852.2640 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [40/229], Loss: 0.2033, Time: 852.5619 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [45/229], Loss: 0.1825, Time: 852.8697 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [50/229], Loss: 0.1601, Time: 853.1745 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [55/229], Loss: 0.1811, Time: 853.4753 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [60/229], Loss: 0.1694, Time: 853.7821 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [65/229], Loss: 0.1687, Time: 854.0929 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [70/229], Loss: 0.1510, Time: 854.4147 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [75/229], Loss: 0.1964, Time: 854.7145 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [80/229], Loss: 0.2103, Time: 855.0243 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [85/229], Loss: 0.1634, Time: 855.3541 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [90/229], Loss: 0.1471, Time: 855.6719 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [95/229], Loss: 0.1847, Time: 855.9778 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [100/229], Loss: 0.2089, Time: 856.2726 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [105/229], Loss: 0.1661, Time: 856.5684 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [110/229], Loss: 0.1667, Time: 856.8692 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [115/229], Loss: 0.1778, Time: 857.2120 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [120/229], Loss: 0.1645, Time: 857.5158 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [125/229], Loss: 0.1598, Time: 857.8386 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [130/229], Loss: 0.2040, Time: 858.1684 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [135/229], Loss: 0.1837, Time: 858.4612 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [140/229], Loss: 0.1475, Time: 858.7540 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [145/229], Loss: 0.2009, Time: 859.0469 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [150/229], Loss: 0.1560, Time: 859.3467 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [155/229], Loss: 0.1762, Time: 859.6505 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [160/229], Loss: 0.2048, Time: 859.9553 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [165/229], Loss: 0.1527, Time: 860.2571 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [170/229], Loss: 0.1438, Time: 860.5629 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [175/229], Loss: 0.2052, Time: 860.8667 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [180/229], Loss: 0.1842, Time: 861.1715 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [185/229], Loss: 0.1754, Time: 861.4704 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [190/229], Loss: 0.1926, Time: 861.7842 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [195/229], Loss: 0.1730, Time: 862.0830 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [200/229], Loss: 0.1750, Time: 862.3948 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [205/229], Loss: 0.1667, Time: 862.7016 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [210/229], Loss: 0.1839, Time: 863.0044 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [215/229], Loss: 0.1560, Time: 863.3052 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [220/229], Loss: 0.1693, Time: 863.5961 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [225/229], Loss: 0.1813, Time: 863.8999 secs, learning rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(YTrain)\n",
    "start_time = time.time()\n",
    "model = model.float()\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "loss_tmp = 0\n",
    "norm = 1\n",
    "for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss1 = criterion(norm*outputs, norm*y.float())\n",
    "        loss2 = torch.mean(outputs**2 - y.float()**2)\n",
    "        loss = loss1 + loss2\n",
    "        loss_tmp += loss.item()\n",
    "loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ind = np.arange(int(total_step/batch_size))\n",
    "    random.shuffle(ind)\n",
    "    for i,k in enumerate(ind):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XTrain[k*batch_size:(k+1)*batch_size,:,:,:], YTrain[k*batch_size:(k+1)*batch_size,:]\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x.float())\n",
    "        loss1 = criterion(norm*outputs, norm*y.float())\n",
    "        loss2 = torch.mean(outputs**2 - y.float()**2)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 5== 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs, learning rate: {:.4f}'\n",
    "                    .format(epoch + 1, num_epochs, i + 1, int(total_step/batch_size), loss.item(), time.time() - start_time, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    loss_tmp = 0\n",
    "    result = []\n",
    "    for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss1 = criterion(norm*outputs, norm*y.float())\n",
    "        loss2 = torch.mean(outputs**2 - y.float()**2)\n",
    "        loss = loss1 + loss2\n",
    "        loss_tmp += loss.item()\n",
    "        result.append(outputs)\n",
    "    loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 20.0)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x396 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(loss_train)), loss_train, label = 'Training error')\n",
    "plt.plot(np.arange(0, len(loss_train)+1, int(total_step/batch_size)), loss_val, label = 'Validation error')\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim([0,20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(-1.0, 5.0)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x396 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFeCAYAAACYZlYBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2HUlEQVR4nO3deXRU9f3/8ecsSSb7HrZAEvZdICiiCFZwQxG1IKhFWywgav1WqyK4gUULrda91rpVqb+6i7VSFAVFEBRQkH1fk5CNJGSf7f7+gIxEEkgwyTB3Xo9zPCZ37sy8581kXnM/997PtRiGYSAiIiKmYfV3ASIiItK0FO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjJ2fxcAcNVVVxEVFQVAamoqf/rTn/xckYiISODye7hXV1djGAbz5s3zdykiIiKm4Pdh+S1btlBZWcnEiRO54YYbWLt2rb9LEhERCWgWf89Qt3XrVtatW8fYsWPZs2cPkyZNYuHChdjtdQ8quN0e7HZbC1cpIiISOPw+LJ+RkUFaWhoWi4WMjAzi4uLIz8+nTZs2da5fVFTRpM+fnBxNfn5pkz6mWag3dVNf6qfe1E+9qZv6Ur+a3iQnRzf6vn4fln/33XeZM2cOALm5uZSVlZGcnOznqkRERAKX37fcx4wZw/Tp07n22muxWCw8+uij9Q7Ji4iIyMn5PUVDQ0N5/PHH/V2GiIiIafh9WF5ERESalsJdRETEZBTuIiIiJqNwFxERMRmFu4iIiMko3EVExFRuu20ya9asqrXsyScf46OP5h+37pgxo6iurmbevH+yadOGWrdVV1czZsyoEz7Xhx++j9vtZvv2rbz66os/u/am4vdT4URExJzeXryDVVvyTriOzWbB42n4LOhndk/hmgs6n3CdUaOuZOHCj8nMPBMAl8vF8uVfMWXKrfXeZ8KEXze4hmPNm/cql1xyGV26dKNLl26n9BjNQeEuIiKmcv75w3nhheeoqqrC4XDw1Vdfkpk5kIcemoHTWU1hYQGTJt3C0KHn++7zyCMzGT78Ivr27cfDD99PaWkp7dql+m7//vs1vPrqi3i9XiorK3noodn88MP3HDpUyMyZMxg79lo+/PA9Zs36E59++j/efvvfhISE0L59B+655z4+/fR/rFixnOrqKrKyDnD99TcycuSJRwV+DoW7iIg0i2su6HzSrezmmFs+LCyMoUPPZ+nSJVx00aUsWPAfBgwYyEUXXcqAAQNZv34dL7/8Qq1wrzF//ntkZHRiypRb2bhxA999txqA3bt38eCDfyQpKZnXX3+FJUs+48Ybb+Kf/3yZmTMfZePG9QCUlBTz8ssv8OqrbxAREcnTTz/Ohx++R3h4BOXlZfz1r8+yf/8+pk27Q+EuIiLSGKNGXcVzzz1F//6ZlJaWcvbZ5/Laay/z8ccfAhbcbned99u/fx/nnHMuAL169fZNh56cnMyTT/6F8PAI8vPz6NPnjDrvn52dRUZGRyIiIgE444wBrFq1kp49e9O5c1cAUlJa4XQ6m/gV16YD6kRExHQ6depMZWU577zzJpdddgUvvfR3LrnkMh544I8MGDCw3vtlZGSwYcORrfBt27b4vgTMnfsIM2Y8xH33zSQp6ceLm1ksVo69cnqbNu3Ys2c3lZWVAKxd+x3t23c4uq6lyV9nfRTuIiJiSpdddgUffTSfESMu5he/GM5zzz3FrbdOYtWqbyguLq7zPqNH/5Ls7CymTr2J999/h5CQEAAuvvhSbrllElOnTqSiooKCgnwAzjijH3fddbvv/nFxcUycOIXbb5/C5Mm/pqSkmCuvHNPsr/WnLMaxXzkCQFPvm9G1hOun3tRNfamfelM/9aZu6kv9Avp67iIiItK0FO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjKaoU5EREzlmWeeYOvWzRw6VEhVVRVt27YjLi6e2bPnnvB+8+b9k8zMgfTs2bvO25966nHGjbue1q1bN0fZTUrnuescy3qpN3VTX+qn3tQvGHvz/o7/8n3e+hOuY7Na8HgbHkP9U/pwdefLG7TuggUfsXfvHqZO/V2DH/908nPOc9eWu4iImN4jj8ykpKSEw4dLmDv3rzz//DPk5eVSWFjAuecOZfLkW3xXhjt0qLDOK7jddttk7r57Bp999gk5OdkUFRWRm5vD7353J4MGDWb58q94+eW/ExkZRXR0DJ06deamm6b45fUq3EVEpFlc3fnyk25lt+SIRmbmQMaNu56cnGx69erDvfc+QHV1NVdfPZLJk2+pte7JruAWEhLK448/zapVK/n3v99g4MCzePLJx3jhhVdISEhk1qz7W+Q11UfhLiIiQaFDhzQAYmJi2Lx5I999t5rIyEicTtdx657sCm5du3Y7entrnM5qiouLiIyMJCEhETgy53xhYWFzvZST0tHyIiISFCyWI5G3YMF/iYqK5qGHZjN+/K+orq7ip4efnewKbj+9OT4+gYqKcoqKigDYuHFD0xV+CrTlLiIiQSUz80xmzbqfjRvXExISQmpqe99V3k6V1Wrljjvu4e67/4/IyCgMw0tqavsmqrjxdLR8EB7B2lDqTd3Ul/qpN/VTb+pmpr7Mm/cq48ZdT2hoKA8//ABnnjmISy9t2JH9ddHR8iIiIn4WERHBlCm/xuFw0Lp1W4YPv8hvtSjcRUREmsAvfzmOX/5ynL/LAHRAnYiIiOko3EVERExG4S4iImIyCncRERGTUbiLiIiYjMJdRETEZBTuIiIiJqNwFxERMRmFu4iIiMko3EVERExG4S4iImIyCncRERGTUbiLiIiYzGkR7oWFhQwbNoydO3f6uxQREZGA5/dwd7lcPPjggzgcDn+XIiIiYgp+D/e5c+cyfvx4UlJS/F2KiIiIKdj9+eTvv/8+CQkJnHfeefzjH/9o0H3i4yOw221NWkdycnSTPp6ZqDd1U1/qp97UT72pm/pSv1PtjcUwDKOJa2mw66+/HovFgsViYfPmzaSnp/P888+TnJxc733y80ubtIbk5Ogmf0yzUG/qpr7UT72pn3pTN/WlfjW9OZWA9+uW+xtvvOH7ecKECcycOfOEwS4iIiIn5/d97iIiItK0/Lrlfqx58+b5uwQRERFT0Ja7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETMbu7wI8Hg/3338/u3fvxmKxMGvWLLp27ervskRERAKW37fclyxZAsCbb77J73//e5544gk/VyQiIhLYLIZhGP4uwu12Y7fb+eCDD1i5ciVz5849wboe7HZbC1YnIiISWPw+LA9gt9uZNm0aixYt4umnnz7hukVFFU363MnJ0eTnlzbpY5qFelM39aV+6k391Ju6qS/1q+lNcnJ0o+/r92H5GnPnzuWTTz7hgQceoKKiaQNcREQkmPg93OfPn88LL7wAQHh4OBaLBavV72WJiIgELL8Py1900UVMnz6d66+/HrfbzYwZM3A4HP4uS0REJGD5PdwjIiJ46qmn/F2GiIiIaWj8W0RExGQU7iIiIiajcBcRETEZhbuIiIjJKNxFRERMRuEuIiJiMgp3ERERk1G4i4iImIzCXURExGQU7iIiIiajcBcRETEZhbuIiIjJKNxFRERMRuEuIiJiMgp3ERERk1G4i4iImIzCXURExGQU7iIiIiajcBcRETEZhbuIiIjJKNxFRERMRuEuIiJiMgp3ERERk1G4i4iImIzCXURExGQU7iIiIiajcBcRETEZhbuIiIjJKNxFRERMRuEuIiJiMgp3ERERk1G4i4iImEyjwr2goIDnn3+eadOmUVhYyIIFC9iyZUtz1SYiIiKnoMHhvn79ei6++GJWrFjBxx9/TEVFBd9++y3XXHMNy5Yta84aRUREpBEaHO5z5sxh8uTJvP7664SEhAAwc+ZMJk+ezOOPP95sBYqIiEjjNDjcN23axKWXXnrc8tGjR7Nr164mLUpEREROXYPDPTExkZ07dx63fM2aNaSkpDRpUSIiInLq7A1dcdKkSTzwwANMmjQJwzBYvnw5OTk5vP7669x1113NWaOIiIg0QoPDfdy4cSQnJ/Pyyy/jcDh4/PHHycjI4JFHHmHkyJHNWaOIiIg0QoPDfdWqVQwdOpQLLrig1nKn08lnn33GiBEjmrw4ERERabyT7nP3er14PB5uuOEGioqK8Hq9tf7bsmULd955Z0vUKiIiIg1wwi33N998k5kzZ2KxWDAMg6FDh9a53rnnntssxYmY1ZZD2yl3lZMSkULbyFbYrLY61/MaXgCsFk0meTrbUbybFdmrOKftWRRWHSLEGkKriGQ2Fm6he0JX2ke39XeJEmROGO7jx4+nU6dOeL1ebrzxRp5++mliY2N9t1ssFiIiIujatespPbnL5WLGjBlkZWXhdDqZOnUqw4cPP6XHEgkE7+/4LyEWOwv3LvYtc9gcRISEExUSSX5lIQNS+mK1WAm3O1h18HsiQsI5P/VcNhZuxWELI84RS1RIJANS+lJcXUKriBQc9jA/vqrglVuRz/PrXiG/shCAlQdXH7eOdddCruk6mvMiMoHQFq5QgpXFMAyjIStmZWXRtm1bLBZLkz35e++9x5YtW7jvvvsoLi7myiuv5IsvvjjhffLzS5vs+QGSk6Ob/DHNQr2p26n2Jbc8j4e/eey45SHWEFxe1ynXc0ZSL/qn9KVNZCvaRLaisOoQiY6EekcDmpMZ3zOFlYcIs4cd+fJVUcine5dwqKoIgJzyXEqch4+7T4IjnqKqYs5qPYBvDq7xLQ+x2ukS34nJfW5kRfYqOsamkRrkW/VmfM80lZreJCdHN/q+DQ738vJy3nzzTXbs2IHH4wHAMAycTiebN2/m008/bfSTl5eXYxgGUVFRFBUVMWbMGD7//PMT3sft9mC3t/yHlsjP8fW+NTy54iXf7+F2B+P6jOKs1H7EhEWzfO8qCiuLiAgJp8pdzbqDm8grK2R8nysID3GQV15A96TOVLgqcXqcfLBpIdsP7an1HCG2ECyA0+NiQJve3DLoRmLCogAoc5bj9nrwGl4SwuNa7oWfhmo+8mo2VAoqDpF9OJfuSZ34bNeRqbRLqkrJKj1I66hkPt62GAsW+rbqzoHDOeSVF9Z6vB7JXRiWPohKVxWvrX2Xm8+cwND0QRRXlZAUkcD7m/7HprztOD1OthQcP1fIny68l04Jac38qiXYNDjc77jjDlauXMk555zDwoULufTSS9m7dy/r16/ntttu47bbbjvlIsrKypg6dSrXXHMNo0aNOuG62nJvOepN3RrTF5fXzY6iXbyw/p+4vG4A7sq8jQ7R7X7WlrVhGJS6ythetIt/bvo37aPaUVxdQlRoJC6vi7yKAgA6xWbQKS6dz/Z96dt/f8eAqbSLasNn+75kSNtBxDviTrmOn/LHe+ZgeS5xYXE47GE4PU6yyw9is9iZv+NjXF4X/VP6ArA2fz2JjoQjxzu4K3B73bSJbEVB5aETjpxYLVaSwxPJrcgHYFjqOQxLPZdvctZwVusBtI48MomX1/CSW5FPm8hWdT5OcnI0e7PzmL/zY37I30Spq6zW7bGhMUSFRnJd91+SHtOhKVoTEPQ5U78W2XIfOHAgTz/9NOeccw5XXHEFjz76KL1792bOnDlkZ2fz9NNPN/rJAXJycrj11lu57rrrGDNmzEnXV7i3HPWmbg3ty5ZD23l+3Su4jSMjXUPanU3HmDQGtcls0nrcXjd264+Hz5S7Kli09ws+37/UF+jHig6JIjE8gT2H99E9vgu9ErsRGxbDgJQzfAfPnurut8a8ZwzDwG14qHBVsCJnNeWuI6MLvZN6UFRVRMfYdL7O/pbYsBhCbCHYLFaKqw+DYeDlyMdWbnke6wo2kuCI58IOw/g6+1v2l2U3quYQq530mA5sL/5xGu3u8V1IiUgmtyKPi9J+Qbf4zpS5yqn2VJPgiD+lAxyP7Y3X8GIYBgv3LmbB7kW11gu3h3Nx2i+wW+1UuCrIbNXP9wXCjPQ5U7+fE+4NPs/d6XSSnp4OQJcuXVi/fj29e/dm/PjxXHfddY1+YjhyCdmJEyfy4IMPMnjw4FN6DJHTkWEY/GvzO75gP6/dYMZ3u6pZnuvYYAeIDIngys4jGdLubKo91azOXcune5cA0CepJxsKNvu2GrcUbWdL0XYA1uVvxGN4yC47yM19f82Bshz6Jfdu0n33mwq3sjJnNQ57GDuL93CwIu+4dZZmfd3oxz1UVcRb2+bXe3tkSAS/6zeJclcFcWExVLqr2VWyh+TwRNJiOhAbFk2Fq5IQWwh2i63OLzfRoVFEE9Xo2upitVjBApdlXMjw9kNZeXA1ZyT1YnvxLt7Y/A7zdy7wrbs0awV/yLyVMFsosWExTfL8Yn4NDvfOnTuzfPlyxo4dS5cuXVi9ejXXXnsthw8fxul0ntKT//3vf+fw4cP87W9/429/+xsAL774Ig6H45QeT+R0kF9RyIsbXqeoupjo0CiSwxO5KO38Fq8jKTwBgHZRbbg0fTj7SrPoHJdBUVUx+ZUFZJfl8s72D33rr8lb5/v52AP/hqWeS3pMe8pdFWSXHWR0p0uJCo3E7XVjtVjJKc+luPown+5dzOheF3L4cBXlznIOVRWxtWgHsWExGMCB0mwKqw7VqrH10SHsg+W5AHSIbkdcWBxOjxOn18mhqmKSwxPJiE2j3FWB5+iW/YGybL7LW8fg1mcyNHUwmw5t42B5LikRyfRO7MEnexfTNa4TieHxeAwvCY54wmy1j1TPiK099B0REv7zm34KHPYwzk89cjrxWa0H0Ck2nT2H92EYBluLdvJ1zrfMWvlnokIieejse/xWpwSWBg/LL1myhNtvv53777+foUOHMnLkSDIzM9m+fTv9+/fnySefbOZSj9CwfMtRb+p2or5sK9rBS+v/Rbm7AoBxXa9iaOrpOSplGAavbXoTm8VGv5TebCvaSUxoNB/v/tR3fEBdQq0hJIUnklOei0GDPj6AI1u+CWHxZMR2ICOmAxmx6SSGx/tqWVewka5xnUwbXqfy9+Tyurl76YO+f48+ST25qdf1hNhCmqNEv9DnTP1aZJ87wIEDB/B4PKSlpbFlyxY+/PBD4uPjueGGG1psa1vh3nLUm7rV1ZfXNr1JVlkOZc4ySpw/3jZr8DSSwhNbusSfpbi6hE2F2+gUm4bFYuHr7FUs2vdFg+57ToeBhBkOVuasptJdRVpMewa3OZNu8Z1IDk9q0lNpA82p/j3tPbyfJfuXs78si4PluWTEdKBDTCqlzjJ+1eOa40YkAo0+Z+rXIuE+ffp07rvvPqKiau9zKikp4YEHHjjlA+oaS+HectSbuh3blzJXORWuCh5e+ZhvK3Zou3MY02UUxdUlJB4dGjeDw85SYkKjyS47SHRoFHarnZ3Fu0mP7cCne5dwVqsB9O/YzdebSncV4XbtYqvxc/+eSp1l3Lvs4VrL+qf05dpuVxMZEvFzy/Mbfc7Ur9kOqFu9ejV79uwBYP78+XTv3p3IyMha6+zatYvly5c3+olFAl2Fq5LZ3zxOqfPIwWlnthqA1WLhkvQLsFltpgp2gJjQIx8wbaNa+5b1TuoBwNWdLz9ufQV704oOjWJQ60x+KNjIOW3O4vP9S/k+7wcOV5dyx4CbOewso8RZQofoVH+XKqeBE4Z7VFQUzz//PIZhYBgGr776Klbrj6eA1Ew/e8899zR7oSKnk4LKQ7y/47++YAe4qvNlxIY1/hu2SEP9qsdY3N6rCbWFUOYq55uDa9hZsps7v7wfp9eFBQt/PGd6k85dIIGpwcPyEyZM4LnnniM0NBSHw8HWrVtZunQpvXv3btHT2DQs33LUm7oVksfMJX89MtubI55eid0Z3GYgaTHt/V2a3+k9U7/m6E1J9WHe3/FfsssOkl1+EAALFn4/4GYsWEiJSCI6tGlO32sues/Ur0XOc7/pppsYNmwYzz33HO3bt+dXv/oVCQkJPPfcc9x7772MHz++0U8uEihW565lWdZK4sLi+C5vLV7Dyy9ShzAyYwQRAby/UwJbbFgMv+l1ZJ6RzYXbeHbdSxgYPPHd8wAkhScy8+x7gvpAxmDV4GmWnnjiCaZMmcLgwYN59913SUpKYuHChTz22GO8/PLLzVmjiF95DS+vbvx/bC/exarc70iJSmJynxsY0/UKBbucNuq6AE1BZSHPrn2JrLIcP1Qk/tTgLffdu3czevRoLBYLixcvZsSIEVgsFnr06EFe3vGzTIkEMrfXzTvb/4PNYmXLoR21bpt1wR9wlWpLSE4v0aFRpEa15UBZNlaLlTBbGKlRbdhStJ1n177Eg2ffrYMcg0iDwz0lJYUtW7ZQUlLC9u3bmTlzJgDLli2jXbt2zVWfSIszDIMfCjaxLGulb1n3+C70T+lDoiOBOEcM+aXaRyinn2ln3n7kAGgMrBYrVouVd7f/hyX7l3HX0gfpGteJw85SQm2h3Jl5CyHWBkeABJgG/8v+5je/4Xe/+x1Wq5V+/fqRmZnpmzZ2zpw5zVmjSIvZUbybv//wKpXuKt+ysV1H+6YHFTmd1cxZf6xL0odzuLqU7cW72Fb84yVnV+as5rx2Z7dwhdJSGjVD3ebNm8nKymLIkCE4HA7Wrl2Lw+Gge/fuzVljLTpavuUEU28Mw2B/aRbPrH2RCnclAO2j2vLLLlfQOS6j1gFJwdSXxlJv6ufv3ngNL06PkypPNTNXzMVjeOmb1IsRHYaSEZvG3sP7SQxPICok8uQP1oT83ZfTWYscLQ/Qo0cPevTo4fu9X79+jX5CkdPRypzV/GvLO77fLVgY03U0neMy/FiVSNOxWqw47A4cdgdT+vyaf299j7X561mbv57Bbc5kRc4qokIiub3/ZNpFtfF3ufIzaYeLBK28inxsFhvxjjiWHFgGHJlV7aGz78HldZHgiPdzhSLNo0diVx4+Zzrbi3by1Pf/YEXOKuDIdMp/+vZJruw8kqHtziHURBeoCTYKdwlKVe4q/rL6Wao81aSEJ3GwIo9eid255YyJ/i5NpMV0ie/ExekXsHDP51ySPpxwu4P5OxbwwY6PqXRVMqrTJf4uUU6Rwl2CimEYvLntA3YV7/HtWz9YkUfPxG5c332Mn6sTaXmXZ1zE2a0Hkhxx5OqFnWIzeGzNsyzcu5hvDn5Hekx7Lu94Ea0jW/m5UmkMhbsElQNl2b5T3KwWKzf1/hVew8sZSb2wWW1+rk6k5VksFl+wA2TEduDs1gNZeXA1RdXFFOUXs75gExN6jmNgq37+K1QaReEuQWHpgRUcrMglu+ygb9mk3hPom9zLj1WJnJ5+2eVyeiZ2pW9ybzYWbuFfm9/mjc3vUFBZSGRIJJkpfTU742lO4S6mVuGqpMJdwTvbP8RreIEjW+xzhjwY0NfAFmlOESERZB7dSu+X3JtqdzWvb36Lj3Z9AsD/dn/GHzJvIcERr3nrT1MKdzGloqpiVueuZcHuRTi9LgAuaH8ekSERpMW0V7CLNMKgNplEh0ZxoCybkurDfHFgOQ+umEOI1c7EXtfTK7G7dmudZhTuYjprctfxz03/9m2pA6TFtGdUx0t0ao/IKeqZ2I2eid0wDIPs8ly2Fe3A5XXzwvrXaBWRzM19f01kSKTvi/OhqiK2F+3irNYDtHXvBwp3MY2FexazJnct2eUHCbWF8ovUIQxLPZfCqkO0j2pLiIJd5GezWCzcesZEPIaXh1f+heLqEnIr8pm18i84bA4m9ZlAoiOBZ9e9REFlIZ/sXczI9BH0T+mLzWrD4/WwNn8D3RO6EGEPByCvooBwu+O0v/Z8IGnU9LOnA00/23ICoTcl1aVsOrQVm8XKa5veBMBhC+N3/SeRHtOhWZ4zEPriL+pN/czYm32HD7C9eBfF1SUs3v/VCdcNsdo5r91gDpRm++a4jwuLpdJdidPjIjYshl+0H8LSAyvIbHUGXsNLu6g2nNmqv+9COMHm50w/q3A34R9cUzmde+M1vKzMWc3CPZ9TWFXkW94lriNju45u1ukzT+e++Jt6Uz+z98ZrePnvrk/5ZO9iAAa26kdueR77y7I5s1V/NhRurnVBpoawWqzYLDY6RLfj9wNuDoiAz68oJCo0skkur9tic8uL+NthZylfZ3+L3Wrngx0f17rtjOTeTO5zg58qEwluVouVyzteRN/knnSITsVqseL0ODGAMFso83csYNG+L+gYm8bEXtfzzcHv6JPUg7i4CMJd0ews3kNuRR6xYTH8/Yd/Ake+MHgNLztL9vDapjdpH92OuNAYvBi0iWzNmty1OL1Orul6pT9fOgDF1SV8e/A7Ptr1Cee2HcT4blf5tR6FuwQMl9fNnG+fosR5uNbyc9qcSY/EbvRObLmrE4rI8awWa63dYaG2UN/Pl6QPx2EP49y2g4gOjeKS9AsASI4/snXaJb4jXeI7AjCodSbbi3fRMTaN1blrAVidu9b380/9kL+JSX0mkBbTvnle2DHKXOVklx3E5XWRV1GAgcGC3Z9ReXTGS4B2Ua2bvY6TUbjLaW9N7joq3ZXYrfbjgh0gs1U/uid08UNlItJQDnsYl6QPb9C6v+ox1vfz2K6jmfbVLN/vI9NHsK80iw2Fm33LiqqL+fPqZwBIciSQHtuB7UU7qfY46ZHYjWu6jiYm9Pih7YLKQyQ44rBarJRUl1LuKqftCYJ5e9FOXlw/j3J3Ra3lobZQUiKSyKsoACAz5YwGvc7mpHCX05bL48LldfPKxjd8yyxYuDNzKocqi+if0pf8ygLNeS1iMsfuW48KieSyjAv5ePciftdvku+LvNfwUlRVwmf7vqTcVc53eT9gYFBYVURB1SHfFR+/z/uB/IoCRnW8mOzyg5zbdhDbinby+b4v2X14H5dnXEyVp4rP9n0JwKzB06j2OH3H7Rx2lvLZ3i85WJHH5kPbAOge34VtxTsJtzuocFVyTdcrGdxmIAWVh6hwV5wWs/fpgDqTH+Tyc/izNwWVhTzx3d8pri7xLYsKieSarleS2cq/34r1nqmfelM/9aZuDemL1/BSUFlISkRyvevsL80iKiSSak81q3PXckZyH1Kj2vDvre+xPPvbRtcVbg8nMiSCgspC37JIewS/7TOBrvGdMAwDi8WC2+vGbm2e7WQdUCemsu/wAZ747nnfzHJRIZHc1u+3tI5I0bnqIkHIarGeMNgB2ke38/18eceLfT+P63oVNoudak81cGT2yqjQSHIr8skqywEgKTyRbvGdfF8Cwu3hVLorqXRXkuCIp39KHwam9CMxPME3SU/NxDzNFew/1+lZlQStw85SPj46Zeyl6cNJj+lAekwHokIj/V2aiAQgm9XGuG5X1nnbpsKtLMtayXU9xhAVEsmZrfoTHRpNXFgsXx5YTp+knifcB386U7jLacHlcbEqdy3/3voeXsNLuN3ByIwLA+K8VhEJTDVT6tboEt/J9/PFR4/mD1QKd/GroqpivjiwnK+yVlDtcQKQEp7EeamDFewiIqdI4S4txjAMvstbx7aiI1NPFlYV+Y4+jbRHEB8Zz8j04b5LTYqIyKlRuEuL8Bpevs9bzysb/1+t5RkxaZzdJpNBrTN1sJyISBNRuEuzyq8o5P0d/2VXyR7KXOW+5dGhUZzb5iwu73ixLgcpItLEFO7SbNxeN8+te4n8Y84TBXhy2CPaShcRaUYKd2kShmFQ5anCbrGzImcVe0sPsL1oZ60rtgH0SuyuYBcRaWYKd2kSX2Wt5O1t80l0xFNQdQg4cpBcv+TeDO8wjAW7F3FFx0toHZni50pFRMxP4S6nrMpdjcvr4vVNb7Hp0FYAX7BP7HUd/VP6+k5nu63fb/1Wp4hIsFG4S6NVuav4fP9XLNn/FZXuKt/yngndiAqNZEBKX/ok9fRjhSIiwU3hLg3m9rrJKsvh831LWZO3zrd8ePuhXNl5pCadERE5TSjc5aSq3FWsyv2er7O/ZV9pFgCRIRHcdsZvSY1uq1AXETnNnBbhvm7dOh577DHmzZvn71LkGFXuanaV7OWNze9wsCLPt3xQ60xGZlxIUniCH6sTEZH6+D3cX3zxRf7zn/8QHh7u71KCnmEYbC3aQYIjHoDHvvs3u4v3A0cuu1rmKueStAsY1ekSf5bpF1v3FfHfFXvxeg1CQ204nR5/l3RaMmNvOrWL5eqhHf1dhkijWAzDMPxZwCeffEK3bt245557ePvtt0+6vtvtwW63tUBl5renaD9f7F7B0PRBvLTmTXYc2nPcOnarnZsGjGN4pyEcOJxD66gU7Nbg6//Tb33Pom/3+bsM8ZP/PHaFZlKUgOL3LfeLL76YAwcONHj9oqKKJn3+5ORo8vNLm/QxT1eGYeDyuvg6ZxXtIlvzyd4lbD60jQXbl9S5/rD0s7ky7XJCbaHk55cSRhRF1U3b/0BRXnHkinV/mnI2PTolk18QHO+ZxkpOijZVbx5/cy1b9hWTl1eK1frzwj2YPmsaQ32pX01vkpOjG31fv4e7NA/DMHAbHpweJ1aLhc/2fsmKnNWkxbTnh4KNAIRYf5wpzmFzUOWpItQawszB9xIbFq0/umN4jw5whdis2GxWbFYdRFgXs/XGdjTQvYaBFW25S+BQuJvIpsKtzN+5gKTwRIqrSthbuv+4dWqCHcDlddExNo0zknvTO7E7pc5yYsNiiA1r/LdEs/N6j4T7z916k8BiOfrv7fEaaG+gBBKF+2nMa3ipcFcSFRLpW1blrqakuoRWkSm4PC72lh7gsLOUao+TpQeWk1WWQ1ZZTq3HiQ2NZlCbgQB8uncJvRN7kBHbgY92fULX+M6M6DAMgNaRSD08CvegZDu6n73my51IoDgtwj01NbVBB9OZhdfw1jo33DAMthfvokN0O2wWGwVVh0gJT+KjXZ/wxYFl3NZvEkVVxXy+fyn7j55nXp/u8V3ondTDN4tcr8Ru/KbXdb7b+yT1ICk8kaiQSFpHpNAtoXOzvU4zqflwtyncg4r1mGF5kUByWoS7GRiG4QvtmqNqD1UV4fF6SY5IBI5sda/MWc2C3Yvol9Kb9Jg0PIaH/+1eRImzlLiwWKo9TirdlbUe+4nvnq/3eXsldifeEUdRVTHlrgou63ghHWPTARjRYRi2nxzZXnMbQL+UPk3wyoODb1heR0wHFesxw/IigUTh3ggHy3MxgEp3JbtL9rGjeDcHy3NpHdmKDYWb8RpeksMT6RCdSmRIJEuzvgagQ3QqFiy19oEvz/6W5dnf1nr84uoSAJLDE2tdAz3UGoLT66q1bu/E7pzTdhB9knrUO0OcLq3adGo+2zUsH1xqRmoMhbsEGIV7A31xYDnvbf8Ir+E97ra8ygLfz/mVhbWCGWBf6Y+n+oVYQ5jc5wZ+KNjEV1krfMvHd7uK/aVZOD0ubug5DsMw2FK0g/bRbbFZbJS5yil3lRMfFkdcWKzOuW1hXu+Rf3cNywcXbblLoFK418Hj9VBQWUiVp5r/7fmc9QWbgCMTuvw03K/oeAmp0e1Ij2mPzWIl1BbKgbJsiqpKqPZUExcWS7g9HMPwsiJnNb9oP4SUiCR6Jnbjgvbn8c62DxnTZRStfnqdcwv0Suzm+zUyJAJIbu6XLvXwaFg+KFl1QJ0EKIX7UWXOcsJsoeRU5PLOtv+wq2TPcevcnXkbO0p20yOhK60ikvF4Pcft04Yjw/AdolOPXx5Te1lKRBK39rupyV6DNJ+az3Zle3DRAXUSqBTuQKmzjJkr/kyryGSyynJwe93EhcWSEZvGoNYDWLB7Ee2jU0mNbktqdFvf/eoKdjEnr9fAarFod0iQqdly17C8BJqgDne3182b6z9k5d61VHmq2Ht4P1aLlZt6/4r+yX18H+R9knr6uVLxN4/X0MF0Qcg3Q53CXQJMUIf7NwfX8P6Whb7fI+0RXNN1NANS+vqxKjkdeQ1DB9MFoR+H5f1ciEgjBXW4r8heBcAvO19Ol/jOtD9myF3kWF6vgYmmTJcG0gF1EqiCOtzPazeYy3pcQI9IDbvLidXsc5fgYtOpcBKggjrcB7XJ1JXPpEE0LB+cdLS8BCoNNIo0gMdr+K4QJsGjZleMhuUl0CjcRRrA69WWezDSPncJVAp3kQbwGtrnHox8+9w1LC8BRuEu0gA6zz04WXWeuwQohbtIAxgalg9KCncJVAp3kQbw6FS4oKR97hKoFO4iDeA1NCwfjHTJVwlUCneRBvB6UbgHIZvOc5cApXAXaQANywcnDctLoFK4izSAznMPThqWl0ClcBc5CcMwtM89SGlYXgKVwl3kJGo+15XtwUfD8hKoFO4iJ1Gz1aZh+eCj67lLoFK4i5xEzf5Wqy7oHnRsmsRGApQ+rUROouaDXRvuwcdi0QF1EpgU7iInUTMsrwPqgo+23CVQKdxFTuLHYXmFe7DxXc9dR8tLgFG4i5xEzVabDqgLPjrPXQKVwl3kJLzacg9atqP73A2FuwQYhbvISfx4QJ3CPdhoy10ClcJd5CQ8OqAuaFk1Q50EKIW7yElon3vwsupoeQlQCneRk9CwfPCy6jx3CVAKd5GTqPlc17B88NGFYyRQKdxFTkJb7sFLF46RQKVwFzkJj/a5By3tc5dApXAXOQlNPxu8NCwvgUrhLnISP05i4+dCpMVZdJ67BCh9XImchEf73IOWTfvcJUAp3EVOomZIVvvcg8+Pk9j4uRCRRrL7uwCv18vMmTPZunUroaGhzJ49m7S0NH+XJeKjueWDl6aflUDl9y33zz77DKfTyVtvvcUf/vAH5syZ4++SRGrRJV+Dl67nLoHK71vua9as4bzzzgOgX79+bNiwocWe+1+fbuW77QX6w62H1WpRbwCX2wton3swqvk3/2FnAb9/ZtnPeyz9PdXJbH2xAFcMyeAX/dv5tQ6/h3tZWRlRUVG+3202G263G7u97tLi4yOw221N8tyJ8RFEOkKa5LHE3MJCbZzTL5Xk5GgA3//leGbqjWEYnHtGW/ZkH/Z3KRIgrFZISohssr+DU30cv4d7VFQU5eXlvt+9Xm+9wQ5QVFTRZM996ZntuWFkT/LzS5vsMc0kOTlavfmJ/PxS9eUEzNibmy7t3iSPY8beNAWz9qUpXlNNb04l4P2+z33AgAEsXboUgLVr19K1a1c/VyQiIhLY/L7lfuGFF7J8+XLGjx+PYRg8+uij/i5JREQkoPk93K1WKw8//LC/yxARETENvw/Li4iISNNSuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJjMaRHuixYt4g9/+IO/yxARETEFu78LmD17NsuWLaNHjx7+LkVERMQU/L7lPmDAAGbOnOnvMkREREyjxbbc33nnHV577bVayx599FFGjhzJN9980+DHSU6OburSmuUxzUK9qZv6Uj/1pn7qTd3Ul/qdam9aLNzHjh3L2LFjW+rpREREgpbfh+VFRESkaSncRURETMZiGIbh7yJERESk6WjLXURExGQU7iIiIiajcBcRETEZv89Q5y9er5eZM2eydetWQkNDmT17Nmlpaf4uyy/WrVvHY489xrx589i7dy/33nsvFouFLl268NBDD2G1Wnn22Wf54osvsNvtzJgxg759+/q77GbjcrmYMWMGWVlZOJ1Opk6dSufOnYO+LwAej4f777+f3bt3Y7FYmDVrFmFhYerNMQoLC7n66qt55ZVXsNvt6s1RV111FVFRUQCkpqYybtw4HnnkEWw2G0OGDOG2224Lys/lF154gcWLF+Nyubj22ms566yzmuY9YwSpTz75xJg2bZphGIbx/fffGzfffLOfK/KPf/zjH8bll19ujB071jAMw5gyZYqxcuVKwzAM44EHHjA+/fRTY8OGDcaECRMMr9drZGVlGVdffbU/S2527777rjF79mzDMAyjqKjIGDZsmPpy1KJFi4x7773XMAzDWLlypXHzzTerN8dwOp3GLbfcYlx00UXGjh071JujqqqqjNGjR9dadsUVVxh79+41vF6v8dvf/tbYuHFj0H0ur1y50pgyZYrh8XiMsrIy4+mnn26y90zQDsuvWbOG8847D4B+/fqxYcMGP1fkHx06dOCZZ57x/b5x40bOOussAIYOHcrXX3/NmjVrGDJkCBaLhbZt2+LxeDh06JC/Sm52l1xyCf/3f/8HgGEY2Gw29eWoESNG8Mc//hGA7OxsYmJi1JtjzJ07l/Hjx5OSkgLo76nGli1bqKysZOLEidxwww2sWrUKp9NJhw4dsFgsDBkyxNebYPpcXrZsGV27duXWW2/l5ptv5vzzz2+y90zQhntZWZlviAjAZrPhdrv9WJF/XHzxxdjtP+6dMQwDi8UCQGRkJKWlpcf1qma5WUVGRhIVFUVZWRm33347v//979WXY9jtdqZNm8Yf//hHRo0apd4c9f7775OQkOALJ9DfUw2Hw8FNN93Eyy+/zKxZs5g+fTrh4eG+2+vrjdk/l4uKitiwYQNPPfUUs2bN4q677mqy90zQ7nOPioqivLzc97vX660VcsHKav3x+155eTkxMTHH9aq8vJzoaHPPBZ2Tk8Ott97Kddddx6hRo/jLX/7iuy2Y+1Jj7ty53HXXXVxzzTVUV1f7lgdzb9577z0sFgsrVqxg8+bNTJs2rdbWVTD3JiMjg7S0NCwWCxkZGURHR1NcXOy7vaY3VVVVQfW5HBcXR8eOHQkNDaVjx46EhYVx8OBB3+0/5z0TtFvuAwYMYOnSpQCsXbuWrl27+rmi00PPnj19F/JZunQpAwcOZMCAASxbtgyv10t2djZer5eEhAQ/V9p8CgoKmDhxInfffTdjxowB1Jca8+fP54UXXgAgPDwci8VC79691RvgjTfe4F//+hfz5s2jR48ezJ07l6FDh6o3wLvvvsucOXMAyM3NpbKykoiICPbt24dhGCxbtszXm2D6XM7MzOSrr77CMAxfXwYPHtwk75mgnaGu5qjMbdu2YRgGjz76KJ06dfJ3WX5x4MAB7rzzTt5++212797NAw88gMvlomPHjsyePRubzcYzzzzD0qVL8Xq9TJ8+nYEDB/q77GYze/Zs/ve//9GxY0ffsvvuu4/Zs2cHdV8AKioqmD59OgUFBbjdbiZNmkSnTp2C/j3zUxMmTGDmzJlYrVb1BnA6nUyfPp3s7GwsFgt33XUXVquVRx99FI/Hw5AhQ7jjjjuC8nP5z3/+M9988w2GYXDHHXeQmpraJO+ZoA13ERERswraYXkRERGzUriLiIiYjMJdRETEZBTuIiIiJqNwFxERMRmFu0iQ2rx5M6tXr+abb76hW7dupp4JTCTYKNxFgtStt97K7t276d+/P8uWLTP1TGAiwUbhLhLkQkNDSU5O9ncZItKEFO4iQWjChAlkZWVx//33c8EFF/iG5Q8cOEC3bt34/PPPueCCC+jfvz9z5sxh69atXH311fTr14+bb76ZiooK32O99dZbDB8+nP79+3Pttdfyww8/+PGViQgo3EWC0jPPPEPr1q259957mTFjxnG3v/jii/ztb39j5syZvPrqq9x+++3cfffdvPjii6xatYr33nsPgMWLF/PUU08xffp0PvjgA4YOHcqNN95IXl5eS78kETmGwl0kCMXFxWGz2YiKiqrz6lJTp06le/fujB49mri4OC677DIGDx7MmWeeyVlnncWuXbsAeOmll5g8eTIjRowgPT2dqVOn0rt3b955552WfkkicgwdQSMix0lNTfX9HBYWRtu2bX2/OxwOnE4nADt37uSvf/0rTz31lO92p9NJ69atW65YETmOwl1EjvPTI+et1roH+TweD9OmTWPIkCG1lkdERDRbbSJychqWF5FTlpGRwcGDB0lLS/P998orr/Dtt9/6uzSRoKZwFwlSkZGR7Nq1i5KSklN+jN/85jfMmzePDz74gH379vHss8/y3nvv0bFjxyasVEQaS8PyIkHq+uuvZ+7cub4j30/FyJEjKSws5NlnnyUvL4+OHTvy3HPP0aNHjyasVEQay2IYhuHvIkRERKTpaFheRETEZBTuIiIiJqNwFxERMRmFu4iIiMko3EVERExG4S4iImIyCncRERGTUbiLiIiYzP8HR6tWjPTySoYAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(result)), YVal, label = 'Validation')\n",
    "plt.plot(np.arange(len(result)), result, label = 'Training')\n",
    "plt.ylabel('state', fontsize = 14)\n",
    "plt.xlabel('time', fontsize = 14)\n",
    "plt.legend()\n",
    "plt.ylim([-1,5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}