{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation.generate_path import generate_path\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from estimation.distance_sensor import distance_sensors\n",
    "from estimation.non_iterative_estimator import non_iterative_estimator\n",
    "from estimation.kalman_filter_from_points_with_acc import kalman_filter_from_points_acc\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2897, 1)\n",
      "(1, 96, 2897)\n"
     ]
    }
   ],
   "source": [
    "# create test data\n",
    "target_initial_pos = np.array([0, 0, 5000])\n",
    "target_speed_xy = 50\n",
    "target_speed_z = 10\n",
    "target_rot_speed = 3\n",
    "time_res = 0.1\n",
    "\n",
    "path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "path1.add_straight_interval(100)\n",
    "path1.add_xy_turn_interval(90, -np.deg2rad(target_rot_speed))\n",
    "path1.add_straight_interval(100)\n",
    "outliers = np.random.randint(0, 100, size=len(path1.path))\n",
    "outliers = outliers > (100 - 2)\n",
    "\n",
    "# create noisy sensors\n",
    "sensors = distance_sensors([[-5000,0,0],[ 400, -7400, 0],[ 800, 800, 0]], 15)\n",
    "sensors.calculate_measurements(path1.path)\n",
    "non_it_est = non_iterative_estimator(sensors, path1.path[0,:])\n",
    "estimated_path = non_it_est.estimate_path()\n",
    "\n",
    "sensors_noisy = distance_sensors([[-5000,0,0],[ 400, -7400, 0],[ 800, 800, 0]], 200)\n",
    "sensors_noisy.calculate_measurements(path1.path)\n",
    "non_it_est_noisy = non_iterative_estimator(sensors, path1.path[0,:])\n",
    "estimated_path_noisy = non_it_est.estimate_path()\n",
    "\n",
    "sigma_a = 1\n",
    "sigma_v = 500\n",
    "kf = kalman_filter_from_points_acc(time_res, sigma_a, sigma_v, non_diag_reduction_ratio=2)\n",
    "kf_path, P, X = kf.filter_path(estimated_path)\n",
    "\n",
    "sample = 1\n",
    "XTest = []\n",
    "for i in np.arange(len(kf_path) - sample):\n",
    "    tmp = np.concatenate((kf_path[i, :].reshape(1,-1), np.reshape(P[i, :, :], (1,-1)), X[i,:].reshape(1,-1)), 1)\n",
    "    # tmp = np.array([7000, 5000, 3000]).reshape(1,3)\n",
    "    if outliers[i+1]:\n",
    "        tmp =  np.concatenate((tmp, estimated_path_noisy[i+1, :].reshape(1,-1)),1)\n",
    "    else:\n",
    "        tmp =  np.concatenate((tmp, estimated_path[i+1, :].reshape(1,-1)),1)\n",
    "\n",
    "    # tmp = np.concatenate((tmp, outliers[i+1].reshape(1,1)), 1)\n",
    "\n",
    "    # tmp = outliers[i+1].reshape(1,1)\n",
    "    tmp = tmp.reshape(1, tmp.shape[1] ,1)\n",
    "    if i > 0:\n",
    "        XTest = np.concatenate((XTest, tmp), 2)\n",
    "    else:\n",
    "        XTest = tmp\n",
    "\n",
    "YTest = outliers[1:].reshape(-1,1)\n",
    "\n",
    "print(np.shape(YTest))\n",
    "print(np.shape(XTest))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4650, 1)\n",
      "(1, 96, 4650)\n"
     ]
    }
   ],
   "source": [
    "# create train data\n",
    "run_number = 5\n",
    "XTrain = []\n",
    "YTrain = []\n",
    "for k in np.arange(run_number):\n",
    "    target_initial_pos = np.random.randint(-7000, 7000, size=(1, 3))[0]\n",
    "    sensors_pos = np.random.randint(-7000, 7000, size=(3, 3))[:,:]\n",
    "    target_speed_xy = 50\n",
    "    target_speed_z = 10\n",
    "    target_rot_speed = 3\n",
    "    time_res = 0.1\n",
    "\n",
    "    path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "    path1.add_straight_interval(np.random.randint(0,100,size=1)[0])\n",
    "    path1.add_xy_turn_interval(np.random.randint(0,100,size=1)[0], -random.choice([-1, 1])*np.deg2rad(target_rot_speed))\n",
    "    outliers = np.random.randint(0, 100, size=len(path1.path))\n",
    "    outliers = outliers > (100 - 50)\n",
    "\n",
    "    # create noisy sensors\n",
    "    sensors = distance_sensors(sensors_pos, 15)\n",
    "    sensors.calculate_measurements(path1.path)\n",
    "    non_it_est = non_iterative_estimator(sensors, path1.path[0,:])\n",
    "    estimated_path = non_it_est.estimate_path()\n",
    "\n",
    "    sensors_noisy = distance_sensors(sensors_pos, 200)\n",
    "    sensors_noisy.calculate_measurements(path1.path)\n",
    "    non_it_est_noisy = non_iterative_estimator(sensors, path1.path[0,:])\n",
    "    estimated_path_noisy = non_it_est.estimate_path()\n",
    "\n",
    "    sigma_a = 1\n",
    "    sigma_v = 500\n",
    "    kf = kalman_filter_from_points_acc(time_res, sigma_a, sigma_v, non_diag_reduction_ratio=2)\n",
    "    kf_path, P, X = kf.filter_path(estimated_path)\n",
    "\n",
    "    sample = 1\n",
    "    for i in np.arange(len(kf_path) - sample):\n",
    "        tmp = np.concatenate((kf_path[i, :].reshape(1,-1), np.reshape(P[i, :, :], (1,-1)), X[i,:].reshape(1,-1)), 1)\n",
    "        if outliers[i+1]:\n",
    "            tmp =  np.concatenate((tmp, estimated_path_noisy[i+1, :].reshape(1,-1)),1)\n",
    "        else:\n",
    "            tmp =  np.concatenate((tmp, estimated_path[i+1, :].reshape(1,-1)),1)\n",
    "\n",
    "        # tmp = np.concatenate((tmp, outliers[i+1].reshape(1,1)), 1)\n",
    "\n",
    "        tmp = tmp.reshape(1, tmp.shape[1] ,1)\n",
    "        if (k == 0) & (i == 0):\n",
    "            XTrain = tmp\n",
    "        else:\n",
    "            XTrain = np.concatenate((XTrain, tmp), 2)\n",
    "\n",
    "    if k > 0:\n",
    "        YTrain = np.concatenate((YTrain, outliers[1:].reshape(-1,1)))\n",
    "    else:\n",
    "        YTrain = outliers[1:].reshape(-1,1)\n",
    "\n",
    "print(np.shape(YTrain))\n",
    "print(np.shape(XTrain))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "ind = np.arange(len(YTest))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XVal = torch.from_numpy(np.transpose(XTest[:,:,ind], (2, 0, 1)))\n",
    "YVal = torch.from_numpy(YTest[ind,:])\n",
    "\n",
    "ind = np.arange(len(YTrain))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XTrain = torch.from_numpy(np.transpose(XTrain[:,:,ind], (2, 0, 1)))\n",
    "YTrain = torch.from_numpy(YTrain[ind,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# create network\n",
    "class state_estimat(nn.Module):\n",
    "    def __init__(self, d_in, num_classes):\n",
    "        # initialzing the parent object (important!)\n",
    "        super(state_estimat, self).__init__()\n",
    "        # Create a pipeline - a sequence of layers\n",
    "        self.pipe = torch.nn.Sequential(\n",
    "            # nn.Conv1d(1, 16, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(97, 10),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(97, 2),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv1d(1,16, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv1d(16,16, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Flatten(),\n",
    "            nn.Linear(96, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes))\n",
    "            # nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.normalize(x, p=1.0, dim = 1)\n",
    "        return self.pipe(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "state_estimat(\n",
      "  (pipe): Sequential(\n",
      "    (0): Linear(in_features=96, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters:\n",
    "# num_epochs = 100\n",
    "num_epochs = 10\n",
    "# batch_size = 512\n",
    "batch_size = 2\n",
    "learning_rate = 0.01\n",
    "learning_rate_drop_period = 6\n",
    "\n",
    "# Device configuration, as before\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(device)\n",
    "# create model\n",
    "model = state_estimat(d_in=4, num_classes=1).to(device)\n",
    "print(model)\n",
    "# Loss and optimizer\n",
    "# criterion = torch.nn.BCELoss()\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=learning_rate_drop_period, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [5/1448], Loss: 0.8162, Time: 0.9834 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [10/1448], Loss: 0.1775, Time: 0.9904 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [15/1448], Loss: 0.0020, Time: 0.9974 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [20/1448], Loss: 0.0264, Time: 1.0034 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [25/1448], Loss: 0.0145, Time: 1.0104 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [30/1448], Loss: 0.0001, Time: 1.0184 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [35/1448], Loss: 0.5423, Time: 1.0244 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [40/1448], Loss: 0.0001, Time: 1.0314 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [45/1448], Loss: 0.0021, Time: 1.0384 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [50/1448], Loss: 0.0013, Time: 1.0444 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [55/1448], Loss: 0.0000, Time: 1.0514 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [60/1448], Loss: 0.0001, Time: 1.0583 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [65/1448], Loss: 0.0001, Time: 1.0653 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [70/1448], Loss: 0.0000, Time: 1.0713 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [75/1448], Loss: 0.0000, Time: 1.0783 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [80/1448], Loss: 0.0000, Time: 1.0853 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [85/1448], Loss: 0.0000, Time: 1.0913 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [90/1448], Loss: 0.0000, Time: 1.0983 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [95/1448], Loss: 0.0000, Time: 1.1053 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [100/1448], Loss: 0.0001, Time: 1.1113 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [105/1448], Loss: 0.0001, Time: 1.1183 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [110/1448], Loss: 0.0000, Time: 1.1253 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [115/1448], Loss: 0.0000, Time: 1.1323 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [120/1448], Loss: 0.0020, Time: 1.1383 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [125/1448], Loss: 0.0062, Time: 1.1453 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [130/1448], Loss: 0.0026, Time: 1.1523 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [135/1448], Loss: 0.0000, Time: 1.1583 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [140/1448], Loss: 0.0001, Time: 1.1653 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [145/1448], Loss: 0.5148, Time: 1.1723 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [150/1448], Loss: 0.0027, Time: 1.1793 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [155/1448], Loss: 0.0001, Time: 1.1863 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [160/1448], Loss: 0.0001, Time: 1.1933 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [165/1448], Loss: 0.0001, Time: 1.1993 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [170/1448], Loss: 0.0001, Time: 1.2073 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [175/1448], Loss: 0.0000, Time: 1.2153 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [180/1448], Loss: 0.4972, Time: 1.2232 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [185/1448], Loss: 0.0007, Time: 1.2302 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [190/1448], Loss: 0.0010, Time: 1.2369 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [195/1448], Loss: 0.0010, Time: 1.2429 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [200/1448], Loss: 0.0006, Time: 1.2498 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [205/1448], Loss: 0.0001, Time: 1.2568 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [210/1448], Loss: 0.0001, Time: 1.2628 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [215/1448], Loss: 0.0001, Time: 1.2698 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [220/1448], Loss: 0.0000, Time: 1.2758 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [225/1448], Loss: 0.0001, Time: 1.2828 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [230/1448], Loss: 0.0001, Time: 1.2898 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [235/1448], Loss: 0.0008, Time: 1.2958 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [240/1448], Loss: 0.0010, Time: 1.3028 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [245/1448], Loss: 0.0009, Time: 1.3088 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [250/1448], Loss: 0.0004, Time: 1.3158 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [255/1448], Loss: 0.0002, Time: 1.3228 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [260/1448], Loss: 0.0000, Time: 1.3295 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [265/1448], Loss: 0.0000, Time: 1.3365 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [270/1448], Loss: 0.0000, Time: 1.3435 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [275/1448], Loss: 0.0001, Time: 1.3505 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [280/1448], Loss: 0.0001, Time: 1.3575 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [285/1448], Loss: 0.0001, Time: 1.3655 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [290/1448], Loss: 0.5122, Time: 1.3725 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [295/1448], Loss: 0.0011, Time: 1.3785 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [300/1448], Loss: 0.0013, Time: 1.3855 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [305/1448], Loss: 0.0014, Time: 1.3925 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [310/1448], Loss: 0.0005, Time: 1.3995 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [315/1448], Loss: 0.0004, Time: 1.4055 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [320/1448], Loss: 0.0012, Time: 1.4125 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [325/1448], Loss: 0.0013, Time: 1.4195 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [330/1448], Loss: 0.0013, Time: 1.4254 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [335/1448], Loss: 0.0010, Time: 1.4324 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [340/1448], Loss: 0.0007, Time: 1.4384 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [345/1448], Loss: 0.0004, Time: 1.4454 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [350/1448], Loss: 0.0002, Time: 1.4514 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [355/1448], Loss: 0.0001, Time: 1.4584 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [360/1448], Loss: 0.0000, Time: 1.4654 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [365/1448], Loss: 0.0000, Time: 1.4724 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [370/1448], Loss: 0.0000, Time: 1.4784 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [375/1448], Loss: 0.0000, Time: 1.4854 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [380/1448], Loss: 0.0000, Time: 1.4924 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [385/1448], Loss: 0.0001, Time: 1.4984 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [390/1448], Loss: 0.4849, Time: 1.5054 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [395/1448], Loss: 0.0009, Time: 1.5114 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [400/1448], Loss: 0.0017, Time: 1.5184 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [405/1448], Loss: 0.0019, Time: 1.5244 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [410/1448], Loss: 0.0018, Time: 1.5314 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [415/1448], Loss: 0.0013, Time: 1.5384 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [420/1448], Loss: 0.0008, Time: 1.5444 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [425/1448], Loss: 0.0004, Time: 1.5524 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [430/1448], Loss: 0.0002, Time: 1.5594 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [435/1448], Loss: 0.0001, Time: 1.5664 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [440/1448], Loss: 0.0001, Time: 1.5734 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [445/1448], Loss: 0.0000, Time: 1.5814 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [450/1448], Loss: 0.0000, Time: 1.5893 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [455/1448], Loss: 0.0000, Time: 1.5963 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [460/1448], Loss: 0.0001, Time: 1.6033 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [465/1448], Loss: 0.0002, Time: 1.6093 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [470/1448], Loss: 0.0004, Time: 1.6163 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [475/1448], Loss: 0.0004, Time: 1.6233 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [480/1448], Loss: 0.0004, Time: 1.6300 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [485/1448], Loss: 0.0003, Time: 1.6370 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [490/1448], Loss: 0.0002, Time: 1.6430 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [495/1448], Loss: 0.0001, Time: 1.6500 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [500/1448], Loss: 0.0000, Time: 1.6570 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [505/1448], Loss: 0.0000, Time: 1.6630 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [510/1448], Loss: 0.0000, Time: 1.6700 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [515/1448], Loss: 0.0000, Time: 1.6760 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [520/1448], Loss: 0.0000, Time: 1.6830 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [525/1448], Loss: 0.0000, Time: 1.6900 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [530/1448], Loss: 0.0000, Time: 1.6960 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [535/1448], Loss: 0.0000, Time: 1.7030 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [540/1448], Loss: 0.0000, Time: 1.7090 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [545/1448], Loss: 0.0000, Time: 1.7160 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [550/1448], Loss: 0.5004, Time: 1.7220 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [555/1448], Loss: 0.0001, Time: 1.7290 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [560/1448], Loss: 0.0003, Time: 1.7370 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [565/1448], Loss: 0.0003, Time: 1.7430 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [570/1448], Loss: 0.0003, Time: 1.7500 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [575/1448], Loss: 0.0002, Time: 1.7570 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [580/1448], Loss: 0.0001, Time: 1.7640 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [585/1448], Loss: 0.0002, Time: 1.7700 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [590/1448], Loss: 0.0004, Time: 1.7770 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [595/1448], Loss: 0.0004, Time: 1.7829 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [600/1448], Loss: 0.0004, Time: 1.7899 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [605/1448], Loss: 0.0002, Time: 1.7969 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [610/1448], Loss: 0.0001, Time: 1.8039 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [615/1448], Loss: 0.0001, Time: 1.8099 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [620/1448], Loss: 0.0000, Time: 1.8169 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [625/1448], Loss: 0.0000, Time: 1.8229 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [630/1448], Loss: 0.0000, Time: 1.8299 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [635/1448], Loss: 0.0000, Time: 1.8378 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [640/1448], Loss: 0.0000, Time: 1.8448 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [645/1448], Loss: 0.0000, Time: 1.8518 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [650/1448], Loss: 0.0000, Time: 1.8588 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [655/1448], Loss: 0.0002, Time: 1.8648 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [660/1448], Loss: 0.0004, Time: 1.8718 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [665/1448], Loss: 0.0004, Time: 1.8786 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [670/1448], Loss: 0.0003, Time: 1.8846 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [675/1448], Loss: 0.0002, Time: 1.8906 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [680/1448], Loss: 0.0001, Time: 1.8976 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [685/1448], Loss: 0.0000, Time: 1.9046 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [690/1448], Loss: 0.0000, Time: 1.9106 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [695/1448], Loss: 0.0000, Time: 1.9176 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [700/1448], Loss: 0.0000, Time: 1.9256 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [705/1448], Loss: 0.0000, Time: 1.9326 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [710/1448], Loss: 0.0000, Time: 1.9397 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [715/1448], Loss: 0.0000, Time: 1.9477 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [720/1448], Loss: 0.0000, Time: 1.9557 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [725/1448], Loss: 0.0000, Time: 1.9637 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [730/1448], Loss: 0.0000, Time: 1.9717 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [735/1448], Loss: 0.0001, Time: 1.9797 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [740/1448], Loss: 0.0004, Time: 1.9877 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [745/1448], Loss: 0.0004, Time: 1.9957 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [750/1448], Loss: 0.0004, Time: 2.0037 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [755/1448], Loss: 0.0002, Time: 2.0127 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [760/1448], Loss: 0.0001, Time: 2.0217 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [765/1448], Loss: 0.0006, Time: 2.0317 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [770/1448], Loss: 0.0016, Time: 2.0413 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [775/1448], Loss: 0.0019, Time: 2.0503 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [780/1448], Loss: 0.0014, Time: 2.0603 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [785/1448], Loss: 0.0010, Time: 2.0693 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [790/1448], Loss: 0.0019, Time: 2.0803 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [795/1448], Loss: 0.0026, Time: 2.0933 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [800/1448], Loss: 0.0024, Time: 2.1033 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [805/1448], Loss: 0.0017, Time: 2.1143 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [810/1448], Loss: 0.0009, Time: 2.1241 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [815/1448], Loss: 0.0004, Time: 2.1341 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [820/1448], Loss: 0.0001, Time: 2.1451 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [825/1448], Loss: 0.0000, Time: 2.1551 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [830/1448], Loss: 0.0000, Time: 2.1661 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [835/1448], Loss: 0.0000, Time: 2.1751 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [840/1448], Loss: 0.0000, Time: 2.1860 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [845/1448], Loss: 0.0000, Time: 2.1960 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [850/1448], Loss: 0.0000, Time: 2.2060 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [855/1448], Loss: 0.0000, Time: 2.2160 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [860/1448], Loss: 0.0000, Time: 2.2260 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [865/1448], Loss: 0.0000, Time: 2.2370 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [870/1448], Loss: 0.0001, Time: 2.2470 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [875/1448], Loss: 0.0004, Time: 2.2570 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [880/1448], Loss: 0.0005, Time: 2.2680 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [885/1448], Loss: 0.0004, Time: 2.2770 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [890/1448], Loss: 0.0009, Time: 2.2870 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [895/1448], Loss: 0.0013, Time: 2.2960 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [900/1448], Loss: 0.0031, Time: 2.3070 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [905/1448], Loss: 0.0041, Time: 2.3160 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [910/1448], Loss: 0.0035, Time: 2.3261 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [915/1448], Loss: 0.0023, Time: 2.3351 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [920/1448], Loss: 0.0011, Time: 2.3441 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [925/1448], Loss: 0.0004, Time: 2.3531 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [930/1448], Loss: 0.0005, Time: 2.3621 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [935/1448], Loss: 0.0005, Time: 2.3711 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [940/1448], Loss: 0.0004, Time: 2.3801 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [945/1448], Loss: 0.0002, Time: 2.3891 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [950/1448], Loss: 0.0001, Time: 2.3981 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [955/1448], Loss: 0.0003, Time: 2.4071 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [960/1448], Loss: 0.0005, Time: 2.4151 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [965/1448], Loss: 0.0005, Time: 2.4241 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [970/1448], Loss: 0.0006, Time: 2.4331 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [975/1448], Loss: 0.0010, Time: 2.4421 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [980/1448], Loss: 0.4610, Time: 2.4510 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [985/1448], Loss: 0.0036, Time: 2.4590 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [990/1448], Loss: 0.0039, Time: 2.4680 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [995/1448], Loss: 0.0029, Time: 2.4770 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1000/1448], Loss: 0.0017, Time: 2.4860 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1005/1448], Loss: 0.0007, Time: 2.4950 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1010/1448], Loss: 0.0002, Time: 2.5040 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1015/1448], Loss: 0.0000, Time: 2.5130 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1020/1448], Loss: 0.0000, Time: 2.5220 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1025/1448], Loss: 0.0000, Time: 2.5310 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1030/1448], Loss: 0.0000, Time: 2.5420 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1035/1448], Loss: 0.0000, Time: 2.5510 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1040/1448], Loss: 0.0000, Time: 2.5600 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1045/1448], Loss: 0.0002, Time: 2.5690 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1050/1448], Loss: 0.0004, Time: 2.5780 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1055/1448], Loss: 0.0004, Time: 2.5880 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1060/1448], Loss: 0.0003, Time: 2.5990 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1065/1448], Loss: 0.0002, Time: 2.6080 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1070/1448], Loss: 0.0001, Time: 2.6169 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1075/1448], Loss: 0.0000, Time: 2.6269 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1080/1448], Loss: 0.4987, Time: 2.6359 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1085/1448], Loss: 0.0002, Time: 2.6449 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1090/1448], Loss: 0.0004, Time: 2.6539 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1095/1448], Loss: 0.0004, Time: 2.6629 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1100/1448], Loss: 0.0003, Time: 2.6719 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1105/1448], Loss: 0.0002, Time: 2.6809 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1110/1448], Loss: 0.0001, Time: 2.6909 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1115/1448], Loss: 0.0000, Time: 2.6996 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1120/1448], Loss: 0.0000, Time: 2.7085 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1125/1448], Loss: 0.0000, Time: 2.7185 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1130/1448], Loss: 0.0000, Time: 2.7275 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1135/1448], Loss: 0.0000, Time: 2.7365 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1140/1448], Loss: 0.0000, Time: 2.7465 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1145/1448], Loss: 0.0000, Time: 2.7545 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1150/1448], Loss: 0.0000, Time: 2.7645 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1155/1448], Loss: 0.0000, Time: 2.7730 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1160/1448], Loss: 0.0000, Time: 2.7820 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1165/1448], Loss: 0.0000, Time: 2.7910 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1170/1448], Loss: 0.0000, Time: 2.8000 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1175/1448], Loss: 0.0000, Time: 2.8090 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1180/1448], Loss: 0.0000, Time: 2.8179 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1185/1448], Loss: 0.0000, Time: 2.8269 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1190/1448], Loss: 0.0000, Time: 2.8369 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1195/1448], Loss: 0.0000, Time: 2.8459 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1200/1448], Loss: 0.0000, Time: 2.8549 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1205/1448], Loss: 0.0000, Time: 2.8639 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1210/1448], Loss: 0.0000, Time: 2.8729 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1215/1448], Loss: 0.5000, Time: 2.8819 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1220/1448], Loss: 0.0003, Time: 2.8912 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1225/1448], Loss: 0.0006, Time: 2.9002 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1230/1448], Loss: 0.0006, Time: 2.9102 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1235/1448], Loss: 0.0004, Time: 2.9192 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1240/1448], Loss: 0.0002, Time: 2.9282 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1245/1448], Loss: 0.0001, Time: 2.9372 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1250/1448], Loss: 0.0000, Time: 2.9463 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1255/1448], Loss: 0.0001, Time: 2.9553 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1260/1448], Loss: 0.0014, Time: 2.9643 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1265/1448], Loss: 0.0021, Time: 2.9733 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1270/1448], Loss: 0.0019, Time: 2.9820 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1275/1448], Loss: 0.0012, Time: 2.9910 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1280/1448], Loss: 0.0005, Time: 3.0000 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1285/1448], Loss: 0.0001, Time: 3.0090 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1290/1448], Loss: 0.0000, Time: 3.0180 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1295/1448], Loss: 0.0000, Time: 3.0270 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1300/1448], Loss: 0.0000, Time: 3.0360 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1305/1448], Loss: 0.0000, Time: 3.0450 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1310/1448], Loss: 0.0000, Time: 3.0540 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1315/1448], Loss: 0.0000, Time: 3.0620 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1320/1448], Loss: 0.0000, Time: 3.0710 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1325/1448], Loss: 0.0000, Time: 3.0809 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1330/1448], Loss: 0.0000, Time: 3.0899 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1335/1448], Loss: 0.0000, Time: 3.1009 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1340/1448], Loss: 0.0000, Time: 3.1109 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1345/1448], Loss: 0.0000, Time: 3.1209 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1350/1448], Loss: 0.0000, Time: 3.1299 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1355/1448], Loss: 0.0000, Time: 3.1389 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1360/1448], Loss: 0.0000, Time: 3.1479 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1365/1448], Loss: 0.0001, Time: 3.1569 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1370/1448], Loss: 0.0005, Time: 3.1659 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1375/1448], Loss: 0.0007, Time: 3.1749 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1380/1448], Loss: 0.0005, Time: 3.1849 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1385/1448], Loss: 0.0003, Time: 3.1929 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1390/1448], Loss: 0.0001, Time: 3.2019 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1395/1448], Loss: 0.0000, Time: 3.2109 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1400/1448], Loss: 0.0000, Time: 3.2199 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1405/1448], Loss: 0.0000, Time: 3.2289 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1410/1448], Loss: 0.0000, Time: 3.2379 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1415/1448], Loss: 0.0000, Time: 3.2468 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1420/1448], Loss: 0.0000, Time: 3.2558 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1425/1448], Loss: 0.0000, Time: 3.2648 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1430/1448], Loss: 0.0005, Time: 3.2738 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1435/1448], Loss: 0.0007, Time: 3.2838 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1440/1448], Loss: 0.0006, Time: 3.2928 secs, learning rate: 0.0100\n",
      "Epoch [1/10], Step [1445/1448], Loss: 0.0003, Time: 3.3018 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [5/1448], Loss: 0.0001, Time: 4.3242 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [10/1448], Loss: 0.0000, Time: 4.3332 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [15/1448], Loss: 0.0000, Time: 4.3422 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [20/1448], Loss: 0.0000, Time: 4.3522 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [25/1448], Loss: 0.0000, Time: 4.3612 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [30/1448], Loss: 0.0000, Time: 4.3702 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [35/1448], Loss: 0.0004, Time: 4.3791 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [40/1448], Loss: 0.0006, Time: 4.3881 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [45/1448], Loss: 0.0005, Time: 4.3971 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [50/1448], Loss: 0.0003, Time: 4.4061 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [55/1448], Loss: 0.0001, Time: 4.4161 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [60/1448], Loss: 0.0000, Time: 4.4251 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [65/1448], Loss: 0.0002, Time: 4.4341 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [70/1448], Loss: 0.0005, Time: 4.4431 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [75/1448], Loss: 0.0005, Time: 4.4521 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [80/1448], Loss: 0.0004, Time: 4.4611 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [85/1448], Loss: 0.0002, Time: 4.4701 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [90/1448], Loss: 0.0001, Time: 4.4801 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [95/1448], Loss: 0.4979, Time: 4.4891 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [100/1448], Loss: 0.0003, Time: 4.4981 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [105/1448], Loss: 0.0005, Time: 4.5071 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [110/1448], Loss: 0.0005, Time: 4.5161 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [115/1448], Loss: 0.0003, Time: 4.5261 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [120/1448], Loss: 0.0001, Time: 4.5351 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [125/1448], Loss: 0.0000, Time: 4.5450 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [130/1448], Loss: 0.0000, Time: 4.5540 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [135/1448], Loss: 0.0000, Time: 4.5630 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [140/1448], Loss: 0.0000, Time: 4.5720 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [145/1448], Loss: 0.0000, Time: 4.5810 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [150/1448], Loss: 0.0000, Time: 4.5900 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [155/1448], Loss: 0.0001, Time: 4.5990 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [160/1448], Loss: 0.0005, Time: 4.6080 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [165/1448], Loss: 0.0007, Time: 4.6170 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [170/1448], Loss: 0.0006, Time: 4.6270 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [175/1448], Loss: 0.0003, Time: 4.6380 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [180/1448], Loss: 0.0001, Time: 4.6470 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [185/1448], Loss: 0.0002, Time: 4.6560 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [190/1448], Loss: 0.0005, Time: 4.6650 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [195/1448], Loss: 0.0006, Time: 4.6740 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [200/1448], Loss: 0.0009, Time: 4.6830 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [205/1448], Loss: 0.0014, Time: 4.6920 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [210/1448], Loss: 0.0012, Time: 4.7010 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [215/1448], Loss: 0.0007, Time: 4.7099 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [220/1448], Loss: 0.0003, Time: 4.7189 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [225/1448], Loss: 0.0000, Time: 4.7289 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [230/1448], Loss: 0.0000, Time: 4.7379 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [235/1448], Loss: 0.0000, Time: 4.7479 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [240/1448], Loss: 0.0000, Time: 4.7579 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [245/1448], Loss: 0.0000, Time: 4.7689 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [250/1448], Loss: 0.0000, Time: 4.7779 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [255/1448], Loss: 0.0000, Time: 4.7879 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [260/1448], Loss: 0.0000, Time: 4.7969 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [265/1448], Loss: 0.0000, Time: 4.8049 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [270/1448], Loss: 0.0000, Time: 4.8139 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [275/1448], Loss: 0.0000, Time: 4.8229 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [280/1448], Loss: 0.0000, Time: 4.8319 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [285/1448], Loss: 0.0000, Time: 4.8409 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [290/1448], Loss: 0.0000, Time: 4.8499 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [295/1448], Loss: 0.0000, Time: 4.8589 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [300/1448], Loss: 0.0000, Time: 4.8678 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [305/1448], Loss: 0.0002, Time: 4.8768 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [310/1448], Loss: 0.0007, Time: 4.8858 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [315/1448], Loss: 0.0008, Time: 4.8948 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [320/1448], Loss: 0.0005, Time: 4.9028 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [325/1448], Loss: 0.0002, Time: 4.9128 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [330/1448], Loss: 0.0001, Time: 4.9218 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [335/1448], Loss: 0.0000, Time: 4.9318 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [340/1448], Loss: 0.0000, Time: 4.9408 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [345/1448], Loss: 0.0000, Time: 4.9498 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [350/1448], Loss: 0.5045, Time: 4.9598 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [355/1448], Loss: 0.0003, Time: 4.9688 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [360/1448], Loss: 0.0007, Time: 4.9778 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [365/1448], Loss: 0.0007, Time: 4.9878 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [370/1448], Loss: 0.0004, Time: 4.9958 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [375/1448], Loss: 0.0002, Time: 5.0048 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [380/1448], Loss: 0.0000, Time: 5.0138 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [385/1448], Loss: 0.0000, Time: 5.0228 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [390/1448], Loss: 0.0000, Time: 5.0317 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [395/1448], Loss: 0.0003, Time: 5.0407 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [400/1448], Loss: 0.0006, Time: 5.0497 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [405/1448], Loss: 0.0005, Time: 5.0587 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [410/1448], Loss: 0.0003, Time: 5.0677 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [415/1448], Loss: 0.0001, Time: 5.0767 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [420/1448], Loss: 0.0000, Time: 5.0857 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [425/1448], Loss: 0.0000, Time: 5.0947 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [430/1448], Loss: 0.0000, Time: 5.1037 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [435/1448], Loss: 0.0000, Time: 5.1127 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [440/1448], Loss: 0.0000, Time: 5.1217 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [445/1448], Loss: 0.0000, Time: 5.1317 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [450/1448], Loss: 0.0000, Time: 5.1427 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [455/1448], Loss: 0.0000, Time: 5.1537 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [460/1448], Loss: 0.0000, Time: 5.1627 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [465/1448], Loss: 0.0006, Time: 5.1717 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [470/1448], Loss: 0.0009, Time: 5.1817 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [475/1448], Loss: 0.0007, Time: 5.1896 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [480/1448], Loss: 0.0004, Time: 5.1996 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [485/1448], Loss: 0.0001, Time: 5.2083 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [490/1448], Loss: 0.0000, Time: 5.2173 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [495/1448], Loss: 0.0000, Time: 5.2263 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [500/1448], Loss: 0.0001, Time: 5.2353 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [505/1448], Loss: 0.0005, Time: 5.2443 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [510/1448], Loss: 0.0006, Time: 5.2533 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [515/1448], Loss: 0.0004, Time: 5.2623 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [520/1448], Loss: 0.0002, Time: 5.2712 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [525/1448], Loss: 0.0000, Time: 5.2812 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [530/1448], Loss: 0.0000, Time: 5.2902 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [535/1448], Loss: 0.0000, Time: 5.2992 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [540/1448], Loss: 0.0000, Time: 5.3082 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [545/1448], Loss: 0.0000, Time: 5.3182 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [550/1448], Loss: 0.5033, Time: 5.3272 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [555/1448], Loss: 0.0004, Time: 5.3362 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [560/1448], Loss: 0.0008, Time: 5.3462 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [565/1448], Loss: 0.0008, Time: 5.3552 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [570/1448], Loss: 0.0004, Time: 5.3636 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [575/1448], Loss: 0.0002, Time: 5.3726 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [580/1448], Loss: 0.0000, Time: 5.3816 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [585/1448], Loss: 0.0002, Time: 5.3906 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [590/1448], Loss: 0.0006, Time: 5.3996 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [595/1448], Loss: 0.0006, Time: 5.4076 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [600/1448], Loss: 0.0004, Time: 5.4176 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [605/1448], Loss: 0.0001, Time: 5.4256 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [610/1448], Loss: 0.0000, Time: 5.4346 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [615/1448], Loss: 0.0000, Time: 5.4436 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [620/1448], Loss: 0.0002, Time: 5.4536 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [625/1448], Loss: 0.0006, Time: 5.4636 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [630/1448], Loss: 0.0006, Time: 5.4716 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [635/1448], Loss: 0.0004, Time: 5.4806 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [640/1448], Loss: 0.0001, Time: 5.4896 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [645/1448], Loss: 0.0000, Time: 5.4986 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [650/1448], Loss: 0.0002, Time: 5.5086 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [655/1448], Loss: 0.0006, Time: 5.5176 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [660/1448], Loss: 0.0006, Time: 5.5265 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [665/1448], Loss: 0.0006, Time: 5.5365 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [670/1448], Loss: 0.4651, Time: 5.5455 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [675/1448], Loss: 0.0031, Time: 5.5545 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [680/1448], Loss: 0.0031, Time: 5.5635 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [685/1448], Loss: 0.0019, Time: 5.5725 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [690/1448], Loss: 0.0007, Time: 5.5815 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [695/1448], Loss: 0.0007, Time: 5.5905 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [700/1448], Loss: 0.0007, Time: 5.5995 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [705/1448], Loss: 0.0005, Time: 5.6085 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [710/1448], Loss: 0.0002, Time: 5.6165 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [715/1448], Loss: 0.0000, Time: 5.6255 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [720/1448], Loss: 0.0000, Time: 5.6345 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [725/1448], Loss: 0.0000, Time: 5.6455 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [730/1448], Loss: 0.0000, Time: 5.6555 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [735/1448], Loss: 0.0000, Time: 5.6645 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [740/1448], Loss: 0.0000, Time: 5.6735 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [745/1448], Loss: 0.0000, Time: 5.6828 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [750/1448], Loss: 0.0000, Time: 5.6918 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [755/1448], Loss: 0.4999, Time: 5.7008 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [760/1448], Loss: 0.0005, Time: 5.7098 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [765/1448], Loss: 0.0009, Time: 5.7198 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [770/1448], Loss: 0.0011, Time: 5.7288 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [775/1448], Loss: 0.0020, Time: 5.7378 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [780/1448], Loss: 0.0017, Time: 5.7468 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [785/1448], Loss: 0.0009, Time: 5.7558 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [790/1448], Loss: 0.0003, Time: 5.7648 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [795/1448], Loss: 0.0000, Time: 5.7738 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [800/1448], Loss: 0.5021, Time: 5.7828 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [805/1448], Loss: 0.0002, Time: 5.7918 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [810/1448], Loss: 0.0005, Time: 5.8008 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [815/1448], Loss: 0.0004, Time: 5.8098 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [820/1448], Loss: 0.0003, Time: 5.8187 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [825/1448], Loss: 0.0001, Time: 5.8277 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [830/1448], Loss: 0.0000, Time: 5.8367 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [835/1448], Loss: 0.0000, Time: 5.8477 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [840/1448], Loss: 0.0000, Time: 5.8597 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [845/1448], Loss: 0.0001, Time: 5.8697 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [850/1448], Loss: 0.0006, Time: 5.8787 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [855/1448], Loss: 0.0007, Time: 5.8877 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [860/1448], Loss: 0.0005, Time: 5.8967 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [865/1448], Loss: 0.0002, Time: 5.9047 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [870/1448], Loss: 0.0001, Time: 5.9147 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [875/1448], Loss: 0.0000, Time: 5.9247 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [880/1448], Loss: 0.0001, Time: 5.9337 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [885/1448], Loss: 0.0005, Time: 5.9427 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [890/1448], Loss: 0.0006, Time: 5.9527 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [895/1448], Loss: 0.0004, Time: 5.9607 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [900/1448], Loss: 0.0002, Time: 5.9707 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [905/1448], Loss: 0.0000, Time: 5.9796 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [910/1448], Loss: 0.0000, Time: 5.9886 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [915/1448], Loss: 0.0000, Time: 5.9975 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [920/1448], Loss: 0.0000, Time: 6.0065 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [925/1448], Loss: 0.0005, Time: 6.0155 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [930/1448], Loss: 0.0007, Time: 6.0245 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [935/1448], Loss: 0.0011, Time: 6.0335 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [940/1448], Loss: 0.0018, Time: 6.0425 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [945/1448], Loss: 0.4633, Time: 6.0515 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [950/1448], Loss: 0.0044, Time: 6.0595 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [955/1448], Loss: 0.0052, Time: 6.0685 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [960/1448], Loss: 0.0036, Time: 6.0775 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [965/1448], Loss: 0.0030, Time: 6.0875 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [970/1448], Loss: 0.0033, Time: 6.0965 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [975/1448], Loss: 0.0033, Time: 6.1055 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [980/1448], Loss: 0.0021, Time: 6.1155 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [985/1448], Loss: 0.0009, Time: 6.1235 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [990/1448], Loss: 0.0002, Time: 6.1325 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [995/1448], Loss: 0.0000, Time: 6.1414 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1000/1448], Loss: 0.0000, Time: 6.1514 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1005/1448], Loss: 0.0001, Time: 6.1614 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1010/1448], Loss: 0.0001, Time: 6.1714 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1015/1448], Loss: 0.0001, Time: 6.1814 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1020/1448], Loss: 0.0000, Time: 6.1904 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1025/1448], Loss: 0.0000, Time: 6.1994 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1030/1448], Loss: 0.0000, Time: 6.2084 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1035/1448], Loss: 0.0000, Time: 6.2174 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1040/1448], Loss: 0.0000, Time: 6.2254 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1045/1448], Loss: 0.0000, Time: 6.2344 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1050/1448], Loss: 0.0000, Time: 6.2444 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1055/1448], Loss: 0.0000, Time: 6.2534 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1060/1448], Loss: 0.0000, Time: 6.2624 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1065/1448], Loss: 0.0000, Time: 6.2714 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1070/1448], Loss: 0.0000, Time: 6.2804 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1075/1448], Loss: 0.0000, Time: 6.2894 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1080/1448], Loss: 0.0000, Time: 6.2983 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1085/1448], Loss: 0.0000, Time: 6.3083 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1090/1448], Loss: 0.0000, Time: 6.3173 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1095/1448], Loss: 0.0000, Time: 6.3273 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1100/1448], Loss: 0.0000, Time: 6.3363 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1105/1448], Loss: 0.0000, Time: 6.3453 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1110/1448], Loss: 0.0000, Time: 6.3543 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1115/1448], Loss: 0.0000, Time: 6.3633 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1120/1448], Loss: 0.0000, Time: 6.3723 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1125/1448], Loss: 0.0000, Time: 6.3813 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1130/1448], Loss: 0.0000, Time: 6.3893 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1135/1448], Loss: 0.0000, Time: 6.3993 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1140/1448], Loss: 0.0000, Time: 6.4073 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1145/1448], Loss: 0.0000, Time: 6.4163 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1150/1448], Loss: 0.0000, Time: 6.4253 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1155/1448], Loss: 0.0000, Time: 6.4353 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1160/1448], Loss: 0.0000, Time: 6.4433 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1165/1448], Loss: 0.0000, Time: 6.4533 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1170/1448], Loss: 0.0000, Time: 6.4622 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1175/1448], Loss: 0.0000, Time: 6.4712 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1180/1448], Loss: 0.0000, Time: 6.4802 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1185/1448], Loss: 0.0000, Time: 6.4892 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1190/1448], Loss: 0.0002, Time: 6.4982 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1195/1448], Loss: 0.0016, Time: 6.5072 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1200/1448], Loss: 0.0057, Time: 6.5162 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1205/1448], Loss: 0.0070, Time: 6.5262 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1210/1448], Loss: 0.0048, Time: 6.5352 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1215/1448], Loss: 0.0021, Time: 6.5442 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1220/1448], Loss: 0.0004, Time: 6.5532 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1225/1448], Loss: 0.0000, Time: 6.5622 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1230/1448], Loss: 0.0001, Time: 6.5702 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1235/1448], Loss: 0.0002, Time: 6.5792 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1240/1448], Loss: 0.0002, Time: 6.5882 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1245/1448], Loss: 0.0000, Time: 6.5975 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1250/1448], Loss: 0.0004, Time: 6.6065 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1255/1448], Loss: 0.0008, Time: 6.6155 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1260/1448], Loss: 0.0006, Time: 6.6245 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1265/1448], Loss: 0.0003, Time: 6.6335 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1270/1448], Loss: 0.0002, Time: 6.6425 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1275/1448], Loss: 0.0000, Time: 6.6525 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1280/1448], Loss: 0.0001, Time: 6.6635 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1285/1448], Loss: 0.0000, Time: 6.6735 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1290/1448], Loss: 0.0000, Time: 6.6835 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1295/1448], Loss: 0.0000, Time: 6.6925 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1300/1448], Loss: 0.0000, Time: 6.7024 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1305/1448], Loss: 0.0000, Time: 6.7104 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1310/1448], Loss: 0.0000, Time: 6.7204 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1315/1448], Loss: 0.0000, Time: 6.7294 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1320/1448], Loss: 0.0000, Time: 6.7384 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1325/1448], Loss: 0.0000, Time: 6.7474 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1330/1448], Loss: 0.0000, Time: 6.7564 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1335/1448], Loss: 0.0000, Time: 6.7654 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1340/1448], Loss: 0.0000, Time: 6.7744 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1345/1448], Loss: 0.0000, Time: 6.7834 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1350/1448], Loss: 0.0000, Time: 6.7924 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1355/1448], Loss: 0.4988, Time: 6.8014 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1360/1448], Loss: 0.0007, Time: 6.8104 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1365/1448], Loss: 0.0010, Time: 6.8194 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1370/1448], Loss: 0.0008, Time: 6.8284 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1375/1448], Loss: 0.0004, Time: 6.8374 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1380/1448], Loss: 0.0001, Time: 6.8464 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1385/1448], Loss: 0.0000, Time: 6.8544 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1390/1448], Loss: 0.0000, Time: 6.8653 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1395/1448], Loss: 0.0000, Time: 6.8743 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1400/1448], Loss: 0.0000, Time: 6.8833 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1405/1448], Loss: 0.0002, Time: 6.8923 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1410/1448], Loss: 0.0008, Time: 6.9013 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1415/1448], Loss: 0.0020, Time: 6.9103 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1420/1448], Loss: 0.0027, Time: 6.9203 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1425/1448], Loss: 0.0019, Time: 6.9293 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1430/1448], Loss: 0.0009, Time: 6.9383 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1435/1448], Loss: 0.0002, Time: 6.9463 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1440/1448], Loss: 0.0000, Time: 6.9553 secs, learning rate: 0.0100\n",
      "Epoch [2/10], Step [1445/1448], Loss: 0.0000, Time: 6.9643 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [5/1448], Loss: 0.0001, Time: 7.9907 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [10/1448], Loss: 0.0001, Time: 7.9996 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [15/1448], Loss: 0.0000, Time: 8.0086 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [20/1448], Loss: 0.0000, Time: 8.0176 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [25/1448], Loss: 0.0007, Time: 8.0266 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [30/1448], Loss: 0.0011, Time: 8.0366 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [35/1448], Loss: 0.0008, Time: 8.0456 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [40/1448], Loss: 0.0004, Time: 8.0546 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [45/1448], Loss: 0.0001, Time: 8.0636 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [50/1448], Loss: 0.0000, Time: 8.0726 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [55/1448], Loss: 0.0000, Time: 8.0816 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [60/1448], Loss: 0.0000, Time: 8.0906 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [65/1448], Loss: 0.0000, Time: 8.0996 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [70/1448], Loss: 0.0000, Time: 8.1086 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [75/1448], Loss: 0.0000, Time: 8.1176 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [80/1448], Loss: 0.0000, Time: 8.1266 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [85/1448], Loss: 0.0000, Time: 8.1356 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [90/1448], Loss: 0.0000, Time: 8.1456 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [95/1448], Loss: 0.0000, Time: 8.1546 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [100/1448], Loss: 0.0000, Time: 8.1635 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [105/1448], Loss: 0.0000, Time: 8.1735 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [110/1448], Loss: 0.0000, Time: 8.1835 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [115/1448], Loss: 0.0000, Time: 8.1935 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [120/1448], Loss: 0.0000, Time: 8.2025 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [125/1448], Loss: 0.0000, Time: 8.2125 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [130/1448], Loss: 0.0000, Time: 8.2215 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [135/1448], Loss: 0.0000, Time: 8.2305 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [140/1448], Loss: 0.0000, Time: 8.2395 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [145/1448], Loss: 0.5000, Time: 8.2485 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [150/1448], Loss: 0.0006, Time: 8.2575 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [155/1448], Loss: 0.0010, Time: 8.2665 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [160/1448], Loss: 0.0008, Time: 8.2755 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [165/1448], Loss: 0.0004, Time: 8.2845 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [170/1448], Loss: 0.0001, Time: 8.2935 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [175/1448], Loss: 0.0000, Time: 8.3035 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [180/1448], Loss: 0.0000, Time: 8.3125 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [185/1448], Loss: 0.0000, Time: 8.3215 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [190/1448], Loss: 0.0000, Time: 8.3304 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [195/1448], Loss: 0.0000, Time: 8.3394 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [200/1448], Loss: 0.0000, Time: 8.3484 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [205/1448], Loss: 0.0000, Time: 8.3564 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [210/1448], Loss: 0.0000, Time: 8.3674 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [215/1448], Loss: 0.0000, Time: 8.3764 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [220/1448], Loss: 0.0000, Time: 8.3854 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [225/1448], Loss: 0.0001, Time: 8.3954 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [230/1448], Loss: 0.0008, Time: 8.4044 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [235/1448], Loss: 0.0011, Time: 8.4134 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [240/1448], Loss: 0.0011, Time: 8.4224 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [245/1448], Loss: 0.4573, Time: 8.4314 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [250/1448], Loss: 0.0041, Time: 8.4394 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [255/1448], Loss: 0.4440, Time: 8.4494 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [260/1448], Loss: 0.0044, Time: 8.4574 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [265/1448], Loss: 0.0029, Time: 8.4663 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [270/1448], Loss: 0.0012, Time: 8.4753 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [275/1448], Loss: 0.0002, Time: 8.5203 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [280/1448], Loss: 0.0000, Time: 8.5293 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [285/1448], Loss: 0.0001, Time: 8.5383 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [290/1448], Loss: 0.0002, Time: 8.5472 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [295/1448], Loss: 0.0001, Time: 8.5552 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [300/1448], Loss: 0.0001, Time: 8.5652 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [305/1448], Loss: 0.0000, Time: 8.5743 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [310/1448], Loss: 0.0000, Time: 8.5833 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [315/1448], Loss: 0.0000, Time: 8.5923 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [320/1448], Loss: 0.0000, Time: 8.6023 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [325/1448], Loss: 0.0000, Time: 8.6113 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [330/1448], Loss: 0.0000, Time: 8.6202 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [335/1448], Loss: 0.0000, Time: 8.6292 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [340/1448], Loss: 0.0000, Time: 8.6382 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [345/1448], Loss: 0.0000, Time: 8.6473 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [350/1448], Loss: 0.0000, Time: 8.6563 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [355/1448], Loss: 0.0000, Time: 8.6643 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [360/1448], Loss: 0.0000, Time: 8.6733 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [365/1448], Loss: 0.0000, Time: 8.6823 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [370/1448], Loss: 0.0000, Time: 8.6923 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [375/1448], Loss: 0.0000, Time: 8.7023 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [380/1448], Loss: 0.0000, Time: 8.7113 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [385/1448], Loss: 0.0000, Time: 8.7203 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [390/1448], Loss: 0.0004, Time: 8.7293 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [395/1448], Loss: 0.0010, Time: 8.7393 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [400/1448], Loss: 0.0009, Time: 8.7483 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [405/1448], Loss: 0.0005, Time: 8.7573 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [410/1448], Loss: 0.0001, Time: 8.7673 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [415/1448], Loss: 0.0000, Time: 8.7753 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [420/1448], Loss: 0.0000, Time: 8.7843 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [425/1448], Loss: 0.0000, Time: 8.7943 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [430/1448], Loss: 0.0000, Time: 8.8033 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [435/1448], Loss: 0.0000, Time: 8.8123 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [440/1448], Loss: 0.0000, Time: 8.8213 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [445/1448], Loss: 0.0000, Time: 8.8303 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [450/1448], Loss: 0.0000, Time: 8.8393 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [455/1448], Loss: 0.0000, Time: 8.8483 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [460/1448], Loss: 0.0000, Time: 8.8563 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [465/1448], Loss: 0.0000, Time: 8.8662 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [470/1448], Loss: 0.0000, Time: 8.8752 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [475/1448], Loss: 0.0000, Time: 8.8832 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [480/1448], Loss: 0.0000, Time: 8.8922 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [485/1448], Loss: 0.0008, Time: 8.9012 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [490/1448], Loss: 0.0011, Time: 8.9102 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [495/1448], Loss: 0.0008, Time: 8.9192 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [500/1448], Loss: 0.0003, Time: 8.9282 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [505/1448], Loss: 0.0000, Time: 8.9372 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [510/1448], Loss: 0.0000, Time: 8.9462 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [515/1448], Loss: 0.0000, Time: 8.9552 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [520/1448], Loss: 0.0000, Time: 8.9652 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [525/1448], Loss: 0.0000, Time: 8.9732 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [530/1448], Loss: 0.0000, Time: 8.9822 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [535/1448], Loss: 0.0000, Time: 8.9912 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [540/1448], Loss: 0.0000, Time: 9.0012 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [545/1448], Loss: 0.0000, Time: 9.0102 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [550/1448], Loss: 0.0000, Time: 9.0192 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [555/1448], Loss: 0.0000, Time: 9.0281 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [560/1448], Loss: 0.0000, Time: 9.0371 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [565/1448], Loss: 0.0002, Time: 9.0461 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [570/1448], Loss: 0.0009, Time: 9.0551 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [575/1448], Loss: 0.0011, Time: 9.0641 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [580/1448], Loss: 0.0007, Time: 9.0731 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [585/1448], Loss: 0.0002, Time: 9.0821 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [590/1448], Loss: 0.0000, Time: 9.0911 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [595/1448], Loss: 0.0000, Time: 9.1001 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [600/1448], Loss: 0.0000, Time: 9.1091 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [605/1448], Loss: 0.0006, Time: 9.1171 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [610/1448], Loss: 0.0008, Time: 9.1261 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [615/1448], Loss: 0.0005, Time: 9.1351 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [620/1448], Loss: 0.0002, Time: 9.1451 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [625/1448], Loss: 0.0000, Time: 9.1541 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [630/1448], Loss: 0.0000, Time: 9.1632 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [635/1448], Loss: 0.0000, Time: 9.1732 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [640/1448], Loss: 0.0000, Time: 9.1822 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [645/1448], Loss: 0.0007, Time: 9.1912 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [650/1448], Loss: 0.0009, Time: 9.2012 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [655/1448], Loss: 0.0006, Time: 9.2112 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [660/1448], Loss: 0.0002, Time: 9.2221 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [665/1448], Loss: 0.0000, Time: 9.2311 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [670/1448], Loss: 0.0000, Time: 9.2401 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [675/1448], Loss: 0.0000, Time: 9.2486 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [680/1448], Loss: 0.0000, Time: 9.2576 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [685/1448], Loss: 0.0000, Time: 9.2666 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [690/1448], Loss: 0.0000, Time: 9.2756 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [695/1448], Loss: 0.5011, Time: 9.2846 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [700/1448], Loss: 0.0007, Time: 9.2936 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [705/1448], Loss: 0.0012, Time: 9.3026 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [710/1448], Loss: 0.0023, Time: 9.3116 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [715/1448], Loss: 0.0042, Time: 9.3206 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [720/1448], Loss: 0.0051, Time: 9.3295 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [725/1448], Loss: 0.0033, Time: 9.3395 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [730/1448], Loss: 0.0012, Time: 9.3485 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [735/1448], Loss: 0.0002, Time: 9.3565 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [740/1448], Loss: 0.0001, Time: 9.4085 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [745/1448], Loss: 0.0003, Time: 9.4195 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [750/1448], Loss: 0.0003, Time: 9.4295 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [755/1448], Loss: 0.0002, Time: 9.4405 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [760/1448], Loss: 0.0002, Time: 9.4495 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [765/1448], Loss: 0.0009, Time: 9.4585 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [770/1448], Loss: 0.0010, Time: 9.4675 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [775/1448], Loss: 0.0006, Time: 9.4765 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [780/1448], Loss: 0.0002, Time: 9.4855 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [785/1448], Loss: 0.0000, Time: 9.4944 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [790/1448], Loss: 0.5022, Time: 9.5034 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [795/1448], Loss: 0.0003, Time: 9.5124 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [800/1448], Loss: 0.0007, Time: 9.5224 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [805/1448], Loss: 0.0006, Time: 9.5314 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [810/1448], Loss: 0.0003, Time: 9.5414 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [815/1448], Loss: 0.0001, Time: 9.5504 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [820/1448], Loss: 0.0000, Time: 9.5594 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [825/1448], Loss: 0.0000, Time: 9.5684 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [830/1448], Loss: 0.0000, Time: 9.5774 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [835/1448], Loss: 0.0000, Time: 9.5864 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [840/1448], Loss: 0.0000, Time: 9.5964 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [845/1448], Loss: 0.0000, Time: 9.6044 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [850/1448], Loss: 0.0000, Time: 9.6134 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [855/1448], Loss: 0.0000, Time: 9.6224 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [860/1448], Loss: 0.0000, Time: 9.6314 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [865/1448], Loss: 0.0000, Time: 9.6404 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [870/1448], Loss: 0.0005, Time: 9.6494 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [875/1448], Loss: 0.0015, Time: 9.6583 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [880/1448], Loss: 0.0033, Time: 9.6673 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [885/1448], Loss: 0.0030, Time: 9.6763 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [890/1448], Loss: 0.0015, Time: 9.6853 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [895/1448], Loss: 0.0004, Time: 9.6943 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [900/1448], Loss: 0.0000, Time: 9.7043 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [905/1448], Loss: 0.0000, Time: 9.7143 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [910/1448], Loss: 0.0001, Time: 9.7243 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [915/1448], Loss: 0.0001, Time: 9.7353 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [920/1448], Loss: 0.0001, Time: 9.7443 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [925/1448], Loss: 0.0000, Time: 9.7533 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [930/1448], Loss: 0.0000, Time: 9.7623 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [935/1448], Loss: 0.0008, Time: 9.7713 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [940/1448], Loss: 0.0012, Time: 9.7803 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [945/1448], Loss: 0.0022, Time: 9.7903 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [950/1448], Loss: 0.0025, Time: 9.8003 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [955/1448], Loss: 0.0016, Time: 9.8087 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [960/1448], Loss: 0.0006, Time: 9.8177 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [965/1448], Loss: 0.0009, Time: 9.8266 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [970/1448], Loss: 0.4716, Time: 9.8356 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [975/1448], Loss: 0.4565, Time: 9.8456 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [980/1448], Loss: 0.0045, Time: 9.8546 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [985/1448], Loss: 0.0041, Time: 9.8656 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [990/1448], Loss: 0.0022, Time: 9.8766 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [995/1448], Loss: 0.0007, Time: 9.8866 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1000/1448], Loss: 0.0007, Time: 9.8966 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1005/1448], Loss: 0.0006, Time: 9.9066 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1010/1448], Loss: 0.0003, Time: 9.9156 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1015/1448], Loss: 0.0001, Time: 9.9256 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1020/1448], Loss: 0.0000, Time: 9.9346 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1025/1448], Loss: 0.0000, Time: 9.9436 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1030/1448], Loss: 0.0000, Time: 9.9526 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1035/1448], Loss: 0.0000, Time: 9.9616 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1040/1448], Loss: 0.0000, Time: 9.9706 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1045/1448], Loss: 0.0000, Time: 9.9796 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1050/1448], Loss: 0.0000, Time: 9.9885 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1055/1448], Loss: 0.0003, Time: 9.9975 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1060/1448], Loss: 0.0009, Time: 10.0065 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1065/1448], Loss: 0.0010, Time: 10.0155 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1070/1448], Loss: 0.0006, Time: 10.0245 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1075/1448], Loss: 0.0002, Time: 10.0335 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1080/1448], Loss: 0.0000, Time: 10.0425 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1085/1448], Loss: 0.0000, Time: 10.0535 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1090/1448], Loss: 0.0000, Time: 10.0625 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1095/1448], Loss: 0.0000, Time: 10.0715 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1100/1448], Loss: 0.0000, Time: 10.0805 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1105/1448], Loss: 0.0006, Time: 10.0905 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1110/1448], Loss: 0.0009, Time: 10.0995 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1115/1448], Loss: 0.0007, Time: 10.1085 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1120/1448], Loss: 0.0003, Time: 10.1185 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1125/1448], Loss: 0.0001, Time: 10.1275 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1130/1448], Loss: 0.0000, Time: 10.1375 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1135/1448], Loss: 0.5039, Time: 10.1465 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1140/1448], Loss: 0.0003, Time: 10.1554 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1145/1448], Loss: 0.0007, Time: 10.1634 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1150/1448], Loss: 0.0006, Time: 10.1734 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1155/1448], Loss: 0.0003, Time: 10.1824 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1160/1448], Loss: 0.0001, Time: 10.1904 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1165/1448], Loss: 0.0000, Time: 10.2004 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1170/1448], Loss: 0.0000, Time: 10.2084 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1175/1448], Loss: 0.0000, Time: 10.2184 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1180/1448], Loss: 0.0000, Time: 10.2294 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1185/1448], Loss: 0.0000, Time: 10.2384 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1190/1448], Loss: 0.0000, Time: 10.2484 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1195/1448], Loss: 0.0000, Time: 10.2568 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1200/1448], Loss: 0.0000, Time: 10.2658 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1205/1448], Loss: 0.0000, Time: 10.2758 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1210/1448], Loss: 0.0000, Time: 10.2848 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1215/1448], Loss: 0.0000, Time: 10.2938 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1220/1448], Loss: 0.0000, Time: 10.3038 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1225/1448], Loss: 0.0000, Time: 10.3130 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1230/1448], Loss: 0.0000, Time: 10.3223 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1235/1448], Loss: 0.5002, Time: 10.3313 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1240/1448], Loss: 0.0006, Time: 10.3403 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1245/1448], Loss: 0.0010, Time: 10.3493 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1250/1448], Loss: 0.0008, Time: 10.3583 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1255/1448], Loss: 0.0004, Time: 10.3663 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1260/1448], Loss: 0.0001, Time: 10.3753 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1265/1448], Loss: 0.0000, Time: 10.3843 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1270/1448], Loss: 0.0001, Time: 10.3933 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1275/1448], Loss: 0.0005, Time: 10.4023 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1280/1448], Loss: 0.0007, Time: 10.4113 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1285/1448], Loss: 0.0024, Time: 10.4203 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1290/1448], Loss: 0.0052, Time: 10.4293 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1295/1448], Loss: 0.0047, Time: 10.4383 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1300/1448], Loss: 0.0025, Time: 10.4473 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1305/1448], Loss: 0.0007, Time: 10.4552 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1310/1448], Loss: 0.0001, Time: 10.4642 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1315/1448], Loss: 0.0000, Time: 10.4742 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1320/1448], Loss: 0.0000, Time: 10.4832 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1325/1448], Loss: 0.0003, Time: 10.4922 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1330/1448], Loss: 0.0004, Time: 10.5012 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1335/1448], Loss: 0.0003, Time: 10.5112 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1340/1448], Loss: 0.0001, Time: 10.5202 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1345/1448], Loss: 0.0000, Time: 10.5292 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1350/1448], Loss: 0.0000, Time: 10.5382 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1355/1448], Loss: 0.0000, Time: 10.5472 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1360/1448], Loss: 0.0000, Time: 10.5557 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1365/1448], Loss: 0.0000, Time: 10.5647 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1370/1448], Loss: 0.5026, Time: 10.5727 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1375/1448], Loss: 0.0005, Time: 10.5827 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1380/1448], Loss: 0.0010, Time: 10.5907 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1385/1448], Loss: 0.0020, Time: 10.5997 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1390/1448], Loss: 0.0026, Time: 10.6087 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1395/1448], Loss: 0.0018, Time: 10.6177 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1400/1448], Loss: 0.0007, Time: 10.6267 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1405/1448], Loss: 0.0003, Time: 10.6357 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1410/1448], Loss: 0.0007, Time: 10.6446 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1415/1448], Loss: 0.0006, Time: 10.6536 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1420/1448], Loss: 0.0003, Time: 10.6636 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1425/1448], Loss: 0.0001, Time: 10.6736 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1430/1448], Loss: 0.0000, Time: 10.6826 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1435/1448], Loss: 0.0000, Time: 10.6916 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1440/1448], Loss: 0.0000, Time: 10.7006 secs, learning rate: 0.0100\n",
      "Epoch [3/10], Step [1445/1448], Loss: 0.0000, Time: 10.7096 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [5/1448], Loss: 0.0000, Time: 11.7380 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [10/1448], Loss: 0.0000, Time: 11.7480 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [15/1448], Loss: 0.0000, Time: 11.7570 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [20/1448], Loss: 0.0000, Time: 11.7660 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [25/1448], Loss: 0.0000, Time: 11.7750 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [30/1448], Loss: 0.0000, Time: 11.7839 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [35/1448], Loss: 0.0000, Time: 11.7929 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [40/1448], Loss: 0.0000, Time: 11.8029 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [45/1448], Loss: 0.0000, Time: 11.8119 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [50/1448], Loss: 0.0000, Time: 11.8209 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [55/1448], Loss: 0.0000, Time: 11.8299 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [60/1448], Loss: 0.0000, Time: 11.8399 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [65/1448], Loss: 0.0000, Time: 11.8489 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [70/1448], Loss: 0.0000, Time: 11.8579 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [75/1448], Loss: 0.0003, Time: 11.8679 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [80/1448], Loss: 0.0009, Time: 11.8769 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [85/1448], Loss: 0.0010, Time: 11.8869 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [90/1448], Loss: 0.0006, Time: 11.8959 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [95/1448], Loss: 0.0002, Time: 11.9049 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [100/1448], Loss: 0.0001, Time: 11.9139 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [105/1448], Loss: 0.0006, Time: 11.9239 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [110/1448], Loss: 0.0007, Time: 11.9329 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [115/1448], Loss: 0.0005, Time: 11.9439 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [120/1448], Loss: 0.0009, Time: 11.9578 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [125/1448], Loss: 0.0012, Time: 11.9668 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [130/1448], Loss: 0.0009, Time: 11.9758 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [135/1448], Loss: 0.0004, Time: 11.9858 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [140/1448], Loss: 0.0001, Time: 11.9948 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [145/1448], Loss: 0.0000, Time: 12.0038 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [150/1448], Loss: 0.0000, Time: 12.0128 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [155/1448], Loss: 0.0000, Time: 12.0218 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [160/1448], Loss: 0.0000, Time: 12.0308 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [165/1448], Loss: 0.0000, Time: 12.0398 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [170/1448], Loss: 0.0000, Time: 12.0488 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [175/1448], Loss: 0.0000, Time: 12.0578 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [180/1448], Loss: 0.0000, Time: 12.0668 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [185/1448], Loss: 0.0000, Time: 12.0758 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [190/1448], Loss: 0.0000, Time: 12.0848 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [195/1448], Loss: 0.0002, Time: 12.0938 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [200/1448], Loss: 0.0009, Time: 12.1028 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [205/1448], Loss: 0.0010, Time: 12.1127 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [210/1448], Loss: 0.0007, Time: 12.1217 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [215/1448], Loss: 0.4845, Time: 12.1307 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [220/1448], Loss: 0.0009, Time: 12.1397 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [225/1448], Loss: 0.0009, Time: 12.1487 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [230/1448], Loss: 0.0006, Time: 12.1577 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [235/1448], Loss: 0.0002, Time: 12.1667 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [240/1448], Loss: 0.0000, Time: 12.1757 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [245/1448], Loss: 0.0000, Time: 12.1847 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [250/1448], Loss: 0.0000, Time: 12.1947 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [255/1448], Loss: 0.0000, Time: 12.2037 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [260/1448], Loss: 0.0000, Time: 12.2127 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [265/1448], Loss: 0.0000, Time: 12.2214 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [270/1448], Loss: 0.0000, Time: 12.2304 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [275/1448], Loss: 0.0000, Time: 12.2394 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [280/1448], Loss: 0.0000, Time: 12.2504 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [285/1448], Loss: 0.0001, Time: 12.2604 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [290/1448], Loss: 0.0008, Time: 12.2694 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [295/1448], Loss: 0.0011, Time: 12.2784 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [300/1448], Loss: 0.0008, Time: 12.2874 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [305/1448], Loss: 0.0003, Time: 12.2964 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [310/1448], Loss: 0.0001, Time: 12.3064 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [315/1448], Loss: 0.0000, Time: 12.3154 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [320/1448], Loss: 0.0000, Time: 12.3244 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [325/1448], Loss: 0.0000, Time: 12.3334 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [330/1448], Loss: 0.0000, Time: 12.3424 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [335/1448], Loss: 0.0000, Time: 12.3524 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [340/1448], Loss: 0.0000, Time: 12.3613 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [345/1448], Loss: 0.0000, Time: 12.3703 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [350/1448], Loss: 0.0000, Time: 12.3793 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [355/1448], Loss: 0.0000, Time: 12.3883 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [360/1448], Loss: 0.0005, Time: 12.3973 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [365/1448], Loss: 0.0011, Time: 12.4063 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [370/1448], Loss: 0.0010, Time: 12.4153 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [375/1448], Loss: 0.4783, Time: 12.4243 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [380/1448], Loss: 0.0013, Time: 12.4333 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [385/1448], Loss: 0.0012, Time: 12.4423 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [390/1448], Loss: 0.0007, Time: 12.4513 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [395/1448], Loss: 0.0002, Time: 12.4593 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [400/1448], Loss: 0.0000, Time: 12.4683 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [405/1448], Loss: 0.0000, Time: 12.4773 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [410/1448], Loss: 0.0000, Time: 12.4863 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [415/1448], Loss: 0.0000, Time: 12.4953 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [420/1448], Loss: 0.0000, Time: 12.5053 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [425/1448], Loss: 0.0000, Time: 12.5141 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [430/1448], Loss: 0.0000, Time: 12.5235 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [435/1448], Loss: 0.0000, Time: 12.5325 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [440/1448], Loss: 0.0000, Time: 12.5425 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [445/1448], Loss: 0.0000, Time: 12.5515 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [450/1448], Loss: 0.0000, Time: 12.5605 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [455/1448], Loss: 0.4993, Time: 12.5695 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [460/1448], Loss: 0.0006, Time: 12.5785 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [465/1448], Loss: 0.0011, Time: 12.5875 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [470/1448], Loss: 0.0009, Time: 12.5965 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [475/1448], Loss: 0.0004, Time: 12.6055 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [480/1448], Loss: 0.0001, Time: 12.6144 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [485/1448], Loss: 0.0000, Time: 12.6234 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [490/1448], Loss: 0.0000, Time: 12.6324 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [495/1448], Loss: 0.0000, Time: 12.6414 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [500/1448], Loss: 0.0000, Time: 12.6494 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [505/1448], Loss: 0.0000, Time: 12.6584 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [510/1448], Loss: 0.0000, Time: 12.6684 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [515/1448], Loss: 0.0000, Time: 12.6764 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [520/1448], Loss: 0.0000, Time: 12.6864 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [525/1448], Loss: 0.0000, Time: 12.6954 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [530/1448], Loss: 0.0000, Time: 12.7054 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [535/1448], Loss: 0.0000, Time: 12.7134 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [540/1448], Loss: 0.0000, Time: 12.7234 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [545/1448], Loss: 0.0000, Time: 12.7324 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [550/1448], Loss: 0.0000, Time: 12.7414 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [555/1448], Loss: 0.0000, Time: 12.7514 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [560/1448], Loss: 0.0000, Time: 12.7614 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [565/1448], Loss: 0.0000, Time: 12.7713 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [570/1448], Loss: 0.0000, Time: 12.7803 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [575/1448], Loss: 0.0000, Time: 12.7893 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [580/1448], Loss: 0.0000, Time: 12.7983 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [585/1448], Loss: 0.0000, Time: 12.8073 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [590/1448], Loss: 0.0000, Time: 12.8163 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [595/1448], Loss: 0.0000, Time: 12.8253 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [600/1448], Loss: 0.0000, Time: 12.8343 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [605/1448], Loss: 0.0000, Time: 12.8433 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [610/1448], Loss: 0.0000, Time: 12.8523 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [615/1448], Loss: 0.0000, Time: 12.8613 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [620/1448], Loss: 0.0000, Time: 12.8703 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [625/1448], Loss: 0.0006, Time: 12.8793 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [630/1448], Loss: 0.0037, Time: 12.8883 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [635/1448], Loss: 0.0044, Time: 12.8973 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [640/1448], Loss: 0.0027, Time: 12.9073 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [645/1448], Loss: 0.0009, Time: 12.9163 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [650/1448], Loss: 0.0001, Time: 12.9252 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [655/1448], Loss: 0.0000, Time: 12.9343 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [660/1448], Loss: 0.0002, Time: 12.9432 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [665/1448], Loss: 0.0001, Time: 12.9522 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [670/1448], Loss: 0.4830, Time: 12.9612 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [675/1448], Loss: 0.0027, Time: 12.9712 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [680/1448], Loss: 0.0084, Time: 12.9802 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [685/1448], Loss: 0.0121, Time: 12.9892 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [690/1448], Loss: 0.0087, Time: 12.9972 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [695/1448], Loss: 0.0037, Time: 13.0062 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [700/1448], Loss: 0.0007, Time: 13.0152 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [705/1448], Loss: 0.0000, Time: 13.0242 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [710/1448], Loss: 0.0003, Time: 13.0332 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [715/1448], Loss: 0.0005, Time: 13.0423 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [720/1448], Loss: 0.0000, Time: 13.0513 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [725/1448], Loss: 0.0003, Time: 13.0593 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [730/1448], Loss: 0.0006, Time: 13.0683 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [735/1448], Loss: 0.0005, Time: 13.0773 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [740/1448], Loss: 0.0002, Time: 13.0873 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [745/1448], Loss: 0.0000, Time: 13.0973 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [750/1448], Loss: 0.0000, Time: 13.1063 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [755/1448], Loss: 0.0000, Time: 13.1153 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [760/1448], Loss: 0.0000, Time: 13.1243 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [765/1448], Loss: 0.0001, Time: 13.1333 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [770/1448], Loss: 0.0007, Time: 13.1433 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [775/1448], Loss: 0.0009, Time: 13.1533 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [780/1448], Loss: 0.0006, Time: 13.1633 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [785/1448], Loss: 0.0002, Time: 13.1723 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [790/1448], Loss: 0.0000, Time: 13.1813 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [795/1448], Loss: 0.0000, Time: 13.1903 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [800/1448], Loss: 0.0000, Time: 13.1992 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [805/1448], Loss: 0.0000, Time: 13.2072 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [810/1448], Loss: 0.0000, Time: 13.2166 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [815/1448], Loss: 0.0000, Time: 13.2256 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [820/1448], Loss: 0.0000, Time: 13.2346 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [825/1448], Loss: 0.0000, Time: 13.2436 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [830/1448], Loss: 0.0000, Time: 13.2526 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [835/1448], Loss: 0.0000, Time: 13.2626 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [840/1448], Loss: 0.0000, Time: 13.2726 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [845/1448], Loss: 0.0000, Time: 13.2826 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [850/1448], Loss: 0.0000, Time: 13.2916 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [855/1448], Loss: 0.0000, Time: 13.3006 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [860/1448], Loss: 0.0000, Time: 13.3106 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [865/1448], Loss: 0.0000, Time: 13.3196 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [870/1448], Loss: 0.0000, Time: 13.3286 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [875/1448], Loss: 0.0000, Time: 13.3385 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [880/1448], Loss: 0.0000, Time: 13.3465 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [885/1448], Loss: 0.0000, Time: 13.3565 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [890/1448], Loss: 0.0000, Time: 13.3655 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [895/1448], Loss: 0.0000, Time: 13.3745 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [900/1448], Loss: 0.0000, Time: 13.3835 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [905/1448], Loss: 0.0000, Time: 13.3915 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [910/1448], Loss: 0.0000, Time: 13.4005 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [915/1448], Loss: 0.0005, Time: 13.4095 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [920/1448], Loss: 0.0011, Time: 13.4185 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [925/1448], Loss: 0.0010, Time: 13.4275 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [930/1448], Loss: 0.0019, Time: 13.4365 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [935/1448], Loss: 0.0019, Time: 13.4455 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [940/1448], Loss: 0.0011, Time: 13.4545 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [945/1448], Loss: 0.0003, Time: 13.4635 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [950/1448], Loss: 0.0003, Time: 13.4735 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [955/1448], Loss: 0.0006, Time: 13.4825 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [960/1448], Loss: 0.0006, Time: 13.4915 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [965/1448], Loss: 0.0003, Time: 13.5014 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [970/1448], Loss: 0.0001, Time: 13.5104 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [975/1448], Loss: 0.0000, Time: 13.5194 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [980/1448], Loss: 0.0000, Time: 13.5284 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [985/1448], Loss: 0.0000, Time: 13.5374 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [990/1448], Loss: 0.0000, Time: 13.5464 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [995/1448], Loss: 0.4869, Time: 13.5554 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1000/1448], Loss: 0.0028, Time: 13.5644 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1005/1448], Loss: 0.0057, Time: 13.5734 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1010/1448], Loss: 0.0107, Time: 13.5824 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1015/1448], Loss: 0.0097, Time: 13.5914 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1020/1448], Loss: 0.0052, Time: 13.6004 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1025/1448], Loss: 0.0015, Time: 13.6094 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1030/1448], Loss: 0.0001, Time: 13.6184 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1035/1448], Loss: 0.0001, Time: 13.6264 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1040/1448], Loss: 0.0004, Time: 13.6364 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1045/1448], Loss: 0.0004, Time: 13.6444 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1050/1448], Loss: 0.0002, Time: 13.6534 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1055/1448], Loss: 0.0001, Time: 13.6633 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1060/1448], Loss: 0.0000, Time: 13.6723 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1065/1448], Loss: 0.0000, Time: 13.6813 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1070/1448], Loss: 0.0000, Time: 13.6903 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1075/1448], Loss: 0.0000, Time: 13.7003 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1080/1448], Loss: 0.0000, Time: 13.7093 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1085/1448], Loss: 0.0000, Time: 13.7173 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1090/1448], Loss: 0.0000, Time: 13.7263 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1095/1448], Loss: 0.0000, Time: 13.7353 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1100/1448], Loss: 0.0000, Time: 13.7443 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1105/1448], Loss: 0.0000, Time: 13.7533 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1110/1448], Loss: 0.0004, Time: 13.7623 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1115/1448], Loss: 0.0010, Time: 13.7733 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1120/1448], Loss: 0.0009, Time: 13.7833 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1125/1448], Loss: 0.0005, Time: 13.7923 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1130/1448], Loss: 0.0001, Time: 13.8013 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1135/1448], Loss: 0.0000, Time: 13.8103 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1140/1448], Loss: 0.0000, Time: 13.8193 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1145/1448], Loss: 0.0000, Time: 13.8282 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1150/1448], Loss: 0.0000, Time: 13.8372 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1155/1448], Loss: 0.0000, Time: 13.8472 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1160/1448], Loss: 0.0000, Time: 13.8562 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1165/1448], Loss: 0.0000, Time: 13.8652 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1170/1448], Loss: 0.0000, Time: 13.8742 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1175/1448], Loss: 0.0000, Time: 13.8842 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1180/1448], Loss: 0.0000, Time: 13.8932 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1185/1448], Loss: 0.0000, Time: 13.9032 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1190/1448], Loss: 0.4789, Time: 13.9122 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1195/1448], Loss: 0.0032, Time: 13.9212 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1200/1448], Loss: 0.0048, Time: 13.9302 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1205/1448], Loss: 0.0061, Time: 13.9392 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1210/1448], Loss: 0.0041, Time: 13.9482 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1215/1448], Loss: 0.0016, Time: 13.9572 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1220/1448], Loss: 0.0003, Time: 13.9662 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1225/1448], Loss: 0.0003, Time: 13.9752 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1230/1448], Loss: 0.0004, Time: 13.9841 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1235/1448], Loss: 0.0002, Time: 13.9931 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1240/1448], Loss: 0.0001, Time: 14.0021 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1245/1448], Loss: 0.0000, Time: 14.0111 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1250/1448], Loss: 0.0000, Time: 14.0201 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1255/1448], Loss: 0.0000, Time: 14.0291 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1260/1448], Loss: 0.0000, Time: 14.0391 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1265/1448], Loss: 0.0000, Time: 14.0481 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1270/1448], Loss: 0.0000, Time: 14.0571 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1275/1448], Loss: 0.0000, Time: 14.0661 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1280/1448], Loss: 0.0000, Time: 14.0751 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1285/1448], Loss: 0.0000, Time: 14.0841 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1290/1448], Loss: 0.0000, Time: 14.0931 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1295/1448], Loss: 0.0007, Time: 14.1031 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1300/1448], Loss: 0.0011, Time: 14.1121 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1305/1448], Loss: 0.4729, Time: 14.1211 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1310/1448], Loss: 0.0018, Time: 14.1301 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1315/1448], Loss: 0.0016, Time: 14.1391 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1320/1448], Loss: 0.0008, Time: 14.1480 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1325/1448], Loss: 0.0002, Time: 14.1560 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1330/1448], Loss: 0.0000, Time: 14.1650 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1335/1448], Loss: 0.0000, Time: 14.1740 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1340/1448], Loss: 0.0003, Time: 14.1830 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1345/1448], Loss: 0.0006, Time: 14.1920 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1350/1448], Loss: 0.0005, Time: 14.2010 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1355/1448], Loss: 0.0002, Time: 14.2100 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1360/1448], Loss: 0.0000, Time: 14.2190 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1365/1448], Loss: 0.0000, Time: 14.2280 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1370/1448], Loss: 0.0000, Time: 14.2380 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1375/1448], Loss: 0.0000, Time: 14.2470 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1380/1448], Loss: 0.0000, Time: 14.2560 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1385/1448], Loss: 0.0000, Time: 14.2660 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1390/1448], Loss: 0.0000, Time: 14.2750 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1395/1448], Loss: 0.0000, Time: 14.2870 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1400/1448], Loss: 0.0000, Time: 14.2960 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1405/1448], Loss: 0.0005, Time: 14.3050 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1410/1448], Loss: 0.0019, Time: 14.3139 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1415/1448], Loss: 0.0035, Time: 14.3229 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1420/1448], Loss: 0.0050, Time: 14.3319 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1425/1448], Loss: 0.4364, Time: 14.3409 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1430/1448], Loss: 0.0055, Time: 14.3499 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1435/1448], Loss: 0.0036, Time: 14.3589 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1440/1448], Loss: 0.0014, Time: 14.3679 secs, learning rate: 0.0100\n",
      "Epoch [4/10], Step [1445/1448], Loss: 0.0002, Time: 14.3769 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [5/1448], Loss: 0.0001, Time: 15.4023 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [10/1448], Loss: 0.0002, Time: 15.4113 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [15/1448], Loss: 0.0002, Time: 15.4203 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [20/1448], Loss: 0.0001, Time: 15.4293 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [25/1448], Loss: 0.0000, Time: 15.4393 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [30/1448], Loss: 0.0000, Time: 15.4482 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [35/1448], Loss: 0.0000, Time: 15.4572 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [40/1448], Loss: 0.0000, Time: 15.4662 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [45/1448], Loss: 0.0000, Time: 15.4752 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [50/1448], Loss: 0.0000, Time: 15.4842 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [55/1448], Loss: 0.0000, Time: 15.4932 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [60/1448], Loss: 0.0000, Time: 15.5022 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [65/1448], Loss: 0.0000, Time: 15.5112 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [70/1448], Loss: 0.0000, Time: 15.5212 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [75/1448], Loss: 0.0000, Time: 15.5302 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [80/1448], Loss: 0.0001, Time: 15.5392 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [85/1448], Loss: 0.0008, Time: 15.5482 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [90/1448], Loss: 0.0010, Time: 15.5572 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [95/1448], Loss: 0.0007, Time: 15.5672 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [100/1448], Loss: 0.0010, Time: 15.5762 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [105/1448], Loss: 0.0013, Time: 15.5852 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [110/1448], Loss: 0.0009, Time: 15.5942 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [115/1448], Loss: 0.0004, Time: 15.6042 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [120/1448], Loss: 0.0001, Time: 15.6131 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [125/1448], Loss: 0.0000, Time: 15.6221 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [130/1448], Loss: 0.0000, Time: 15.6321 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [135/1448], Loss: 0.0001, Time: 15.6411 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [140/1448], Loss: 0.0000, Time: 15.6501 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [145/1448], Loss: 0.0000, Time: 15.6591 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [150/1448], Loss: 0.0000, Time: 15.6681 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [155/1448], Loss: 0.0000, Time: 15.6771 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [160/1448], Loss: 0.0000, Time: 15.6861 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [165/1448], Loss: 0.0000, Time: 15.6951 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [170/1448], Loss: 0.0000, Time: 15.7041 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [175/1448], Loss: 0.0000, Time: 15.7131 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [180/1448], Loss: 0.0000, Time: 15.7221 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [185/1448], Loss: 0.0000, Time: 15.7311 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [190/1448], Loss: 0.0000, Time: 15.7401 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [195/1448], Loss: 0.0000, Time: 15.7491 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [200/1448], Loss: 0.0000, Time: 15.7581 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [205/1448], Loss: 0.0004, Time: 15.7671 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [210/1448], Loss: 0.0010, Time: 15.7760 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [215/1448], Loss: 0.0009, Time: 15.7850 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [220/1448], Loss: 0.0005, Time: 15.7940 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [225/1448], Loss: 0.0010, Time: 15.8040 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [230/1448], Loss: 0.0012, Time: 15.8130 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [235/1448], Loss: 0.4735, Time: 15.8220 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [240/1448], Loss: 0.0016, Time: 15.8320 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [245/1448], Loss: 0.0014, Time: 15.8420 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [250/1448], Loss: 0.0023, Time: 15.8510 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [255/1448], Loss: 0.0038, Time: 15.8610 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [260/1448], Loss: 0.0040, Time: 15.8700 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [265/1448], Loss: 0.0043, Time: 15.8790 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [270/1448], Loss: 0.0035, Time: 15.8880 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [275/1448], Loss: 0.0017, Time: 15.8980 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [280/1448], Loss: 0.0005, Time: 15.9070 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [285/1448], Loss: 0.0000, Time: 15.9160 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [290/1448], Loss: 0.0000, Time: 15.9250 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [295/1448], Loss: 0.0000, Time: 15.9340 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [300/1448], Loss: 0.0003, Time: 15.9429 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [305/1448], Loss: 0.0005, Time: 15.9519 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [310/1448], Loss: 0.0003, Time: 15.9609 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [315/1448], Loss: 0.0002, Time: 15.9699 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [320/1448], Loss: 0.0000, Time: 15.9789 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [325/1448], Loss: 0.0000, Time: 15.9889 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [330/1448], Loss: 0.0000, Time: 15.9989 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [335/1448], Loss: 0.0000, Time: 16.0069 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [340/1448], Loss: 0.0000, Time: 16.0169 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [345/1448], Loss: 0.0000, Time: 16.0259 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [350/1448], Loss: 0.0000, Time: 16.0349 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [355/1448], Loss: 0.0000, Time: 16.0439 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [360/1448], Loss: 0.0000, Time: 16.0539 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [365/1448], Loss: 0.0000, Time: 16.0619 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [370/1448], Loss: 0.0000, Time: 16.0719 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [375/1448], Loss: 0.0000, Time: 16.0809 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [380/1448], Loss: 0.0000, Time: 16.0899 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [385/1448], Loss: 0.0000, Time: 16.0989 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [390/1448], Loss: 0.5000, Time: 16.1078 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [395/1448], Loss: 0.0005, Time: 16.1178 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [400/1448], Loss: 0.0010, Time: 16.1258 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [405/1448], Loss: 0.0008, Time: 16.1358 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [410/1448], Loss: 0.0004, Time: 16.1448 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [415/1448], Loss: 0.0001, Time: 16.1538 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [420/1448], Loss: 0.0000, Time: 16.1628 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [425/1448], Loss: 0.0000, Time: 16.1718 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [430/1448], Loss: 0.5060, Time: 16.1808 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [435/1448], Loss: 0.0008, Time: 16.1898 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [440/1448], Loss: 0.0030, Time: 16.1998 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [445/1448], Loss: 0.0033, Time: 16.2088 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [450/1448], Loss: 0.0021, Time: 16.2178 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [455/1448], Loss: 0.0007, Time: 16.2268 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [460/1448], Loss: 0.0001, Time: 16.2368 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [465/1448], Loss: 0.0001, Time: 16.2458 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [470/1448], Loss: 0.0003, Time: 16.2538 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [475/1448], Loss: 0.0004, Time: 16.2637 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [480/1448], Loss: 0.0003, Time: 16.2727 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [485/1448], Loss: 0.0001, Time: 16.2807 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [490/1448], Loss: 0.0002, Time: 16.2897 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [495/1448], Loss: 0.0007, Time: 16.2987 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [500/1448], Loss: 0.0008, Time: 16.3077 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [505/1448], Loss: 0.0005, Time: 16.3177 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [510/1448], Loss: 0.0002, Time: 16.3277 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [515/1448], Loss: 0.0000, Time: 16.3367 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [520/1448], Loss: 0.0000, Time: 16.3457 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [525/1448], Loss: 0.0000, Time: 16.3547 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [530/1448], Loss: 0.0000, Time: 16.3637 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [535/1448], Loss: 0.0000, Time: 16.3727 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [540/1448], Loss: 0.0000, Time: 16.3837 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [545/1448], Loss: 0.0000, Time: 16.3927 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [550/1448], Loss: 0.0004, Time: 16.4017 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [555/1448], Loss: 0.0010, Time: 16.4117 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [560/1448], Loss: 0.0010, Time: 16.4207 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [565/1448], Loss: 0.0005, Time: 16.4306 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [570/1448], Loss: 0.0002, Time: 16.4386 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [575/1448], Loss: 0.0000, Time: 16.4476 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [580/1448], Loss: 0.0000, Time: 16.4566 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [585/1448], Loss: 0.0002, Time: 16.4656 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [590/1448], Loss: 0.0006, Time: 16.4746 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [595/1448], Loss: 0.0006, Time: 16.4846 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [600/1448], Loss: 0.0004, Time: 16.4936 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [605/1448], Loss: 0.0001, Time: 16.5026 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [610/1448], Loss: 0.0000, Time: 16.5116 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [615/1448], Loss: 0.0000, Time: 16.5206 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [620/1448], Loss: 0.0000, Time: 16.5296 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [625/1448], Loss: 0.0000, Time: 16.5386 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [630/1448], Loss: 0.0000, Time: 16.5476 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [635/1448], Loss: 0.0000, Time: 16.5556 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [640/1448], Loss: 0.0000, Time: 16.5646 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [645/1448], Loss: 0.0000, Time: 16.5736 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [650/1448], Loss: 0.0000, Time: 16.5846 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [655/1448], Loss: 0.0000, Time: 16.5935 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [660/1448], Loss: 0.0000, Time: 16.6025 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [665/1448], Loss: 0.0000, Time: 16.6125 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [670/1448], Loss: 0.0007, Time: 16.6215 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [675/1448], Loss: 0.0010, Time: 16.6305 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [680/1448], Loss: 0.0008, Time: 16.6395 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [685/1448], Loss: 0.0003, Time: 16.6485 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [690/1448], Loss: 0.0001, Time: 16.6575 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [695/1448], Loss: 0.0000, Time: 16.6665 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [700/1448], Loss: 0.0000, Time: 16.6755 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [705/1448], Loss: 0.0004, Time: 16.6845 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [710/1448], Loss: 0.0007, Time: 16.6935 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [715/1448], Loss: 0.0006, Time: 16.7025 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [720/1448], Loss: 0.0003, Time: 16.7115 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [725/1448], Loss: 0.0001, Time: 16.7205 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [730/1448], Loss: 0.0000, Time: 16.7295 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [735/1448], Loss: 0.0000, Time: 16.7385 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [740/1448], Loss: 0.0000, Time: 16.7475 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [745/1448], Loss: 0.0000, Time: 16.7564 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [750/1448], Loss: 0.0000, Time: 16.7644 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [755/1448], Loss: 0.0000, Time: 16.7744 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [760/1448], Loss: 0.0000, Time: 16.7834 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [765/1448], Loss: 0.0000, Time: 16.7924 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [770/1448], Loss: 0.0000, Time: 16.8024 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [775/1448], Loss: 0.0000, Time: 16.8114 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [780/1448], Loss: 0.0000, Time: 16.8214 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [785/1448], Loss: 0.0000, Time: 16.8314 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [790/1448], Loss: 0.0000, Time: 16.8414 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [795/1448], Loss: 0.5001, Time: 16.8504 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [800/1448], Loss: 0.0006, Time: 16.8594 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [805/1448], Loss: 0.0010, Time: 16.8684 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [810/1448], Loss: 0.0008, Time: 16.8774 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [815/1448], Loss: 0.0004, Time: 16.8864 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [820/1448], Loss: 0.0001, Time: 16.8954 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [825/1448], Loss: 0.0000, Time: 16.9044 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [830/1448], Loss: 0.0000, Time: 16.9133 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [835/1448], Loss: 0.0000, Time: 16.9223 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [840/1448], Loss: 0.0000, Time: 16.9313 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [845/1448], Loss: 0.0000, Time: 16.9403 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [850/1448], Loss: 0.0000, Time: 16.9493 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [855/1448], Loss: 0.0000, Time: 16.9573 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [860/1448], Loss: 0.0000, Time: 16.9673 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [865/1448], Loss: 0.4987, Time: 16.9773 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [870/1448], Loss: 0.0007, Time: 16.9863 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [875/1448], Loss: 0.0011, Time: 16.9963 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [880/1448], Loss: 0.0013, Time: 17.0053 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [885/1448], Loss: 0.0029, Time: 17.0153 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [890/1448], Loss: 0.0047, Time: 17.0243 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [895/1448], Loss: 0.0037, Time: 17.0333 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [900/1448], Loss: 0.0017, Time: 17.0423 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [905/1448], Loss: 0.0004, Time: 17.0503 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [910/1448], Loss: 0.0000, Time: 17.0593 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [915/1448], Loss: 0.0001, Time: 17.0683 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [920/1448], Loss: 0.0002, Time: 17.0772 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [925/1448], Loss: 0.0002, Time: 17.0862 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [930/1448], Loss: 0.0001, Time: 17.0962 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [935/1448], Loss: 0.0000, Time: 17.1052 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [940/1448], Loss: 0.0002, Time: 17.1142 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [945/1448], Loss: 0.0010, Time: 17.1232 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [950/1448], Loss: 0.0011, Time: 17.1322 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [955/1448], Loss: 0.0018, Time: 17.1412 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [960/1448], Loss: 0.0021, Time: 17.1502 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [965/1448], Loss: 0.0014, Time: 17.1592 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [970/1448], Loss: 0.0005, Time: 17.1682 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [975/1448], Loss: 0.0002, Time: 17.1782 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [980/1448], Loss: 0.0006, Time: 17.1872 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [985/1448], Loss: 0.0006, Time: 17.1962 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [990/1448], Loss: 0.0003, Time: 17.2052 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [995/1448], Loss: 0.0001, Time: 17.2152 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1000/1448], Loss: 0.0000, Time: 17.2242 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1005/1448], Loss: 0.0000, Time: 17.2332 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1010/1448], Loss: 0.0000, Time: 17.2421 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1015/1448], Loss: 0.0000, Time: 17.2511 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1020/1448], Loss: 0.0000, Time: 17.2601 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1025/1448], Loss: 0.0000, Time: 17.2701 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1030/1448], Loss: 0.5009, Time: 17.2791 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1035/1448], Loss: 0.0006, Time: 17.2871 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1040/1448], Loss: 0.0011, Time: 17.2961 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1045/1448], Loss: 0.0021, Time: 17.3061 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1050/1448], Loss: 0.0026, Time: 17.3161 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1055/1448], Loss: 0.0017, Time: 17.3251 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1060/1448], Loss: 0.0007, Time: 17.3351 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1065/1448], Loss: 0.0001, Time: 17.3461 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1070/1448], Loss: 0.0000, Time: 17.3551 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1075/1448], Loss: 0.0001, Time: 17.3651 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1080/1448], Loss: 0.0001, Time: 17.3741 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1085/1448], Loss: 0.0001, Time: 17.3831 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1090/1448], Loss: 0.0000, Time: 17.3921 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1095/1448], Loss: 0.0000, Time: 17.4010 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1100/1448], Loss: 0.0000, Time: 17.4110 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1105/1448], Loss: 0.0000, Time: 17.4200 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1110/1448], Loss: 0.0000, Time: 17.4290 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1115/1448], Loss: 0.0000, Time: 17.4380 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1120/1448], Loss: 0.0000, Time: 17.4470 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1125/1448], Loss: 0.0000, Time: 17.4560 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1130/1448], Loss: 0.0000, Time: 17.4650 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1135/1448], Loss: 0.0000, Time: 17.4740 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1140/1448], Loss: 0.0007, Time: 17.4830 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1145/1448], Loss: 0.0010, Time: 17.4910 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1150/1448], Loss: 0.0008, Time: 17.5000 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1155/1448], Loss: 0.0003, Time: 17.5100 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1160/1448], Loss: 0.0001, Time: 17.5180 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1165/1448], Loss: 0.0000, Time: 17.5280 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1170/1448], Loss: 0.0000, Time: 17.5370 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1175/1448], Loss: 0.0000, Time: 17.5460 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1180/1448], Loss: 0.0000, Time: 17.5560 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1185/1448], Loss: 0.0000, Time: 17.5649 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1190/1448], Loss: 0.0000, Time: 17.5739 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1195/1448], Loss: 0.0000, Time: 17.5829 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1200/1448], Loss: 0.0000, Time: 17.5919 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1205/1448], Loss: 0.0000, Time: 17.6029 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1210/1448], Loss: 0.0000, Time: 17.6119 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1215/1448], Loss: 0.0000, Time: 17.6209 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1220/1448], Loss: 0.0000, Time: 17.6299 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1225/1448], Loss: 0.5000, Time: 17.6389 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1230/1448], Loss: 0.0006, Time: 17.6479 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1235/1448], Loss: 0.0011, Time: 17.6569 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1240/1448], Loss: 0.0009, Time: 17.6669 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1245/1448], Loss: 0.0004, Time: 17.6759 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1250/1448], Loss: 0.0001, Time: 17.6849 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1255/1448], Loss: 0.0000, Time: 17.6939 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1260/1448], Loss: 0.0000, Time: 17.7029 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1265/1448], Loss: 0.0000, Time: 17.7119 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1270/1448], Loss: 0.0000, Time: 17.7209 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1275/1448], Loss: 0.0000, Time: 17.7308 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1280/1448], Loss: 0.0000, Time: 17.7398 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1285/1448], Loss: 0.0000, Time: 17.7488 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1290/1448], Loss: 0.0000, Time: 17.7588 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1295/1448], Loss: 0.0005, Time: 17.7678 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1300/1448], Loss: 0.0021, Time: 17.7758 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1305/1448], Loss: 0.0038, Time: 17.7858 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1310/1448], Loss: 0.0030, Time: 17.7958 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1315/1448], Loss: 0.0014, Time: 17.8048 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1320/1448], Loss: 0.0003, Time: 17.8138 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1325/1448], Loss: 0.0000, Time: 17.8228 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1330/1448], Loss: 0.0001, Time: 17.8318 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1335/1448], Loss: 0.0002, Time: 17.8408 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1340/1448], Loss: 0.0001, Time: 17.8518 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1345/1448], Loss: 0.0001, Time: 17.8618 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1350/1448], Loss: 0.0000, Time: 17.8708 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1355/1448], Loss: 0.0000, Time: 17.8798 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1360/1448], Loss: 0.0000, Time: 17.8888 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1365/1448], Loss: 0.0000, Time: 17.8977 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1370/1448], Loss: 0.0001, Time: 17.9087 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1375/1448], Loss: 0.0009, Time: 17.9177 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1380/1448], Loss: 0.0012, Time: 17.9267 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1385/1448], Loss: 0.0008, Time: 17.9357 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1390/1448], Loss: 0.0003, Time: 17.9447 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1395/1448], Loss: 0.0000, Time: 17.9547 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1400/1448], Loss: 0.0000, Time: 17.9637 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1405/1448], Loss: 0.0000, Time: 17.9727 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1410/1448], Loss: 0.0005, Time: 17.9817 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1415/1448], Loss: 0.0007, Time: 17.9907 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1420/1448], Loss: 0.0016, Time: 18.0007 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1425/1448], Loss: 0.0067, Time: 18.0087 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1430/1448], Loss: 0.0098, Time: 18.0177 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1435/1448], Loss: 0.0073, Time: 18.0267 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1440/1448], Loss: 0.0032, Time: 18.0357 secs, learning rate: 0.0100\n",
      "Epoch [5/10], Step [1445/1448], Loss: 0.0007, Time: 18.0447 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [5/1448], Loss: 0.0001, Time: 19.0700 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [10/1448], Loss: 0.0003, Time: 19.0790 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [15/1448], Loss: 0.0004, Time: 19.0890 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [20/1448], Loss: 0.0002, Time: 19.0980 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [25/1448], Loss: 0.0001, Time: 19.1070 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [30/1448], Loss: 0.0000, Time: 19.1160 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [35/1448], Loss: 0.0000, Time: 19.1250 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [40/1448], Loss: 0.0000, Time: 19.1350 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [45/1448], Loss: 0.0000, Time: 19.1440 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [50/1448], Loss: 0.0000, Time: 19.1530 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [55/1448], Loss: 0.0000, Time: 19.1620 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [60/1448], Loss: 0.0000, Time: 19.1710 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [65/1448], Loss: 0.0000, Time: 19.1800 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [70/1448], Loss: 0.0000, Time: 19.1889 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [75/1448], Loss: 0.0001, Time: 19.1989 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [80/1448], Loss: 0.0008, Time: 19.2079 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [85/1448], Loss: 0.0027, Time: 19.2169 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [90/1448], Loss: 0.0033, Time: 19.2259 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [95/1448], Loss: 0.4557, Time: 19.2349 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [100/1448], Loss: 0.0027, Time: 19.2439 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [105/1448], Loss: 0.0040, Time: 19.2529 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [110/1448], Loss: 0.0034, Time: 19.2619 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [115/1448], Loss: 0.0017, Time: 19.2719 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [120/1448], Loss: 0.0005, Time: 19.2809 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [125/1448], Loss: 0.0000, Time: 19.2899 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [130/1448], Loss: 0.0001, Time: 19.2989 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [135/1448], Loss: 0.0011, Time: 19.3089 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [140/1448], Loss: 0.0023, Time: 19.3179 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [145/1448], Loss: 0.0021, Time: 19.3269 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [150/1448], Loss: 0.0011, Time: 19.3359 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [155/1448], Loss: 0.0003, Time: 19.3449 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [160/1448], Loss: 0.0000, Time: 19.3538 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [165/1448], Loss: 0.0000, Time: 19.3628 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [170/1448], Loss: 0.0001, Time: 19.3718 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [175/1448], Loss: 0.0001, Time: 19.3828 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [180/1448], Loss: 0.0001, Time: 19.3928 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [185/1448], Loss: 0.0000, Time: 19.4018 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [190/1448], Loss: 0.0000, Time: 19.4108 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [195/1448], Loss: 0.0000, Time: 19.4198 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [200/1448], Loss: 0.0000, Time: 19.4288 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [205/1448], Loss: 0.0000, Time: 19.4378 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [210/1448], Loss: 0.0000, Time: 19.4468 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [215/1448], Loss: 0.0004, Time: 19.4568 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [220/1448], Loss: 0.0010, Time: 19.4658 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [225/1448], Loss: 0.0021, Time: 19.4748 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [230/1448], Loss: 0.0039, Time: 19.4848 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [235/1448], Loss: 0.0050, Time: 19.4938 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [240/1448], Loss: 0.0035, Time: 19.5028 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [245/1448], Loss: 0.0015, Time: 19.5128 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [250/1448], Loss: 0.0003, Time: 19.5217 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [255/1448], Loss: 0.0001, Time: 19.5307 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [260/1448], Loss: 0.0003, Time: 19.5397 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [265/1448], Loss: 0.0003, Time: 19.5487 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [270/1448], Loss: 0.0002, Time: 19.5567 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [275/1448], Loss: 0.0001, Time: 19.5667 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [280/1448], Loss: 0.0000, Time: 19.5757 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [285/1448], Loss: 0.0002, Time: 19.5837 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [290/1448], Loss: 0.0007, Time: 19.5927 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [295/1448], Loss: 0.0007, Time: 19.6017 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [300/1448], Loss: 0.0004, Time: 19.6107 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [305/1448], Loss: 0.0003, Time: 19.6197 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [310/1448], Loss: 0.0009, Time: 19.6287 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [315/1448], Loss: 0.4709, Time: 19.6377 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [320/1448], Loss: 0.0021, Time: 19.6477 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [325/1448], Loss: 0.0019, Time: 19.6567 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [330/1448], Loss: 0.0011, Time: 19.6657 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [335/1448], Loss: 0.0004, Time: 19.6747 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [340/1448], Loss: 0.0000, Time: 19.6846 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [345/1448], Loss: 0.0000, Time: 19.6936 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [350/1448], Loss: 0.0001, Time: 19.7026 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [355/1448], Loss: 0.0001, Time: 19.7116 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [360/1448], Loss: 0.0001, Time: 19.7206 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [365/1448], Loss: 0.0000, Time: 19.7296 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [370/1448], Loss: 0.0000, Time: 19.7386 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [375/1448], Loss: 0.0000, Time: 19.7476 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [380/1448], Loss: 0.0000, Time: 19.7566 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [385/1448], Loss: 0.0000, Time: 19.7656 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [390/1448], Loss: 0.0000, Time: 19.7746 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [395/1448], Loss: 0.0000, Time: 19.7836 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [400/1448], Loss: 0.0000, Time: 19.7926 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [405/1448], Loss: 0.0000, Time: 19.8016 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [410/1448], Loss: 0.0000, Time: 19.8096 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [415/1448], Loss: 0.0000, Time: 19.8186 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [420/1448], Loss: 0.0000, Time: 19.8276 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [425/1448], Loss: 0.0000, Time: 19.8386 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [430/1448], Loss: 0.0000, Time: 19.8475 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [435/1448], Loss: 0.0000, Time: 19.8555 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [440/1448], Loss: 0.0000, Time: 19.8655 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [445/1448], Loss: 0.0000, Time: 19.8745 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [450/1448], Loss: 0.0000, Time: 19.8845 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [455/1448], Loss: 0.0004, Time: 19.8955 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [460/1448], Loss: 0.0009, Time: 19.9045 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [465/1448], Loss: 0.0009, Time: 19.9145 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [470/1448], Loss: 0.0005, Time: 19.9245 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [475/1448], Loss: 0.0002, Time: 19.9335 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [480/1448], Loss: 0.0000, Time: 19.9425 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [485/1448], Loss: 0.0000, Time: 19.9515 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [490/1448], Loss: 0.0000, Time: 19.9615 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [495/1448], Loss: 0.0000, Time: 19.9705 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [500/1448], Loss: 0.0000, Time: 19.9795 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [505/1448], Loss: 0.0000, Time: 19.9885 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [510/1448], Loss: 0.0000, Time: 19.9975 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [515/1448], Loss: 0.0000, Time: 20.0064 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [520/1448], Loss: 0.0000, Time: 20.0154 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [525/1448], Loss: 0.0000, Time: 20.0254 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [530/1448], Loss: 0.0000, Time: 20.0344 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [535/1448], Loss: 0.0000, Time: 20.0434 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [540/1448], Loss: 0.0003, Time: 20.0524 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [545/1448], Loss: 0.0009, Time: 20.0614 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [550/1448], Loss: 0.0022, Time: 20.0714 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [555/1448], Loss: 0.4489, Time: 20.0804 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [560/1448], Loss: 0.0047, Time: 20.0894 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [565/1448], Loss: 0.0037, Time: 20.0984 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [570/1448], Loss: 0.0017, Time: 20.1074 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [575/1448], Loss: 0.0004, Time: 20.1164 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [580/1448], Loss: 0.0000, Time: 20.1244 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [585/1448], Loss: 0.0001, Time: 20.1334 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [590/1448], Loss: 0.0002, Time: 20.1424 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [595/1448], Loss: 0.0002, Time: 20.1524 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [600/1448], Loss: 0.0001, Time: 20.1614 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [605/1448], Loss: 0.0000, Time: 20.1703 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [610/1448], Loss: 0.0000, Time: 20.1793 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [615/1448], Loss: 0.0000, Time: 20.1883 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [620/1448], Loss: 0.0000, Time: 20.1973 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [625/1448], Loss: 0.0000, Time: 20.2053 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [630/1448], Loss: 0.0000, Time: 20.2153 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [635/1448], Loss: 0.0000, Time: 20.2243 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [640/1448], Loss: 0.0000, Time: 20.2333 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [645/1448], Loss: 0.0000, Time: 20.2423 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [650/1448], Loss: 0.0000, Time: 20.2523 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [655/1448], Loss: 0.0000, Time: 20.2623 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [660/1448], Loss: 0.0000, Time: 20.2709 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [665/1448], Loss: 0.0000, Time: 20.2799 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [670/1448], Loss: 0.5001, Time: 20.2889 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [675/1448], Loss: 0.0019, Time: 20.2989 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [680/1448], Loss: 0.0040, Time: 20.3079 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [685/1448], Loss: 0.0035, Time: 20.3159 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [690/1448], Loss: 0.0018, Time: 20.3259 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [695/1448], Loss: 0.0005, Time: 20.3348 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [700/1448], Loss: 0.0000, Time: 20.3448 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [705/1448], Loss: 0.0000, Time: 20.3538 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [710/1448], Loss: 0.0000, Time: 20.3628 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [715/1448], Loss: 0.0003, Time: 20.3718 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [720/1448], Loss: 0.0005, Time: 20.3808 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [725/1448], Loss: 0.0004, Time: 20.3908 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [730/1448], Loss: 0.0002, Time: 20.4028 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [735/1448], Loss: 0.0000, Time: 20.4128 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [740/1448], Loss: 0.0000, Time: 20.4218 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [745/1448], Loss: 0.0003, Time: 20.4308 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [750/1448], Loss: 0.0007, Time: 20.4398 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [755/1448], Loss: 0.0007, Time: 20.4498 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [760/1448], Loss: 0.0004, Time: 20.4588 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [765/1448], Loss: 0.0001, Time: 20.4678 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [770/1448], Loss: 0.0000, Time: 20.4768 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [775/1448], Loss: 0.0000, Time: 20.4858 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [780/1448], Loss: 0.0000, Time: 20.4947 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [785/1448], Loss: 0.0000, Time: 20.5037 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [790/1448], Loss: 0.0000, Time: 20.5127 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [795/1448], Loss: 0.0000, Time: 20.5217 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [800/1448], Loss: 0.0000, Time: 20.5307 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [805/1448], Loss: 0.0000, Time: 20.5397 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [810/1448], Loss: 0.0000, Time: 20.5477 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [815/1448], Loss: 0.0000, Time: 20.5567 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [820/1448], Loss: 0.0000, Time: 20.5657 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [825/1448], Loss: 0.0000, Time: 20.5747 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [830/1448], Loss: 0.0000, Time: 20.5837 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [835/1448], Loss: 0.0000, Time: 20.5923 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [840/1448], Loss: 0.0000, Time: 20.6023 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [845/1448], Loss: 0.0000, Time: 20.6113 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [850/1448], Loss: 0.5002, Time: 20.6203 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [855/1448], Loss: 0.0006, Time: 20.6303 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [860/1448], Loss: 0.0010, Time: 20.6403 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [865/1448], Loss: 0.0009, Time: 20.6493 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [870/1448], Loss: 0.0004, Time: 20.6583 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [875/1448], Loss: 0.0001, Time: 20.6672 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [880/1448], Loss: 0.0000, Time: 20.6762 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [885/1448], Loss: 0.0000, Time: 20.6842 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [890/1448], Loss: 0.5064, Time: 20.6932 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [895/1448], Loss: 0.0003, Time: 20.7022 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [900/1448], Loss: 0.0008, Time: 20.7112 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [905/1448], Loss: 0.0007, Time: 20.7202 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [910/1448], Loss: 0.0004, Time: 20.7292 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [915/1448], Loss: 0.0001, Time: 20.7382 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [920/1448], Loss: 0.0000, Time: 20.7472 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [925/1448], Loss: 0.0000, Time: 20.7562 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [930/1448], Loss: 0.0000, Time: 20.7652 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [935/1448], Loss: 0.0001, Time: 20.7742 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [940/1448], Loss: 0.0026, Time: 20.7832 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [945/1448], Loss: 0.0038, Time: 20.7922 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [950/1448], Loss: 0.0028, Time: 20.8022 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [955/1448], Loss: 0.0012, Time: 20.8112 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [960/1448], Loss: 0.0002, Time: 20.8202 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [965/1448], Loss: 0.0000, Time: 20.8301 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [970/1448], Loss: 0.0001, Time: 20.8391 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [975/1448], Loss: 0.0001, Time: 20.8491 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [980/1448], Loss: 0.0001, Time: 20.8571 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [985/1448], Loss: 0.0001, Time: 20.8671 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [990/1448], Loss: 0.0000, Time: 20.8761 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [995/1448], Loss: 0.0000, Time: 20.8851 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1000/1448], Loss: 0.0000, Time: 20.8941 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1005/1448], Loss: 0.0000, Time: 20.9041 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1010/1448], Loss: 0.0000, Time: 20.9151 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1015/1448], Loss: 0.0000, Time: 20.9241 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1020/1448], Loss: 0.0000, Time: 20.9331 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1025/1448], Loss: 0.0000, Time: 20.9421 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1030/1448], Loss: 0.0003, Time: 20.9501 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1035/1448], Loss: 0.0009, Time: 20.9591 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1040/1448], Loss: 0.0010, Time: 20.9681 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1045/1448], Loss: 0.0006, Time: 20.9771 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1050/1448], Loss: 0.0002, Time: 20.9870 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1055/1448], Loss: 0.0000, Time: 20.9961 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1060/1448], Loss: 0.0000, Time: 21.0051 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1065/1448], Loss: 0.0000, Time: 21.0151 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1070/1448], Loss: 0.0000, Time: 21.0251 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1075/1448], Loss: 0.0000, Time: 21.0341 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1080/1448], Loss: 0.0000, Time: 21.0431 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1085/1448], Loss: 0.0000, Time: 21.0521 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1090/1448], Loss: 0.0000, Time: 21.0601 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1095/1448], Loss: 0.0000, Time: 21.0691 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1100/1448], Loss: 0.0005, Time: 21.0781 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1105/1448], Loss: 0.0011, Time: 21.0871 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1110/1448], Loss: 0.0010, Time: 21.0960 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1115/1448], Loss: 0.0005, Time: 21.1050 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1120/1448], Loss: 0.0001, Time: 21.1140 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1125/1448], Loss: 0.0000, Time: 21.1230 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1130/1448], Loss: 0.0000, Time: 21.1320 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1135/1448], Loss: 0.0000, Time: 21.1410 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1140/1448], Loss: 0.0000, Time: 21.1500 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1145/1448], Loss: 0.0000, Time: 21.1580 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1150/1448], Loss: 0.0000, Time: 21.1670 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1155/1448], Loss: 0.0004, Time: 21.1770 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1160/1448], Loss: 0.0011, Time: 21.1860 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1165/1448], Loss: 0.0010, Time: 21.1960 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1170/1448], Loss: 0.0005, Time: 21.2050 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1175/1448], Loss: 0.0001, Time: 21.2150 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1180/1448], Loss: 0.0004, Time: 21.2240 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1185/1448], Loss: 0.0008, Time: 21.2330 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1190/1448], Loss: 0.0006, Time: 21.2420 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1195/1448], Loss: 0.0009, Time: 21.2509 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1200/1448], Loss: 0.0025, Time: 21.2599 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1205/1448], Loss: 0.0068, Time: 21.2689 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1210/1448], Loss: 0.0074, Time: 21.2779 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1215/1448], Loss: 0.0045, Time: 21.2869 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1220/1448], Loss: 0.0016, Time: 21.2959 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1225/1448], Loss: 0.0002, Time: 21.3039 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1230/1448], Loss: 0.0000, Time: 21.3129 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1235/1448], Loss: 0.0002, Time: 21.3221 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1240/1448], Loss: 0.0003, Time: 21.3312 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1245/1448], Loss: 0.0002, Time: 21.3402 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1250/1448], Loss: 0.0001, Time: 21.3492 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1255/1448], Loss: 0.0000, Time: 21.3582 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1260/1448], Loss: 0.0000, Time: 21.3682 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1265/1448], Loss: 0.0000, Time: 21.3772 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1270/1448], Loss: 0.0000, Time: 21.3862 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1275/1448], Loss: 0.0002, Time: 21.3952 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1280/1448], Loss: 0.0009, Time: 21.4052 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1285/1448], Loss: 0.0011, Time: 21.4162 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1290/1448], Loss: 0.0007, Time: 21.4262 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1295/1448], Loss: 0.0002, Time: 21.4351 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1300/1448], Loss: 0.0000, Time: 21.4451 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1305/1448], Loss: 0.0000, Time: 21.4531 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1310/1448], Loss: 0.0000, Time: 21.4621 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1315/1448], Loss: 0.0000, Time: 21.4721 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1320/1448], Loss: 0.0000, Time: 21.4811 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1325/1448], Loss: 0.0000, Time: 21.4901 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1330/1448], Loss: 0.0000, Time: 21.4991 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1335/1448], Loss: 0.0000, Time: 21.5071 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1340/1448], Loss: 0.0000, Time: 21.5171 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1345/1448], Loss: 0.0000, Time: 21.5261 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1350/1448], Loss: 0.0000, Time: 21.5351 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1355/1448], Loss: 0.0005, Time: 21.5441 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1360/1448], Loss: 0.0028, Time: 21.5531 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1365/1448], Loss: 0.0039, Time: 21.5621 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1370/1448], Loss: 0.0027, Time: 21.5721 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1375/1448], Loss: 0.0011, Time: 21.5811 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1380/1448], Loss: 0.0002, Time: 21.5901 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1385/1448], Loss: 0.0000, Time: 21.5990 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1390/1448], Loss: 0.0001, Time: 21.6080 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1395/1448], Loss: 0.0000, Time: 21.6170 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1400/1448], Loss: 0.0004, Time: 21.6260 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1405/1448], Loss: 0.0006, Time: 21.6350 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1410/1448], Loss: 0.0004, Time: 21.6440 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1415/1448], Loss: 0.0002, Time: 21.6530 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1420/1448], Loss: 0.0000, Time: 21.6620 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1425/1448], Loss: 0.0000, Time: 21.6712 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1430/1448], Loss: 0.0000, Time: 21.6802 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1435/1448], Loss: 0.0000, Time: 21.6892 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1440/1448], Loss: 0.0000, Time: 21.6982 secs, learning rate: 0.0100\n",
      "Epoch [6/10], Step [1445/1448], Loss: 0.0000, Time: 21.7072 secs, learning rate: 0.0100\n",
      "Epoch [7/10], Step [5/1448], Loss: 0.0000, Time: 22.8505 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [10/1448], Loss: 0.0000, Time: 22.8605 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [15/1448], Loss: 0.0000, Time: 22.8695 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [20/1448], Loss: 0.0000, Time: 22.8785 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [25/1448], Loss: 0.0000, Time: 22.8875 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [30/1448], Loss: 0.0000, Time: 22.8965 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [35/1448], Loss: 0.0000, Time: 22.9055 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [40/1448], Loss: 0.0000, Time: 22.9145 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [45/1448], Loss: 0.0000, Time: 22.9235 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [50/1448], Loss: 0.0000, Time: 22.9325 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [55/1448], Loss: 0.0000, Time: 22.9415 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [60/1448], Loss: 0.0001, Time: 22.9514 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [65/1448], Loss: 0.0001, Time: 22.9604 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [70/1448], Loss: 0.0001, Time: 22.9694 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [75/1448], Loss: 0.0002, Time: 22.9784 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [80/1448], Loss: 0.0003, Time: 22.9874 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [85/1448], Loss: 0.0003, Time: 22.9964 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [90/1448], Loss: 0.0003, Time: 23.0054 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [95/1448], Loss: 0.0005, Time: 23.0144 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [100/1448], Loss: 0.0006, Time: 23.0244 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [105/1448], Loss: 0.0008, Time: 23.0334 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [110/1448], Loss: 0.0009, Time: 23.0424 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [115/1448], Loss: 0.0010, Time: 23.0524 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [120/1448], Loss: 0.0011, Time: 23.0614 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [125/1448], Loss: 0.0011, Time: 23.0704 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [130/1448], Loss: 0.0011, Time: 23.0794 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [135/1448], Loss: 0.0010, Time: 23.0884 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [140/1448], Loss: 0.0009, Time: 23.0984 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [145/1448], Loss: 0.0009, Time: 23.1074 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [150/1448], Loss: 0.0008, Time: 23.1163 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [155/1448], Loss: 0.0007, Time: 23.1253 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [160/1448], Loss: 0.0006, Time: 23.1343 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [165/1448], Loss: 0.0007, Time: 23.1433 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [170/1448], Loss: 0.0007, Time: 23.1533 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [175/1448], Loss: 0.0008, Time: 23.1623 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [180/1448], Loss: 0.0008, Time: 23.1713 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [185/1448], Loss: 0.0007, Time: 23.1803 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [190/1448], Loss: 0.0007, Time: 23.1893 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [195/1448], Loss: 0.0006, Time: 23.1973 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [200/1448], Loss: 0.0005, Time: 23.2063 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [205/1448], Loss: 0.0006, Time: 23.2153 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [210/1448], Loss: 0.0006, Time: 23.2243 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [215/1448], Loss: 0.0006, Time: 23.2333 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [220/1448], Loss: 0.0005, Time: 23.2433 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [225/1448], Loss: 0.0005, Time: 23.2523 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [230/1448], Loss: 0.0004, Time: 23.2613 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [235/1448], Loss: 0.0004, Time: 23.2713 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [240/1448], Loss: 0.0003, Time: 23.2802 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [245/1448], Loss: 0.0003, Time: 23.2892 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [250/1448], Loss: 0.0003, Time: 23.2982 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [255/1448], Loss: 0.0002, Time: 23.3072 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [260/1448], Loss: 0.0002, Time: 23.3162 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [265/1448], Loss: 0.0002, Time: 23.3252 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [270/1448], Loss: 0.0002, Time: 23.3352 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [275/1448], Loss: 0.0001, Time: 23.3442 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [280/1448], Loss: 0.0001, Time: 23.3532 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [285/1448], Loss: 0.0001, Time: 23.3632 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [290/1448], Loss: 0.0001, Time: 23.3732 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [295/1448], Loss: 0.0001, Time: 23.3832 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [300/1448], Loss: 0.0001, Time: 23.3912 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [305/1448], Loss: 0.0001, Time: 23.4002 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [310/1448], Loss: 0.0001, Time: 23.4092 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [315/1448], Loss: 0.0001, Time: 23.4182 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [320/1448], Loss: 0.0001, Time: 23.4272 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [325/1448], Loss: 0.0001, Time: 23.4382 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [330/1448], Loss: 0.0001, Time: 23.4491 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [335/1448], Loss: 0.0001, Time: 23.4571 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [340/1448], Loss: 0.0001, Time: 23.4671 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [345/1448], Loss: 0.0001, Time: 23.4771 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [350/1448], Loss: 0.0002, Time: 23.4861 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [355/1448], Loss: 0.0002, Time: 23.4961 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [360/1448], Loss: 0.0002, Time: 23.5051 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [365/1448], Loss: 0.0001, Time: 23.5141 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [370/1448], Loss: 0.0001, Time: 23.5231 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [375/1448], Loss: 0.0001, Time: 23.5321 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [380/1448], Loss: 0.0001, Time: 23.5411 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [385/1448], Loss: 0.0001, Time: 23.5501 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [390/1448], Loss: 0.0001, Time: 23.5591 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [395/1448], Loss: 0.0001, Time: 23.5681 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [400/1448], Loss: 0.0001, Time: 23.5771 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [405/1448], Loss: 0.0001, Time: 23.5861 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [410/1448], Loss: 0.0000, Time: 23.5951 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [415/1448], Loss: 0.0000, Time: 23.6040 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [420/1448], Loss: 0.0000, Time: 23.6130 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [425/1448], Loss: 0.0000, Time: 23.6220 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [430/1448], Loss: 0.0000, Time: 23.6320 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [435/1448], Loss: 0.0000, Time: 23.6410 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [440/1448], Loss: 0.0000, Time: 23.6490 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [445/1448], Loss: 0.0000, Time: 23.6590 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [450/1448], Loss: 0.0000, Time: 23.6680 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [455/1448], Loss: 0.0000, Time: 23.6780 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [460/1448], Loss: 0.0000, Time: 23.6870 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [465/1448], Loss: 0.0000, Time: 23.6960 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [470/1448], Loss: 0.0000, Time: 23.7050 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [475/1448], Loss: 0.0001, Time: 23.7140 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [480/1448], Loss: 0.0001, Time: 23.7230 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [485/1448], Loss: 0.0001, Time: 23.7320 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [490/1448], Loss: 0.0001, Time: 23.7410 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [495/1448], Loss: 0.0001, Time: 23.7500 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [500/1448], Loss: 0.0001, Time: 23.7580 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [505/1448], Loss: 0.0001, Time: 23.7679 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [510/1448], Loss: 0.0001, Time: 23.7759 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [515/1448], Loss: 0.0001, Time: 23.7859 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [520/1448], Loss: 0.0001, Time: 23.7949 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [525/1448], Loss: 0.0001, Time: 23.8039 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [530/1448], Loss: 0.0001, Time: 23.8129 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [535/1448], Loss: 0.0001, Time: 23.8229 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [540/1448], Loss: 0.0001, Time: 23.8329 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [545/1448], Loss: 0.0000, Time: 23.8409 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [550/1448], Loss: 0.0000, Time: 23.8509 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [555/1448], Loss: 0.0000, Time: 23.8599 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [560/1448], Loss: 0.0000, Time: 23.8699 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [565/1448], Loss: 0.0000, Time: 23.8789 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [570/1448], Loss: 0.0000, Time: 23.8879 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [575/1448], Loss: 0.0000, Time: 23.8969 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [580/1448], Loss: 0.0000, Time: 23.9059 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [585/1448], Loss: 0.0000, Time: 23.9149 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [590/1448], Loss: 0.0000, Time: 23.9239 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [595/1448], Loss: 0.0000, Time: 23.9328 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [600/1448], Loss: 0.0000, Time: 23.9448 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [605/1448], Loss: 0.0000, Time: 23.9558 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [610/1448], Loss: 0.0000, Time: 23.9648 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [615/1448], Loss: 0.0000, Time: 23.9738 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [620/1448], Loss: 0.0000, Time: 23.9828 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [625/1448], Loss: 0.0000, Time: 23.9918 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [630/1448], Loss: 0.0000, Time: 24.0008 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [635/1448], Loss: 0.0000, Time: 24.0088 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [640/1448], Loss: 0.0001, Time: 24.0188 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [645/1448], Loss: 0.0001, Time: 24.0278 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [650/1448], Loss: 0.0001, Time: 24.0368 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [655/1448], Loss: 0.0001, Time: 24.0468 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [660/1448], Loss: 0.0001, Time: 24.0558 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [665/1448], Loss: 0.0001, Time: 24.0658 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [670/1448], Loss: 0.0001, Time: 24.0748 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [675/1448], Loss: 0.0001, Time: 24.0838 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [680/1448], Loss: 0.0001, Time: 24.0927 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [685/1448], Loss: 0.0001, Time: 24.1017 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [690/1448], Loss: 0.0002, Time: 24.1097 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [695/1448], Loss: 0.0002, Time: 24.1197 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [700/1448], Loss: 0.0003, Time: 24.1287 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [705/1448], Loss: 0.0003, Time: 24.1377 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [710/1448], Loss: 0.0002, Time: 24.1467 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [715/1448], Loss: 0.0002, Time: 24.1557 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [720/1448], Loss: 0.0002, Time: 24.1647 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [725/1448], Loss: 0.0002, Time: 24.1737 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [730/1448], Loss: 0.0002, Time: 24.1827 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [735/1448], Loss: 0.0001, Time: 24.1907 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [740/1448], Loss: 0.0001, Time: 24.1997 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [745/1448], Loss: 0.0001, Time: 24.2097 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [750/1448], Loss: 0.0001, Time: 24.2187 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [755/1448], Loss: 0.0001, Time: 24.2287 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [760/1448], Loss: 0.0001, Time: 24.2377 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [765/1448], Loss: 0.0002, Time: 24.2477 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [770/1448], Loss: 0.0002, Time: 24.2566 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [775/1448], Loss: 0.0001, Time: 24.2656 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [780/1448], Loss: 0.0001, Time: 24.2746 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [785/1448], Loss: 0.0001, Time: 24.2836 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [790/1448], Loss: 0.0001, Time: 24.2926 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [795/1448], Loss: 0.0001, Time: 24.3016 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [800/1448], Loss: 0.0001, Time: 24.3106 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [805/1448], Loss: 0.4919, Time: 24.3196 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [810/1448], Loss: 0.0001, Time: 24.3286 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [815/1448], Loss: 0.0001, Time: 24.3376 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [820/1448], Loss: 0.0001, Time: 24.3466 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [825/1448], Loss: 0.0001, Time: 24.3556 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [830/1448], Loss: 0.0001, Time: 24.3636 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [835/1448], Loss: 0.0001, Time: 24.3736 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [840/1448], Loss: 0.0001, Time: 24.3816 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [845/1448], Loss: 0.0001, Time: 24.3916 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [850/1448], Loss: 0.0001, Time: 24.4006 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [855/1448], Loss: 0.0001, Time: 24.4096 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [860/1448], Loss: 0.0002, Time: 24.4185 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [865/1448], Loss: 0.0003, Time: 24.4275 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [870/1448], Loss: 0.0003, Time: 24.4375 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [875/1448], Loss: 0.0003, Time: 24.4475 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [880/1448], Loss: 0.0002, Time: 24.4575 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [885/1448], Loss: 0.0002, Time: 24.4675 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [890/1448], Loss: 0.0002, Time: 24.4765 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [895/1448], Loss: 0.0002, Time: 24.4855 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [900/1448], Loss: 0.0002, Time: 24.4945 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [905/1448], Loss: 0.0001, Time: 24.5035 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [910/1448], Loss: 0.0001, Time: 24.5125 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [915/1448], Loss: 0.0001, Time: 24.5215 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [920/1448], Loss: 0.0001, Time: 24.5305 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [925/1448], Loss: 0.0001, Time: 24.5395 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [930/1448], Loss: 0.0002, Time: 24.5485 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [935/1448], Loss: 0.0002, Time: 24.5575 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [940/1448], Loss: 0.0001, Time: 24.5665 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [945/1448], Loss: 0.0001, Time: 24.5755 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [950/1448], Loss: 0.0001, Time: 24.5854 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [955/1448], Loss: 0.0001, Time: 24.5944 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [960/1448], Loss: 0.0001, Time: 24.6034 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [965/1448], Loss: 0.0001, Time: 24.6124 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [970/1448], Loss: 0.4915, Time: 24.6224 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [975/1448], Loss: 0.4896, Time: 24.6314 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [980/1448], Loss: 0.0002, Time: 24.6404 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [985/1448], Loss: 0.0002, Time: 24.6494 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [990/1448], Loss: 0.0003, Time: 24.6584 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [995/1448], Loss: 0.0003, Time: 24.6674 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1000/1448], Loss: 0.0002, Time: 24.6764 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1005/1448], Loss: 0.0002, Time: 24.6854 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1010/1448], Loss: 0.0002, Time: 24.6944 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1015/1448], Loss: 0.0002, Time: 24.7034 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1020/1448], Loss: 0.0002, Time: 24.7134 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1025/1448], Loss: 0.0003, Time: 24.7224 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1030/1448], Loss: 0.0003, Time: 24.7314 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1035/1448], Loss: 0.0002, Time: 24.7404 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1040/1448], Loss: 0.0002, Time: 24.7493 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1045/1448], Loss: 0.0002, Time: 24.7573 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1050/1448], Loss: 0.0002, Time: 24.7673 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1055/1448], Loss: 0.0001, Time: 24.7753 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1060/1448], Loss: 0.0001, Time: 24.7853 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1065/1448], Loss: 0.0001, Time: 24.7943 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1070/1448], Loss: 0.0001, Time: 24.8033 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1075/1448], Loss: 0.0001, Time: 24.8133 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1080/1448], Loss: 0.0001, Time: 24.8223 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1085/1448], Loss: 0.0001, Time: 24.8323 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1090/1448], Loss: 0.0001, Time: 24.8413 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1095/1448], Loss: 0.0000, Time: 24.8503 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1100/1448], Loss: 0.0000, Time: 24.8593 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1105/1448], Loss: 0.0000, Time: 24.8673 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1110/1448], Loss: 0.0000, Time: 24.8763 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1115/1448], Loss: 0.0000, Time: 24.8853 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1120/1448], Loss: 0.0000, Time: 24.8943 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1125/1448], Loss: 0.0000, Time: 24.9043 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1130/1448], Loss: 0.0000, Time: 24.9122 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1135/1448], Loss: 0.0000, Time: 24.9222 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1140/1448], Loss: 0.0000, Time: 24.9302 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1145/1448], Loss: 0.0001, Time: 24.9392 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1150/1448], Loss: 0.0002, Time: 24.9482 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1155/1448], Loss: 0.0002, Time: 24.9582 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1160/1448], Loss: 0.0003, Time: 24.9682 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1165/1448], Loss: 0.0003, Time: 24.9782 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1170/1448], Loss: 0.0003, Time: 24.9872 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1175/1448], Loss: 0.0003, Time: 24.9962 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1180/1448], Loss: 0.0003, Time: 25.0052 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1185/1448], Loss: 0.0002, Time: 25.0152 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1190/1448], Loss: 0.0002, Time: 25.0242 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1195/1448], Loss: 0.0002, Time: 25.0342 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1200/1448], Loss: 0.0002, Time: 25.0422 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1205/1448], Loss: 0.0001, Time: 25.0512 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1210/1448], Loss: 0.0001, Time: 25.0602 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1215/1448], Loss: 0.0001, Time: 25.0691 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1220/1448], Loss: 0.0001, Time: 25.0791 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1225/1448], Loss: 0.0001, Time: 25.0881 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1230/1448], Loss: 0.0001, Time: 25.0971 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1235/1448], Loss: 0.0001, Time: 25.1061 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1240/1448], Loss: 0.0000, Time: 25.1151 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1245/1448], Loss: 0.0000, Time: 25.1241 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1250/1448], Loss: 0.0000, Time: 25.1331 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1255/1448], Loss: 0.0000, Time: 25.1421 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1260/1448], Loss: 0.0000, Time: 25.1511 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1265/1448], Loss: 0.0000, Time: 25.1601 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1270/1448], Loss: 0.0000, Time: 25.1701 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1275/1448], Loss: 0.0000, Time: 25.1791 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1280/1448], Loss: 0.0000, Time: 25.1871 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1285/1448], Loss: 0.0001, Time: 25.1971 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1290/1448], Loss: 0.0001, Time: 25.2061 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1295/1448], Loss: 0.0001, Time: 25.2151 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1300/1448], Loss: 0.0001, Time: 25.2241 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1305/1448], Loss: 0.0001, Time: 25.2330 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1310/1448], Loss: 0.0001, Time: 25.2420 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1315/1448], Loss: 0.0000, Time: 25.2510 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1320/1448], Loss: 0.0000, Time: 25.2600 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1325/1448], Loss: 0.0000, Time: 25.2690 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1330/1448], Loss: 0.0001, Time: 25.2780 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1335/1448], Loss: 0.0002, Time: 25.2870 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1340/1448], Loss: 0.0002, Time: 25.2960 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1345/1448], Loss: 0.0002, Time: 25.3050 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1350/1448], Loss: 0.0002, Time: 25.3140 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1355/1448], Loss: 0.0002, Time: 25.3230 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1360/1448], Loss: 0.0002, Time: 25.3320 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1365/1448], Loss: 0.0002, Time: 25.3410 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1370/1448], Loss: 0.0001, Time: 25.3510 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1375/1448], Loss: 0.0001, Time: 25.3600 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1380/1448], Loss: 0.0001, Time: 25.3690 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1385/1448], Loss: 0.0002, Time: 25.3780 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1390/1448], Loss: 0.0002, Time: 25.3880 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1395/1448], Loss: 0.0002, Time: 25.3970 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1400/1448], Loss: 0.0002, Time: 25.4060 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1405/1448], Loss: 0.0002, Time: 25.4155 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1410/1448], Loss: 0.0002, Time: 25.4245 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1415/1448], Loss: 0.0003, Time: 25.4335 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1420/1448], Loss: 0.0002, Time: 25.4425 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1425/1448], Loss: 0.0002, Time: 25.4515 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1430/1448], Loss: 0.0002, Time: 25.4615 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1435/1448], Loss: 0.0002, Time: 25.4714 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1440/1448], Loss: 0.0002, Time: 25.4814 secs, learning rate: 0.0010\n",
      "Epoch [7/10], Step [1445/1448], Loss: 0.0001, Time: 25.4904 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [5/1448], Loss: 0.0001, Time: 26.5178 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [10/1448], Loss: 0.0001, Time: 26.5268 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [15/1448], Loss: 0.0001, Time: 26.5368 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [20/1448], Loss: 0.0001, Time: 26.5458 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [25/1448], Loss: 0.0001, Time: 26.5548 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [30/1448], Loss: 0.0001, Time: 26.5638 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [35/1448], Loss: 0.0001, Time: 26.5728 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [40/1448], Loss: 0.0001, Time: 26.5828 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [45/1448], Loss: 0.0002, Time: 26.5918 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [50/1448], Loss: 0.0002, Time: 26.6008 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [55/1448], Loss: 0.0002, Time: 26.6097 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [60/1448], Loss: 0.0002, Time: 26.6187 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [65/1448], Loss: 0.0002, Time: 26.6277 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [70/1448], Loss: 0.0002, Time: 26.6377 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [75/1448], Loss: 0.0003, Time: 26.6467 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [80/1448], Loss: 0.0003, Time: 26.6557 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [85/1448], Loss: 0.0004, Time: 26.6647 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [90/1448], Loss: 0.0005, Time: 26.6747 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [95/1448], Loss: 0.0005, Time: 26.6837 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [100/1448], Loss: 0.0006, Time: 26.6927 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [105/1448], Loss: 0.0005, Time: 26.7017 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [110/1448], Loss: 0.0005, Time: 26.7107 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [115/1448], Loss: 0.0004, Time: 26.7207 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [120/1448], Loss: 0.0004, Time: 26.7297 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [125/1448], Loss: 0.0004, Time: 26.7387 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [130/1448], Loss: 0.4828, Time: 26.7477 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [135/1448], Loss: 0.0004, Time: 26.7577 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [140/1448], Loss: 0.0004, Time: 26.7667 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [145/1448], Loss: 0.0004, Time: 26.7756 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [150/1448], Loss: 0.0003, Time: 26.7856 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [155/1448], Loss: 0.0003, Time: 26.7946 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [160/1448], Loss: 0.0003, Time: 26.8036 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [165/1448], Loss: 0.0002, Time: 26.8126 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [170/1448], Loss: 0.0003, Time: 26.8216 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [175/1448], Loss: 0.0004, Time: 26.8306 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [180/1448], Loss: 0.0005, Time: 26.8396 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [185/1448], Loss: 0.0006, Time: 26.8486 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [190/1448], Loss: 0.0007, Time: 26.8576 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [195/1448], Loss: 0.0006, Time: 26.8666 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [200/1448], Loss: 0.0006, Time: 26.8746 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [205/1448], Loss: 0.0005, Time: 26.8846 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [210/1448], Loss: 0.0005, Time: 26.8926 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [215/1448], Loss: 0.0006, Time: 26.9026 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [220/1448], Loss: 0.0006, Time: 26.9116 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [225/1448], Loss: 0.0005, Time: 26.9209 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [230/1448], Loss: 0.0005, Time: 26.9309 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [235/1448], Loss: 0.0004, Time: 26.9399 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [240/1448], Loss: 0.0004, Time: 26.9499 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [245/1448], Loss: 0.0003, Time: 26.9579 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [250/1448], Loss: 0.0003, Time: 26.9678 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [255/1448], Loss: 0.0003, Time: 26.9768 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [260/1448], Loss: 0.0002, Time: 26.9858 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [265/1448], Loss: 0.0002, Time: 26.9948 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [270/1448], Loss: 0.0002, Time: 27.0048 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [275/1448], Loss: 0.0002, Time: 27.0148 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [280/1448], Loss: 0.0001, Time: 27.0238 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [285/1448], Loss: 0.0001, Time: 27.0328 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [290/1448], Loss: 0.0001, Time: 27.0418 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [295/1448], Loss: 0.0001, Time: 27.0508 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [300/1448], Loss: 0.0001, Time: 27.0598 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [305/1448], Loss: 0.0001, Time: 27.0688 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [310/1448], Loss: 0.0001, Time: 27.0778 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [315/1448], Loss: 0.0000, Time: 27.0868 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [320/1448], Loss: 0.0000, Time: 27.0968 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [325/1448], Loss: 0.0000, Time: 27.1058 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [330/1448], Loss: 0.0000, Time: 27.1148 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [335/1448], Loss: 0.0001, Time: 27.1237 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [340/1448], Loss: 0.0001, Time: 27.1327 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [345/1448], Loss: 0.0001, Time: 27.1427 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [350/1448], Loss: 0.0001, Time: 27.1517 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [355/1448], Loss: 0.0001, Time: 27.1597 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [360/1448], Loss: 0.0001, Time: 27.1697 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [365/1448], Loss: 0.0001, Time: 27.1787 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [370/1448], Loss: 0.0001, Time: 27.1877 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [375/1448], Loss: 0.0001, Time: 27.1967 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [380/1448], Loss: 0.0000, Time: 27.2057 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [385/1448], Loss: 0.0001, Time: 27.2147 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [390/1448], Loss: 0.0001, Time: 27.2237 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [395/1448], Loss: 0.0001, Time: 27.2337 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [400/1448], Loss: 0.0001, Time: 27.2417 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [405/1448], Loss: 0.0001, Time: 27.2507 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [410/1448], Loss: 0.0001, Time: 27.2607 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [415/1448], Loss: 0.0001, Time: 27.2697 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [420/1448], Loss: 0.0001, Time: 27.2787 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [425/1448], Loss: 0.0001, Time: 27.2886 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [430/1448], Loss: 0.0001, Time: 27.2976 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [435/1448], Loss: 0.0000, Time: 27.3056 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [440/1448], Loss: 0.0000, Time: 27.3156 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [445/1448], Loss: 0.0000, Time: 27.3246 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [450/1448], Loss: 0.0001, Time: 27.3346 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [455/1448], Loss: 0.0001, Time: 27.3436 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [460/1448], Loss: 0.0001, Time: 27.3526 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [465/1448], Loss: 0.0001, Time: 27.3626 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [470/1448], Loss: 0.0001, Time: 27.3716 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [475/1448], Loss: 0.0001, Time: 27.3806 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [480/1448], Loss: 0.0001, Time: 27.3896 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [485/1448], Loss: 0.0001, Time: 27.3986 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [490/1448], Loss: 0.0001, Time: 27.4076 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [495/1448], Loss: 0.0001, Time: 27.4156 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [500/1448], Loss: 0.0000, Time: 27.4246 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [505/1448], Loss: 0.0000, Time: 27.4336 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [510/1448], Loss: 0.0000, Time: 27.4426 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [515/1448], Loss: 0.0000, Time: 27.4515 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [520/1448], Loss: 0.0000, Time: 27.4605 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [525/1448], Loss: 0.0000, Time: 27.4695 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [530/1448], Loss: 0.0000, Time: 27.4785 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [535/1448], Loss: 0.0000, Time: 27.4875 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [540/1448], Loss: 0.0000, Time: 27.4975 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [545/1448], Loss: 0.0000, Time: 27.5075 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [550/1448], Loss: 0.0000, Time: 27.5165 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [555/1448], Loss: 0.0000, Time: 27.5265 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [560/1448], Loss: 0.0000, Time: 27.5375 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [565/1448], Loss: 0.0000, Time: 27.5475 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [570/1448], Loss: 0.0000, Time: 27.5565 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [575/1448], Loss: 0.0000, Time: 27.5665 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [580/1448], Loss: 0.0000, Time: 27.5755 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [585/1448], Loss: 0.0000, Time: 27.5845 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [590/1448], Loss: 0.0000, Time: 27.5935 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [595/1448], Loss: 0.0000, Time: 27.6025 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [600/1448], Loss: 0.0000, Time: 27.6115 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [605/1448], Loss: 0.0000, Time: 27.6204 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [610/1448], Loss: 0.4939, Time: 27.6294 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [615/1448], Loss: 0.0001, Time: 27.6384 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [620/1448], Loss: 0.0001, Time: 27.6474 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [625/1448], Loss: 0.0001, Time: 27.6564 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [630/1448], Loss: 0.0001, Time: 27.6654 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [635/1448], Loss: 0.0001, Time: 27.6754 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [640/1448], Loss: 0.0001, Time: 27.6854 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [645/1448], Loss: 0.0001, Time: 27.6944 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [650/1448], Loss: 0.0001, Time: 27.7034 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [655/1448], Loss: 0.0001, Time: 27.7134 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [660/1448], Loss: 0.0001, Time: 27.7224 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [665/1448], Loss: 0.0001, Time: 27.7314 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [670/1448], Loss: 0.0001, Time: 27.7404 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [675/1448], Loss: 0.0002, Time: 27.7494 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [680/1448], Loss: 0.0002, Time: 27.7584 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [685/1448], Loss: 0.0003, Time: 27.7674 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [690/1448], Loss: 0.0004, Time: 27.7763 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [695/1448], Loss: 0.0004, Time: 27.7853 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [700/1448], Loss: 0.0004, Time: 27.7953 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [705/1448], Loss: 0.0004, Time: 27.8043 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [710/1448], Loss: 0.0003, Time: 27.8123 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [715/1448], Loss: 0.4833, Time: 27.8213 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [720/1448], Loss: 0.0003, Time: 27.8303 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [725/1448], Loss: 0.0004, Time: 27.8393 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [730/1448], Loss: 0.0005, Time: 27.8493 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [735/1448], Loss: 0.0006, Time: 27.8573 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [740/1448], Loss: 0.0007, Time: 27.8673 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [745/1448], Loss: 0.0007, Time: 27.8763 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [750/1448], Loss: 0.0007, Time: 27.8853 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [755/1448], Loss: 0.0006, Time: 27.8943 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [760/1448], Loss: 0.0005, Time: 27.9043 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [765/1448], Loss: 0.0005, Time: 27.9133 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [770/1448], Loss: 0.0004, Time: 27.9223 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [775/1448], Loss: 0.0004, Time: 27.9323 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [780/1448], Loss: 0.0004, Time: 27.9402 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [785/1448], Loss: 0.0004, Time: 27.9502 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [790/1448], Loss: 0.0004, Time: 27.9592 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [795/1448], Loss: 0.0004, Time: 27.9682 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [800/1448], Loss: 0.0004, Time: 27.9782 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [805/1448], Loss: 0.0003, Time: 27.9872 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [810/1448], Loss: 0.0003, Time: 27.9962 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [815/1448], Loss: 0.4846, Time: 28.0042 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [820/1448], Loss: 0.0003, Time: 28.0142 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [825/1448], Loss: 0.0003, Time: 28.0252 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [830/1448], Loss: 0.0003, Time: 28.0342 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [835/1448], Loss: 0.0003, Time: 28.0432 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [840/1448], Loss: 0.0003, Time: 28.0522 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [845/1448], Loss: 0.0002, Time: 28.0612 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [850/1448], Loss: 0.0003, Time: 28.0712 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [855/1448], Loss: 0.0003, Time: 28.0802 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [860/1448], Loss: 0.0003, Time: 28.0892 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [865/1448], Loss: 0.0003, Time: 28.0991 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [870/1448], Loss: 0.0003, Time: 28.1081 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [875/1448], Loss: 0.0003, Time: 28.1181 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [880/1448], Loss: 0.0003, Time: 28.1271 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [885/1448], Loss: 0.0003, Time: 28.1361 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [890/1448], Loss: 0.0003, Time: 28.1451 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [895/1448], Loss: 0.0003, Time: 28.1541 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [900/1448], Loss: 0.0003, Time: 28.1631 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [905/1448], Loss: 0.0002, Time: 28.1721 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [910/1448], Loss: 0.0002, Time: 28.1811 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [915/1448], Loss: 0.0002, Time: 28.1901 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [920/1448], Loss: 0.0002, Time: 28.1991 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [925/1448], Loss: 0.0001, Time: 28.2081 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [930/1448], Loss: 0.0001, Time: 28.2171 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [935/1448], Loss: 0.0001, Time: 28.2261 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [940/1448], Loss: 0.0001, Time: 28.2351 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [945/1448], Loss: 0.0001, Time: 28.2431 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [950/1448], Loss: 0.0001, Time: 28.2531 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [955/1448], Loss: 0.0001, Time: 28.2620 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [960/1448], Loss: 0.0001, Time: 28.2720 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [965/1448], Loss: 0.0001, Time: 28.2810 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [970/1448], Loss: 0.0001, Time: 28.2900 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [975/1448], Loss: 0.0002, Time: 28.2990 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [980/1448], Loss: 0.0002, Time: 28.3080 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [985/1448], Loss: 0.0002, Time: 28.3180 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [990/1448], Loss: 0.0002, Time: 28.3270 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [995/1448], Loss: 0.0002, Time: 28.3360 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1000/1448], Loss: 0.0002, Time: 28.3450 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1005/1448], Loss: 0.0002, Time: 28.3540 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1010/1448], Loss: 0.0002, Time: 28.3620 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1015/1448], Loss: 0.0002, Time: 28.3710 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1020/1448], Loss: 0.0002, Time: 28.3800 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1025/1448], Loss: 0.0002, Time: 28.3890 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1030/1448], Loss: 0.0002, Time: 28.3980 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1035/1448], Loss: 0.0002, Time: 28.4070 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1040/1448], Loss: 0.0002, Time: 28.4160 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1045/1448], Loss: 0.0002, Time: 28.4249 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1050/1448], Loss: 0.0002, Time: 28.4339 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1055/1448], Loss: 0.0002, Time: 28.4429 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1060/1448], Loss: 0.0002, Time: 28.4519 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1065/1448], Loss: 0.0002, Time: 28.4619 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1070/1448], Loss: 0.0002, Time: 28.4709 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1075/1448], Loss: 0.0002, Time: 28.4799 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1080/1448], Loss: 0.0001, Time: 28.4889 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1085/1448], Loss: 0.0001, Time: 28.4989 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1090/1448], Loss: 0.0001, Time: 28.5079 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1095/1448], Loss: 0.0001, Time: 28.5169 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1100/1448], Loss: 0.0001, Time: 28.5279 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1105/1448], Loss: 0.0001, Time: 28.5378 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1110/1448], Loss: 0.0001, Time: 28.5468 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1115/1448], Loss: 0.0001, Time: 28.5558 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1120/1448], Loss: 0.0000, Time: 28.5648 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1125/1448], Loss: 0.0000, Time: 28.5728 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1130/1448], Loss: 0.0000, Time: 28.5818 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1135/1448], Loss: 0.0000, Time: 28.5908 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1140/1448], Loss: 0.0000, Time: 28.5998 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1145/1448], Loss: 0.0000, Time: 28.6088 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1150/1448], Loss: 0.0000, Time: 28.6178 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1155/1448], Loss: 0.0000, Time: 28.6268 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1160/1448], Loss: 0.0000, Time: 28.6358 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1165/1448], Loss: 0.0000, Time: 28.6448 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1170/1448], Loss: 0.0000, Time: 28.6538 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1175/1448], Loss: 0.0000, Time: 28.6638 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1180/1448], Loss: 0.0000, Time: 28.6728 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1185/1448], Loss: 0.0001, Time: 28.6818 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1190/1448], Loss: 0.0001, Time: 28.6908 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1195/1448], Loss: 0.0001, Time: 28.6997 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1200/1448], Loss: 0.0001, Time: 28.7087 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1205/1448], Loss: 0.0001, Time: 28.7187 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1210/1448], Loss: 0.0001, Time: 28.7277 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1215/1448], Loss: 0.0001, Time: 28.7367 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1220/1448], Loss: 0.0001, Time: 28.7457 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1225/1448], Loss: 0.0001, Time: 28.7547 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1230/1448], Loss: 0.0002, Time: 28.7637 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1235/1448], Loss: 0.0002, Time: 28.7727 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1240/1448], Loss: 0.0002, Time: 28.7817 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1245/1448], Loss: 0.0002, Time: 28.7907 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1250/1448], Loss: 0.0002, Time: 28.7997 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1255/1448], Loss: 0.0001, Time: 28.8087 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1260/1448], Loss: 0.0001, Time: 28.8177 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1265/1448], Loss: 0.0001, Time: 28.8267 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1270/1448], Loss: 0.0001, Time: 28.8357 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1275/1448], Loss: 0.0001, Time: 28.8447 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1280/1448], Loss: 0.0001, Time: 28.8537 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1285/1448], Loss: 0.0002, Time: 28.8636 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1290/1448], Loss: 0.0002, Time: 28.8726 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1295/1448], Loss: 0.0003, Time: 28.8816 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1300/1448], Loss: 0.0003, Time: 28.8906 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1305/1448], Loss: 0.0003, Time: 28.8996 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1310/1448], Loss: 0.0002, Time: 28.9096 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1315/1448], Loss: 0.0002, Time: 28.9186 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1320/1448], Loss: 0.0002, Time: 28.9266 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1325/1448], Loss: 0.0002, Time: 28.9366 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1330/1448], Loss: 0.0001, Time: 28.9456 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1335/1448], Loss: 0.0001, Time: 28.9536 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1340/1448], Loss: 0.0001, Time: 28.9636 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1345/1448], Loss: 0.0001, Time: 28.9716 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1350/1448], Loss: 0.0001, Time: 28.9806 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1355/1448], Loss: 0.0001, Time: 28.9896 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1360/1448], Loss: 0.0001, Time: 28.9996 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1365/1448], Loss: 0.0001, Time: 29.0076 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1370/1448], Loss: 0.0000, Time: 29.0166 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1375/1448], Loss: 0.0000, Time: 29.0255 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1380/1448], Loss: 0.0000, Time: 29.0365 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1385/1448], Loss: 0.0000, Time: 29.0465 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1390/1448], Loss: 0.0001, Time: 29.0565 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1395/1448], Loss: 0.0001, Time: 29.0655 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1400/1448], Loss: 0.0001, Time: 29.0745 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1405/1448], Loss: 0.0001, Time: 29.0835 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1410/1448], Loss: 0.0001, Time: 29.0935 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1415/1448], Loss: 0.0001, Time: 29.1035 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1420/1448], Loss: 0.0001, Time: 29.1125 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1425/1448], Loss: 0.0001, Time: 29.1215 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1430/1448], Loss: 0.4931, Time: 29.1305 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1435/1448], Loss: 0.0001, Time: 29.1385 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1440/1448], Loss: 0.0001, Time: 29.1475 secs, learning rate: 0.0010\n",
      "Epoch [8/10], Step [1445/1448], Loss: 0.0001, Time: 29.1565 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [5/1448], Loss: 0.0001, Time: 30.1828 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [10/1448], Loss: 0.0001, Time: 30.1918 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [15/1448], Loss: 0.0001, Time: 30.2008 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [20/1448], Loss: 0.0001, Time: 30.2098 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [25/1448], Loss: 0.0002, Time: 30.2188 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [30/1448], Loss: 0.0002, Time: 30.2288 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [35/1448], Loss: 0.0002, Time: 30.2378 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [40/1448], Loss: 0.0001, Time: 30.2468 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [45/1448], Loss: 0.0001, Time: 30.2558 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [50/1448], Loss: 0.0002, Time: 30.2658 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [55/1448], Loss: 0.0003, Time: 30.2748 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [60/1448], Loss: 0.0003, Time: 30.2838 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [65/1448], Loss: 0.0004, Time: 30.2928 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [70/1448], Loss: 0.0003, Time: 30.3018 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [75/1448], Loss: 0.0004, Time: 30.3108 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [80/1448], Loss: 0.0004, Time: 30.3198 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [85/1448], Loss: 0.0004, Time: 30.3287 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [90/1448], Loss: 0.0004, Time: 30.3377 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [95/1448], Loss: 0.0004, Time: 30.3477 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [100/1448], Loss: 0.0003, Time: 30.3567 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [105/1448], Loss: 0.0003, Time: 30.3657 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [110/1448], Loss: 0.0003, Time: 30.3767 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [115/1448], Loss: 0.0002, Time: 30.3867 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [120/1448], Loss: 0.0002, Time: 30.3957 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [125/1448], Loss: 0.0002, Time: 30.4047 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [130/1448], Loss: 0.0001, Time: 30.4137 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [135/1448], Loss: 0.0002, Time: 30.4237 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [140/1448], Loss: 0.0002, Time: 30.4327 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [145/1448], Loss: 0.0003, Time: 30.4417 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [150/1448], Loss: 0.0003, Time: 30.4507 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [155/1448], Loss: 0.0003, Time: 30.4597 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [160/1448], Loss: 0.0003, Time: 30.4687 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [165/1448], Loss: 0.0003, Time: 30.4777 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [170/1448], Loss: 0.0003, Time: 30.4866 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [175/1448], Loss: 0.0003, Time: 30.4956 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [180/1448], Loss: 0.0004, Time: 30.5046 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [185/1448], Loss: 0.0005, Time: 30.5136 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [190/1448], Loss: 0.0005, Time: 30.5226 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [195/1448], Loss: 0.0005, Time: 30.5316 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [200/1448], Loss: 0.0004, Time: 30.5396 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [205/1448], Loss: 0.0004, Time: 30.5486 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [210/1448], Loss: 0.0004, Time: 30.5586 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [215/1448], Loss: 0.0003, Time: 30.5686 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [220/1448], Loss: 0.0003, Time: 30.5786 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [225/1448], Loss: 0.0002, Time: 30.5876 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [230/1448], Loss: 0.0002, Time: 30.5966 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [235/1448], Loss: 0.0002, Time: 30.6056 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [240/1448], Loss: 0.0002, Time: 30.6146 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [245/1448], Loss: 0.0001, Time: 30.6236 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [250/1448], Loss: 0.0001, Time: 30.6326 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [255/1448], Loss: 0.0001, Time: 30.6426 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [260/1448], Loss: 0.0001, Time: 30.6525 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [265/1448], Loss: 0.0001, Time: 30.6615 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [270/1448], Loss: 0.0001, Time: 30.6705 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [275/1448], Loss: 0.0001, Time: 30.6795 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [280/1448], Loss: 0.0001, Time: 30.6885 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [285/1448], Loss: 0.0001, Time: 30.6975 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [290/1448], Loss: 0.0001, Time: 30.7065 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [295/1448], Loss: 0.0001, Time: 30.7155 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [300/1448], Loss: 0.0001, Time: 30.7235 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [305/1448], Loss: 0.0001, Time: 30.7325 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [310/1448], Loss: 0.0001, Time: 30.7415 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [315/1448], Loss: 0.0002, Time: 30.7505 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [320/1448], Loss: 0.0003, Time: 30.7605 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [325/1448], Loss: 0.0004, Time: 30.7695 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [330/1448], Loss: 0.0006, Time: 30.7785 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [335/1448], Loss: 0.0006, Time: 30.7885 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [340/1448], Loss: 0.4738, Time: 30.7985 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [345/1448], Loss: 0.0009, Time: 30.8085 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [350/1448], Loss: 0.0010, Time: 30.8174 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [355/1448], Loss: 0.0010, Time: 30.8264 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [360/1448], Loss: 0.0010, Time: 30.8354 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [365/1448], Loss: 0.0009, Time: 30.8444 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [370/1448], Loss: 0.0008, Time: 30.8534 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [375/1448], Loss: 0.0007, Time: 30.8624 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [380/1448], Loss: 0.0007, Time: 30.8714 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [385/1448], Loss: 0.0006, Time: 30.8804 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [390/1448], Loss: 0.4780, Time: 30.8893 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [395/1448], Loss: 0.0006, Time: 30.8983 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [400/1448], Loss: 0.0006, Time: 30.9073 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [405/1448], Loss: 0.4776, Time: 30.9163 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [410/1448], Loss: 0.0006, Time: 30.9253 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [415/1448], Loss: 0.0008, Time: 30.9343 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [420/1448], Loss: 0.0008, Time: 30.9433 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [425/1448], Loss: 0.4728, Time: 30.9523 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [430/1448], Loss: 0.0009, Time: 30.9623 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [435/1448], Loss: 0.0009, Time: 30.9713 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [440/1448], Loss: 0.0009, Time: 30.9803 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [445/1448], Loss: 0.0008, Time: 30.9893 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [450/1448], Loss: 0.0007, Time: 30.9983 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [455/1448], Loss: 0.0007, Time: 31.0073 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [460/1448], Loss: 0.0006, Time: 31.0173 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [465/1448], Loss: 0.0005, Time: 31.0253 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [470/1448], Loss: 0.0005, Time: 31.0352 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [475/1448], Loss: 0.0004, Time: 31.0442 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [480/1448], Loss: 0.0004, Time: 31.0532 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [485/1448], Loss: 0.0003, Time: 31.0622 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [490/1448], Loss: 0.0003, Time: 31.0722 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [495/1448], Loss: 0.0002, Time: 31.0822 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [500/1448], Loss: 0.0002, Time: 31.0912 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [505/1448], Loss: 0.0002, Time: 31.1002 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [510/1448], Loss: 0.0002, Time: 31.1102 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [515/1448], Loss: 0.0001, Time: 31.1192 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [520/1448], Loss: 0.0001, Time: 31.1282 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [525/1448], Loss: 0.0001, Time: 31.1372 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [530/1448], Loss: 0.0001, Time: 31.1462 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [535/1448], Loss: 0.0001, Time: 31.1542 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [540/1448], Loss: 0.0001, Time: 31.1642 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [545/1448], Loss: 0.0001, Time: 31.1732 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [550/1448], Loss: 0.0001, Time: 31.1822 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [555/1448], Loss: 0.0000, Time: 31.1921 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [560/1448], Loss: 0.0000, Time: 31.2011 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [565/1448], Loss: 0.0000, Time: 31.2101 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [570/1448], Loss: 0.0000, Time: 31.2201 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [575/1448], Loss: 0.4950, Time: 31.2291 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [580/1448], Loss: 0.0001, Time: 31.2381 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [585/1448], Loss: 0.0001, Time: 31.2471 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [590/1448], Loss: 0.4872, Time: 31.2561 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [595/1448], Loss: 0.0003, Time: 31.2651 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [600/1448], Loss: 0.0003, Time: 31.2741 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [605/1448], Loss: 0.0003, Time: 31.2831 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [610/1448], Loss: 0.0003, Time: 31.2921 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [615/1448], Loss: 0.0003, Time: 31.3011 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [620/1448], Loss: 0.0003, Time: 31.3101 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [625/1448], Loss: 0.0002, Time: 31.3191 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [630/1448], Loss: 0.0002, Time: 31.3281 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [635/1448], Loss: 0.0003, Time: 31.3371 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [640/1448], Loss: 0.0003, Time: 31.3461 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [645/1448], Loss: 0.0003, Time: 31.3550 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [650/1448], Loss: 0.0003, Time: 31.3650 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [655/1448], Loss: 0.0002, Time: 31.3740 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [660/1448], Loss: 0.0002, Time: 31.3830 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [665/1448], Loss: 0.0002, Time: 31.3910 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [670/1448], Loss: 0.0002, Time: 31.4010 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [675/1448], Loss: 0.0001, Time: 31.4100 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [680/1448], Loss: 0.0001, Time: 31.4200 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [685/1448], Loss: 0.0001, Time: 31.4290 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [690/1448], Loss: 0.0001, Time: 31.4380 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [695/1448], Loss: 0.0001, Time: 31.4470 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [700/1448], Loss: 0.0001, Time: 31.4560 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [705/1448], Loss: 0.0001, Time: 31.4650 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [710/1448], Loss: 0.0001, Time: 31.4740 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [715/1448], Loss: 0.0000, Time: 31.4830 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [720/1448], Loss: 0.0000, Time: 31.4916 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [725/1448], Loss: 0.0000, Time: 31.5006 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [730/1448], Loss: 0.0000, Time: 31.5086 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [735/1448], Loss: 0.0000, Time: 31.5186 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [740/1448], Loss: 0.0000, Time: 31.5276 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [745/1448], Loss: 0.0000, Time: 31.5366 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [750/1448], Loss: 0.0000, Time: 31.5446 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [755/1448], Loss: 0.0000, Time: 31.5556 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [760/1448], Loss: 0.0000, Time: 31.5646 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [765/1448], Loss: 0.0000, Time: 31.5746 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [770/1448], Loss: 0.0000, Time: 31.5846 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [775/1448], Loss: 0.0001, Time: 31.5946 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [780/1448], Loss: 0.0001, Time: 31.6035 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [785/1448], Loss: 0.0001, Time: 31.6135 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [790/1448], Loss: 0.0001, Time: 31.6225 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [795/1448], Loss: 0.0001, Time: 31.6315 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [800/1448], Loss: 0.0000, Time: 31.6405 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [805/1448], Loss: 0.0000, Time: 31.6485 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [810/1448], Loss: 0.0000, Time: 31.6585 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [815/1448], Loss: 0.0000, Time: 31.6675 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [820/1448], Loss: 0.0000, Time: 31.6765 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [825/1448], Loss: 0.0000, Time: 31.6845 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [830/1448], Loss: 0.0000, Time: 31.6935 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [835/1448], Loss: 0.0000, Time: 31.7025 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [840/1448], Loss: 0.0000, Time: 31.7125 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [845/1448], Loss: 0.0000, Time: 31.7205 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [850/1448], Loss: 0.0000, Time: 31.7295 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [855/1448], Loss: 0.0000, Time: 31.7395 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [860/1448], Loss: 0.0000, Time: 31.7485 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [865/1448], Loss: 0.0000, Time: 31.7575 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [870/1448], Loss: 0.0000, Time: 31.7674 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [875/1448], Loss: 0.0000, Time: 31.7764 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [880/1448], Loss: 0.0000, Time: 31.7864 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [885/1448], Loss: 0.0000, Time: 31.7954 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [890/1448], Loss: 0.0000, Time: 31.8044 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [895/1448], Loss: 0.0000, Time: 31.8134 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [900/1448], Loss: 0.0000, Time: 31.8224 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [905/1448], Loss: 0.0000, Time: 31.8314 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [910/1448], Loss: 0.0000, Time: 31.8394 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [915/1448], Loss: 0.0000, Time: 31.8484 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [920/1448], Loss: 0.0000, Time: 31.8574 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [925/1448], Loss: 0.0000, Time: 31.8664 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [930/1448], Loss: 0.0000, Time: 31.8754 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [935/1448], Loss: 0.0000, Time: 31.8844 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [940/1448], Loss: 0.0000, Time: 31.8934 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [945/1448], Loss: 0.0000, Time: 31.9024 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [950/1448], Loss: 0.0000, Time: 31.9114 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [955/1448], Loss: 0.0000, Time: 31.9204 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [960/1448], Loss: 0.0000, Time: 31.9303 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [965/1448], Loss: 0.0000, Time: 31.9393 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [970/1448], Loss: 0.0000, Time: 31.9483 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [975/1448], Loss: 0.0000, Time: 31.9573 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [980/1448], Loss: 0.0000, Time: 31.9673 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [985/1448], Loss: 0.0000, Time: 31.9773 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [990/1448], Loss: 0.0000, Time: 31.9863 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [995/1448], Loss: 0.0000, Time: 31.9953 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1000/1448], Loss: 0.0000, Time: 32.0043 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1005/1448], Loss: 0.0000, Time: 32.0133 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1010/1448], Loss: 0.0000, Time: 32.0213 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1015/1448], Loss: 0.0000, Time: 32.0303 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1020/1448], Loss: 0.0000, Time: 32.0393 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1025/1448], Loss: 0.0000, Time: 32.0483 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1030/1448], Loss: 0.0000, Time: 32.0573 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1035/1448], Loss: 0.0000, Time: 32.0663 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1040/1448], Loss: 0.0000, Time: 32.0753 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1045/1448], Loss: 0.0000, Time: 32.0863 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1050/1448], Loss: 0.0001, Time: 32.0962 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1055/1448], Loss: 0.4913, Time: 32.1052 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1060/1448], Loss: 0.0002, Time: 32.1142 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1065/1448], Loss: 0.0003, Time: 32.1232 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1070/1448], Loss: 0.0003, Time: 32.1332 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1075/1448], Loss: 0.0004, Time: 32.1422 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1080/1448], Loss: 0.0004, Time: 32.1512 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1085/1448], Loss: 0.0003, Time: 32.1612 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1090/1448], Loss: 0.0003, Time: 32.1712 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1095/1448], Loss: 0.0003, Time: 32.1802 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1100/1448], Loss: 0.0002, Time: 32.1892 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1105/1448], Loss: 0.0002, Time: 32.1982 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1110/1448], Loss: 0.0002, Time: 32.2072 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1115/1448], Loss: 0.0002, Time: 32.2162 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1120/1448], Loss: 0.0001, Time: 32.2252 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1125/1448], Loss: 0.0001, Time: 32.2342 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1130/1448], Loss: 0.0001, Time: 32.2432 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1135/1448], Loss: 0.0001, Time: 32.2522 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1140/1448], Loss: 0.0002, Time: 32.2609 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1145/1448], Loss: 0.0002, Time: 32.2699 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1150/1448], Loss: 0.0002, Time: 32.2790 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1155/1448], Loss: 0.0002, Time: 32.2880 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1160/1448], Loss: 0.0003, Time: 32.2970 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1165/1448], Loss: 0.0003, Time: 32.3060 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1170/1448], Loss: 0.0002, Time: 32.3140 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1175/1448], Loss: 0.0002, Time: 32.3230 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1180/1448], Loss: 0.0003, Time: 32.3330 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1185/1448], Loss: 0.0003, Time: 32.3425 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1190/1448], Loss: 0.0003, Time: 32.3515 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1195/1448], Loss: 0.0003, Time: 32.3615 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1200/1448], Loss: 0.0003, Time: 32.3705 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1205/1448], Loss: 0.0002, Time: 32.3815 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1210/1448], Loss: 0.0002, Time: 32.3915 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1215/1448], Loss: 0.0002, Time: 32.4005 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1220/1448], Loss: 0.0001, Time: 32.4095 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1225/1448], Loss: 0.0001, Time: 32.4185 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1230/1448], Loss: 0.0001, Time: 32.4275 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1235/1448], Loss: 0.0001, Time: 32.4365 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1240/1448], Loss: 0.0001, Time: 32.4454 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1245/1448], Loss: 0.0001, Time: 32.4544 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1250/1448], Loss: 0.0001, Time: 32.4634 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1255/1448], Loss: 0.0001, Time: 32.4724 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1260/1448], Loss: 0.0000, Time: 32.4814 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1265/1448], Loss: 0.0000, Time: 32.4904 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1270/1448], Loss: 0.0000, Time: 32.4994 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1275/1448], Loss: 0.0000, Time: 32.5084 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1280/1448], Loss: 0.0000, Time: 32.5184 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1285/1448], Loss: 0.0000, Time: 32.5274 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1290/1448], Loss: 0.0001, Time: 32.5364 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1295/1448], Loss: 0.0001, Time: 32.5454 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1300/1448], Loss: 0.0002, Time: 32.5544 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1305/1448], Loss: 0.0002, Time: 32.5644 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1310/1448], Loss: 0.0002, Time: 32.5734 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1315/1448], Loss: 0.0002, Time: 32.5824 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1320/1448], Loss: 0.0002, Time: 32.5934 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1325/1448], Loss: 0.0001, Time: 32.6034 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1330/1448], Loss: 0.0001, Time: 32.6123 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1335/1448], Loss: 0.0001, Time: 32.6213 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1340/1448], Loss: 0.0001, Time: 32.6303 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1345/1448], Loss: 0.0002, Time: 32.6393 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1350/1448], Loss: 0.0002, Time: 32.6483 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1355/1448], Loss: 0.0002, Time: 32.6573 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1360/1448], Loss: 0.0002, Time: 32.6673 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1365/1448], Loss: 0.0001, Time: 32.6753 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1370/1448], Loss: 0.0001, Time: 32.6843 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1375/1448], Loss: 0.0001, Time: 32.6933 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1380/1448], Loss: 0.0001, Time: 32.7023 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1385/1448], Loss: 0.0001, Time: 32.7123 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1390/1448], Loss: 0.0001, Time: 32.7213 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1395/1448], Loss: 0.0001, Time: 32.7303 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1400/1448], Loss: 0.0001, Time: 32.7393 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1405/1448], Loss: 0.0000, Time: 32.7483 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1410/1448], Loss: 0.0000, Time: 32.7573 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1415/1448], Loss: 0.4941, Time: 32.7662 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1420/1448], Loss: 0.0001, Time: 32.7762 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1425/1448], Loss: 0.0001, Time: 32.7852 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1430/1448], Loss: 0.0001, Time: 32.7942 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1435/1448], Loss: 0.0001, Time: 32.8032 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1440/1448], Loss: 0.0001, Time: 32.8122 secs, learning rate: 0.0010\n",
      "Epoch [9/10], Step [1445/1448], Loss: 0.0001, Time: 32.8212 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [5/1448], Loss: 0.0001, Time: 33.8456 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [10/1448], Loss: 0.0001, Time: 33.8546 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [15/1448], Loss: 0.0001, Time: 33.8636 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [20/1448], Loss: 0.0000, Time: 33.8726 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [25/1448], Loss: 0.0000, Time: 33.8816 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [30/1448], Loss: 0.0000, Time: 33.8906 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [35/1448], Loss: 0.0000, Time: 33.8996 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [40/1448], Loss: 0.0000, Time: 33.9085 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [45/1448], Loss: 0.0000, Time: 33.9185 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [50/1448], Loss: 0.0000, Time: 33.9275 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [55/1448], Loss: 0.0000, Time: 33.9365 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [60/1448], Loss: 0.0000, Time: 33.9455 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [65/1448], Loss: 0.0000, Time: 33.9545 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [70/1448], Loss: 0.0000, Time: 33.9635 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [75/1448], Loss: 0.0000, Time: 33.9735 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [80/1448], Loss: 0.0000, Time: 33.9825 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [85/1448], Loss: 0.0000, Time: 33.9915 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [90/1448], Loss: 0.0000, Time: 34.0005 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [95/1448], Loss: 0.0001, Time: 34.0095 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [100/1448], Loss: 0.0001, Time: 34.0195 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [105/1448], Loss: 0.0001, Time: 34.0285 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [110/1448], Loss: 0.0000, Time: 34.0375 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [115/1448], Loss: 0.0000, Time: 34.0475 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [120/1448], Loss: 0.0000, Time: 34.0555 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [125/1448], Loss: 0.0000, Time: 34.0655 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [130/1448], Loss: 0.0000, Time: 34.0744 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [135/1448], Loss: 0.0000, Time: 34.0834 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [140/1448], Loss: 0.0000, Time: 34.0924 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [145/1448], Loss: 0.0000, Time: 34.1014 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [150/1448], Loss: 0.0000, Time: 34.1134 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [155/1448], Loss: 0.0000, Time: 34.1244 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [160/1448], Loss: 0.0000, Time: 34.1344 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [165/1448], Loss: 0.0000, Time: 34.1444 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [170/1448], Loss: 0.0000, Time: 34.1534 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [175/1448], Loss: 0.0000, Time: 34.1624 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [180/1448], Loss: 0.0000, Time: 34.1714 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [185/1448], Loss: 0.0000, Time: 34.1804 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [190/1448], Loss: 0.0000, Time: 34.1894 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [195/1448], Loss: 0.0000, Time: 34.1984 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [200/1448], Loss: 0.0000, Time: 34.2074 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [205/1448], Loss: 0.0000, Time: 34.2164 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [210/1448], Loss: 0.0000, Time: 34.2254 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [215/1448], Loss: 0.0000, Time: 34.2344 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [220/1448], Loss: 0.0000, Time: 34.2444 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [225/1448], Loss: 0.0000, Time: 34.2531 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [230/1448], Loss: 0.0000, Time: 34.2621 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [235/1448], Loss: 0.0000, Time: 34.2711 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [240/1448], Loss: 0.0000, Time: 34.2811 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [245/1448], Loss: 0.0000, Time: 34.2901 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [250/1448], Loss: 0.0000, Time: 34.2991 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [255/1448], Loss: 0.0000, Time: 34.3081 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [260/1448], Loss: 0.0000, Time: 34.3170 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [265/1448], Loss: 0.0000, Time: 34.3260 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [270/1448], Loss: 0.0000, Time: 34.3360 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [275/1448], Loss: 0.0000, Time: 34.3450 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [280/1448], Loss: 0.0001, Time: 34.3540 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [285/1448], Loss: 0.0001, Time: 34.3630 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [290/1448], Loss: 0.0001, Time: 34.3720 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [295/1448], Loss: 0.0001, Time: 34.3800 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [300/1448], Loss: 0.0001, Time: 34.3890 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [305/1448], Loss: 0.0001, Time: 34.3980 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [310/1448], Loss: 0.0001, Time: 34.4070 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [315/1448], Loss: 0.0002, Time: 34.4160 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [320/1448], Loss: 0.0002, Time: 34.4240 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [325/1448], Loss: 0.0002, Time: 34.4340 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [330/1448], Loss: 0.0003, Time: 34.4430 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [335/1448], Loss: 0.0002, Time: 34.4530 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [340/1448], Loss: 0.0002, Time: 34.4620 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [345/1448], Loss: 0.0002, Time: 34.4710 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [350/1448], Loss: 0.0002, Time: 34.4799 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [355/1448], Loss: 0.0002, Time: 34.4899 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [360/1448], Loss: 0.0001, Time: 34.4989 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [365/1448], Loss: 0.0001, Time: 34.5079 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [370/1448], Loss: 0.4901, Time: 34.5179 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [375/1448], Loss: 0.0001, Time: 34.5269 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [380/1448], Loss: 0.0002, Time: 34.5359 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [385/1448], Loss: 0.0002, Time: 34.5449 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [390/1448], Loss: 0.0002, Time: 34.5539 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [395/1448], Loss: 0.0002, Time: 34.5629 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [400/1448], Loss: 0.0001, Time: 34.5719 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [405/1448], Loss: 0.0001, Time: 34.5809 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [410/1448], Loss: 0.0001, Time: 34.5899 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [415/1448], Loss: 0.0001, Time: 34.5989 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [420/1448], Loss: 0.0001, Time: 34.6079 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [425/1448], Loss: 0.0001, Time: 34.6169 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [430/1448], Loss: 0.0001, Time: 34.6269 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [435/1448], Loss: 0.0000, Time: 34.6379 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [440/1448], Loss: 0.0000, Time: 34.6468 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [445/1448], Loss: 0.0000, Time: 34.6558 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [450/1448], Loss: 0.0001, Time: 34.6658 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [455/1448], Loss: 0.0002, Time: 34.6748 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [460/1448], Loss: 0.0002, Time: 34.6838 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [465/1448], Loss: 0.0002, Time: 34.6938 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [470/1448], Loss: 0.0003, Time: 34.7028 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [475/1448], Loss: 0.0003, Time: 34.7118 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [480/1448], Loss: 0.0004, Time: 34.7208 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [485/1448], Loss: 0.0003, Time: 34.7298 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [490/1448], Loss: 0.0003, Time: 34.7388 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [495/1448], Loss: 0.0004, Time: 34.7478 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [500/1448], Loss: 0.0004, Time: 34.7558 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [505/1448], Loss: 0.0004, Time: 34.7648 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [510/1448], Loss: 0.0004, Time: 34.7738 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [515/1448], Loss: 0.0005, Time: 34.7828 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [520/1448], Loss: 0.0005, Time: 34.7918 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [525/1448], Loss: 0.0005, Time: 34.8008 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [530/1448], Loss: 0.0004, Time: 34.8097 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [535/1448], Loss: 0.0004, Time: 34.8207 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [540/1448], Loss: 0.0003, Time: 34.8307 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [545/1448], Loss: 0.0003, Time: 34.8387 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [550/1448], Loss: 0.0003, Time: 34.8487 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [555/1448], Loss: 0.0002, Time: 34.8577 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [560/1448], Loss: 0.0002, Time: 34.8667 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [565/1448], Loss: 0.0002, Time: 34.8767 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [570/1448], Loss: 0.0001, Time: 34.8857 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [575/1448], Loss: 0.0001, Time: 34.8947 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [580/1448], Loss: 0.0001, Time: 34.9037 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [585/1448], Loss: 0.0001, Time: 34.9127 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [590/1448], Loss: 0.0001, Time: 34.9217 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [595/1448], Loss: 0.0001, Time: 34.9307 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [600/1448], Loss: 0.0001, Time: 34.9397 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [605/1448], Loss: 0.0001, Time: 34.9487 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [610/1448], Loss: 0.0001, Time: 34.9567 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [615/1448], Loss: 0.0002, Time: 34.9656 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [620/1448], Loss: 0.0003, Time: 34.9746 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [625/1448], Loss: 0.0004, Time: 34.9836 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [630/1448], Loss: 0.0004, Time: 34.9924 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [635/1448], Loss: 0.0004, Time: 35.0014 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [640/1448], Loss: 0.0003, Time: 35.0104 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [645/1448], Loss: 0.0003, Time: 35.0204 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [650/1448], Loss: 0.0003, Time: 35.0294 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [655/1448], Loss: 0.0002, Time: 35.0384 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [660/1448], Loss: 0.0002, Time: 35.0484 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [665/1448], Loss: 0.0003, Time: 35.0574 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [670/1448], Loss: 0.0003, Time: 35.0674 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [675/1448], Loss: 0.0003, Time: 35.0764 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [680/1448], Loss: 0.0003, Time: 35.0854 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [685/1448], Loss: 0.0004, Time: 35.0954 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [690/1448], Loss: 0.0004, Time: 35.1034 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [695/1448], Loss: 0.0004, Time: 35.1124 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [700/1448], Loss: 0.0003, Time: 35.1223 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [705/1448], Loss: 0.0003, Time: 35.1313 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [710/1448], Loss: 0.0003, Time: 35.1403 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [715/1448], Loss: 0.0002, Time: 35.1513 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [720/1448], Loss: 0.0003, Time: 35.1602 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [725/1448], Loss: 0.0003, Time: 35.1702 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [730/1448], Loss: 0.0004, Time: 35.1792 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [735/1448], Loss: 0.0004, Time: 35.1882 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [740/1448], Loss: 0.0004, Time: 35.1972 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [745/1448], Loss: 0.0004, Time: 35.2062 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [750/1448], Loss: 0.0004, Time: 35.2162 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [755/1448], Loss: 0.0003, Time: 35.2252 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [760/1448], Loss: 0.0003, Time: 35.2342 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [765/1448], Loss: 0.0003, Time: 35.2442 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [770/1448], Loss: 0.0002, Time: 35.2542 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [775/1448], Loss: 0.0002, Time: 35.2642 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [780/1448], Loss: 0.0002, Time: 35.2732 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [785/1448], Loss: 0.0001, Time: 35.2822 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [790/1448], Loss: 0.0001, Time: 35.2902 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [795/1448], Loss: 0.0001, Time: 35.3001 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [800/1448], Loss: 0.0001, Time: 35.3081 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [805/1448], Loss: 0.0001, Time: 35.3171 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [810/1448], Loss: 0.0001, Time: 35.3261 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [815/1448], Loss: 0.0001, Time: 35.3351 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [820/1448], Loss: 0.0000, Time: 35.3451 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [825/1448], Loss: 0.0000, Time: 35.3541 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [830/1448], Loss: 0.0000, Time: 35.3631 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [835/1448], Loss: 0.0000, Time: 35.3731 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [840/1448], Loss: 0.0000, Time: 35.3831 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [845/1448], Loss: 0.0000, Time: 35.3931 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [850/1448], Loss: 0.0000, Time: 35.4021 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [855/1448], Loss: 0.0000, Time: 35.4111 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [860/1448], Loss: 0.0000, Time: 35.4201 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [865/1448], Loss: 0.0000, Time: 35.4301 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [870/1448], Loss: 0.0000, Time: 35.4391 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [875/1448], Loss: 0.0000, Time: 35.4481 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [880/1448], Loss: 0.0000, Time: 35.4581 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [885/1448], Loss: 0.0000, Time: 35.4670 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [890/1448], Loss: 0.0000, Time: 35.4760 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [895/1448], Loss: 0.0001, Time: 35.4850 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [900/1448], Loss: 0.0001, Time: 35.4940 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [905/1448], Loss: 0.0001, Time: 35.5030 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [910/1448], Loss: 0.0000, Time: 35.5110 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [915/1448], Loss: 0.0000, Time: 35.5210 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [920/1448], Loss: 0.0000, Time: 35.5290 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [925/1448], Loss: 0.0000, Time: 35.5380 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [930/1448], Loss: 0.0000, Time: 35.5470 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [935/1448], Loss: 0.0000, Time: 35.5560 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [940/1448], Loss: 0.0000, Time: 35.5650 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [945/1448], Loss: 0.0001, Time: 35.5740 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [950/1448], Loss: 0.0001, Time: 35.5840 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [955/1448], Loss: 0.0002, Time: 35.5930 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [960/1448], Loss: 0.0002, Time: 35.6020 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [965/1448], Loss: 0.0002, Time: 35.6110 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [970/1448], Loss: 0.0002, Time: 35.6200 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [975/1448], Loss: 0.0002, Time: 35.6289 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [980/1448], Loss: 0.0002, Time: 35.6379 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [985/1448], Loss: 0.0003, Time: 35.6489 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [990/1448], Loss: 0.0003, Time: 35.6589 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [995/1448], Loss: 0.0002, Time: 35.6689 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1000/1448], Loss: 0.0002, Time: 35.6789 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1005/1448], Loss: 0.0002, Time: 35.6869 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1010/1448], Loss: 0.0002, Time: 35.6959 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1015/1448], Loss: 0.0001, Time: 35.7049 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1020/1448], Loss: 0.0001, Time: 35.7139 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1025/1448], Loss: 0.0001, Time: 35.7229 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1030/1448], Loss: 0.0001, Time: 35.7319 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1035/1448], Loss: 0.0001, Time: 35.7399 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1040/1448], Loss: 0.0001, Time: 35.7489 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1045/1448], Loss: 0.0001, Time: 35.7579 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1050/1448], Loss: 0.0001, Time: 35.7679 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1055/1448], Loss: 0.0001, Time: 35.7779 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1060/1448], Loss: 0.0001, Time: 35.7869 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1065/1448], Loss: 0.0001, Time: 35.7958 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1070/1448], Loss: 0.0001, Time: 35.8048 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1075/1448], Loss: 0.0001, Time: 35.8148 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1080/1448], Loss: 0.0001, Time: 35.8248 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1085/1448], Loss: 0.0001, Time: 35.8338 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1090/1448], Loss: 0.0001, Time: 35.8428 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1095/1448], Loss: 0.0001, Time: 35.8508 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1100/1448], Loss: 0.0000, Time: 35.8598 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1105/1448], Loss: 0.0000, Time: 35.8698 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1110/1448], Loss: 0.0000, Time: 35.8788 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1115/1448], Loss: 0.0000, Time: 35.8878 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1120/1448], Loss: 0.0000, Time: 35.8968 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1125/1448], Loss: 0.4943, Time: 35.9048 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1130/1448], Loss: 0.0002, Time: 35.9138 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1135/1448], Loss: 0.4838, Time: 35.9228 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1140/1448], Loss: 0.0004, Time: 35.9318 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1145/1448], Loss: 0.0005, Time: 35.9408 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1150/1448], Loss: 0.0006, Time: 35.9498 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1155/1448], Loss: 0.0006, Time: 35.9597 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1160/1448], Loss: 0.4777, Time: 35.9687 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1165/1448], Loss: 0.0006, Time: 35.9777 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1170/1448], Loss: 0.0006, Time: 35.9877 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1175/1448], Loss: 0.0006, Time: 35.9977 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1180/1448], Loss: 0.0005, Time: 36.0077 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1185/1448], Loss: 0.0005, Time: 36.0167 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1190/1448], Loss: 0.0004, Time: 36.0257 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1195/1448], Loss: 0.0004, Time: 36.0347 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1200/1448], Loss: 0.0003, Time: 36.0437 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1205/1448], Loss: 0.0003, Time: 36.0527 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1210/1448], Loss: 0.0003, Time: 36.0617 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1215/1448], Loss: 0.0002, Time: 36.0697 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1220/1448], Loss: 0.0002, Time: 36.0787 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1225/1448], Loss: 0.0002, Time: 36.0877 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1230/1448], Loss: 0.0001, Time: 36.0977 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1235/1448], Loss: 0.0001, Time: 36.1057 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1240/1448], Loss: 0.0001, Time: 36.1146 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1245/1448], Loss: 0.0001, Time: 36.1236 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1250/1448], Loss: 0.0001, Time: 36.1326 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1255/1448], Loss: 0.0001, Time: 36.1426 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1260/1448], Loss: 0.0001, Time: 36.1516 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1265/1448], Loss: 0.0000, Time: 36.1616 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1270/1448], Loss: 0.0000, Time: 36.1726 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1275/1448], Loss: 0.0000, Time: 36.1816 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1280/1448], Loss: 0.0000, Time: 36.1906 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1285/1448], Loss: 0.0001, Time: 36.2006 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1290/1448], Loss: 0.0001, Time: 36.2096 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1295/1448], Loss: 0.0001, Time: 36.2196 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1300/1448], Loss: 0.0001, Time: 36.2286 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1305/1448], Loss: 0.0001, Time: 36.2376 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1310/1448], Loss: 0.0001, Time: 36.2456 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1315/1448], Loss: 0.0002, Time: 36.2546 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1320/1448], Loss: 0.0002, Time: 36.2636 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1325/1448], Loss: 0.0003, Time: 36.2726 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1330/1448], Loss: 0.0004, Time: 36.2815 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1335/1448], Loss: 0.0004, Time: 36.2905 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1340/1448], Loss: 0.0004, Time: 36.2995 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1345/1448], Loss: 0.0004, Time: 36.3075 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1350/1448], Loss: 0.0005, Time: 36.3165 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1355/1448], Loss: 0.0005, Time: 36.3255 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1360/1448], Loss: 0.0005, Time: 36.3355 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1365/1448], Loss: 0.0005, Time: 36.3455 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1370/1448], Loss: 0.0004, Time: 36.3545 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1375/1448], Loss: 0.0004, Time: 36.3635 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1380/1448], Loss: 0.0005, Time: 36.3725 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1385/1448], Loss: 0.0005, Time: 36.3825 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1390/1448], Loss: 0.0004, Time: 36.3915 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1395/1448], Loss: 0.0004, Time: 36.4005 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1400/1448], Loss: 0.0004, Time: 36.4095 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1405/1448], Loss: 0.0003, Time: 36.4185 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1410/1448], Loss: 0.0003, Time: 36.4285 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1415/1448], Loss: 0.0004, Time: 36.4365 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1420/1448], Loss: 0.0004, Time: 36.4454 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1425/1448], Loss: 0.0003, Time: 36.4546 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1430/1448], Loss: 0.0003, Time: 36.4636 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1435/1448], Loss: 0.0003, Time: 36.4726 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1440/1448], Loss: 0.0003, Time: 36.4816 secs, learning rate: 0.0010\n",
      "Epoch [10/10], Step [1445/1448], Loss: 0.0003, Time: 36.4906 secs, learning rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# total_step = len(YTrain)\n",
    "total_step = len(YVal)\n",
    "start_time = time.time()\n",
    "model = model.float()\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "loss_tmp = 0\n",
    "norm = 1\n",
    "for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm*outputs, norm*y.float().reshape(1,1,1))\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().reshape(1,1,1))\n",
    "        # loss1 = criterion(norm*outputs, norm*y.float().T)\n",
    "        # loss2 = torch.mean(outputs**2 - y.float().T**2)\n",
    "        # loss = loss1 + loss2\n",
    "\n",
    "        loss_tmp += loss.item()\n",
    "loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ind = np.arange(int(total_step/batch_size))\n",
    "    random.shuffle(ind)\n",
    "    for i,k in enumerate(ind):\n",
    "        # each i is a batch of 128 samples\n",
    "        #x, y = XTrain[k*batch_size:(k+1)*batch_size,:,:], YTrain[k*batch_size:(k+1)*batch_size,:]\n",
    "        x, y = XVal[k*batch_size:(k+1)*batch_size,:,:], YVal[k*batch_size:(k+1)*batch_size,:]\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        # x = nn.functional.normalize(x.float(), p=1.0, dim = 1)\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm*outputs, norm*y.float().reshape(batch_size,1,1))\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().reshape(batch_size,1,1))\n",
    "        # loss1 = criterion(norm*outputs, norm*y.float().reshape(batch_size,1))\n",
    "        # loss2 = torch.sum(abs(outputs - y.float().reshape(batch_size,1)))\n",
    "        # loss = loss1 + loss2\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 5== 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs, learning rate: {:.4f}'\n",
    "                    .format(epoch + 1, num_epochs, i + 1, int(total_step/batch_size), loss.item(), time.time() - start_time, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    loss_tmp = 0\n",
    "    result = []\n",
    "    for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm*outputs, norm*y.float().reshape(1,1,1))\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().reshape(1,1,1))\n",
    "        # loss1 = criterion(norm*outputs, norm*y.float().reshape(1,1,1))\n",
    "        # loss2 = torch.mean(outputs**2 - y.float().reshape(1,1,1)**2)\n",
    "        # loss = loss1 + loss2\n",
    "        \n",
    "        loss_tmp += loss.item()\n",
    "        result.append(outputs[0,0].item())\n",
    "        # result.append(nn.Sigmoid()(outputs[0,0]).item())\n",
    "    loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x232678c4d68>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(loss_train)), loss_train, label = 'Training error')\n",
    "plt.plot(np.arange(0, len(loss_train)+1, int(total_step/batch_size)), loss_val, label = 'Validation error')\n",
    "plt.ylabel('loss', fontsize = 14)\n",
    "plt.xlabel('steps', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "# plt.ylim([0,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x23269249588>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(result)), YVal, label = 'expected')\n",
    "plt.plot(np.arange(len(result)), result, label = 'model output')\n",
    "plt.ylabel('state', fontsize = 14)\n",
    "plt.xlabel('time', fontsize = 14)\n",
    "plt.legend()\n",
    "# plt.ylim([100,120])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x232692b2b38>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(result)), result, label = 'model output')\n",
    "plt.plot(np.arange(len(result)), YVal, label = 'expected')\n",
    "plt.ylabel('state', fontsize = 14)\n",
    "plt.xlabel('time', fontsize = 14)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}