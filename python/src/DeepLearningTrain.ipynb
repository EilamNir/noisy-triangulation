{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation.generate_path import generate_path\n",
    "import matplotlib.pyplot as plt\n",
    "from estimation.distance_sensor import distance_sensors\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575, 1)\n",
      "(4, 3, 4, 575)\n"
     ]
    }
   ],
   "source": [
    "# create test data\n",
    "target_initial_pos = np.array([0, 0, 5000])\n",
    "target_speed_xy = 50\n",
    "target_speed_z = 10\n",
    "target_rot_speed = 3\n",
    "time_res = 0.5\n",
    "\n",
    "path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "path1.add_straight_interval(100)\n",
    "path1.add_xy_turn_interval(90, -np.deg2rad(target_rot_speed))\n",
    "path1.add_straight_interval(100)\n",
    "\n",
    "# create noisy sensors\n",
    "sensors = distance_sensors([[-5000,0,0],[ 400, -7400, 0],[ 800, 800, 0]], 15)\n",
    "sensors.calculate_measurements(path1.path)\n",
    "\n",
    "sample = 4\n",
    "XTest = []\n",
    "for i in np.arange(len(path1.path) - sample + 1):\n",
    "    tmp = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i,:], (1,3))), 0)\n",
    "    tmp = tmp.reshape(4,3,1)\n",
    "    for j in np.arange(1,sample):\n",
    "        matrix = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i+j,:], (1,3))), 0)\n",
    "        matrix = matrix.reshape(4,3,1)\n",
    "        tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "    if i > 0:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = np.concatenate((XTest, tmp), 3)\n",
    "    else:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = tmp\n",
    "\n",
    "YTest = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTest))\n",
    "print(np.shape(XTest))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117733, 1)\n",
      "(4, 3, 4, 117733)\n"
     ]
    }
   ],
   "source": [
    "# create train data\n",
    "run_number = 600\n",
    "XTrain = []\n",
    "YTrain = []\n",
    "for k in np.arange(run_number):\n",
    "    target_initial_pos = np.random.randint(-7000, 7000, size=(1, 3))[0]\n",
    "    sensors_pos = np.random.randint(-7000, 7000, size=(3, 3))[:,:]\n",
    "    target_speed_xy = 50\n",
    "    target_speed_z = 10\n",
    "    target_rot_speed = 3\n",
    "    time_res = 0.5\n",
    "\n",
    "    path1 = generate_path(np.deg2rad(np.random.randint(0,360,size=1)[0]), target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "    path1.add_straight_interval(np.random.randint(0,100,size=1)[0])\n",
    "    path1.add_xy_turn_interval(np.random.randint(0,100,size=1)[0], -random.choice([-1, 1])*np.deg2rad(target_rot_speed))\n",
    "\n",
    "    # create noisy sensors\n",
    "    sensors = distance_sensors(sensors_pos, 20)\n",
    "    sensors.calculate_measurements(path1.path)\n",
    "\n",
    "    sample = 4\n",
    "    for i in np.arange(len(path1.path) - sample + 1):\n",
    "        tmp = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i,:], (1,3))), 0)\n",
    "        tmp = tmp.reshape(4,3,1)\n",
    "        for j in np.arange(1,sample):\n",
    "            matrix = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i+j,:], (1,3))), 0)\n",
    "            matrix = matrix.reshape(4,3,1)\n",
    "            tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "        if len(XTrain):\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = np.concatenate((XTrain, tmp), 3)\n",
    "        else:\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = tmp\n",
    "    if len(YTrain):\n",
    "        YTrain = np.concatenate((YTrain, path1.state_key[sample-1:]), 0)\n",
    "    else:\n",
    "        YTrain = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTrain))\n",
    "print(np.shape(XTrain))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "ind = np.arange(len(YTrain))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XVal = torch.from_numpy(np.transpose(XTest, (3, 2, 0, 1)))\n",
    "YVal = torch.from_numpy(YTest)\n",
    "\n",
    "XTrain = torch.from_numpy(np.transpose(XTrain[:,:,:,ind], (3, 2, 0, 1)))\n",
    "YTrain = torch.from_numpy(YTrain[ind,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# create network\n",
    "class state_estimat(nn.Module):\n",
    "    def __init__(self, d_in, num_classes):\n",
    "        # initialzing the parent object (important!)\n",
    "        super(state_estimat, self).__init__()\n",
    "        # Create a pipeline - a sequence of layers\n",
    "        self.pipe = torch.nn.Sequential(\n",
    "            nn.Conv2d(d_in, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*3*4, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_estimat(\n",
      "  (pipe): Sequential(\n",
      "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters:\n",
    "num_epochs = 60\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "learning_rate_drop_period = 10\n",
    "input_shape = [3,4,3]\n",
    "\n",
    "# Device configuration, as before\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# create model\n",
    "model = state_estimat(d_in=4, num_classes=1).to(device)\n",
    "print(model)\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=learning_rate_drop_period, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def my_loss(target, output):\n",
    "    loss = torch.mean(math.exp(output) - math.exp(target))\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Step [5/229], Loss: 52685.8750, Time: 1.3072 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [10/229], Loss: 1503.5280, Time: 1.7479 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [15/229], Loss: 3560.8777, Time: 2.2052 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [20/229], Loss: 588.9982, Time: 2.6764 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [25/229], Loss: 1062.9678, Time: 3.2010 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [30/229], Loss: 154.9467, Time: 3.7242 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [35/229], Loss: 167.4223, Time: 4.0870 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [40/229], Loss: 203.5834, Time: 4.4553 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [45/229], Loss: 86.3059, Time: 4.9120 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [50/229], Loss: 55.4759, Time: 5.2683 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [55/229], Loss: 68.2989, Time: 5.6531 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [60/229], Loss: 46.4460, Time: 6.0323 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [65/229], Loss: 32.6892, Time: 6.3871 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [70/229], Loss: 37.5682, Time: 6.7439 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [75/229], Loss: 30.1498, Time: 7.0952 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [80/229], Loss: 28.7244, Time: 7.4659 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [85/229], Loss: 25.3392, Time: 7.8192 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [90/229], Loss: 27.1268, Time: 8.1780 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [95/229], Loss: 23.3729, Time: 8.5313 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [100/229], Loss: 22.6067, Time: 8.8861 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [105/229], Loss: 22.3128, Time: 9.3403 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [110/229], Loss: 20.6278, Time: 9.7561 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [115/229], Loss: 19.3705, Time: 10.1293 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [120/229], Loss: 22.7392, Time: 10.4881 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [125/229], Loss: 19.9653, Time: 10.8579 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [130/229], Loss: 17.3227, Time: 11.2152 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [135/229], Loss: 18.8169, Time: 11.5889 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [140/229], Loss: 18.4438, Time: 11.9532 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [145/229], Loss: 15.1837, Time: 12.3380 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [150/229], Loss: 16.2665, Time: 12.7792 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [155/229], Loss: 17.4241, Time: 13.1470 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [160/229], Loss: 15.5693, Time: 13.4943 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [165/229], Loss: 14.7070, Time: 13.8840 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [170/229], Loss: 13.7869, Time: 14.3502 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [175/229], Loss: 14.0046, Time: 14.7220 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [180/229], Loss: 14.7834, Time: 15.0943 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [185/229], Loss: 13.5870, Time: 15.4531 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [190/229], Loss: 13.4970, Time: 15.8698 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [195/229], Loss: 12.4176, Time: 16.2521 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [200/229], Loss: 11.9438, Time: 16.7018 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [205/229], Loss: 12.1653, Time: 17.1500 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [210/229], Loss: 13.4389, Time: 17.7312 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [215/229], Loss: 11.6376, Time: 18.1259 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [220/229], Loss: 12.4027, Time: 18.5332 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [225/229], Loss: 10.8870, Time: 18.8990 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [5/229], Loss: 10.9483, Time: 19.9658 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [10/229], Loss: 10.6573, Time: 20.4530 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [15/229], Loss: 10.2552, Time: 20.8328 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [20/229], Loss: 10.5513, Time: 21.3170 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [25/229], Loss: 10.3478, Time: 21.6848 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [30/229], Loss: 10.9610, Time: 22.3159 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [35/229], Loss: 10.1446, Time: 22.7381 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [40/229], Loss: 9.3105, Time: 23.2278 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [45/229], Loss: 9.7936, Time: 23.7050 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [50/229], Loss: 9.0330, Time: 24.1168 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [55/229], Loss: 9.0346, Time: 24.4601 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [60/229], Loss: 9.3107, Time: 24.8778 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [65/229], Loss: 8.8510, Time: 25.2331 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [70/229], Loss: 7.8030, Time: 25.5569 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [75/229], Loss: 8.7229, Time: 25.8547 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [80/229], Loss: 8.1373, Time: 26.1869 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [85/229], Loss: 8.2468, Time: 26.5077 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [90/229], Loss: 8.3183, Time: 27.0089 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [95/229], Loss: 7.8508, Time: 27.4771 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [100/229], Loss: 7.8033, Time: 27.8839 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [105/229], Loss: 6.5345, Time: 28.2107 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [110/229], Loss: 7.9845, Time: 28.5250 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [115/229], Loss: 7.4709, Time: 28.8148 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [120/229], Loss: 7.6342, Time: 29.1241 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [125/229], Loss: 6.7671, Time: 29.4289 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [130/229], Loss: 6.5428, Time: 29.7238 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [135/229], Loss: 8.0340, Time: 30.0131 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [140/229], Loss: 6.8243, Time: 30.3009 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [145/229], Loss: 7.0457, Time: 30.7511 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [150/229], Loss: 6.8896, Time: 31.7235 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [155/229], Loss: 6.5117, Time: 32.5730 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [160/229], Loss: 7.0379, Time: 33.0357 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [165/229], Loss: 6.0815, Time: 33.3805 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [170/229], Loss: 5.9861, Time: 33.6763 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [175/229], Loss: 6.0348, Time: 33.9881 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [180/229], Loss: 5.4313, Time: 34.2870 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [185/229], Loss: 6.2308, Time: 34.5748 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [190/229], Loss: 5.9664, Time: 34.8936 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [195/229], Loss: 5.8548, Time: 35.1844 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [200/229], Loss: 5.5634, Time: 35.5482 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [205/229], Loss: 5.6616, Time: 35.8510 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [210/229], Loss: 5.9667, Time: 36.1418 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [215/229], Loss: 5.5799, Time: 36.4326 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [220/229], Loss: 5.4512, Time: 36.7215 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [225/229], Loss: 5.7096, Time: 37.0043 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [5/229], Loss: 5.3971, Time: 37.8877 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [10/229], Loss: 5.3948, Time: 38.1826 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [15/229], Loss: 5.5855, Time: 38.4704 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [20/229], Loss: 4.4378, Time: 38.7562 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [25/229], Loss: 4.9933, Time: 39.0560 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [30/229], Loss: 4.5176, Time: 39.3408 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [35/229], Loss: 4.8114, Time: 39.6427 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [40/229], Loss: 4.9426, Time: 39.9285 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [45/229], Loss: 5.0889, Time: 40.2193 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [50/229], Loss: 4.6661, Time: 40.5201 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [55/229], Loss: 4.5814, Time: 40.8289 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [60/229], Loss: 4.9158, Time: 41.1277 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [65/229], Loss: 4.3949, Time: 41.4186 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [70/229], Loss: 4.3183, Time: 41.7224 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [75/229], Loss: 4.2472, Time: 42.0102 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [80/229], Loss: 4.6890, Time: 42.3100 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [85/229], Loss: 4.1081, Time: 42.6108 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [90/229], Loss: 4.4386, Time: 42.8966 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [95/229], Loss: 4.1895, Time: 43.2145 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [100/229], Loss: 3.7652, Time: 43.5253 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [105/229], Loss: 4.3319, Time: 43.8351 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [110/229], Loss: 4.4680, Time: 44.1289 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [115/229], Loss: 4.0368, Time: 44.4187 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [120/229], Loss: 3.9423, Time: 44.7145 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [125/229], Loss: 3.9107, Time: 45.0123 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [130/229], Loss: 3.3682, Time: 45.2982 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [135/229], Loss: 3.8357, Time: 45.5890 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [140/229], Loss: 4.0199, Time: 45.8738 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [145/229], Loss: 3.7805, Time: 46.1656 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [150/229], Loss: 3.7241, Time: 46.4525 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [155/229], Loss: 3.5316, Time: 46.7573 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [160/229], Loss: 3.3880, Time: 47.0521 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [165/229], Loss: 3.4812, Time: 47.3699 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [170/229], Loss: 3.5218, Time: 47.6707 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [175/229], Loss: 3.5613, Time: 47.9615 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [180/229], Loss: 3.1385, Time: 48.2553 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [185/229], Loss: 3.5364, Time: 48.5412 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [190/229], Loss: 3.3083, Time: 48.8280 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [195/229], Loss: 3.2296, Time: 49.1148 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [200/229], Loss: 3.5244, Time: 49.4136 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [205/229], Loss: 3.5756, Time: 49.7424 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [210/229], Loss: 3.2020, Time: 50.0592 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [215/229], Loss: 3.5061, Time: 50.3501 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [220/229], Loss: 2.9072, Time: 50.6489 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [225/229], Loss: 3.3366, Time: 50.9367 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [5/229], Loss: 2.8328, Time: 51.8082 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [10/229], Loss: 2.9583, Time: 52.0870 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [15/229], Loss: 3.0146, Time: 52.3878 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [20/229], Loss: 3.1009, Time: 52.6876 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [25/229], Loss: 2.9212, Time: 52.9784 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [30/229], Loss: 2.7268, Time: 53.2613 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [35/229], Loss: 3.0397, Time: 53.5461 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [40/229], Loss: 3.4643, Time: 53.8489 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [45/229], Loss: 3.2691, Time: 54.1797 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [50/229], Loss: 2.7996, Time: 54.4735 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [55/229], Loss: 2.5945, Time: 54.7733 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [60/229], Loss: 2.8462, Time: 55.0681 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [65/229], Loss: 2.7419, Time: 55.3730 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [70/229], Loss: 2.7404, Time: 55.6718 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [75/229], Loss: 2.5807, Time: 55.9806 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [80/229], Loss: 3.1743, Time: 56.2894 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [85/229], Loss: 2.6061, Time: 56.5812 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [90/229], Loss: 2.2981, Time: 56.8880 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [95/229], Loss: 2.9242, Time: 57.1888 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [100/229], Loss: 2.6377, Time: 57.4856 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [105/229], Loss: 2.6657, Time: 57.8174 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [110/229], Loss: 2.1984, Time: 58.1143 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [115/229], Loss: 2.4677, Time: 58.4361 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [120/229], Loss: 2.6327, Time: 58.7309 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [125/229], Loss: 2.4070, Time: 59.0227 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [130/229], Loss: 2.5880, Time: 59.3135 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [135/229], Loss: 2.5279, Time: 59.6193 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [140/229], Loss: 2.1310, Time: 59.9421 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [145/229], Loss: 2.2507, Time: 60.2340 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [150/229], Loss: 2.2386, Time: 60.5328 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [155/229], Loss: 2.4740, Time: 60.8576 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [160/229], Loss: 2.2326, Time: 61.1594 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [165/229], Loss: 1.9598, Time: 61.4672 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [170/229], Loss: 2.0446, Time: 61.7690 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [175/229], Loss: 2.3494, Time: 62.0638 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [180/229], Loss: 2.0195, Time: 62.3746 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [185/229], Loss: 1.8662, Time: 62.6934 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [190/229], Loss: 1.9006, Time: 62.9873 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [195/229], Loss: 1.8495, Time: 63.2741 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [200/229], Loss: 2.1348, Time: 63.5689 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [205/229], Loss: 2.4530, Time: 63.8747 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [210/229], Loss: 1.8824, Time: 64.2245 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [215/229], Loss: 1.9205, Time: 64.5253 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [220/229], Loss: 2.1084, Time: 64.8151 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [225/229], Loss: 1.8896, Time: 65.1219 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [5/229], Loss: 1.9974, Time: 65.9954 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [10/229], Loss: 1.7698, Time: 66.2852 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [15/229], Loss: 1.8583, Time: 66.5780 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [20/229], Loss: 1.8780, Time: 66.8749 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [25/229], Loss: 1.9088, Time: 67.1617 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [30/229], Loss: 1.9200, Time: 67.4665 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [35/229], Loss: 1.8036, Time: 67.7773 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [40/229], Loss: 1.6810, Time: 68.0891 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [45/229], Loss: 1.7062, Time: 68.3809 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [50/229], Loss: 1.8634, Time: 68.6727 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [55/229], Loss: 1.8434, Time: 68.9656 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [60/229], Loss: 2.0853, Time: 69.2544 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [65/229], Loss: 1.7046, Time: 69.5442 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [70/229], Loss: 1.9187, Time: 69.8450 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [75/229], Loss: 1.8498, Time: 70.1358 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [80/229], Loss: 1.5915, Time: 70.4217 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [85/229], Loss: 1.7536, Time: 70.7095 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [90/229], Loss: 1.7979, Time: 70.9963 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [95/229], Loss: 1.5528, Time: 71.3051 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [100/229], Loss: 1.7511, Time: 71.6089 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [105/229], Loss: 1.6837, Time: 71.8968 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [110/229], Loss: 1.7024, Time: 72.1836 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [115/229], Loss: 1.4100, Time: 72.4934 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [120/229], Loss: 1.7179, Time: 72.7922 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [125/229], Loss: 1.4155, Time: 73.0790 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [130/229], Loss: 1.5834, Time: 73.3768 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [135/229], Loss: 1.3696, Time: 73.6787 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [140/229], Loss: 1.7289, Time: 73.9785 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [145/229], Loss: 1.5830, Time: 74.2643 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [150/229], Loss: 1.5152, Time: 74.5481 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [155/229], Loss: 1.4421, Time: 74.8329 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [160/229], Loss: 1.4707, Time: 75.1378 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [165/229], Loss: 1.5967, Time: 75.4306 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [170/229], Loss: 1.2893, Time: 75.7154 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [175/229], Loss: 1.4027, Time: 76.0202 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [180/229], Loss: 1.3848, Time: 76.3040 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [185/229], Loss: 1.5148, Time: 76.5909 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [190/229], Loss: 1.4117, Time: 76.8757 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [195/229], Loss: 1.3526, Time: 77.1895 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [200/229], Loss: 1.5221, Time: 77.4813 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [205/229], Loss: 1.5189, Time: 77.7671 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [210/229], Loss: 1.5650, Time: 78.0610 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [215/229], Loss: 1.2850, Time: 78.3478 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [220/229], Loss: 1.3406, Time: 78.6486 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [225/229], Loss: 1.3346, Time: 78.9364 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [5/229], Loss: 1.3874, Time: 79.8119 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [10/229], Loss: 1.3005, Time: 80.1057 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [15/229], Loss: 1.1312, Time: 80.3925 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [20/229], Loss: 1.3766, Time: 80.6853 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [25/229], Loss: 1.2632, Time: 80.9792 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [30/229], Loss: 1.3340, Time: 81.2640 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [35/229], Loss: 1.2778, Time: 81.6078 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [40/229], Loss: 1.2438, Time: 81.9026 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [45/229], Loss: 1.2998, Time: 82.1964 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [50/229], Loss: 1.2064, Time: 82.4892 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [55/229], Loss: 1.2496, Time: 82.7950 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [60/229], Loss: 1.2760, Time: 83.0978 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [65/229], Loss: 1.1534, Time: 83.3937 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [70/229], Loss: 1.2189, Time: 83.6775 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [75/229], Loss: 1.2006, Time: 83.9683 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [80/229], Loss: 1.1850, Time: 84.2681 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [85/229], Loss: 1.0511, Time: 84.5550 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [90/229], Loss: 1.2130, Time: 84.8518 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [95/229], Loss: 1.1326, Time: 85.1386 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [100/229], Loss: 1.1803, Time: 85.4284 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [105/229], Loss: 1.1613, Time: 85.7312 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [110/229], Loss: 1.0250, Time: 86.0280 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [115/229], Loss: 1.0934, Time: 86.3249 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [120/229], Loss: 1.2791, Time: 86.6107 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [125/229], Loss: 1.0849, Time: 86.9155 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [130/229], Loss: 0.9853, Time: 87.2133 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [135/229], Loss: 1.2406, Time: 87.5331 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [140/229], Loss: 1.1793, Time: 87.8279 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [145/229], Loss: 0.9426, Time: 88.1237 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [150/229], Loss: 1.0123, Time: 88.4086 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [155/229], Loss: 0.9943, Time: 88.7044 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [160/229], Loss: 1.0296, Time: 88.9942 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [165/229], Loss: 1.1082, Time: 89.2810 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [170/229], Loss: 1.0038, Time: 89.5709 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [175/229], Loss: 0.9958, Time: 89.8607 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [180/229], Loss: 1.1959, Time: 90.1515 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [185/229], Loss: 0.9779, Time: 90.4403 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [190/229], Loss: 1.3389, Time: 90.7441 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [195/229], Loss: 0.9445, Time: 91.0449 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [200/229], Loss: 0.9447, Time: 91.3278 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [205/229], Loss: 1.0088, Time: 91.6346 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [210/229], Loss: 1.0073, Time: 91.9344 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [215/229], Loss: 0.9933, Time: 92.2292 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [220/229], Loss: 1.0873, Time: 92.5140 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [225/229], Loss: 0.9709, Time: 92.7999 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [5/229], Loss: 0.8605, Time: 93.7073 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [10/229], Loss: 0.8684, Time: 93.9971 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [15/229], Loss: 0.9557, Time: 94.2909 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [20/229], Loss: 0.8319, Time: 94.5928 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [25/229], Loss: 0.9469, Time: 94.8926 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [30/229], Loss: 1.0796, Time: 95.1864 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [35/229], Loss: 0.8047, Time: 95.4742 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [40/229], Loss: 0.8554, Time: 95.7650 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [45/229], Loss: 0.8207, Time: 96.0529 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [50/229], Loss: 0.8808, Time: 96.3447 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [55/229], Loss: 1.0068, Time: 96.6395 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [60/229], Loss: 0.8928, Time: 96.9413 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [65/229], Loss: 0.8202, Time: 97.2411 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [70/229], Loss: 0.8514, Time: 97.5279 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [75/229], Loss: 0.9297, Time: 97.8667 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [80/229], Loss: 0.8184, Time: 98.1556 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [85/229], Loss: 0.8121, Time: 98.4634 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [90/229], Loss: 0.8219, Time: 98.7492 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [95/229], Loss: 0.8896, Time: 99.0840 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [100/229], Loss: 0.8515, Time: 99.3688 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [105/229], Loss: 0.8657, Time: 99.6866 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [110/229], Loss: 0.8124, Time: 99.9834 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [115/229], Loss: 0.8495, Time: 100.2832 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [120/229], Loss: 0.9126, Time: 100.5721 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [125/229], Loss: 0.8148, Time: 100.8649 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [130/229], Loss: 0.7109, Time: 101.1547 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [135/229], Loss: 0.9137, Time: 101.4525 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [140/229], Loss: 0.7850, Time: 101.7563 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [145/229], Loss: 0.8446, Time: 102.0552 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [150/229], Loss: 0.7292, Time: 102.3460 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [155/229], Loss: 0.7444, Time: 102.6368 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [160/229], Loss: 0.7855, Time: 102.9226 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [165/229], Loss: 0.7937, Time: 103.2154 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [170/229], Loss: 0.7862, Time: 103.5272 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [175/229], Loss: 0.7216, Time: 103.8450 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [180/229], Loss: 0.8150, Time: 104.2098 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [185/229], Loss: 0.7794, Time: 104.4946 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [190/229], Loss: 0.7555, Time: 104.7915 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [195/229], Loss: 0.7836, Time: 105.0933 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [200/229], Loss: 0.9888, Time: 105.3871 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [205/229], Loss: 0.6635, Time: 105.6769 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [210/229], Loss: 0.7006, Time: 105.9637 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [215/229], Loss: 0.6774, Time: 106.2526 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [220/229], Loss: 0.6968, Time: 106.5364 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [225/229], Loss: 0.7162, Time: 106.8342 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [5/229], Loss: 0.8198, Time: 107.7287 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [10/229], Loss: 0.7609, Time: 108.0225 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [15/229], Loss: 0.7021, Time: 108.3413 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [20/229], Loss: 0.6515, Time: 108.6271 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [25/229], Loss: 0.6493, Time: 108.9129 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [30/229], Loss: 0.7757, Time: 109.2357 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [35/229], Loss: 0.6184, Time: 109.5355 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [40/229], Loss: 0.8515, Time: 109.8254 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [45/229], Loss: 0.7238, Time: 110.1122 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [50/229], Loss: 0.6780, Time: 110.4000 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [55/229], Loss: 0.5986, Time: 110.7018 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [60/229], Loss: 0.6997, Time: 110.9996 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [65/229], Loss: 0.6682, Time: 111.2865 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [70/229], Loss: 0.5437, Time: 111.5723 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [75/229], Loss: 0.5558, Time: 111.8651 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [80/229], Loss: 0.6193, Time: 112.1639 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [85/229], Loss: 0.6701, Time: 112.4517 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [90/229], Loss: 0.6322, Time: 112.7356 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [95/229], Loss: 0.6255, Time: 113.0204 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [100/229], Loss: 0.5128, Time: 113.3032 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [105/229], Loss: 0.5249, Time: 113.6080 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [110/229], Loss: 0.5787, Time: 113.8968 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [115/229], Loss: 0.6954, Time: 114.1897 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [120/229], Loss: 0.6138, Time: 114.4835 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [125/229], Loss: 0.5164, Time: 114.7703 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [130/229], Loss: 0.5545, Time: 115.1191 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [135/229], Loss: 0.5736, Time: 115.4159 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [140/229], Loss: 0.5325, Time: 115.7057 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [145/229], Loss: 0.5756, Time: 115.9956 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [150/229], Loss: 0.6378, Time: 116.2874 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [155/229], Loss: 0.5420, Time: 116.5862 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [160/229], Loss: 0.7053, Time: 116.9490 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [165/229], Loss: 0.5567, Time: 117.3637 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [170/229], Loss: 0.6403, Time: 117.7795 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [175/229], Loss: 0.6577, Time: 118.0743 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [180/229], Loss: 0.5885, Time: 118.3701 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [185/229], Loss: 0.6511, Time: 118.6629 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [190/229], Loss: 0.5256, Time: 118.9497 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [195/229], Loss: 0.5601, Time: 119.2396 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [200/229], Loss: 0.5463, Time: 119.5424 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [205/229], Loss: 0.5293, Time: 119.8302 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [210/229], Loss: 0.5449, Time: 120.1182 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [215/229], Loss: 0.5990, Time: 120.4092 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [220/229], Loss: 0.5157, Time: 120.7152 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [225/229], Loss: 0.6194, Time: 121.0163 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [5/229], Loss: 0.6008, Time: 121.9373 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [10/229], Loss: 0.5772, Time: 122.2323 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [15/229], Loss: 0.4921, Time: 122.5283 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [20/229], Loss: 0.4928, Time: 122.8303 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [25/229], Loss: 0.4898, Time: 123.1253 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [30/229], Loss: 0.4860, Time: 123.4173 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [35/229], Loss: 0.4774, Time: 123.7293 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [40/229], Loss: 0.5685, Time: 124.0193 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [45/229], Loss: 0.4449, Time: 124.3213 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [50/229], Loss: 0.4824, Time: 124.6173 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [55/229], Loss: 0.4944, Time: 124.9183 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [60/229], Loss: 0.4695, Time: 125.2283 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [65/229], Loss: 0.4990, Time: 125.5223 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [70/229], Loss: 0.5381, Time: 125.8303 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [75/229], Loss: 0.4649, Time: 126.1183 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [80/229], Loss: 0.4778, Time: 126.4203 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [85/229], Loss: 0.5135, Time: 126.7143 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [90/229], Loss: 0.4316, Time: 127.0033 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [95/229], Loss: 0.5350, Time: 127.3033 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [100/229], Loss: 0.5129, Time: 127.6083 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [105/229], Loss: 0.4356, Time: 127.8993 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [110/229], Loss: 0.5212, Time: 128.1923 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [115/229], Loss: 0.4141, Time: 128.5053 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [120/229], Loss: 0.4584, Time: 128.8003 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [125/229], Loss: 0.5075, Time: 129.1043 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [130/229], Loss: 0.4534, Time: 129.3963 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [135/229], Loss: 0.4271, Time: 129.6863 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [140/229], Loss: 0.3877, Time: 129.9793 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [145/229], Loss: 0.5118, Time: 130.2693 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [150/229], Loss: 0.4251, Time: 130.5612 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [155/229], Loss: 0.4250, Time: 130.8623 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [160/229], Loss: 0.4363, Time: 131.1693 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [165/229], Loss: 0.4469, Time: 131.4562 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [170/229], Loss: 0.5169, Time: 131.7473 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [175/229], Loss: 0.4604, Time: 132.0962 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [180/229], Loss: 0.4450, Time: 132.3932 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [185/229], Loss: 0.4725, Time: 132.6912 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [190/229], Loss: 0.4200, Time: 132.9813 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [195/229], Loss: 0.3912, Time: 133.2722 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [200/229], Loss: 0.3573, Time: 133.5632 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [205/229], Loss: 0.4062, Time: 133.8522 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [210/229], Loss: 0.4284, Time: 134.1592 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [215/229], Loss: 0.3729, Time: 134.4552 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [220/229], Loss: 0.4330, Time: 134.7462 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [225/229], Loss: 0.3654, Time: 135.0462 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [5/229], Loss: 0.4208, Time: 135.9473 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [10/229], Loss: 0.4034, Time: 136.2492 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [15/229], Loss: 0.4201, Time: 136.5342 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [20/229], Loss: 0.4216, Time: 136.8222 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [25/229], Loss: 0.3816, Time: 137.1242 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [30/229], Loss: 0.3906, Time: 137.4220 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [35/229], Loss: 0.3582, Time: 137.7288 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [40/229], Loss: 0.3994, Time: 138.0197 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [45/229], Loss: 0.3550, Time: 138.3075 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [50/229], Loss: 0.4342, Time: 138.5963 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [55/229], Loss: 0.3855, Time: 138.8831 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [60/229], Loss: 0.4414, Time: 139.1790 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [65/229], Loss: 0.3886, Time: 139.4608 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [70/229], Loss: 0.3306, Time: 139.7496 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [75/229], Loss: 0.3500, Time: 140.0484 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [80/229], Loss: 0.4384, Time: 140.3782 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [85/229], Loss: 0.3226, Time: 140.9149 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [90/229], Loss: 0.3757, Time: 141.2457 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [95/229], Loss: 0.3332, Time: 141.5305 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [100/229], Loss: 0.3729, Time: 141.8303 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [105/229], Loss: 0.3078, Time: 142.1181 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [110/229], Loss: 0.3267, Time: 142.4080 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [115/229], Loss: 0.4945, Time: 142.7138 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [120/229], Loss: 0.3208, Time: 143.0076 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [125/229], Loss: 0.3615, Time: 143.2954 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [130/229], Loss: 0.3843, Time: 143.5882 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [135/229], Loss: 0.4073, Time: 143.8890 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [140/229], Loss: 0.3416, Time: 144.1859 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [145/229], Loss: 0.3197, Time: 144.4757 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [150/229], Loss: 0.3217, Time: 144.7615 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [155/229], Loss: 0.3958, Time: 145.0603 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [160/229], Loss: 0.3323, Time: 145.3461 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [165/229], Loss: 0.3232, Time: 145.6320 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [170/229], Loss: 0.3689, Time: 145.9248 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [175/229], Loss: 0.2675, Time: 146.2076 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [180/229], Loss: 0.3972, Time: 146.5074 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [185/229], Loss: 0.3751, Time: 146.8102 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [190/229], Loss: 0.2958, Time: 147.1051 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [195/229], Loss: 0.3723, Time: 147.4079 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [200/229], Loss: 0.3131, Time: 147.6927 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [205/229], Loss: 0.3055, Time: 147.9895 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [210/229], Loss: 0.3061, Time: 148.2883 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [215/229], Loss: 0.3095, Time: 148.5961 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [220/229], Loss: 0.2637, Time: 148.9559 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [225/229], Loss: 0.2822, Time: 149.2487 secs, learning rate: 0.0010\n",
      "Epoch [11/60], Step [5/229], Loss: 0.3109, Time: 150.1352 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [10/229], Loss: 0.2702, Time: 150.4220 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [15/229], Loss: 0.3698, Time: 150.7128 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [20/229], Loss: 0.2718, Time: 150.9977 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [25/229], Loss: 0.2509, Time: 151.2955 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [30/229], Loss: 0.2574, Time: 151.5833 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [35/229], Loss: 0.3696, Time: 151.8851 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [40/229], Loss: 0.3388, Time: 152.1809 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [45/229], Loss: 0.3458, Time: 152.4797 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [50/229], Loss: 0.2869, Time: 152.7696 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [55/229], Loss: 0.2947, Time: 153.0624 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [60/229], Loss: 0.2882, Time: 153.3472 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [65/229], Loss: 0.2887, Time: 153.6400 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [70/229], Loss: 0.2600, Time: 153.9428 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [75/229], Loss: 0.2495, Time: 154.2337 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [80/229], Loss: 0.3032, Time: 154.5155 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [85/229], Loss: 0.3159, Time: 154.8113 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [90/229], Loss: 0.3160, Time: 155.1021 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [95/229], Loss: 0.2985, Time: 155.3889 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [100/229], Loss: 0.3105, Time: 155.6738 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [105/229], Loss: 0.3063, Time: 155.9756 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [110/229], Loss: 0.2489, Time: 156.2674 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [115/229], Loss: 0.3118, Time: 156.5522 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [120/229], Loss: 0.3101, Time: 156.8401 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [125/229], Loss: 0.2751, Time: 157.1349 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [130/229], Loss: 0.2906, Time: 157.4287 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [135/229], Loss: 0.2990, Time: 157.7345 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [140/229], Loss: 0.3624, Time: 158.0263 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [145/229], Loss: 0.2527, Time: 158.3211 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [150/229], Loss: 0.2375, Time: 158.6379 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [155/229], Loss: 0.2815, Time: 158.9288 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [160/229], Loss: 0.2872, Time: 159.2146 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [165/229], Loss: 0.2906, Time: 159.5064 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [170/229], Loss: 0.3628, Time: 159.7982 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [175/229], Loss: 0.3342, Time: 160.0881 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [180/229], Loss: 0.3232, Time: 160.3849 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [185/229], Loss: 0.2842, Time: 160.6757 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [190/229], Loss: 0.3197, Time: 160.9625 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [195/229], Loss: 0.2605, Time: 161.2783 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [200/229], Loss: 0.3130, Time: 161.5751 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [205/229], Loss: 0.2499, Time: 161.8630 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [210/229], Loss: 0.2865, Time: 162.1528 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [215/229], Loss: 0.3141, Time: 162.4466 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [220/229], Loss: 0.3214, Time: 162.7514 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [225/229], Loss: 0.3236, Time: 163.0452 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [5/229], Loss: 0.2929, Time: 163.9307 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [10/229], Loss: 0.2719, Time: 164.2335 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [15/229], Loss: 0.4106, Time: 164.5193 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [20/229], Loss: 0.2909, Time: 164.8161 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [25/229], Loss: 0.2539, Time: 165.1159 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [30/229], Loss: 0.3091, Time: 165.3978 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [35/229], Loss: 0.3568, Time: 165.6966 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [40/229], Loss: 0.3406, Time: 166.0404 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [45/229], Loss: 0.2429, Time: 166.3352 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [50/229], Loss: 0.3324, Time: 166.6720 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [55/229], Loss: 0.2784, Time: 166.9848 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [60/229], Loss: 0.3053, Time: 167.2806 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [65/229], Loss: 0.2878, Time: 167.5794 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [70/229], Loss: 0.3535, Time: 167.8702 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [75/229], Loss: 0.2778, Time: 168.1531 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [80/229], Loss: 0.3012, Time: 168.4409 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [85/229], Loss: 0.3211, Time: 168.7427 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [90/229], Loss: 0.3165, Time: 169.0455 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [95/229], Loss: 0.3072, Time: 169.3463 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [100/229], Loss: 0.2455, Time: 169.6352 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [105/229], Loss: 0.3548, Time: 169.9190 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [110/229], Loss: 0.2813, Time: 170.2348 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [115/229], Loss: 0.2954, Time: 170.5236 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [120/229], Loss: 0.2624, Time: 170.8194 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [125/229], Loss: 0.3046, Time: 171.1182 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [130/229], Loss: 0.2994, Time: 171.4111 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [135/229], Loss: 0.2908, Time: 171.6989 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [140/229], Loss: 0.2887, Time: 171.9847 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [145/229], Loss: 0.2572, Time: 172.2865 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [150/229], Loss: 0.2953, Time: 172.5843 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [155/229], Loss: 0.3022, Time: 172.8752 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [160/229], Loss: 0.2790, Time: 173.1630 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [165/229], Loss: 0.2852, Time: 173.4878 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [170/229], Loss: 0.3651, Time: 173.7836 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [175/229], Loss: 0.2991, Time: 174.0744 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [180/229], Loss: 0.3148, Time: 174.3682 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [185/229], Loss: 0.2895, Time: 174.6711 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [190/229], Loss: 0.2719, Time: 174.9649 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [195/229], Loss: 0.2622, Time: 175.2487 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [200/229], Loss: 0.3304, Time: 175.5415 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [205/229], Loss: 0.2690, Time: 175.8313 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [210/229], Loss: 0.3608, Time: 176.1372 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [215/229], Loss: 0.3068, Time: 176.4500 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [220/229], Loss: 0.3502, Time: 176.7538 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [225/229], Loss: 0.2623, Time: 177.0586 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [5/229], Loss: 0.3603, Time: 177.9490 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [10/229], Loss: 0.2568, Time: 178.2369 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [15/229], Loss: 0.2354, Time: 178.5247 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [20/229], Loss: 0.2408, Time: 178.8365 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [25/229], Loss: 0.3040, Time: 179.1423 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [30/229], Loss: 0.3775, Time: 179.4371 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [35/229], Loss: 0.2959, Time: 179.7359 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [40/229], Loss: 0.2848, Time: 180.0347 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [45/229], Loss: 0.2418, Time: 180.3376 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [50/229], Loss: 0.2695, Time: 180.6274 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [55/229], Loss: 0.3438, Time: 180.9162 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [60/229], Loss: 0.3109, Time: 181.2210 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [65/229], Loss: 0.3417, Time: 181.5068 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [70/229], Loss: 0.2746, Time: 181.7927 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [75/229], Loss: 0.2609, Time: 182.0895 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [80/229], Loss: 0.3086, Time: 182.3903 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [85/229], Loss: 0.2983, Time: 182.7421 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [90/229], Loss: 0.2471, Time: 183.0339 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [95/229], Loss: 0.2792, Time: 183.3307 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [100/229], Loss: 0.2683, Time: 183.6185 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [105/229], Loss: 0.3343, Time: 183.9034 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [110/229], Loss: 0.3051, Time: 184.2002 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [115/229], Loss: 0.2730, Time: 184.4940 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [120/229], Loss: 0.2747, Time: 184.7828 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [125/229], Loss: 0.2861, Time: 185.0766 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [130/229], Loss: 0.3208, Time: 185.3685 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [135/229], Loss: 0.2811, Time: 185.6573 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [140/229], Loss: 0.2955, Time: 185.9681 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [145/229], Loss: 0.2742, Time: 186.2689 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [150/229], Loss: 0.2972, Time: 186.5577 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [155/229], Loss: 0.2803, Time: 186.8455 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [160/229], Loss: 0.3318, Time: 187.1454 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [165/229], Loss: 0.2852, Time: 187.4322 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [170/229], Loss: 0.3159, Time: 187.7190 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [175/229], Loss: 0.2343, Time: 188.0088 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [180/229], Loss: 0.2961, Time: 188.2947 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [185/229], Loss: 0.2940, Time: 188.6105 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [190/229], Loss: 0.2311, Time: 188.9133 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [195/229], Loss: 0.2661, Time: 189.2051 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [200/229], Loss: 0.2974, Time: 189.4949 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [205/229], Loss: 0.3302, Time: 189.7917 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [210/229], Loss: 0.3293, Time: 190.1045 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [215/229], Loss: 0.2485, Time: 190.3934 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [220/229], Loss: 0.3389, Time: 190.6882 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [225/229], Loss: 0.2910, Time: 190.9860 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [5/229], Loss: 0.3278, Time: 191.8515 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [10/229], Loss: 0.2695, Time: 192.1583 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [15/229], Loss: 0.3003, Time: 192.4451 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [20/229], Loss: 0.2764, Time: 192.7399 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [25/229], Loss: 0.2456, Time: 193.0317 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [30/229], Loss: 0.3268, Time: 193.3196 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [35/229], Loss: 0.2557, Time: 193.6014 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [40/229], Loss: 0.2404, Time: 193.9012 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [45/229], Loss: 0.3095, Time: 194.1980 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [50/229], Loss: 0.2293, Time: 194.4868 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [55/229], Loss: 0.2959, Time: 194.7727 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [60/229], Loss: 0.2893, Time: 195.0895 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [65/229], Loss: 0.2904, Time: 195.3833 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [70/229], Loss: 0.2641, Time: 195.6751 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [75/229], Loss: 0.2683, Time: 195.9629 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [80/229], Loss: 0.2668, Time: 196.2527 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [85/229], Loss: 0.2767, Time: 196.5436 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [90/229], Loss: 0.3055, Time: 196.8344 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [95/229], Loss: 0.2364, Time: 197.1372 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [100/229], Loss: 0.3323, Time: 197.4340 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [105/229], Loss: 0.3114, Time: 197.7278 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [110/229], Loss: 0.2960, Time: 198.0426 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [115/229], Loss: 0.2732, Time: 198.3325 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [120/229], Loss: 0.2925, Time: 198.6223 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [125/229], Loss: 0.3299, Time: 198.9111 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [130/229], Loss: 0.2478, Time: 199.2029 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [135/229], Loss: 0.2175, Time: 199.4897 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [140/229], Loss: 0.3246, Time: 199.7766 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [145/229], Loss: 0.2903, Time: 200.1154 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [150/229], Loss: 0.2363, Time: 200.4062 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [155/229], Loss: 0.2841, Time: 200.6950 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [160/229], Loss: 0.3577, Time: 200.9888 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [165/229], Loss: 0.2719, Time: 201.3036 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [170/229], Loss: 0.2511, Time: 201.5974 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [175/229], Loss: 0.2464, Time: 201.8863 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [180/229], Loss: 0.2713, Time: 202.1951 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [185/229], Loss: 0.3798, Time: 202.4809 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [190/229], Loss: 0.2875, Time: 202.7737 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [195/229], Loss: 0.2885, Time: 203.0575 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [200/229], Loss: 0.2659, Time: 203.3464 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [205/229], Loss: 0.2628, Time: 203.6412 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [210/229], Loss: 0.2645, Time: 203.9290 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [215/229], Loss: 0.2453, Time: 204.2568 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [220/229], Loss: 0.2626, Time: 204.5566 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [225/229], Loss: 0.3282, Time: 204.8594 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [5/229], Loss: 0.2423, Time: 205.7439 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [10/229], Loss: 0.2806, Time: 206.0287 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [15/229], Loss: 0.2265, Time: 206.3155 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [20/229], Loss: 0.2732, Time: 206.6024 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [25/229], Loss: 0.2143, Time: 206.9052 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [30/229], Loss: 0.3050, Time: 207.2170 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [35/229], Loss: 0.3058, Time: 207.5298 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [40/229], Loss: 0.2285, Time: 207.8246 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [45/229], Loss: 0.2780, Time: 208.1184 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [50/229], Loss: 0.2477, Time: 208.4062 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [55/229], Loss: 0.2809, Time: 208.7001 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [60/229], Loss: 0.2920, Time: 209.0159 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [65/229], Loss: 0.2671, Time: 209.3167 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [70/229], Loss: 0.2584, Time: 209.6245 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [75/229], Loss: 0.2247, Time: 209.9193 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [80/229], Loss: 0.2579, Time: 210.2071 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [85/229], Loss: 0.2802, Time: 210.5020 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [90/229], Loss: 0.3224, Time: 210.7948 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [95/229], Loss: 0.2081, Time: 211.0996 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [100/229], Loss: 0.2833, Time: 211.3904 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [105/229], Loss: 0.2822, Time: 211.6892 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [110/229], Loss: 0.2887, Time: 211.9830 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [115/229], Loss: 0.2388, Time: 212.2729 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [120/229], Loss: 0.2783, Time: 212.5607 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [125/229], Loss: 0.3289, Time: 212.8515 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [130/229], Loss: 0.2474, Time: 213.1553 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [135/229], Loss: 0.3227, Time: 213.4481 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [140/229], Loss: 0.2433, Time: 213.7440 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [145/229], Loss: 0.2667, Time: 214.0608 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [150/229], Loss: 0.2169, Time: 214.3506 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [155/229], Loss: 0.2463, Time: 214.6404 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [160/229], Loss: 0.2666, Time: 214.9262 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [165/229], Loss: 0.2754, Time: 215.2270 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [170/229], Loss: 0.2735, Time: 215.5209 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [175/229], Loss: 0.2658, Time: 215.8087 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [180/229], Loss: 0.2831, Time: 216.1235 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [185/229], Loss: 0.2946, Time: 216.4203 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [190/229], Loss: 0.3004, Time: 216.7131 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [195/229], Loss: 0.2228, Time: 217.0459 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [200/229], Loss: 0.2763, Time: 217.3437 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [205/229], Loss: 0.2481, Time: 217.6346 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [210/229], Loss: 0.2385, Time: 217.9274 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [215/229], Loss: 0.2540, Time: 218.2252 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [220/229], Loss: 0.2535, Time: 218.5240 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [225/229], Loss: 0.2562, Time: 218.8128 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [5/229], Loss: 0.3119, Time: 219.6893 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [10/229], Loss: 0.2205, Time: 219.9851 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [15/229], Loss: 0.2665, Time: 220.2799 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [20/229], Loss: 0.2519, Time: 220.5797 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [25/229], Loss: 0.2856, Time: 220.8696 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [30/229], Loss: 0.2339, Time: 221.1824 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [35/229], Loss: 0.2709, Time: 221.4762 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [40/229], Loss: 0.2397, Time: 221.7850 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [45/229], Loss: 0.2499, Time: 222.0718 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [50/229], Loss: 0.2449, Time: 222.3736 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [55/229], Loss: 0.2893, Time: 222.6684 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [60/229], Loss: 0.2088, Time: 222.9673 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [65/229], Loss: 0.2063, Time: 223.2551 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [70/229], Loss: 0.3194, Time: 223.5429 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [75/229], Loss: 0.3035, Time: 223.8437 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [80/229], Loss: 0.2972, Time: 224.1375 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [85/229], Loss: 0.3357, Time: 224.4254 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [90/229], Loss: 0.2214, Time: 224.7312 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [95/229], Loss: 0.2848, Time: 225.0390 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [100/229], Loss: 0.3120, Time: 225.3388 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [105/229], Loss: 0.2535, Time: 225.6326 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [110/229], Loss: 0.2535, Time: 225.9224 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [115/229], Loss: 0.2341, Time: 226.2163 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [120/229], Loss: 0.2257, Time: 226.5041 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [125/229], Loss: 0.2709, Time: 226.7929 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [130/229], Loss: 0.2246, Time: 227.0857 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [135/229], Loss: 0.2456, Time: 227.3925 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [140/229], Loss: 0.3329, Time: 227.6804 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [145/229], Loss: 0.2585, Time: 227.9702 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [150/229], Loss: 0.2154, Time: 228.2760 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [155/229], Loss: 0.2400, Time: 228.5658 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [160/229], Loss: 0.2118, Time: 228.8546 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [165/229], Loss: 0.2973, Time: 229.1494 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [170/229], Loss: 0.3043, Time: 229.4463 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [175/229], Loss: 0.2595, Time: 229.7371 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [180/229], Loss: 0.2396, Time: 230.0239 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [185/229], Loss: 0.2656, Time: 230.3247 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [190/229], Loss: 0.2504, Time: 230.6175 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [195/229], Loss: 0.2724, Time: 230.9034 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [200/229], Loss: 0.3039, Time: 231.1922 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [205/229], Loss: 0.2145, Time: 231.4790 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [210/229], Loss: 0.3090, Time: 231.7708 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [215/229], Loss: 0.2651, Time: 232.0646 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [220/229], Loss: 0.2577, Time: 232.3595 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [225/229], Loss: 0.2623, Time: 232.6493 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [5/229], Loss: 0.2769, Time: 233.5297 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [10/229], Loss: 0.2578, Time: 233.8186 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [15/229], Loss: 0.3469, Time: 234.1614 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [20/229], Loss: 0.2620, Time: 234.4512 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [25/229], Loss: 0.2674, Time: 234.7420 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [30/229], Loss: 0.2410, Time: 235.0418 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [35/229], Loss: 0.2848, Time: 235.3346 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [40/229], Loss: 0.2556, Time: 235.6195 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [45/229], Loss: 0.2072, Time: 235.9213 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [50/229], Loss: 0.2297, Time: 236.2131 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [55/229], Loss: 0.2475, Time: 236.5099 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [60/229], Loss: 0.2400, Time: 236.7987 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [65/229], Loss: 0.2196, Time: 237.0925 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [70/229], Loss: 0.2248, Time: 237.3934 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [75/229], Loss: 0.2423, Time: 237.6892 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [80/229], Loss: 0.2234, Time: 237.9840 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [85/229], Loss: 0.3076, Time: 238.2728 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [90/229], Loss: 0.2274, Time: 238.5906 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [95/229], Loss: 0.2399, Time: 238.8984 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [100/229], Loss: 0.2826, Time: 239.1952 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [105/229], Loss: 0.2156, Time: 239.4901 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [110/229], Loss: 0.3413, Time: 239.7879 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [115/229], Loss: 0.2002, Time: 240.0817 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [120/229], Loss: 0.2362, Time: 240.3915 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [125/229], Loss: 0.2346, Time: 240.6883 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [130/229], Loss: 0.2965, Time: 240.9801 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [135/229], Loss: 0.2841, Time: 241.2780 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [140/229], Loss: 0.1993, Time: 241.5738 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [145/229], Loss: 0.2238, Time: 241.8626 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [150/229], Loss: 0.2844, Time: 242.1554 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [155/229], Loss: 0.2504, Time: 242.4502 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [160/229], Loss: 0.2486, Time: 242.7471 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [165/229], Loss: 0.2328, Time: 243.0399 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [170/229], Loss: 0.2291, Time: 243.3347 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [175/229], Loss: 0.2110, Time: 243.6295 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [180/229], Loss: 0.2535, Time: 243.9343 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [185/229], Loss: 0.3069, Time: 244.2301 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [190/229], Loss: 0.2351, Time: 244.5270 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [195/229], Loss: 0.2252, Time: 244.8358 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [200/229], Loss: 0.2462, Time: 245.1316 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [205/229], Loss: 0.2496, Time: 245.4164 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [210/229], Loss: 0.2149, Time: 245.6982 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [215/229], Loss: 0.2206, Time: 246.0570 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [220/229], Loss: 0.2106, Time: 246.4378 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [225/229], Loss: 0.2529, Time: 246.7326 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [5/229], Loss: 0.2101, Time: 247.6061 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [10/229], Loss: 0.2233, Time: 247.9039 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [15/229], Loss: 0.2895, Time: 248.2087 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [20/229], Loss: 0.2176, Time: 248.5025 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [25/229], Loss: 0.2304, Time: 248.7963 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [30/229], Loss: 0.2768, Time: 249.0802 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [35/229], Loss: 0.2276, Time: 249.3750 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [40/229], Loss: 0.2156, Time: 249.6718 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [45/229], Loss: 0.2811, Time: 249.9606 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [50/229], Loss: 0.2279, Time: 250.2984 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [55/229], Loss: 0.2890, Time: 250.5932 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [60/229], Loss: 0.2319, Time: 250.8940 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [65/229], Loss: 0.2466, Time: 251.1839 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [70/229], Loss: 0.2298, Time: 251.4797 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [75/229], Loss: 0.2291, Time: 251.7695 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [80/229], Loss: 0.2615, Time: 252.0593 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [85/229], Loss: 0.2745, Time: 252.3521 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [90/229], Loss: 0.2779, Time: 252.6569 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [95/229], Loss: 0.2418, Time: 252.9488 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [100/229], Loss: 0.2755, Time: 253.2416 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [105/229], Loss: 0.2553, Time: 253.5504 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [110/229], Loss: 0.2364, Time: 253.8362 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [115/229], Loss: 0.2511, Time: 254.1270 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [120/229], Loss: 0.2570, Time: 254.4249 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [125/229], Loss: 0.2513, Time: 254.7257 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [130/229], Loss: 0.2075, Time: 255.0265 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [135/229], Loss: 0.2976, Time: 255.3193 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [140/229], Loss: 0.1787, Time: 255.6111 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [145/229], Loss: 0.2066, Time: 255.8999 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [150/229], Loss: 0.2231, Time: 256.2028 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [155/229], Loss: 0.2391, Time: 256.5026 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [160/229], Loss: 0.2812, Time: 256.7944 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [165/229], Loss: 0.2611, Time: 257.0912 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [170/229], Loss: 0.2682, Time: 257.3890 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [175/229], Loss: 0.2699, Time: 257.6928 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [180/229], Loss: 0.2380, Time: 257.9957 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [185/229], Loss: 0.2125, Time: 258.2985 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [190/229], Loss: 0.2855, Time: 258.5913 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [195/229], Loss: 0.2363, Time: 258.8911 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [200/229], Loss: 0.2596, Time: 259.1889 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [205/229], Loss: 0.2115, Time: 259.4847 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [210/229], Loss: 0.2295, Time: 259.7875 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [215/229], Loss: 0.2069, Time: 260.1044 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [220/229], Loss: 0.2525, Time: 260.4042 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [225/229], Loss: 0.2133, Time: 260.7020 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [5/229], Loss: 0.2082, Time: 261.5654 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [10/229], Loss: 0.2379, Time: 261.8603 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [15/229], Loss: 0.2405, Time: 262.1611 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [20/229], Loss: 0.2401, Time: 262.4549 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [25/229], Loss: 0.2753, Time: 262.7487 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [30/229], Loss: 0.2558, Time: 263.0405 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [35/229], Loss: 0.2373, Time: 263.3364 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [40/229], Loss: 0.2040, Time: 263.6212 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [45/229], Loss: 0.2163, Time: 263.9080 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [50/229], Loss: 0.2134, Time: 264.2048 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [55/229], Loss: 0.2279, Time: 264.4956 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [60/229], Loss: 0.2267, Time: 264.7855 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [65/229], Loss: 0.2079, Time: 265.0853 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [70/229], Loss: 0.2594, Time: 265.3821 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [75/229], Loss: 0.1797, Time: 265.6719 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [80/229], Loss: 0.2695, Time: 265.9587 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [85/229], Loss: 0.2490, Time: 266.2486 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [90/229], Loss: 0.2483, Time: 266.5494 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [95/229], Loss: 0.2268, Time: 266.8572 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [100/229], Loss: 0.2067, Time: 267.1650 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [105/229], Loss: 0.2263, Time: 267.4538 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [110/229], Loss: 0.2241, Time: 267.7936 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [115/229], Loss: 0.2744, Time: 268.0974 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [120/229], Loss: 0.2489, Time: 268.3942 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [125/229], Loss: 0.2067, Time: 268.6961 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [130/229], Loss: 0.1704, Time: 269.0039 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [135/229], Loss: 0.2115, Time: 269.2937 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [140/229], Loss: 0.2266, Time: 269.5795 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [145/229], Loss: 0.1972, Time: 269.8803 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [150/229], Loss: 0.2371, Time: 270.1821 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [155/229], Loss: 0.1763, Time: 270.5039 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [160/229], Loss: 0.2203, Time: 271.0266 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [165/229], Loss: 0.1820, Time: 271.3614 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [170/229], Loss: 0.2933, Time: 271.6502 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [175/229], Loss: 0.2115, Time: 271.9381 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [180/229], Loss: 0.2540, Time: 272.2329 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [185/229], Loss: 0.1724, Time: 272.5297 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [190/229], Loss: 0.1918, Time: 272.8205 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [195/229], Loss: 0.3010, Time: 273.2103 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [200/229], Loss: 0.1893, Time: 273.5750 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [205/229], Loss: 0.2427, Time: 273.9438 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [210/229], Loss: 0.2120, Time: 274.4175 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [215/229], Loss: 0.2591, Time: 274.8602 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [220/229], Loss: 0.1888, Time: 275.2030 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [225/229], Loss: 0.2535, Time: 275.5178 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [5/229], Loss: 0.1657, Time: 276.4283 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [10/229], Loss: 0.2575, Time: 276.7331 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [15/229], Loss: 0.2188, Time: 277.0309 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [20/229], Loss: 0.2306, Time: 277.3217 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [25/229], Loss: 0.2256, Time: 277.6245 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [30/229], Loss: 0.2302, Time: 277.9204 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [35/229], Loss: 0.1970, Time: 278.2192 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [40/229], Loss: 0.2380, Time: 278.5170 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [45/229], Loss: 0.2031, Time: 278.8068 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [50/229], Loss: 0.2362, Time: 279.0926 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [55/229], Loss: 0.2242, Time: 279.3825 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [60/229], Loss: 0.1941, Time: 279.6803 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [65/229], Loss: 0.1799, Time: 279.9751 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [70/229], Loss: 0.2103, Time: 280.2699 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [75/229], Loss: 0.2022, Time: 280.5757 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [80/229], Loss: 0.2170, Time: 280.8705 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [85/229], Loss: 0.1844, Time: 281.1644 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [90/229], Loss: 0.2298, Time: 281.4542 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [95/229], Loss: 0.2053, Time: 281.7480 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [100/229], Loss: 0.1687, Time: 282.0468 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [105/229], Loss: 0.1824, Time: 282.3426 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [110/229], Loss: 0.2167, Time: 282.6325 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [115/229], Loss: 0.1968, Time: 282.9323 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [120/229], Loss: 0.2130, Time: 283.2311 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [125/229], Loss: 0.2952, Time: 283.5289 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [130/229], Loss: 0.2319, Time: 283.8187 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [135/229], Loss: 0.2123, Time: 284.1115 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [140/229], Loss: 0.1923, Time: 284.4064 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [145/229], Loss: 0.1874, Time: 284.7521 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [150/229], Loss: 0.2099, Time: 285.0450 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [155/229], Loss: 0.1984, Time: 285.3348 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [160/229], Loss: 0.2019, Time: 285.6266 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [165/229], Loss: 0.2870, Time: 285.9234 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [170/229], Loss: 0.1894, Time: 286.2232 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [175/229], Loss: 0.1790, Time: 286.5211 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [180/229], Loss: 0.1893, Time: 286.8199 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [185/229], Loss: 0.2143, Time: 287.1087 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [190/229], Loss: 0.2116, Time: 287.4055 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [195/229], Loss: 0.2300, Time: 287.7063 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [200/229], Loss: 0.1976, Time: 288.0061 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [205/229], Loss: 0.1958, Time: 288.2970 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [210/229], Loss: 0.2411, Time: 288.5968 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [215/229], Loss: 0.1964, Time: 288.9016 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [220/229], Loss: 0.1873, Time: 289.1934 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [225/229], Loss: 0.2091, Time: 289.4912 secs, learning rate: 0.0001\n",
      "Epoch [21/60], Step [5/229], Loss: 0.1690, Time: 290.3707 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [10/229], Loss: 0.2227, Time: 290.6605 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [15/229], Loss: 0.1558, Time: 290.9613 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [20/229], Loss: 0.1814, Time: 291.2501 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [25/229], Loss: 0.2061, Time: 291.5410 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [30/229], Loss: 0.2269, Time: 291.8278 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [35/229], Loss: 0.2469, Time: 292.1216 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [40/229], Loss: 0.2206, Time: 292.4204 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [45/229], Loss: 0.1671, Time: 292.7092 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [50/229], Loss: 0.1852, Time: 293.0061 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [55/229], Loss: 0.2374, Time: 293.3199 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [60/229], Loss: 0.1975, Time: 293.6067 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [65/229], Loss: 0.1948, Time: 293.9165 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [70/229], Loss: 0.2425, Time: 294.2143 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [75/229], Loss: 0.1701, Time: 294.5151 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [80/229], Loss: 0.1965, Time: 294.8069 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [85/229], Loss: 0.2207, Time: 295.1018 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [90/229], Loss: 0.2135, Time: 295.4026 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [95/229], Loss: 0.1992, Time: 295.6994 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [100/229], Loss: 0.2233, Time: 295.9972 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [105/229], Loss: 0.1862, Time: 296.2910 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [110/229], Loss: 0.1758, Time: 296.6128 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [115/229], Loss: 0.2374, Time: 296.9186 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [120/229], Loss: 0.2355, Time: 297.2115 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [125/229], Loss: 0.2109, Time: 297.4993 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [130/229], Loss: 0.1797, Time: 297.8311 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [135/229], Loss: 0.2126, Time: 298.1459 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [140/229], Loss: 0.2133, Time: 298.4597 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [145/229], Loss: 0.2344, Time: 298.7475 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [150/229], Loss: 0.2155, Time: 299.0433 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [155/229], Loss: 0.2196, Time: 299.3322 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [160/229], Loss: 0.2152, Time: 299.6180 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [165/229], Loss: 0.1722, Time: 299.9068 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [170/229], Loss: 0.2773, Time: 300.2016 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [175/229], Loss: 0.2246, Time: 300.4944 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [180/229], Loss: 0.2329, Time: 300.8032 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [185/229], Loss: 0.1691, Time: 301.1071 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [190/229], Loss: 0.2313, Time: 301.4019 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [195/229], Loss: 0.1911, Time: 301.6917 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [200/229], Loss: 0.2221, Time: 302.0355 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [205/229], Loss: 0.1915, Time: 302.3333 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [210/229], Loss: 0.2085, Time: 302.6351 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [215/229], Loss: 0.2067, Time: 302.9279 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [220/229], Loss: 0.2030, Time: 303.2307 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [225/229], Loss: 0.2008, Time: 303.5585 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [5/229], Loss: 0.1988, Time: 304.4400 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [10/229], Loss: 0.2170, Time: 304.7418 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [15/229], Loss: 0.1965, Time: 305.0316 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [20/229], Loss: 0.1748, Time: 305.3364 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [25/229], Loss: 0.2075, Time: 305.6343 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [30/229], Loss: 0.1936, Time: 305.9181 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [35/229], Loss: 0.2338, Time: 306.2129 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [40/229], Loss: 0.1869, Time: 306.5037 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [45/229], Loss: 0.1651, Time: 306.7915 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [50/229], Loss: 0.2072, Time: 307.0844 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [55/229], Loss: 0.2179, Time: 307.3892 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [60/229], Loss: 0.1969, Time: 307.6880 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [65/229], Loss: 0.1897, Time: 307.9848 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [70/229], Loss: 0.2094, Time: 308.2886 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [75/229], Loss: 0.1811, Time: 308.5774 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [80/229], Loss: 0.1787, Time: 308.8743 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [85/229], Loss: 0.2132, Time: 309.1731 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [90/229], Loss: 0.2364, Time: 309.4709 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [95/229], Loss: 0.1646, Time: 309.7627 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [100/229], Loss: 0.1545, Time: 310.0505 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [105/229], Loss: 0.2090, Time: 310.3643 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [110/229], Loss: 0.1664, Time: 310.6532 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [115/229], Loss: 0.2402, Time: 310.9390 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [120/229], Loss: 0.2068, Time: 311.2468 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [125/229], Loss: 0.2145, Time: 311.5416 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [130/229], Loss: 0.2053, Time: 311.8304 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [135/229], Loss: 0.1675, Time: 312.1243 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [140/229], Loss: 0.2459, Time: 312.4351 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [145/229], Loss: 0.1803, Time: 312.7239 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [150/229], Loss: 0.1763, Time: 313.0147 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [155/229], Loss: 0.1591, Time: 313.3125 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [160/229], Loss: 0.1865, Time: 313.6063 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [165/229], Loss: 0.1860, Time: 313.9022 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [170/229], Loss: 0.2696, Time: 314.1880 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [175/229], Loss: 0.1754, Time: 314.4888 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [180/229], Loss: 0.2045, Time: 314.7796 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [185/229], Loss: 0.2522, Time: 315.0904 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [190/229], Loss: 0.1976, Time: 315.3902 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [195/229], Loss: 0.2030, Time: 315.6851 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [200/229], Loss: 0.2006, Time: 315.9699 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [205/229], Loss: 0.1669, Time: 316.2577 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [210/229], Loss: 0.2286, Time: 316.5475 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [215/229], Loss: 0.2361, Time: 316.8403 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [220/229], Loss: 0.1979, Time: 317.1382 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [225/229], Loss: 0.2105, Time: 317.4300 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [5/229], Loss: 0.2076, Time: 318.3124 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [10/229], Loss: 0.2315, Time: 318.6073 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [15/229], Loss: 0.2175, Time: 318.9510 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [20/229], Loss: 0.2064, Time: 319.2449 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [25/229], Loss: 0.2370, Time: 319.5547 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [30/229], Loss: 0.2402, Time: 319.8485 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [35/229], Loss: 0.1958, Time: 320.1513 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [40/229], Loss: 0.1711, Time: 320.4381 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [45/229], Loss: 0.2042, Time: 320.7329 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [50/229], Loss: 0.1879, Time: 321.0408 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [55/229], Loss: 0.1647, Time: 321.3296 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [60/229], Loss: 0.2046, Time: 321.6234 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [65/229], Loss: 0.2339, Time: 321.9132 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [70/229], Loss: 0.2068, Time: 322.2100 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [75/229], Loss: 0.1703, Time: 322.4979 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [80/229], Loss: 0.2152, Time: 322.8217 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [85/229], Loss: 0.1527, Time: 323.1315 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [90/229], Loss: 0.2126, Time: 323.4163 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [95/229], Loss: 0.1856, Time: 323.7041 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [100/229], Loss: 0.1909, Time: 323.9949 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [105/229], Loss: 0.2070, Time: 324.3007 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [110/229], Loss: 0.1793, Time: 324.5976 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [115/229], Loss: 0.2212, Time: 324.8954 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [120/229], Loss: 0.2006, Time: 325.1882 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [125/229], Loss: 0.2377, Time: 325.4780 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [130/229], Loss: 0.2158, Time: 325.7708 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [135/229], Loss: 0.2057, Time: 326.0677 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [140/229], Loss: 0.1746, Time: 326.3575 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [145/229], Loss: 0.1514, Time: 326.6503 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [150/229], Loss: 0.2237, Time: 326.9691 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [155/229], Loss: 0.2212, Time: 327.2809 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [160/229], Loss: 0.1827, Time: 327.5767 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [165/229], Loss: 0.1728, Time: 327.8735 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [170/229], Loss: 0.2101, Time: 328.1634 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [175/229], Loss: 0.2432, Time: 328.4612 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [180/229], Loss: 0.2067, Time: 328.7630 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [185/229], Loss: 0.2190, Time: 329.0558 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [190/229], Loss: 0.1959, Time: 329.3506 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [195/229], Loss: 0.2101, Time: 329.6474 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [200/229], Loss: 0.2028, Time: 329.9453 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [205/229], Loss: 0.1683, Time: 330.2421 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [210/229], Loss: 0.2136, Time: 330.5279 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [215/229], Loss: 0.2177, Time: 330.8217 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [220/229], Loss: 0.2241, Time: 331.1165 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [225/229], Loss: 0.2129, Time: 331.4044 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [5/229], Loss: 0.2718, Time: 332.2798 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [10/229], Loss: 0.2055, Time: 332.5676 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [15/229], Loss: 0.1757, Time: 332.8705 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [20/229], Loss: 0.1974, Time: 333.1653 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [25/229], Loss: 0.1878, Time: 333.4521 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [30/229], Loss: 0.2051, Time: 333.7439 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [35/229], Loss: 0.1688, Time: 334.0317 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [40/229], Loss: 0.1738, Time: 334.3236 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [45/229], Loss: 0.2167, Time: 334.6224 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [50/229], Loss: 0.2052, Time: 334.9242 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [55/229], Loss: 0.2304, Time: 335.2180 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [60/229], Loss: 0.2087, Time: 335.5108 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [65/229], Loss: 0.2290, Time: 335.7997 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [70/229], Loss: 0.2161, Time: 336.0975 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [75/229], Loss: 0.1637, Time: 336.4383 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [80/229], Loss: 0.2204, Time: 336.7311 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [85/229], Loss: 0.1513, Time: 337.0309 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [90/229], Loss: 0.2099, Time: 337.3377 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [95/229], Loss: 0.1931, Time: 337.6355 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [100/229], Loss: 0.2294, Time: 337.9233 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [105/229], Loss: 0.1983, Time: 338.2262 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [110/229], Loss: 0.2015, Time: 338.5180 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [115/229], Loss: 0.2363, Time: 338.8108 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [120/229], Loss: 0.1692, Time: 339.1066 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [125/229], Loss: 0.2069, Time: 339.4054 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [130/229], Loss: 0.1974, Time: 339.6982 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [135/229], Loss: 0.2018, Time: 340.0001 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [140/229], Loss: 0.2084, Time: 340.2929 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [145/229], Loss: 0.1863, Time: 340.5967 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [150/229], Loss: 0.2312, Time: 340.9015 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [155/229], Loss: 0.1742, Time: 341.2093 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [160/229], Loss: 0.1966, Time: 341.5081 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [165/229], Loss: 0.2011, Time: 341.7950 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [170/229], Loss: 0.2023, Time: 342.1048 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [175/229], Loss: 0.1635, Time: 342.3926 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [180/229], Loss: 0.1874, Time: 342.6944 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [185/229], Loss: 0.1622, Time: 342.9932 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [190/229], Loss: 0.2048, Time: 343.3050 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [195/229], Loss: 0.1838, Time: 343.6068 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [200/229], Loss: 0.1926, Time: 343.9007 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [205/229], Loss: 0.2315, Time: 344.1925 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [210/229], Loss: 0.2210, Time: 344.4873 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [215/229], Loss: 0.1846, Time: 344.7871 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [220/229], Loss: 0.1820, Time: 345.0739 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [225/229], Loss: 0.2005, Time: 345.3877 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [5/229], Loss: 0.2036, Time: 346.2682 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [10/229], Loss: 0.1651, Time: 346.5680 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [15/229], Loss: 0.1875, Time: 346.8568 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [20/229], Loss: 0.1566, Time: 347.1556 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [25/229], Loss: 0.1813, Time: 347.4515 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [30/229], Loss: 0.1684, Time: 347.7503 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [35/229], Loss: 0.1866, Time: 348.0461 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [40/229], Loss: 0.1846, Time: 348.3409 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [45/229], Loss: 0.1895, Time: 348.6277 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [50/229], Loss: 0.1715, Time: 348.9276 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [55/229], Loss: 0.2268, Time: 349.2224 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [60/229], Loss: 0.2075, Time: 349.5312 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [65/229], Loss: 0.1811, Time: 349.8270 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [70/229], Loss: 0.1716, Time: 350.1168 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [75/229], Loss: 0.1801, Time: 350.4176 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [80/229], Loss: 0.1913, Time: 350.7224 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [85/229], Loss: 0.1548, Time: 351.0223 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [90/229], Loss: 0.1957, Time: 351.3181 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [95/229], Loss: 0.2030, Time: 351.6109 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [100/229], Loss: 0.1772, Time: 351.9057 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [105/229], Loss: 0.2063, Time: 352.1985 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [110/229], Loss: 0.1689, Time: 352.5023 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [115/229], Loss: 0.1946, Time: 352.7912 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [120/229], Loss: 0.1824, Time: 353.0960 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [125/229], Loss: 0.1926, Time: 353.4418 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [130/229], Loss: 0.2468, Time: 353.7316 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [135/229], Loss: 0.2051, Time: 354.0274 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [140/229], Loss: 0.2011, Time: 354.3562 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [145/229], Loss: 0.2162, Time: 354.6500 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [150/229], Loss: 0.1648, Time: 354.9488 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [155/229], Loss: 0.2252, Time: 355.2437 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [160/229], Loss: 0.1936, Time: 355.5395 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [165/229], Loss: 0.1997, Time: 355.8323 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [170/229], Loss: 0.2061, Time: 356.1251 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [175/229], Loss: 0.2206, Time: 356.4119 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [180/229], Loss: 0.1988, Time: 356.7028 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [185/229], Loss: 0.2153, Time: 357.0036 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [190/229], Loss: 0.2013, Time: 357.2934 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [195/229], Loss: 0.2167, Time: 357.5902 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [200/229], Loss: 0.1778, Time: 357.8830 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [205/229], Loss: 0.2068, Time: 358.2008 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [210/229], Loss: 0.1763, Time: 358.4957 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [215/229], Loss: 0.1937, Time: 358.7845 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [220/229], Loss: 0.1832, Time: 359.0823 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [225/229], Loss: 0.1489, Time: 359.3861 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [5/229], Loss: 0.1789, Time: 360.2696 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [10/229], Loss: 0.1883, Time: 360.5564 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [15/229], Loss: 0.1520, Time: 360.8462 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [20/229], Loss: 0.1613, Time: 361.1540 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [25/229], Loss: 0.2279, Time: 361.4538 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [30/229], Loss: 0.1846, Time: 361.7636 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [35/229], Loss: 0.2153, Time: 362.0734 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [40/229], Loss: 0.1497, Time: 362.3743 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [45/229], Loss: 0.1985, Time: 362.6611 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [50/229], Loss: 0.2323, Time: 362.9699 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [55/229], Loss: 0.1941, Time: 363.2757 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [60/229], Loss: 0.2195, Time: 363.5695 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [65/229], Loss: 0.1694, Time: 363.8593 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [70/229], Loss: 0.1600, Time: 364.1652 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [75/229], Loss: 0.1725, Time: 364.4690 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [80/229], Loss: 0.2094, Time: 364.7778 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [85/229], Loss: 0.1458, Time: 365.0746 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [90/229], Loss: 0.2113, Time: 365.3704 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [95/229], Loss: 0.2027, Time: 365.6622 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [100/229], Loss: 0.2030, Time: 365.9840 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [105/229], Loss: 0.1972, Time: 366.2808 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [110/229], Loss: 0.2149, Time: 366.5797 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [115/229], Loss: 0.1894, Time: 366.8745 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [120/229], Loss: 0.1648, Time: 367.1683 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [125/229], Loss: 0.2043, Time: 367.4551 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [130/229], Loss: 0.2048, Time: 367.7549 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [135/229], Loss: 0.1636, Time: 368.0458 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [140/229], Loss: 0.1795, Time: 368.3516 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [145/229], Loss: 0.2379, Time: 368.6694 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [150/229], Loss: 0.2318, Time: 368.9622 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [155/229], Loss: 0.1987, Time: 369.2590 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [160/229], Loss: 0.1668, Time: 369.5508 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [165/229], Loss: 0.1915, Time: 369.8526 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [170/229], Loss: 0.2009, Time: 370.1525 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [175/229], Loss: 0.2148, Time: 370.4493 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [180/229], Loss: 0.1846, Time: 370.8161 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [185/229], Loss: 0.1794, Time: 371.1069 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [190/229], Loss: 0.1876, Time: 371.4197 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [195/229], Loss: 0.1915, Time: 371.7075 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [200/229], Loss: 0.1801, Time: 372.0103 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [205/229], Loss: 0.2015, Time: 372.3121 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [210/229], Loss: 0.2152, Time: 372.6109 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [215/229], Loss: 0.1883, Time: 372.9068 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [220/229], Loss: 0.1968, Time: 373.2006 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [225/229], Loss: 0.1814, Time: 373.5094 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [5/229], Loss: 0.2235, Time: 374.3908 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [10/229], Loss: 0.2132, Time: 374.6787 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [15/229], Loss: 0.2156, Time: 374.9935 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [20/229], Loss: 0.1720, Time: 375.2923 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [25/229], Loss: 0.1796, Time: 375.5871 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [30/229], Loss: 0.1984, Time: 375.8829 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [35/229], Loss: 0.1669, Time: 376.1867 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [40/229], Loss: 0.1507, Time: 376.4866 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [45/229], Loss: 0.2101, Time: 376.7944 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [50/229], Loss: 0.1997, Time: 377.3230 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [55/229], Loss: 0.1873, Time: 377.6888 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [60/229], Loss: 0.2437, Time: 378.0406 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [65/229], Loss: 0.1627, Time: 378.3364 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [70/229], Loss: 0.1848, Time: 378.6412 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [75/229], Loss: 0.1881, Time: 378.9360 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [80/229], Loss: 0.1574, Time: 379.3378 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [85/229], Loss: 0.2290, Time: 379.8045 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [90/229], Loss: 0.1809, Time: 380.2662 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [95/229], Loss: 0.1953, Time: 380.7379 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [100/229], Loss: 0.1980, Time: 381.0397 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [105/229], Loss: 0.2129, Time: 381.3356 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [110/229], Loss: 0.1885, Time: 381.6344 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [115/229], Loss: 0.2133, Time: 381.9382 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [120/229], Loss: 0.1859, Time: 382.2300 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [125/229], Loss: 0.2156, Time: 382.5308 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [130/229], Loss: 0.1701, Time: 382.8236 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [135/229], Loss: 0.2420, Time: 383.1155 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [140/229], Loss: 0.1998, Time: 383.4173 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [145/229], Loss: 0.2584, Time: 383.7231 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [150/229], Loss: 0.1775, Time: 384.0139 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [155/229], Loss: 0.1627, Time: 384.3237 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [160/229], Loss: 0.2038, Time: 384.6225 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [165/229], Loss: 0.2046, Time: 384.9134 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [170/229], Loss: 0.2619, Time: 385.2122 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [175/229], Loss: 0.1680, Time: 385.5280 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [180/229], Loss: 0.1712, Time: 385.8308 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [185/229], Loss: 0.1686, Time: 386.1346 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [190/229], Loss: 0.1931, Time: 386.4234 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [195/229], Loss: 0.2270, Time: 386.7202 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [200/229], Loss: 0.2118, Time: 387.0271 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [205/229], Loss: 0.1560, Time: 387.4218 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [210/229], Loss: 0.1867, Time: 387.7096 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [215/229], Loss: 0.2175, Time: 388.0484 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [220/229], Loss: 0.2602, Time: 388.3462 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [225/229], Loss: 0.2075, Time: 388.6391 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [5/229], Loss: 0.2161, Time: 389.5285 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [10/229], Loss: 0.2128, Time: 389.8173 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [15/229], Loss: 0.1704, Time: 390.1221 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [20/229], Loss: 0.1563, Time: 390.4190 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [25/229], Loss: 0.1468, Time: 390.7198 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [30/229], Loss: 0.1925, Time: 391.0326 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [35/229], Loss: 0.2154, Time: 391.3204 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [40/229], Loss: 0.1943, Time: 391.6172 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [45/229], Loss: 0.2231, Time: 391.9130 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [50/229], Loss: 0.2117, Time: 392.2109 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [55/229], Loss: 0.2175, Time: 392.5107 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [60/229], Loss: 0.1747, Time: 392.7975 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [65/229], Loss: 0.2037, Time: 393.0903 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [70/229], Loss: 0.1941, Time: 393.3861 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [75/229], Loss: 0.1811, Time: 393.6839 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [80/229], Loss: 0.1511, Time: 393.9828 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [85/229], Loss: 0.1447, Time: 394.2726 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [90/229], Loss: 0.1890, Time: 394.5694 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [95/229], Loss: 0.2109, Time: 394.8572 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [100/229], Loss: 0.2245, Time: 395.1570 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [105/229], Loss: 0.2371, Time: 395.4499 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [110/229], Loss: 0.1646, Time: 395.7527 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [115/229], Loss: 0.1608, Time: 396.0745 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [120/229], Loss: 0.2224, Time: 396.3803 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [125/229], Loss: 0.2097, Time: 396.6711 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [130/229], Loss: 0.1748, Time: 396.9619 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [135/229], Loss: 0.1959, Time: 397.2797 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [140/229], Loss: 0.1928, Time: 397.5865 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [145/229], Loss: 0.1755, Time: 397.8754 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [150/229], Loss: 0.2015, Time: 398.1672 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [155/229], Loss: 0.1989, Time: 398.4590 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [160/229], Loss: 0.1440, Time: 398.7518 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [165/229], Loss: 0.1612, Time: 399.0446 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [170/229], Loss: 0.1914, Time: 399.3415 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [175/229], Loss: 0.1853, Time: 399.6403 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [180/229], Loss: 0.1775, Time: 399.9301 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [185/229], Loss: 0.1816, Time: 400.2239 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [190/229], Loss: 0.1911, Time: 400.5187 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [195/229], Loss: 0.1892, Time: 400.8125 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [200/229], Loss: 0.1838, Time: 401.1024 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [205/229], Loss: 0.1877, Time: 401.3982 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [210/229], Loss: 0.1684, Time: 401.7020 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [215/229], Loss: 0.1909, Time: 401.9948 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [220/229], Loss: 0.2034, Time: 402.2866 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [225/229], Loss: 0.1915, Time: 402.5795 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [5/229], Loss: 0.1948, Time: 403.4619 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [10/229], Loss: 0.1944, Time: 403.7527 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [15/229], Loss: 0.1643, Time: 404.0575 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [20/229], Loss: 0.2554, Time: 404.3524 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [25/229], Loss: 0.1548, Time: 404.6532 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [30/229], Loss: 0.1836, Time: 404.9940 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [35/229], Loss: 0.1613, Time: 405.2868 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [40/229], Loss: 0.1792, Time: 405.5956 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [45/229], Loss: 0.2175, Time: 405.8904 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [50/229], Loss: 0.2066, Time: 406.1792 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [55/229], Loss: 0.1852, Time: 406.4701 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [60/229], Loss: 0.1602, Time: 406.7609 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [65/229], Loss: 0.1905, Time: 407.0587 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [70/229], Loss: 0.1724, Time: 407.4425 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [75/229], Loss: 0.1857, Time: 407.9102 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [80/229], Loss: 0.1517, Time: 408.3759 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [85/229], Loss: 0.1519, Time: 408.8246 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [90/229], Loss: 0.1824, Time: 409.2923 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [95/229], Loss: 0.1770, Time: 409.7540 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [100/229], Loss: 0.1816, Time: 410.2337 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [105/229], Loss: 0.1869, Time: 410.6425 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [110/229], Loss: 0.1860, Time: 410.9343 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [115/229], Loss: 0.2396, Time: 411.2421 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [120/229], Loss: 0.2241, Time: 411.5449 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [125/229], Loss: 0.1999, Time: 411.8357 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [130/229], Loss: 0.1537, Time: 412.1276 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [135/229], Loss: 0.1416, Time: 412.4224 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [140/229], Loss: 0.1944, Time: 412.7192 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [145/229], Loss: 0.1747, Time: 413.0100 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [150/229], Loss: 0.1681, Time: 413.3108 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [155/229], Loss: 0.1561, Time: 413.6097 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [160/229], Loss: 0.1800, Time: 413.8985 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [165/229], Loss: 0.1813, Time: 414.1933 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [170/229], Loss: 0.1963, Time: 414.4861 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [175/229], Loss: 0.1609, Time: 414.7809 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [180/229], Loss: 0.1937, Time: 415.0747 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [185/229], Loss: 0.2054, Time: 415.3646 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [190/229], Loss: 0.1725, Time: 415.6514 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [195/229], Loss: 0.1593, Time: 415.9512 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [200/229], Loss: 0.1876, Time: 416.2420 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [205/229], Loss: 0.1648, Time: 416.5358 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [210/229], Loss: 0.2058, Time: 416.8367 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [215/229], Loss: 0.2117, Time: 417.1405 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [220/229], Loss: 0.2062, Time: 417.4403 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [225/229], Loss: 0.1971, Time: 417.7231 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [5/229], Loss: 0.2027, Time: 418.5996 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [10/229], Loss: 0.1812, Time: 418.8904 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [15/229], Loss: 0.1743, Time: 419.1862 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [20/229], Loss: 0.1491, Time: 419.4800 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [25/229], Loss: 0.1878, Time: 419.7788 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [30/229], Loss: 0.1808, Time: 420.0797 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [35/229], Loss: 0.1772, Time: 420.3735 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [40/229], Loss: 0.2064, Time: 420.6833 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [45/229], Loss: 0.2028, Time: 420.9891 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [50/229], Loss: 0.1820, Time: 421.2809 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [55/229], Loss: 0.2065, Time: 421.5797 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [60/229], Loss: 0.1927, Time: 421.8686 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [65/229], Loss: 0.2249, Time: 422.2343 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [70/229], Loss: 0.1608, Time: 422.5311 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [75/229], Loss: 0.1717, Time: 422.8320 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [80/229], Loss: 0.1635, Time: 423.1408 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [85/229], Loss: 0.1834, Time: 423.4416 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [90/229], Loss: 0.1399, Time: 423.7344 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [95/229], Loss: 0.2167, Time: 424.0242 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [100/229], Loss: 0.1904, Time: 424.3490 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [105/229], Loss: 0.1878, Time: 424.8837 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [110/229], Loss: 0.1860, Time: 425.2195 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [115/229], Loss: 0.1402, Time: 425.5113 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [120/229], Loss: 0.1592, Time: 425.8111 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [125/229], Loss: 0.1610, Time: 426.1039 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [130/229], Loss: 0.2008, Time: 426.4028 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [135/229], Loss: 0.2074, Time: 426.7076 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [140/229], Loss: 0.1952, Time: 426.9974 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [145/229], Loss: 0.1630, Time: 427.2942 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [150/229], Loss: 0.1693, Time: 427.5880 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [155/229], Loss: 0.1744, Time: 427.8769 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [160/229], Loss: 0.2152, Time: 428.1907 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [165/229], Loss: 0.2079, Time: 428.4875 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [170/229], Loss: 0.1915, Time: 428.7803 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [175/229], Loss: 0.1486, Time: 429.0701 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [180/229], Loss: 0.1690, Time: 429.3639 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [185/229], Loss: 0.2260, Time: 429.6667 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [190/229], Loss: 0.1511, Time: 429.9566 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [195/229], Loss: 0.1919, Time: 430.2474 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [200/229], Loss: 0.1853, Time: 430.5382 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [205/229], Loss: 0.2144, Time: 430.8480 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [210/229], Loss: 0.1716, Time: 431.1408 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [215/229], Loss: 0.2184, Time: 431.4307 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [220/229], Loss: 0.2128, Time: 431.7225 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [225/229], Loss: 0.2309, Time: 432.0103 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [5/229], Loss: 0.1807, Time: 432.8988 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [10/229], Loss: 0.1914, Time: 433.2006 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [15/229], Loss: 0.2107, Time: 433.5214 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [20/229], Loss: 0.1681, Time: 433.8172 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [25/229], Loss: 0.1900, Time: 434.1240 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [30/229], Loss: 0.1668, Time: 434.4218 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [35/229], Loss: 0.1882, Time: 434.7276 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [40/229], Loss: 0.2113, Time: 435.0564 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [45/229], Loss: 0.1712, Time: 435.3762 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [50/229], Loss: 0.1469, Time: 435.7340 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [55/229], Loss: 0.2037, Time: 436.0938 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [60/229], Loss: 0.1672, Time: 436.4386 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [65/229], Loss: 0.1438, Time: 436.8133 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [70/229], Loss: 0.1991, Time: 437.2830 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [75/229], Loss: 0.2029, Time: 437.7538 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [80/229], Loss: 0.2230, Time: 438.2035 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [85/229], Loss: 0.1561, Time: 438.6492 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [90/229], Loss: 0.1476, Time: 439.1069 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [95/229], Loss: 0.1720, Time: 439.6376 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [100/229], Loss: 0.1594, Time: 440.0983 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [105/229], Loss: 0.1638, Time: 440.5550 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [110/229], Loss: 0.1962, Time: 441.0187 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [115/229], Loss: 0.1767, Time: 441.3975 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [120/229], Loss: 0.1839, Time: 441.8093 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [125/229], Loss: 0.2201, Time: 442.1371 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [130/229], Loss: 0.1909, Time: 442.4429 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [135/229], Loss: 0.1831, Time: 442.7557 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [140/229], Loss: 0.1375, Time: 443.0575 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [145/229], Loss: 0.1670, Time: 443.3733 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [150/229], Loss: 0.2306, Time: 443.6661 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [155/229], Loss: 0.1885, Time: 443.9599 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [160/229], Loss: 0.2279, Time: 444.2647 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [165/229], Loss: 0.1623, Time: 444.5566 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [170/229], Loss: 0.1839, Time: 444.9573 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [175/229], Loss: 0.1502, Time: 445.2881 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [180/229], Loss: 0.1829, Time: 445.5819 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [185/229], Loss: 0.1547, Time: 445.8797 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [190/229], Loss: 0.1939, Time: 446.1756 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [195/229], Loss: 0.1771, Time: 446.4704 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [200/229], Loss: 0.1800, Time: 446.7812 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [205/229], Loss: 0.1819, Time: 447.0830 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [210/229], Loss: 0.1871, Time: 447.3818 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [215/229], Loss: 0.2127, Time: 447.6686 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [220/229], Loss: 0.1413, Time: 447.9605 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [225/229], Loss: 0.2063, Time: 448.2503 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [5/229], Loss: 0.1810, Time: 449.1317 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [10/229], Loss: 0.1504, Time: 449.4306 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [15/229], Loss: 0.1997, Time: 449.7274 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [20/229], Loss: 0.1841, Time: 450.0232 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [25/229], Loss: 0.1559, Time: 450.3250 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [30/229], Loss: 0.2116, Time: 450.6208 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [35/229], Loss: 0.1499, Time: 450.9096 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [40/229], Loss: 0.1991, Time: 451.2005 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [45/229], Loss: 0.1730, Time: 451.4923 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [50/229], Loss: 0.2186, Time: 451.7931 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [55/229], Loss: 0.2026, Time: 452.0839 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [60/229], Loss: 0.1828, Time: 452.3737 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [65/229], Loss: 0.1616, Time: 452.6766 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [70/229], Loss: 0.1543, Time: 452.9754 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [75/229], Loss: 0.1607, Time: 453.2732 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [80/229], Loss: 0.1664, Time: 453.5720 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [85/229], Loss: 0.1625, Time: 453.8668 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [90/229], Loss: 0.1881, Time: 454.1576 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [95/229], Loss: 0.1799, Time: 454.4525 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [100/229], Loss: 0.1834, Time: 454.7523 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [105/229], Loss: 0.1919, Time: 455.0531 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [110/229], Loss: 0.1804, Time: 455.3499 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [115/229], Loss: 0.2337, Time: 455.6397 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [120/229], Loss: 0.1938, Time: 455.9415 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [125/229], Loss: 0.2173, Time: 456.2424 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [130/229], Loss: 0.1473, Time: 456.5891 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [135/229], Loss: 0.2096, Time: 456.8770 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [140/229], Loss: 0.2292, Time: 457.1708 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [145/229], Loss: 0.1770, Time: 457.4726 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [150/229], Loss: 0.1933, Time: 457.7694 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [155/229], Loss: 0.1593, Time: 458.0572 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [160/229], Loss: 0.1979, Time: 458.3521 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [165/229], Loss: 0.1905, Time: 458.6519 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [170/229], Loss: 0.2125, Time: 458.9507 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [175/229], Loss: 0.1574, Time: 459.2455 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [180/229], Loss: 0.2163, Time: 459.5343 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [185/229], Loss: 0.1690, Time: 459.8341 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [190/229], Loss: 0.1367, Time: 460.1350 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [195/229], Loss: 0.1584, Time: 460.4358 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [200/229], Loss: 0.1936, Time: 460.7416 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [205/229], Loss: 0.2057, Time: 461.0434 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [210/229], Loss: 0.1825, Time: 461.3512 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [215/229], Loss: 0.1546, Time: 461.6680 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [220/229], Loss: 0.2181, Time: 462.0378 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [225/229], Loss: 0.1517, Time: 462.3906 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [5/229], Loss: 0.1814, Time: 463.2990 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [10/229], Loss: 0.2123, Time: 463.5938 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [15/229], Loss: 0.2276, Time: 463.8826 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [20/229], Loss: 0.1406, Time: 464.1805 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [25/229], Loss: 0.1366, Time: 464.4803 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [30/229], Loss: 0.1722, Time: 464.7881 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [35/229], Loss: 0.2433, Time: 465.0829 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [40/229], Loss: 0.1747, Time: 465.3837 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [45/229], Loss: 0.1788, Time: 465.6805 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [50/229], Loss: 0.1602, Time: 465.9833 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [55/229], Loss: 0.1969, Time: 466.2742 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [60/229], Loss: 0.1758, Time: 466.5670 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [65/229], Loss: 0.1915, Time: 466.8618 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [70/229], Loss: 0.1360, Time: 467.1526 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [75/229], Loss: 0.1673, Time: 467.4924 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [80/229], Loss: 0.1983, Time: 467.8072 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [85/229], Loss: 0.1670, Time: 468.0960 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [90/229], Loss: 0.1892, Time: 468.3829 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [95/229], Loss: 0.1932, Time: 468.6827 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [100/229], Loss: 0.1757, Time: 468.9915 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [105/229], Loss: 0.1847, Time: 469.2883 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [110/229], Loss: 0.1516, Time: 469.6051 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [115/229], Loss: 0.2057, Time: 470.1298 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [120/229], Loss: 0.1927, Time: 470.4716 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [125/229], Loss: 0.2127, Time: 470.7804 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [130/229], Loss: 0.1771, Time: 471.0782 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [135/229], Loss: 0.1922, Time: 471.3730 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [140/229], Loss: 0.1924, Time: 471.6608 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [145/229], Loss: 0.1686, Time: 471.9547 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [150/229], Loss: 0.1711, Time: 472.2525 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [155/229], Loss: 0.1838, Time: 472.5393 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [160/229], Loss: 0.2109, Time: 472.8491 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [165/229], Loss: 0.2043, Time: 473.1389 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [170/229], Loss: 0.1736, Time: 473.4477 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [175/229], Loss: 0.1897, Time: 473.7995 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [180/229], Loss: 0.1375, Time: 474.1053 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [185/229], Loss: 0.1555, Time: 474.3952 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [190/229], Loss: 0.1835, Time: 474.6830 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [195/229], Loss: 0.2286, Time: 474.9858 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [200/229], Loss: 0.1834, Time: 475.3036 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [205/229], Loss: 0.1506, Time: 475.5934 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [210/229], Loss: 0.2197, Time: 475.8992 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [215/229], Loss: 0.1612, Time: 476.1900 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [220/229], Loss: 0.1781, Time: 476.4799 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [225/229], Loss: 0.2077, Time: 476.7797 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [5/229], Loss: 0.2453, Time: 477.6711 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [10/229], Loss: 0.1539, Time: 477.9650 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [15/229], Loss: 0.1366, Time: 478.2558 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [20/229], Loss: 0.1943, Time: 478.5576 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [25/229], Loss: 0.1767, Time: 478.8584 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [30/229], Loss: 0.1792, Time: 479.1492 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [35/229], Loss: 0.1902, Time: 479.4470 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [40/229], Loss: 0.1921, Time: 479.7429 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [45/229], Loss: 0.1473, Time: 480.0427 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [50/229], Loss: 0.2096, Time: 480.3405 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [55/229], Loss: 0.2266, Time: 480.6313 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [60/229], Loss: 0.1581, Time: 480.9241 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [65/229], Loss: 0.1902, Time: 481.2259 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [70/229], Loss: 0.2049, Time: 481.5248 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [75/229], Loss: 0.1584, Time: 481.8286 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [80/229], Loss: 0.1885, Time: 482.1174 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [85/229], Loss: 0.1695, Time: 482.4082 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [90/229], Loss: 0.1767, Time: 482.6970 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [95/229], Loss: 0.1406, Time: 482.9879 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [100/229], Loss: 0.1831, Time: 483.2807 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [105/229], Loss: 0.2044, Time: 483.5775 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [110/229], Loss: 0.2016, Time: 483.8823 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [115/229], Loss: 0.1690, Time: 484.1961 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [120/229], Loss: 0.1978, Time: 484.5009 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [125/229], Loss: 0.1333, Time: 484.8007 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [130/229], Loss: 0.1918, Time: 485.0985 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [135/229], Loss: 0.2453, Time: 485.3884 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [140/229], Loss: 0.2152, Time: 485.6802 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [145/229], Loss: 0.1832, Time: 485.9730 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [150/229], Loss: 0.1712, Time: 486.2698 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [155/229], Loss: 0.2121, Time: 486.5587 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [160/229], Loss: 0.1853, Time: 486.8605 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [165/229], Loss: 0.1781, Time: 487.1483 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [170/229], Loss: 0.2418, Time: 487.4401 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [175/229], Loss: 0.2073, Time: 487.7489 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [180/229], Loss: 0.1368, Time: 488.0437 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [185/229], Loss: 0.1655, Time: 488.3405 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [190/229], Loss: 0.1842, Time: 488.6314 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [195/229], Loss: 0.1964, Time: 488.9342 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [200/229], Loss: 0.1553, Time: 489.2430 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [205/229], Loss: 0.1461, Time: 489.5508 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [210/229], Loss: 0.1823, Time: 489.8506 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [215/229], Loss: 0.1828, Time: 490.1434 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [220/229], Loss: 0.1821, Time: 490.4393 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [225/229], Loss: 0.1846, Time: 490.7341 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [5/229], Loss: 0.2201, Time: 491.6515 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [10/229], Loss: 0.1680, Time: 491.9523 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [15/229], Loss: 0.1869, Time: 492.2531 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [20/229], Loss: 0.2012, Time: 492.5460 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [25/229], Loss: 0.1691, Time: 492.8378 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [30/229], Loss: 0.2076, Time: 493.1266 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [35/229], Loss: 0.1978, Time: 493.4244 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [40/229], Loss: 0.2136, Time: 493.7302 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [45/229], Loss: 0.1889, Time: 494.0420 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [50/229], Loss: 0.2115, Time: 494.3478 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [55/229], Loss: 0.1837, Time: 494.6337 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [60/229], Loss: 0.1880, Time: 494.9565 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [65/229], Loss: 0.1605, Time: 495.2543 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [70/229], Loss: 0.1556, Time: 495.5491 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [75/229], Loss: 0.1403, Time: 495.8389 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [80/229], Loss: 0.1549, Time: 496.1397 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [85/229], Loss: 0.1607, Time: 496.4356 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [90/229], Loss: 0.1746, Time: 496.7234 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [95/229], Loss: 0.1843, Time: 497.0202 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [100/229], Loss: 0.1735, Time: 497.3170 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [105/229], Loss: 0.2164, Time: 497.6258 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [110/229], Loss: 0.1612, Time: 497.9186 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [115/229], Loss: 0.1661, Time: 498.2155 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [120/229], Loss: 0.1882, Time: 498.5103 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [125/229], Loss: 0.2001, Time: 498.9020 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [130/229], Loss: 0.2373, Time: 499.3188 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [135/229], Loss: 0.1554, Time: 499.6796 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [140/229], Loss: 0.2011, Time: 500.0563 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [145/229], Loss: 0.1663, Time: 500.4341 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [150/229], Loss: 0.1780, Time: 500.7749 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [155/229], Loss: 0.1468, Time: 501.1197 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [160/229], Loss: 0.1418, Time: 501.4255 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [165/229], Loss: 0.1835, Time: 501.7143 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [170/229], Loss: 0.1914, Time: 502.0111 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [175/229], Loss: 0.1875, Time: 502.3129 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [180/229], Loss: 0.1576, Time: 502.6327 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [185/229], Loss: 0.1488, Time: 502.9246 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [190/229], Loss: 0.1711, Time: 503.2324 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [195/229], Loss: 0.1656, Time: 503.5252 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [200/229], Loss: 0.1591, Time: 503.8140 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [205/229], Loss: 0.1590, Time: 504.1018 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [210/229], Loss: 0.1975, Time: 504.4166 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [215/229], Loss: 0.2110, Time: 504.7404 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [220/229], Loss: 0.1476, Time: 505.0323 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [225/229], Loss: 0.1573, Time: 505.3361 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [5/229], Loss: 0.1655, Time: 506.2365 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [10/229], Loss: 0.1759, Time: 506.5283 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [15/229], Loss: 0.1791, Time: 506.8421 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [20/229], Loss: 0.1482, Time: 507.1459 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [25/229], Loss: 0.2195, Time: 507.4438 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [30/229], Loss: 0.1742, Time: 507.7486 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [35/229], Loss: 0.1592, Time: 508.0364 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [40/229], Loss: 0.1859, Time: 508.3972 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [45/229], Loss: 0.2318, Time: 508.6980 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [50/229], Loss: 0.1858, Time: 508.9978 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [55/229], Loss: 0.1943, Time: 509.2976 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [60/229], Loss: 0.1976, Time: 509.5944 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [65/229], Loss: 0.1748, Time: 509.8973 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [70/229], Loss: 0.1453, Time: 510.1901 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [75/229], Loss: 0.1530, Time: 510.4909 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [80/229], Loss: 0.1831, Time: 510.8227 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [85/229], Loss: 0.1820, Time: 511.3374 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [90/229], Loss: 0.1654, Time: 511.6802 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [95/229], Loss: 0.1764, Time: 511.9690 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [100/229], Loss: 0.1872, Time: 512.2558 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [105/229], Loss: 0.1529, Time: 512.5486 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [110/229], Loss: 0.1476, Time: 512.8414 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [115/229], Loss: 0.1820, Time: 513.1403 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [120/229], Loss: 0.1355, Time: 513.4371 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [125/229], Loss: 0.1575, Time: 513.7339 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [130/229], Loss: 0.1745, Time: 514.0417 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [135/229], Loss: 0.2436, Time: 514.3545 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [140/229], Loss: 0.1739, Time: 514.6533 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [145/229], Loss: 0.1551, Time: 514.9431 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [150/229], Loss: 0.2028, Time: 515.2470 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [155/229], Loss: 0.2024, Time: 515.5408 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [160/229], Loss: 0.1648, Time: 515.8336 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [165/229], Loss: 0.2001, Time: 516.1274 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [170/229], Loss: 0.2189, Time: 516.4212 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [175/229], Loss: 0.2034, Time: 516.7130 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [180/229], Loss: 0.1445, Time: 517.0219 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [185/229], Loss: 0.1647, Time: 517.3157 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [190/229], Loss: 0.1907, Time: 517.6115 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [195/229], Loss: 0.1622, Time: 517.9093 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [200/229], Loss: 0.1800, Time: 518.2131 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [205/229], Loss: 0.1718, Time: 518.5149 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [210/229], Loss: 0.1926, Time: 518.8078 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [215/229], Loss: 0.2407, Time: 519.1136 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [220/229], Loss: 0.2030, Time: 519.4044 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [225/229], Loss: 0.1862, Time: 519.6982 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [5/229], Loss: 0.1355, Time: 520.5807 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [10/229], Loss: 0.1933, Time: 520.8695 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [15/229], Loss: 0.1393, Time: 521.1753 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [20/229], Loss: 0.1911, Time: 521.4681 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [25/229], Loss: 0.1932, Time: 521.7669 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [30/229], Loss: 0.1808, Time: 522.0597 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [35/229], Loss: 0.1783, Time: 522.3476 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [40/229], Loss: 0.1810, Time: 522.6484 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [45/229], Loss: 0.1621, Time: 522.9362 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [50/229], Loss: 0.1628, Time: 523.2440 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [55/229], Loss: 0.2395, Time: 523.5488 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [60/229], Loss: 0.2140, Time: 523.8546 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [65/229], Loss: 0.1815, Time: 524.1515 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [70/229], Loss: 0.1814, Time: 524.4483 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [75/229], Loss: 0.1649, Time: 524.7491 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [80/229], Loss: 0.1663, Time: 525.0429 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [85/229], Loss: 0.1830, Time: 525.3917 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [90/229], Loss: 0.1566, Time: 525.6995 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [95/229], Loss: 0.1815, Time: 525.9973 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [100/229], Loss: 0.1782, Time: 526.2911 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [105/229], Loss: 0.1538, Time: 526.5900 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [110/229], Loss: 0.1434, Time: 526.8778 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [115/229], Loss: 0.1692, Time: 527.1856 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [120/229], Loss: 0.1741, Time: 527.4944 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [125/229], Loss: 0.1540, Time: 527.7842 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [130/229], Loss: 0.1806, Time: 528.0710 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [135/229], Loss: 0.1762, Time: 528.3649 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [140/229], Loss: 0.1557, Time: 528.6707 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [145/229], Loss: 0.1963, Time: 528.9625 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [150/229], Loss: 0.1900, Time: 529.2533 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [155/229], Loss: 0.1673, Time: 529.5491 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [160/229], Loss: 0.1667, Time: 529.8489 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [165/229], Loss: 0.2143, Time: 530.1438 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [170/229], Loss: 0.1615, Time: 530.4336 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [175/229], Loss: 0.1855, Time: 530.7304 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [180/229], Loss: 0.1535, Time: 531.0282 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [185/229], Loss: 0.1451, Time: 531.3210 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [190/229], Loss: 0.1601, Time: 531.6139 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [195/229], Loss: 0.1744, Time: 531.9047 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [200/229], Loss: 0.2122, Time: 532.1985 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [205/229], Loss: 0.1799, Time: 532.4873 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [210/229], Loss: 0.1667, Time: 532.7951 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [215/229], Loss: 0.1568, Time: 533.1039 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [220/229], Loss: 0.1895, Time: 533.3958 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [225/229], Loss: 0.2126, Time: 533.6906 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [5/229], Loss: 0.1986, Time: 534.5640 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [10/229], Loss: 0.1880, Time: 534.8569 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [15/229], Loss: 0.1652, Time: 535.1597 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [20/229], Loss: 0.1311, Time: 535.4495 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [25/229], Loss: 0.1814, Time: 535.7403 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [30/229], Loss: 0.2102, Time: 536.0411 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [35/229], Loss: 0.2253, Time: 536.3299 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [40/229], Loss: 0.1342, Time: 536.6198 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [45/229], Loss: 0.2136, Time: 536.9196 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [50/229], Loss: 0.1879, Time: 537.2314 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [55/229], Loss: 0.1579, Time: 537.5312 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [60/229], Loss: 0.1806, Time: 537.8250 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [65/229], Loss: 0.1647, Time: 538.1258 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [70/229], Loss: 0.1487, Time: 538.4237 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [75/229], Loss: 0.1597, Time: 538.7145 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [80/229], Loss: 0.1869, Time: 539.0093 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [85/229], Loss: 0.1641, Time: 539.3071 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [90/229], Loss: 0.1855, Time: 539.5989 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [95/229], Loss: 0.1787, Time: 539.9017 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [100/229], Loss: 0.1927, Time: 540.1966 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [105/229], Loss: 0.2137, Time: 540.4864 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [110/229], Loss: 0.2140, Time: 540.7922 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [115/229], Loss: 0.1727, Time: 541.0930 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [120/229], Loss: 0.1891, Time: 541.3838 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [125/229], Loss: 0.1641, Time: 541.6926 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [130/229], Loss: 0.1644, Time: 541.9905 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [135/229], Loss: 0.1773, Time: 542.2833 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [140/229], Loss: 0.1582, Time: 542.6191 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [145/229], Loss: 0.2030, Time: 542.9189 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [150/229], Loss: 0.1939, Time: 543.2177 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [155/229], Loss: 0.2237, Time: 543.5125 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [160/229], Loss: 0.1967, Time: 543.8073 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [165/229], Loss: 0.2136, Time: 544.1101 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [170/229], Loss: 0.1843, Time: 544.4020 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [175/229], Loss: 0.1440, Time: 544.7178 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [180/229], Loss: 0.1800, Time: 545.0296 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [185/229], Loss: 0.1767, Time: 545.3274 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [190/229], Loss: 0.1822, Time: 545.6302 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [195/229], Loss: 0.1540, Time: 545.9380 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [200/229], Loss: 0.1613, Time: 546.2398 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [205/229], Loss: 0.1544, Time: 546.5386 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [210/229], Loss: 0.1843, Time: 546.8315 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [215/229], Loss: 0.2405, Time: 547.1203 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [220/229], Loss: 0.1342, Time: 547.4121 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [225/229], Loss: 0.2380, Time: 547.7269 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [5/229], Loss: 0.1704, Time: 548.6164 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [10/229], Loss: 0.2339, Time: 548.9142 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [15/229], Loss: 0.1815, Time: 549.2060 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [20/229], Loss: 0.1556, Time: 549.5048 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [25/229], Loss: 0.1836, Time: 549.8516 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [30/229], Loss: 0.1532, Time: 550.3923 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [35/229], Loss: 0.2009, Time: 550.7271 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [40/229], Loss: 0.1847, Time: 551.0419 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [45/229], Loss: 0.2109, Time: 551.3437 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [50/229], Loss: 0.1608, Time: 551.6375 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [55/229], Loss: 0.1859, Time: 551.9283 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [60/229], Loss: 0.1886, Time: 552.2411 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [65/229], Loss: 0.2048, Time: 552.5300 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [70/229], Loss: 0.1943, Time: 552.8997 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [75/229], Loss: 0.1789, Time: 553.3504 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [80/229], Loss: 0.1478, Time: 553.7192 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [85/229], Loss: 0.2075, Time: 554.0810 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [90/229], Loss: 0.1987, Time: 554.4208 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [95/229], Loss: 0.2083, Time: 554.7926 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [100/229], Loss: 0.1381, Time: 555.1693 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [105/229], Loss: 0.1547, Time: 555.5251 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [110/229], Loss: 0.1447, Time: 555.8749 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [115/229], Loss: 0.1433, Time: 556.2317 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [120/229], Loss: 0.2005, Time: 556.5874 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [125/229], Loss: 0.1701, Time: 556.9362 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [130/229], Loss: 0.2285, Time: 557.2291 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [135/229], Loss: 0.1658, Time: 557.5339 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [140/229], Loss: 0.2095, Time: 557.8277 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [145/229], Loss: 0.1950, Time: 558.1195 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [150/229], Loss: 0.1813, Time: 558.4273 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [155/229], Loss: 0.1939, Time: 558.7151 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [160/229], Loss: 0.1445, Time: 559.0140 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [165/229], Loss: 0.1541, Time: 559.3118 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [170/229], Loss: 0.1720, Time: 559.6566 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [175/229], Loss: 0.1632, Time: 559.9534 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [180/229], Loss: 0.1322, Time: 560.2432 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [185/229], Loss: 0.2034, Time: 560.5350 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [190/229], Loss: 0.1866, Time: 560.8268 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [195/229], Loss: 0.1763, Time: 561.1217 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [200/229], Loss: 0.1568, Time: 561.4225 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [205/229], Loss: 0.2411, Time: 561.7213 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [210/229], Loss: 0.1716, Time: 562.0171 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [215/229], Loss: 0.1575, Time: 562.3199 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [220/229], Loss: 0.1931, Time: 562.6217 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [225/229], Loss: 0.2225, Time: 562.9205 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [5/229], Loss: 0.2283, Time: 563.8360 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [10/229], Loss: 0.1602, Time: 564.1398 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [15/229], Loss: 0.1822, Time: 564.4276 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [20/229], Loss: 0.2046, Time: 564.7294 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [25/229], Loss: 0.1506, Time: 565.0372 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [30/229], Loss: 0.1731, Time: 565.3371 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [35/229], Loss: 0.1805, Time: 565.6379 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [40/229], Loss: 0.2041, Time: 565.9327 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [45/229], Loss: 0.1854, Time: 566.2335 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [50/229], Loss: 0.1767, Time: 566.5293 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [55/229], Loss: 0.1715, Time: 566.8391 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [60/229], Loss: 0.1437, Time: 567.1369 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [65/229], Loss: 0.2161, Time: 567.4448 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [70/229], Loss: 0.1629, Time: 567.7466 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [75/229], Loss: 0.1634, Time: 568.0454 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [80/229], Loss: 0.1659, Time: 568.3402 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [85/229], Loss: 0.1549, Time: 568.6300 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [90/229], Loss: 0.1365, Time: 568.9198 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [95/229], Loss: 0.1867, Time: 569.2356 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [100/229], Loss: 0.1840, Time: 569.5285 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [105/229], Loss: 0.2122, Time: 569.8343 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [110/229], Loss: 0.1707, Time: 570.1381 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [115/229], Loss: 0.1977, Time: 570.4369 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [120/229], Loss: 0.1633, Time: 570.7377 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [125/229], Loss: 0.1821, Time: 571.0325 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [130/229], Loss: 0.1860, Time: 571.3204 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [135/229], Loss: 0.1788, Time: 571.6222 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [140/229], Loss: 0.1595, Time: 571.9190 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [145/229], Loss: 0.1670, Time: 572.2218 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [150/229], Loss: 0.1743, Time: 572.5096 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [155/229], Loss: 0.2039, Time: 572.8094 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [160/229], Loss: 0.1952, Time: 573.0983 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [165/229], Loss: 0.2074, Time: 573.4111 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [170/229], Loss: 0.1621, Time: 573.7159 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [175/229], Loss: 0.1325, Time: 574.0377 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [180/229], Loss: 0.1707, Time: 574.3345 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [185/229], Loss: 0.1453, Time: 574.6403 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [190/229], Loss: 0.1613, Time: 574.9371 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [195/229], Loss: 0.1925, Time: 575.2389 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [200/229], Loss: 0.2389, Time: 575.5428 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [205/229], Loss: 0.2126, Time: 575.8416 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [210/229], Loss: 0.1731, Time: 576.1414 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [215/229], Loss: 0.1886, Time: 576.4502 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [220/229], Loss: 0.1716, Time: 576.7450 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [225/229], Loss: 0.1534, Time: 577.0828 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [5/229], Loss: 0.1680, Time: 577.9723 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [10/229], Loss: 0.1625, Time: 578.2911 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [15/229], Loss: 0.1533, Time: 578.5879 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [20/229], Loss: 0.2224, Time: 578.8827 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [25/229], Loss: 0.1586, Time: 579.1945 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [30/229], Loss: 0.1918, Time: 579.4913 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [35/229], Loss: 0.1760, Time: 579.7911 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [40/229], Loss: 0.1945, Time: 580.0880 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [45/229], Loss: 0.2094, Time: 580.3848 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [50/229], Loss: 0.1486, Time: 580.6826 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [55/229], Loss: 0.1940, Time: 580.9714 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [60/229], Loss: 0.1820, Time: 581.2732 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [65/229], Loss: 0.1433, Time: 581.5970 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [70/229], Loss: 0.1755, Time: 581.8948 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [75/229], Loss: 0.2077, Time: 582.1897 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [80/229], Loss: 0.1449, Time: 582.4895 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [85/229], Loss: 0.1960, Time: 582.8043 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [90/229], Loss: 0.1842, Time: 583.1051 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [95/229], Loss: 0.1917, Time: 583.3989 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [100/229], Loss: 0.1950, Time: 583.6927 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [105/229], Loss: 0.1857, Time: 584.0015 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [110/229], Loss: 0.1555, Time: 584.3004 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [115/229], Loss: 0.2026, Time: 584.5992 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [120/229], Loss: 0.1791, Time: 584.8950 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [125/229], Loss: 0.1327, Time: 585.2108 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [130/229], Loss: 0.1422, Time: 585.5136 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [135/229], Loss: 0.2112, Time: 585.8134 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [140/229], Loss: 0.1719, Time: 586.1052 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [145/229], Loss: 0.1799, Time: 586.3971 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [150/229], Loss: 0.1708, Time: 586.6889 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [155/229], Loss: 0.1288, Time: 586.9817 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [160/229], Loss: 0.1993, Time: 587.2815 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [165/229], Loss: 0.1930, Time: 587.7212 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [170/229], Loss: 0.1853, Time: 588.1570 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [175/229], Loss: 0.1779, Time: 588.4698 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [180/229], Loss: 0.1990, Time: 588.7686 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [185/229], Loss: 0.1626, Time: 589.0774 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [190/229], Loss: 0.1815, Time: 589.3712 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [195/229], Loss: 0.1865, Time: 589.6640 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [200/229], Loss: 0.1965, Time: 589.9808 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [205/229], Loss: 0.1552, Time: 590.2827 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [210/229], Loss: 0.1971, Time: 590.5775 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [215/229], Loss: 0.1562, Time: 590.8663 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [220/229], Loss: 0.2138, Time: 591.1591 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [225/229], Loss: 0.2053, Time: 591.4579 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [5/229], Loss: 0.1780, Time: 592.3414 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [10/229], Loss: 0.1851, Time: 592.6382 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [15/229], Loss: 0.2315, Time: 592.9510 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [20/229], Loss: 0.1863, Time: 593.2448 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [25/229], Loss: 0.1544, Time: 593.5367 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [30/229], Loss: 0.1551, Time: 593.8395 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [35/229], Loss: 0.1814, Time: 594.1823 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [40/229], Loss: 0.1709, Time: 594.4701 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [45/229], Loss: 0.1857, Time: 594.7609 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [50/229], Loss: 0.1503, Time: 595.0607 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [55/229], Loss: 0.2049, Time: 595.3515 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [60/229], Loss: 0.2151, Time: 595.6563 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [65/229], Loss: 0.1802, Time: 595.9512 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [70/229], Loss: 0.2149, Time: 596.2510 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [75/229], Loss: 0.1726, Time: 596.5468 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [80/229], Loss: 0.1782, Time: 596.8526 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [85/229], Loss: 0.1625, Time: 597.1524 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [90/229], Loss: 0.1570, Time: 597.4522 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [95/229], Loss: 0.1632, Time: 597.7620 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [100/229], Loss: 0.1777, Time: 598.0659 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [105/229], Loss: 0.1458, Time: 598.3607 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [110/229], Loss: 0.1789, Time: 598.6535 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [115/229], Loss: 0.1313, Time: 598.9423 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [120/229], Loss: 0.2086, Time: 599.2511 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [125/229], Loss: 0.1318, Time: 599.5519 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [130/229], Loss: 0.2212, Time: 599.8498 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [135/229], Loss: 0.1382, Time: 600.1426 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [140/229], Loss: 0.2062, Time: 600.4454 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [145/229], Loss: 0.1829, Time: 600.7352 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [150/229], Loss: 0.1428, Time: 601.0280 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [155/229], Loss: 0.1683, Time: 601.3258 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [160/229], Loss: 0.1586, Time: 601.6267 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [165/229], Loss: 0.1620, Time: 601.9255 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [170/229], Loss: 0.2123, Time: 602.2183 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [175/229], Loss: 0.1635, Time: 602.5261 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [180/229], Loss: 0.1901, Time: 602.8159 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [185/229], Loss: 0.1594, Time: 603.1097 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [190/229], Loss: 0.1725, Time: 603.3996 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [195/229], Loss: 0.1831, Time: 603.7034 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [200/229], Loss: 0.1767, Time: 603.9992 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [205/229], Loss: 0.1712, Time: 604.2960 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [210/229], Loss: 0.1563, Time: 604.5908 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [215/229], Loss: 0.1623, Time: 604.8916 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [220/229], Loss: 0.1640, Time: 605.1895 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [225/229], Loss: 0.1929, Time: 605.4873 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [5/229], Loss: 0.1418, Time: 606.3817 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [10/229], Loss: 0.1781, Time: 606.6805 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [15/229], Loss: 0.1381, Time: 606.9864 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [20/229], Loss: 0.1366, Time: 607.2912 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [25/229], Loss: 0.1843, Time: 607.5840 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [30/229], Loss: 0.2378, Time: 607.8828 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [35/229], Loss: 0.1423, Time: 608.1766 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [40/229], Loss: 0.1718, Time: 608.4694 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [45/229], Loss: 0.1956, Time: 608.7623 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [50/229], Loss: 0.1446, Time: 609.0711 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [55/229], Loss: 0.1753, Time: 609.3689 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [60/229], Loss: 0.2175, Time: 609.6607 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [65/229], Loss: 0.1964, Time: 609.9685 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [70/229], Loss: 0.2396, Time: 610.2763 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [75/229], Loss: 0.1899, Time: 610.5851 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [80/229], Loss: 0.1331, Time: 610.8870 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [85/229], Loss: 0.2085, Time: 611.2347 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [90/229], Loss: 0.1769, Time: 611.5286 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [95/229], Loss: 0.1777, Time: 611.8204 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [100/229], Loss: 0.1702, Time: 612.1142 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [105/229], Loss: 0.1419, Time: 612.4090 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [110/229], Loss: 0.1644, Time: 612.7038 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [115/229], Loss: 0.1893, Time: 612.9996 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [120/229], Loss: 0.1701, Time: 613.2975 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [125/229], Loss: 0.1656, Time: 613.6063 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [130/229], Loss: 0.2062, Time: 613.9071 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [135/229], Loss: 0.1429, Time: 614.2029 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [140/229], Loss: 0.1989, Time: 614.4997 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [145/229], Loss: 0.1361, Time: 614.8055 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [150/229], Loss: 0.2149, Time: 615.1223 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [155/229], Loss: 0.1994, Time: 615.4232 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [160/229], Loss: 0.2031, Time: 615.7180 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [165/229], Loss: 0.1857, Time: 616.0168 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [170/229], Loss: 0.1757, Time: 616.3166 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [175/229], Loss: 0.1441, Time: 616.6074 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [180/229], Loss: 0.1534, Time: 616.9002 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [185/229], Loss: 0.1857, Time: 617.1951 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [190/229], Loss: 0.1770, Time: 617.5049 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [195/229], Loss: 0.1465, Time: 617.8117 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [200/229], Loss: 0.1324, Time: 618.1065 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [205/229], Loss: 0.2090, Time: 618.4063 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [210/229], Loss: 0.1733, Time: 618.7211 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [215/229], Loss: 0.1840, Time: 619.0159 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [220/229], Loss: 0.2074, Time: 619.3207 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [225/229], Loss: 0.1753, Time: 619.6276 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [5/229], Loss: 0.1711, Time: 620.5090 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [10/229], Loss: 0.1614, Time: 620.8048 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [15/229], Loss: 0.1549, Time: 621.1016 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [20/229], Loss: 0.1762, Time: 621.3935 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [25/229], Loss: 0.2026, Time: 621.7003 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [30/229], Loss: 0.1959, Time: 621.9981 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [35/229], Loss: 0.1811, Time: 622.3239 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [40/229], Loss: 0.1561, Time: 622.8386 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [45/229], Loss: 0.1362, Time: 623.1984 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [50/229], Loss: 0.1985, Time: 623.4952 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [55/229], Loss: 0.1954, Time: 623.7910 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [60/229], Loss: 0.1427, Time: 624.0838 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [65/229], Loss: 0.1485, Time: 624.3906 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [70/229], Loss: 0.1530, Time: 624.6864 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [75/229], Loss: 0.1779, Time: 624.9833 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [80/229], Loss: 0.1420, Time: 625.2881 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [85/229], Loss: 0.1847, Time: 625.5839 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [90/229], Loss: 0.2218, Time: 625.8777 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [95/229], Loss: 0.2376, Time: 626.1885 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [100/229], Loss: 0.1891, Time: 626.4953 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [105/229], Loss: 0.1310, Time: 626.8011 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [110/229], Loss: 0.1541, Time: 627.0989 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [115/229], Loss: 0.1509, Time: 627.3998 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [120/229], Loss: 0.2312, Time: 627.7036 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [125/229], Loss: 0.1787, Time: 628.0044 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [130/229], Loss: 0.1658, Time: 628.4481 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [135/229], Loss: 0.1752, Time: 628.7749 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [140/229], Loss: 0.1837, Time: 629.0757 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [145/229], Loss: 0.1652, Time: 629.3765 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [150/229], Loss: 0.1632, Time: 629.6754 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [155/229], Loss: 0.1624, Time: 629.9842 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [160/229], Loss: 0.1795, Time: 630.2810 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [165/229], Loss: 0.1770, Time: 630.5758 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [170/229], Loss: 0.1611, Time: 630.8656 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [175/229], Loss: 0.1510, Time: 631.1654 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [180/229], Loss: 0.1442, Time: 631.4653 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [185/229], Loss: 0.1938, Time: 631.7551 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [190/229], Loss: 0.1393, Time: 632.0499 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [195/229], Loss: 0.1315, Time: 632.3457 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [200/229], Loss: 0.1721, Time: 632.6375 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [205/229], Loss: 0.1891, Time: 632.9433 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [210/229], Loss: 0.2389, Time: 633.2472 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [215/229], Loss: 0.1857, Time: 633.6959 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [220/229], Loss: 0.1704, Time: 634.1426 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [225/229], Loss: 0.1573, Time: 634.4464 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [5/229], Loss: 0.1945, Time: 635.3748 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [10/229], Loss: 0.1422, Time: 635.6707 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [15/229], Loss: 0.2234, Time: 635.9565 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [20/229], Loss: 0.2102, Time: 636.2453 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [25/229], Loss: 0.1828, Time: 636.5251 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [30/229], Loss: 0.2350, Time: 636.8180 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [35/229], Loss: 0.1625, Time: 637.0958 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [40/229], Loss: 0.1679, Time: 637.3816 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [45/229], Loss: 0.1557, Time: 637.6784 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [50/229], Loss: 0.1637, Time: 637.9692 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [55/229], Loss: 0.1953, Time: 638.2541 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [60/229], Loss: 0.1585, Time: 638.5449 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [65/229], Loss: 0.2050, Time: 638.8307 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [70/229], Loss: 0.1657, Time: 639.1085 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [75/229], Loss: 0.1723, Time: 639.3934 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [80/229], Loss: 0.1563, Time: 639.6762 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [85/229], Loss: 0.1786, Time: 639.9580 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [90/229], Loss: 0.1699, Time: 640.2398 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [95/229], Loss: 0.1741, Time: 640.5357 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [100/229], Loss: 0.1960, Time: 640.8285 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [105/229], Loss: 0.1988, Time: 641.1053 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [110/229], Loss: 0.1774, Time: 641.4021 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [115/229], Loss: 0.1565, Time: 641.6979 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [120/229], Loss: 0.1652, Time: 641.9788 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [125/229], Loss: 0.1377, Time: 642.2766 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [130/229], Loss: 0.1775, Time: 642.5544 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [135/229], Loss: 0.1391, Time: 642.8362 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [140/229], Loss: 0.1285, Time: 643.1311 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [145/229], Loss: 0.2024, Time: 643.4239 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [150/229], Loss: 0.1548, Time: 643.7127 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [155/229], Loss: 0.1826, Time: 643.9955 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [160/229], Loss: 0.2046, Time: 644.2764 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [165/229], Loss: 0.1756, Time: 644.5582 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [170/229], Loss: 0.1991, Time: 644.8500 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [175/229], Loss: 0.1767, Time: 645.1488 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [180/229], Loss: 0.1539, Time: 645.4336 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [185/229], Loss: 0.1707, Time: 645.7155 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [190/229], Loss: 0.1637, Time: 646.0752 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [195/229], Loss: 0.1684, Time: 646.4980 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [200/229], Loss: 0.1854, Time: 646.9597 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [205/229], Loss: 0.1429, Time: 647.3774 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [210/229], Loss: 0.1677, Time: 647.8541 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [215/229], Loss: 0.1363, Time: 648.2889 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [220/229], Loss: 0.1915, Time: 648.7316 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [225/229], Loss: 0.1707, Time: 649.1903 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [5/229], Loss: 0.1785, Time: 650.4266 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [10/229], Loss: 0.1282, Time: 650.8563 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [15/229], Loss: 0.1621, Time: 651.3030 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [20/229], Loss: 0.1808, Time: 651.6988 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [25/229], Loss: 0.1517, Time: 652.0985 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [30/229], Loss: 0.1413, Time: 652.4543 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [35/229], Loss: 0.1306, Time: 652.7351 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [40/229], Loss: 0.1982, Time: 653.0330 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [45/229], Loss: 0.1565, Time: 653.3528 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [50/229], Loss: 0.1990, Time: 653.6875 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [55/229], Loss: 0.2106, Time: 653.9714 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [60/229], Loss: 0.1811, Time: 654.2622 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [65/229], Loss: 0.1952, Time: 654.5400 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [70/229], Loss: 0.1714, Time: 654.8578 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [75/229], Loss: 0.1734, Time: 655.1476 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [80/229], Loss: 0.2045, Time: 655.4335 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [85/229], Loss: 0.1589, Time: 655.7133 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [90/229], Loss: 0.2168, Time: 656.0041 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [95/229], Loss: 0.1923, Time: 656.3079 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [100/229], Loss: 0.1522, Time: 656.5918 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [105/229], Loss: 0.1635, Time: 656.8776 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [110/229], Loss: 0.1892, Time: 657.1724 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [115/229], Loss: 0.1988, Time: 657.6951 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [120/229], Loss: 0.1376, Time: 658.0349 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [125/229], Loss: 0.1759, Time: 658.3457 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [130/229], Loss: 0.1910, Time: 658.6275 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [135/229], Loss: 0.2372, Time: 658.9113 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [140/229], Loss: 0.1766, Time: 659.1922 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [145/229], Loss: 0.1447, Time: 659.4830 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [150/229], Loss: 0.2022, Time: 659.7648 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [155/229], Loss: 0.1776, Time: 660.0486 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [160/229], Loss: 0.1420, Time: 660.3514 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [165/229], Loss: 0.1775, Time: 660.6373 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [170/229], Loss: 0.1767, Time: 660.9421 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [175/229], Loss: 0.1721, Time: 661.2339 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [180/229], Loss: 0.1651, Time: 661.5217 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [185/229], Loss: 0.1618, Time: 661.8065 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [190/229], Loss: 0.1796, Time: 662.0864 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [195/229], Loss: 0.1765, Time: 662.3742 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [200/229], Loss: 0.1794, Time: 662.6500 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [205/229], Loss: 0.1655, Time: 662.9418 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [210/229], Loss: 0.1459, Time: 663.2327 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [215/229], Loss: 0.2083, Time: 663.5205 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [220/229], Loss: 0.1452, Time: 663.8003 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [225/229], Loss: 0.1423, Time: 664.0851 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [5/229], Loss: 0.1640, Time: 664.9466 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [10/229], Loss: 0.2066, Time: 665.2324 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [15/229], Loss: 0.1729, Time: 665.5192 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [20/229], Loss: 0.1414, Time: 665.7971 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [25/229], Loss: 0.2141, Time: 666.0759 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [30/229], Loss: 0.1646, Time: 666.3697 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [35/229], Loss: 0.2371, Time: 666.6535 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [40/229], Loss: 0.2045, Time: 666.9454 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [45/229], Loss: 0.2306, Time: 667.2482 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [50/229], Loss: 0.2343, Time: 667.5290 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [55/229], Loss: 0.1618, Time: 667.8178 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [60/229], Loss: 0.1775, Time: 668.1027 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [65/229], Loss: 0.1849, Time: 668.3905 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [70/229], Loss: 0.1416, Time: 668.6693 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [75/229], Loss: 0.1610, Time: 668.9541 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [80/229], Loss: 0.1514, Time: 669.2330 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [85/229], Loss: 0.1988, Time: 669.5118 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [90/229], Loss: 0.1650, Time: 669.7986 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [95/229], Loss: 0.1739, Time: 670.0894 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [100/229], Loss: 0.1771, Time: 670.3832 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [105/229], Loss: 0.2025, Time: 670.6721 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [110/229], Loss: 0.1451, Time: 670.9599 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [115/229], Loss: 0.2052, Time: 671.2767 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [120/229], Loss: 0.1816, Time: 671.5775 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [125/229], Loss: 0.2101, Time: 671.8663 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [130/229], Loss: 0.1695, Time: 672.1562 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [135/229], Loss: 0.1495, Time: 672.4340 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [140/229], Loss: 0.1494, Time: 672.7318 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [145/229], Loss: 0.1732, Time: 673.0126 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [150/229], Loss: 0.1580, Time: 673.3134 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [155/229], Loss: 0.1788, Time: 673.6033 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [160/229], Loss: 0.1823, Time: 673.8911 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [165/229], Loss: 0.1712, Time: 674.1849 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [170/229], Loss: 0.1692, Time: 674.4657 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [175/229], Loss: 0.1548, Time: 674.7436 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [180/229], Loss: 0.1438, Time: 675.0434 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [185/229], Loss: 0.1679, Time: 675.3222 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [190/229], Loss: 0.1857, Time: 675.6140 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [195/229], Loss: 0.1455, Time: 675.9018 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [200/229], Loss: 0.1811, Time: 676.1997 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [205/229], Loss: 0.2204, Time: 676.4975 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [210/229], Loss: 0.2055, Time: 676.7803 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [215/229], Loss: 0.1832, Time: 677.0641 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [220/229], Loss: 0.1952, Time: 677.3599 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [225/229], Loss: 0.1931, Time: 677.6528 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [5/229], Loss: 0.1406, Time: 678.5312 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [10/229], Loss: 0.1745, Time: 678.8100 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [15/229], Loss: 0.1969, Time: 679.0899 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [20/229], Loss: 0.1915, Time: 679.3807 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [25/229], Loss: 0.1887, Time: 679.6735 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [30/229], Loss: 0.1493, Time: 679.9563 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [35/229], Loss: 0.1936, Time: 680.2442 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [40/229], Loss: 0.1397, Time: 680.5300 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [45/229], Loss: 0.1934, Time: 680.8268 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [50/229], Loss: 0.1672, Time: 681.1036 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [55/229], Loss: 0.1540, Time: 681.4034 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [60/229], Loss: 0.2061, Time: 681.6983 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [65/229], Loss: 0.1514, Time: 681.9781 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [70/229], Loss: 0.2384, Time: 682.2889 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [75/229], Loss: 0.1814, Time: 682.5707 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [80/229], Loss: 0.2226, Time: 682.8556 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [85/229], Loss: 0.1524, Time: 683.1394 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [90/229], Loss: 0.1921, Time: 683.4432 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [95/229], Loss: 0.2057, Time: 683.7200 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [100/229], Loss: 0.1311, Time: 684.0068 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [105/229], Loss: 0.1938, Time: 684.2987 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [110/229], Loss: 0.1359, Time: 684.5775 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [115/229], Loss: 0.1914, Time: 684.8853 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [120/229], Loss: 0.1415, Time: 685.1661 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [125/229], Loss: 0.1481, Time: 685.4440 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [130/229], Loss: 0.1554, Time: 685.7348 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [135/229], Loss: 0.2203, Time: 686.0206 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [140/229], Loss: 0.1905, Time: 686.3274 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [145/229], Loss: 0.1879, Time: 686.6222 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [150/229], Loss: 0.1837, Time: 686.9220 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [155/229], Loss: 0.2165, Time: 687.2249 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [160/229], Loss: 0.1644, Time: 687.5057 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [165/229], Loss: 0.1543, Time: 687.8265 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [170/229], Loss: 0.1664, Time: 688.3432 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [175/229], Loss: 0.1759, Time: 688.6740 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [180/229], Loss: 0.1899, Time: 688.9658 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [185/229], Loss: 0.1781, Time: 689.2806 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [190/229], Loss: 0.1986, Time: 689.5664 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [195/229], Loss: 0.1631, Time: 689.8512 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [200/229], Loss: 0.1954, Time: 690.1351 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [205/229], Loss: 0.1854, Time: 690.4249 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [210/229], Loss: 0.1731, Time: 690.7087 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [215/229], Loss: 0.1830, Time: 690.9935 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [220/229], Loss: 0.1518, Time: 691.2923 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [225/229], Loss: 0.2013, Time: 691.5752 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [5/229], Loss: 0.1586, Time: 692.4356 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [10/229], Loss: 0.1918, Time: 692.7235 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [15/229], Loss: 0.1826, Time: 693.0093 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [20/229], Loss: 0.1787, Time: 693.3061 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [25/229], Loss: 0.1525, Time: 693.5899 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [30/229], Loss: 0.2100, Time: 693.8867 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [35/229], Loss: 0.1900, Time: 694.1676 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [40/229], Loss: 0.1671, Time: 694.4484 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [45/229], Loss: 0.1576, Time: 694.7382 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [50/229], Loss: 0.1822, Time: 695.0280 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [55/229], Loss: 0.1699, Time: 695.3079 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [60/229], Loss: 0.1357, Time: 695.5887 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [65/229], Loss: 0.1645, Time: 695.8805 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [70/229], Loss: 0.1960, Time: 696.1733 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [75/229], Loss: 0.1717, Time: 696.4562 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [80/229], Loss: 0.2005, Time: 696.7420 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [85/229], Loss: 0.1441, Time: 697.0328 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [90/229], Loss: 0.1846, Time: 697.3226 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [95/229], Loss: 0.1860, Time: 697.6164 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [100/229], Loss: 0.1763, Time: 697.9113 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [105/229], Loss: 0.1773, Time: 698.2061 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [110/229], Loss: 0.1519, Time: 698.4949 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [115/229], Loss: 0.1533, Time: 698.7807 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [120/229], Loss: 0.1409, Time: 699.0765 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [125/229], Loss: 0.1322, Time: 699.3644 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [130/229], Loss: 0.2381, Time: 699.6482 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [135/229], Loss: 0.2049, Time: 699.9320 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [140/229], Loss: 0.1741, Time: 700.2348 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [145/229], Loss: 0.2099, Time: 700.5286 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [150/229], Loss: 0.1920, Time: 700.8225 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [155/229], Loss: 0.1742, Time: 701.1103 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [160/229], Loss: 0.1821, Time: 701.4101 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [165/229], Loss: 0.2097, Time: 701.7199 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [170/229], Loss: 0.1481, Time: 702.0187 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [175/229], Loss: 0.1851, Time: 702.3036 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [180/229], Loss: 0.1533, Time: 702.5994 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [185/229], Loss: 0.1672, Time: 702.8992 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [190/229], Loss: 0.1912, Time: 703.1890 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [195/229], Loss: 0.1758, Time: 703.4808 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [200/229], Loss: 0.1837, Time: 703.7697 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [205/229], Loss: 0.1615, Time: 704.0625 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [210/229], Loss: 0.2300, Time: 704.3543 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [215/229], Loss: 0.1880, Time: 704.6481 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [220/229], Loss: 0.1452, Time: 704.9369 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [225/229], Loss: 0.1734, Time: 705.2337 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [5/229], Loss: 0.2005, Time: 706.1242 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [10/229], Loss: 0.1908, Time: 706.4250 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [15/229], Loss: 0.2204, Time: 706.7278 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [20/229], Loss: 0.1575, Time: 707.0137 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [25/229], Loss: 0.2034, Time: 707.3075 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [30/229], Loss: 0.2198, Time: 707.6053 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [35/229], Loss: 0.1632, Time: 707.8981 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [40/229], Loss: 0.2365, Time: 708.1959 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [45/229], Loss: 0.1776, Time: 708.4897 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [50/229], Loss: 0.1699, Time: 708.7866 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [55/229], Loss: 0.1829, Time: 709.0734 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [60/229], Loss: 0.2338, Time: 709.3622 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [65/229], Loss: 0.1884, Time: 709.6520 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [70/229], Loss: 0.1670, Time: 709.9548 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [75/229], Loss: 0.2081, Time: 710.2447 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [80/229], Loss: 0.2093, Time: 710.5415 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [85/229], Loss: 0.2074, Time: 710.8133 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [90/229], Loss: 0.2036, Time: 711.3210 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [95/229], Loss: 0.1534, Time: 711.7947 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [100/229], Loss: 0.1808, Time: 712.2094 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [105/229], Loss: 0.2017, Time: 712.5602 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [110/229], Loss: 0.1835, Time: 712.8580 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [115/229], Loss: 0.1441, Time: 713.1709 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [120/229], Loss: 0.1875, Time: 713.4907 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [125/229], Loss: 0.1707, Time: 713.8205 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [130/229], Loss: 0.1727, Time: 714.1273 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [135/229], Loss: 0.2107, Time: 714.4281 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [140/229], Loss: 0.2073, Time: 714.7229 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [145/229], Loss: 0.1353, Time: 715.0437 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [150/229], Loss: 0.1741, Time: 715.3415 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [155/229], Loss: 0.1757, Time: 715.6513 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [160/229], Loss: 0.1844, Time: 715.9511 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [165/229], Loss: 0.1906, Time: 716.2699 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [170/229], Loss: 0.1613, Time: 716.5827 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [175/229], Loss: 0.1946, Time: 716.8856 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [180/229], Loss: 0.1766, Time: 717.1824 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [185/229], Loss: 0.1538, Time: 717.4962 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [190/229], Loss: 0.1611, Time: 717.8150 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [195/229], Loss: 0.2056, Time: 718.1178 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [200/229], Loss: 0.1528, Time: 718.4546 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [205/229], Loss: 0.2135, Time: 718.9733 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [210/229], Loss: 0.1605, Time: 719.3021 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [215/229], Loss: 0.1670, Time: 719.6089 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [220/229], Loss: 0.1479, Time: 719.9177 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [225/229], Loss: 0.1450, Time: 720.2265 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [5/229], Loss: 0.1529, Time: 721.1599 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [10/229], Loss: 0.1552, Time: 721.4597 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [15/229], Loss: 0.1976, Time: 721.7765 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [20/229], Loss: 0.1441, Time: 722.0804 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [25/229], Loss: 0.1843, Time: 722.3702 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [30/229], Loss: 0.1825, Time: 722.6870 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [35/229], Loss: 0.1880, Time: 722.9738 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [40/229], Loss: 0.1906, Time: 723.2806 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [45/229], Loss: 0.1499, Time: 723.5834 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [50/229], Loss: 0.1497, Time: 723.8932 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [55/229], Loss: 0.1522, Time: 724.1931 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [60/229], Loss: 0.1842, Time: 724.4929 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [65/229], Loss: 0.1578, Time: 724.7967 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [70/229], Loss: 0.1272, Time: 725.0985 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [75/229], Loss: 0.1730, Time: 725.3903 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [80/229], Loss: 0.2073, Time: 725.6911 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [85/229], Loss: 0.1528, Time: 725.9889 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [90/229], Loss: 0.1519, Time: 726.3037 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [95/229], Loss: 0.1863, Time: 726.6056 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [100/229], Loss: 0.1619, Time: 726.8994 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [105/229], Loss: 0.2376, Time: 727.2162 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [110/229], Loss: 0.2043, Time: 727.5140 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [115/229], Loss: 0.2072, Time: 727.8208 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [120/229], Loss: 0.1612, Time: 728.1206 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [125/229], Loss: 0.2053, Time: 728.4254 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [130/229], Loss: 0.1761, Time: 728.7223 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [135/229], Loss: 0.1486, Time: 729.0251 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [140/229], Loss: 0.1520, Time: 729.3299 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [145/229], Loss: 0.1828, Time: 729.6407 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [150/229], Loss: 0.2093, Time: 729.9415 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [155/229], Loss: 0.1609, Time: 730.2513 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [160/229], Loss: 0.2296, Time: 730.5631 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [165/229], Loss: 0.1571, Time: 730.8609 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [170/229], Loss: 0.1830, Time: 731.1638 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [175/229], Loss: 0.1665, Time: 731.4616 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [180/229], Loss: 0.1817, Time: 731.7664 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [185/229], Loss: 0.1517, Time: 732.0662 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [190/229], Loss: 0.2107, Time: 732.3750 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [195/229], Loss: 0.1816, Time: 732.6758 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [200/229], Loss: 0.1636, Time: 732.9826 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [205/229], Loss: 0.2358, Time: 733.2844 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [210/229], Loss: 0.2096, Time: 733.5953 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [215/229], Loss: 0.2090, Time: 733.8931 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [220/229], Loss: 0.1761, Time: 734.1939 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [225/229], Loss: 0.1978, Time: 734.4947 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [5/229], Loss: 0.1765, Time: 735.3951 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [10/229], Loss: 0.2361, Time: 735.6920 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [15/229], Loss: 0.1753, Time: 735.9898 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [20/229], Loss: 0.1929, Time: 736.2836 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [25/229], Loss: 0.1533, Time: 736.5894 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [30/229], Loss: 0.1354, Time: 736.8862 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [35/229], Loss: 0.1612, Time: 737.1840 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [40/229], Loss: 0.1497, Time: 737.4898 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [45/229], Loss: 0.1760, Time: 737.8077 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [50/229], Loss: 0.1717, Time: 738.1704 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [55/229], Loss: 0.1313, Time: 738.4762 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [60/229], Loss: 0.1810, Time: 738.7801 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [65/229], Loss: 0.1725, Time: 739.0809 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [70/229], Loss: 0.1947, Time: 739.3897 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [75/229], Loss: 0.1571, Time: 739.6805 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [80/229], Loss: 0.1739, Time: 739.9923 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [85/229], Loss: 0.1710, Time: 740.2831 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [90/229], Loss: 0.1632, Time: 740.5809 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [95/229], Loss: 0.1909, Time: 740.8778 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [100/229], Loss: 0.1401, Time: 741.1906 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [105/229], Loss: 0.2003, Time: 741.4894 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [110/229], Loss: 0.1904, Time: 741.8162 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [115/229], Loss: 0.1368, Time: 742.1230 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [120/229], Loss: 0.1914, Time: 742.4168 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [125/229], Loss: 0.2057, Time: 742.7176 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [130/229], Loss: 0.1834, Time: 743.0254 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [135/229], Loss: 0.1670, Time: 743.3382 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [140/229], Loss: 0.1430, Time: 743.6471 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [145/229], Loss: 0.1528, Time: 743.9609 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [150/229], Loss: 0.1784, Time: 744.2747 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [155/229], Loss: 0.1553, Time: 744.5785 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [160/229], Loss: 0.1851, Time: 744.8873 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [165/229], Loss: 0.1860, Time: 745.1831 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [170/229], Loss: 0.1517, Time: 745.4799 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [175/229], Loss: 0.1927, Time: 745.7957 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [180/229], Loss: 0.1686, Time: 746.1145 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [185/229], Loss: 0.1642, Time: 746.4243 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [190/229], Loss: 0.2252, Time: 746.7341 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [195/229], Loss: 0.2158, Time: 747.0440 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [200/229], Loss: 0.1704, Time: 747.3538 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [205/229], Loss: 0.2357, Time: 747.6526 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [210/229], Loss: 0.1981, Time: 747.9544 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [215/229], Loss: 0.1942, Time: 748.2582 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [220/229], Loss: 0.1434, Time: 748.7889 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [225/229], Loss: 0.1382, Time: 749.1596 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [5/229], Loss: 0.1981, Time: 750.0541 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [10/229], Loss: 0.1641, Time: 750.3479 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [15/229], Loss: 0.1536, Time: 750.6417 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [20/229], Loss: 0.1619, Time: 750.9356 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [25/229], Loss: 0.1570, Time: 751.2374 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [30/229], Loss: 0.2158, Time: 751.5332 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [35/229], Loss: 0.1517, Time: 751.8330 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [40/229], Loss: 0.1546, Time: 752.1328 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [45/229], Loss: 0.2011, Time: 752.4306 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [50/229], Loss: 0.1518, Time: 752.7334 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [55/229], Loss: 0.1612, Time: 753.0233 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [60/229], Loss: 0.1907, Time: 753.3161 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [65/229], Loss: 0.1479, Time: 753.6099 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [70/229], Loss: 0.1552, Time: 753.9087 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [75/229], Loss: 0.1529, Time: 754.2135 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [80/229], Loss: 0.1408, Time: 754.5133 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [85/229], Loss: 0.1699, Time: 754.8152 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [90/229], Loss: 0.1421, Time: 755.1599 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [95/229], Loss: 0.1787, Time: 755.4538 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [100/229], Loss: 0.1367, Time: 755.7546 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [105/229], Loss: 0.2252, Time: 756.0674 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [110/229], Loss: 0.1903, Time: 756.3672 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [115/229], Loss: 0.1598, Time: 756.6820 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [120/229], Loss: 0.1312, Time: 756.9898 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [125/229], Loss: 0.1879, Time: 757.3026 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [130/229], Loss: 0.2071, Time: 757.6044 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [135/229], Loss: 0.1703, Time: 757.9083 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [140/229], Loss: 0.1810, Time: 758.2011 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [145/229], Loss: 0.1842, Time: 758.5029 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [150/229], Loss: 0.1689, Time: 758.8127 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [155/229], Loss: 0.1764, Time: 759.1085 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [160/229], Loss: 0.1764, Time: 759.4163 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [165/229], Loss: 0.1562, Time: 759.7331 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [170/229], Loss: 0.1408, Time: 760.0349 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [175/229], Loss: 0.1686, Time: 760.3358 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [180/229], Loss: 0.2086, Time: 760.6416 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [185/229], Loss: 0.1975, Time: 760.9414 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [190/229], Loss: 0.1817, Time: 761.2502 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [195/229], Loss: 0.1508, Time: 761.5580 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [200/229], Loss: 0.2034, Time: 761.8608 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [205/229], Loss: 0.1496, Time: 762.1606 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [210/229], Loss: 0.1665, Time: 762.4505 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [215/229], Loss: 0.2130, Time: 762.7493 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [220/229], Loss: 0.1720, Time: 763.0511 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [225/229], Loss: 0.1541, Time: 763.3509 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [5/229], Loss: 0.1522, Time: 764.2443 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [10/229], Loss: 0.1803, Time: 764.5522 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [15/229], Loss: 0.1319, Time: 764.8470 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [20/229], Loss: 0.1975, Time: 765.1458 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [25/229], Loss: 0.1981, Time: 765.4396 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [30/229], Loss: 0.1841, Time: 765.7454 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [35/229], Loss: 0.1913, Time: 766.0422 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [40/229], Loss: 0.1914, Time: 766.3510 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [45/229], Loss: 0.1754, Time: 766.6559 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [50/229], Loss: 0.1786, Time: 766.9457 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [55/229], Loss: 0.2095, Time: 767.2455 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [60/229], Loss: 0.2045, Time: 767.5583 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [65/229], Loss: 0.1469, Time: 767.8521 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [70/229], Loss: 0.2200, Time: 768.1559 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [75/229], Loss: 0.1760, Time: 768.4507 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [80/229], Loss: 0.1816, Time: 768.7596 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [85/229], Loss: 0.1906, Time: 769.0594 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [90/229], Loss: 0.1682, Time: 769.3542 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [95/229], Loss: 0.2252, Time: 769.6630 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [100/229], Loss: 0.1882, Time: 769.9668 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [105/229], Loss: 0.1631, Time: 770.2686 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [110/229], Loss: 0.1797, Time: 770.5694 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [115/229], Loss: 0.1764, Time: 770.8633 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [120/229], Loss: 0.1610, Time: 771.2041 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [125/229], Loss: 0.2157, Time: 771.5588 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [130/229], Loss: 0.1832, Time: 771.8507 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [135/229], Loss: 0.1528, Time: 772.1595 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [140/229], Loss: 0.2002, Time: 772.4633 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [145/229], Loss: 0.1796, Time: 772.7681 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [150/229], Loss: 0.1435, Time: 773.0599 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [155/229], Loss: 0.1978, Time: 773.3527 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [160/229], Loss: 0.1741, Time: 773.6515 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [165/229], Loss: 0.1884, Time: 773.9574 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [170/229], Loss: 0.1381, Time: 774.2522 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [175/229], Loss: 0.1562, Time: 774.5670 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [180/229], Loss: 0.1928, Time: 774.8678 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [185/229], Loss: 0.1486, Time: 775.1626 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [190/229], Loss: 0.2031, Time: 775.4654 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [195/229], Loss: 0.1406, Time: 775.7682 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [200/229], Loss: 0.1695, Time: 776.0661 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [205/229], Loss: 0.1577, Time: 776.3649 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [210/229], Loss: 0.1903, Time: 776.6717 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [215/229], Loss: 0.1562, Time: 776.9665 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [220/229], Loss: 0.1669, Time: 777.3483 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [225/229], Loss: 0.1724, Time: 777.8669 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [5/229], Loss: 0.1577, Time: 778.7694 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [10/229], Loss: 0.1755, Time: 779.0742 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [15/229], Loss: 0.1860, Time: 779.3810 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [20/229], Loss: 0.1405, Time: 779.6728 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [25/229], Loss: 0.1352, Time: 779.9726 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [30/229], Loss: 0.1967, Time: 780.2864 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [35/229], Loss: 0.1978, Time: 780.6003 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [40/229], Loss: 0.2106, Time: 780.9021 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [45/229], Loss: 0.1294, Time: 781.1959 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [50/229], Loss: 0.1948, Time: 781.5147 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [55/229], Loss: 0.2050, Time: 781.8215 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [60/229], Loss: 0.2081, Time: 782.1173 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [65/229], Loss: 0.1609, Time: 782.4191 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [70/229], Loss: 0.1640, Time: 782.7319 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [75/229], Loss: 0.1602, Time: 783.0308 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [80/229], Loss: 0.2087, Time: 783.3286 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [85/229], Loss: 0.1921, Time: 783.6254 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [90/229], Loss: 0.1767, Time: 783.9182 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [95/229], Loss: 0.1390, Time: 784.2140 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [100/229], Loss: 0.2035, Time: 784.5208 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [105/229], Loss: 0.1570, Time: 784.8266 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [110/229], Loss: 0.1761, Time: 785.1265 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [115/229], Loss: 0.1312, Time: 785.4233 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [120/229], Loss: 0.1831, Time: 785.7171 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [125/229], Loss: 0.1848, Time: 786.0099 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [130/229], Loss: 0.1820, Time: 786.3107 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [135/229], Loss: 0.1560, Time: 786.6135 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [140/229], Loss: 0.2045, Time: 786.9194 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [145/229], Loss: 0.1758, Time: 787.2352 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [150/229], Loss: 0.1609, Time: 787.5340 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [155/229], Loss: 0.1828, Time: 787.8428 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [160/229], Loss: 0.1447, Time: 788.1466 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [165/229], Loss: 0.1771, Time: 788.4594 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [170/229], Loss: 0.1765, Time: 788.8102 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [175/229], Loss: 0.1509, Time: 789.1170 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [180/229], Loss: 0.1486, Time: 789.4238 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [185/229], Loss: 0.1905, Time: 789.7336 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [190/229], Loss: 0.1403, Time: 790.0474 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [195/229], Loss: 0.1797, Time: 790.3572 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [200/229], Loss: 0.1980, Time: 790.6501 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [205/229], Loss: 0.1765, Time: 790.9489 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [210/229], Loss: 0.1519, Time: 791.2537 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [215/229], Loss: 0.1774, Time: 791.5595 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [220/229], Loss: 0.1895, Time: 791.8583 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [225/229], Loss: 0.1942, Time: 792.1601 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [5/229], Loss: 0.1926, Time: 793.0426 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [10/229], Loss: 0.1704, Time: 793.3494 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [15/229], Loss: 0.1843, Time: 793.6542 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [20/229], Loss: 0.1947, Time: 793.9510 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [25/229], Loss: 0.1954, Time: 794.2528 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [30/229], Loss: 0.1752, Time: 794.5526 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [35/229], Loss: 0.1906, Time: 794.8495 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [40/229], Loss: 0.2092, Time: 795.1553 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [45/229], Loss: 0.1434, Time: 795.4681 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [50/229], Loss: 0.1879, Time: 795.7799 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [55/229], Loss: 0.1405, Time: 796.0737 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [60/229], Loss: 0.1631, Time: 796.3685 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [65/229], Loss: 0.1449, Time: 796.6603 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [70/229], Loss: 0.1911, Time: 796.9612 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [75/229], Loss: 0.1908, Time: 797.2530 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [80/229], Loss: 0.1598, Time: 797.5438 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [85/229], Loss: 0.1706, Time: 797.8436 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [90/229], Loss: 0.1640, Time: 798.1384 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [95/229], Loss: 0.1551, Time: 798.4333 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [100/229], Loss: 0.1832, Time: 798.7361 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [105/229], Loss: 0.1478, Time: 799.0349 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [110/229], Loss: 0.1896, Time: 799.3337 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [115/229], Loss: 0.1561, Time: 799.6305 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [120/229], Loss: 0.1495, Time: 799.9293 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [125/229], Loss: 0.1738, Time: 800.2251 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [130/229], Loss: 0.1441, Time: 800.5210 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [135/229], Loss: 0.1978, Time: 800.8158 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [140/229], Loss: 0.1939, Time: 801.1236 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [145/229], Loss: 0.1709, Time: 801.4234 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [150/229], Loss: 0.1732, Time: 801.7232 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [155/229], Loss: 0.1924, Time: 802.0210 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [160/229], Loss: 0.2070, Time: 802.3318 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [165/229], Loss: 0.1545, Time: 802.6287 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [170/229], Loss: 0.1806, Time: 802.9295 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [175/229], Loss: 0.1668, Time: 803.2563 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [180/229], Loss: 0.1663, Time: 803.5511 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [185/229], Loss: 0.1400, Time: 803.8569 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [190/229], Loss: 0.1390, Time: 804.1567 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [195/229], Loss: 0.2050, Time: 804.4515 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [200/229], Loss: 0.1438, Time: 804.7733 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [205/229], Loss: 0.2044, Time: 805.0762 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [210/229], Loss: 0.1312, Time: 805.3980 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [215/229], Loss: 0.1550, Time: 805.9826 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [220/229], Loss: 0.1528, Time: 806.3034 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [225/229], Loss: 0.1842, Time: 806.6002 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [5/229], Loss: 0.1764, Time: 807.4937 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [10/229], Loss: 0.1429, Time: 807.7975 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [15/229], Loss: 0.2091, Time: 808.1013 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [20/229], Loss: 0.1512, Time: 808.4011 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [25/229], Loss: 0.1778, Time: 808.6919 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [30/229], Loss: 0.1807, Time: 809.0007 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [35/229], Loss: 0.2053, Time: 809.3105 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [40/229], Loss: 0.1977, Time: 809.6024 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [45/229], Loss: 0.2130, Time: 809.9042 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [50/229], Loss: 0.1446, Time: 810.1980 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [55/229], Loss: 0.1692, Time: 810.4978 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [60/229], Loss: 0.1850, Time: 810.8066 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [65/229], Loss: 0.1540, Time: 811.1044 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [70/229], Loss: 0.1527, Time: 811.4003 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [75/229], Loss: 0.1696, Time: 811.7261 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [80/229], Loss: 0.1905, Time: 812.0209 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [85/229], Loss: 0.1407, Time: 812.3227 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [90/229], Loss: 0.2359, Time: 812.6165 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [95/229], Loss: 0.2013, Time: 812.9243 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [100/229], Loss: 0.2326, Time: 813.2221 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [105/229], Loss: 0.1400, Time: 813.5209 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [110/229], Loss: 0.1763, Time: 813.8228 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [115/229], Loss: 0.1507, Time: 814.1246 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [120/229], Loss: 0.1912, Time: 814.4334 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [125/229], Loss: 0.1367, Time: 814.7242 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [130/229], Loss: 0.1764, Time: 815.0280 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [135/229], Loss: 0.1719, Time: 815.3288 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [140/229], Loss: 0.1799, Time: 815.6306 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [145/229], Loss: 0.1403, Time: 815.9395 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [150/229], Loss: 0.1640, Time: 816.2473 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [155/229], Loss: 0.2044, Time: 816.5621 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [160/229], Loss: 0.1907, Time: 816.8539 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [165/229], Loss: 0.1742, Time: 817.1517 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [170/229], Loss: 0.1611, Time: 817.4515 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [175/229], Loss: 0.1783, Time: 817.7583 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [180/229], Loss: 0.1531, Time: 818.0541 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [185/229], Loss: 0.1828, Time: 818.3460 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [190/229], Loss: 0.1958, Time: 818.6498 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [195/229], Loss: 0.1767, Time: 818.9516 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [200/229], Loss: 0.1498, Time: 819.2464 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [205/229], Loss: 0.1521, Time: 819.5602 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [210/229], Loss: 0.1560, Time: 819.8560 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [215/229], Loss: 0.1485, Time: 820.1519 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [220/229], Loss: 0.1739, Time: 820.4517 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [225/229], Loss: 0.1317, Time: 820.7485 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [5/229], Loss: 0.1637, Time: 821.6479 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [10/229], Loss: 0.1662, Time: 821.9597 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [15/229], Loss: 0.1742, Time: 822.2705 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [20/229], Loss: 0.1544, Time: 822.5624 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [25/229], Loss: 0.2129, Time: 822.8712 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [30/229], Loss: 0.1471, Time: 823.2180 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [35/229], Loss: 0.1484, Time: 823.5278 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [40/229], Loss: 0.2043, Time: 823.8386 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [45/229], Loss: 0.1685, Time: 824.1354 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [50/229], Loss: 0.1576, Time: 824.4252 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [55/229], Loss: 0.1719, Time: 824.7340 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [60/229], Loss: 0.1597, Time: 825.0388 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [65/229], Loss: 0.1958, Time: 825.3457 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [70/229], Loss: 0.1477, Time: 825.6525 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [75/229], Loss: 0.1546, Time: 825.9533 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [80/229], Loss: 0.2051, Time: 826.2531 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [85/229], Loss: 0.1402, Time: 826.5489 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [90/229], Loss: 0.2156, Time: 826.8457 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [95/229], Loss: 0.1561, Time: 827.1555 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [100/229], Loss: 0.1271, Time: 827.4633 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [105/229], Loss: 0.1600, Time: 827.7612 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [110/229], Loss: 0.1754, Time: 828.0710 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [115/229], Loss: 0.2079, Time: 828.3788 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [120/229], Loss: 0.1819, Time: 828.6786 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [125/229], Loss: 0.1785, Time: 828.9824 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [130/229], Loss: 0.1400, Time: 829.2892 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [135/229], Loss: 0.1601, Time: 829.5860 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [140/229], Loss: 0.1707, Time: 829.8829 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [145/229], Loss: 0.1601, Time: 830.1787 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [150/229], Loss: 0.1429, Time: 830.4825 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [155/229], Loss: 0.1366, Time: 830.7763 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [160/229], Loss: 0.1816, Time: 831.0901 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [165/229], Loss: 0.1380, Time: 831.3949 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [170/229], Loss: 0.1763, Time: 831.7017 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [175/229], Loss: 0.1755, Time: 831.9985 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [180/229], Loss: 0.1807, Time: 832.2984 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [185/229], Loss: 0.1920, Time: 832.5922 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [190/229], Loss: 0.1446, Time: 832.8970 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [195/229], Loss: 0.1814, Time: 833.3247 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [200/229], Loss: 0.2043, Time: 833.7735 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [205/229], Loss: 0.1520, Time: 834.0843 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [210/229], Loss: 0.1635, Time: 834.3931 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [215/229], Loss: 0.2093, Time: 834.6839 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [220/229], Loss: 0.1553, Time: 834.9867 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [225/229], Loss: 0.2198, Time: 835.2935 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [5/229], Loss: 0.1706, Time: 836.1840 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [10/229], Loss: 0.1389, Time: 836.4958 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [15/229], Loss: 0.1938, Time: 836.7906 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [20/229], Loss: 0.1979, Time: 837.1024 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [25/229], Loss: 0.1610, Time: 837.3962 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [30/229], Loss: 0.1708, Time: 837.6890 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [35/229], Loss: 0.1604, Time: 837.9968 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [40/229], Loss: 0.1869, Time: 838.3027 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [45/229], Loss: 0.1484, Time: 838.6045 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [50/229], Loss: 0.1352, Time: 838.9013 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [55/229], Loss: 0.1415, Time: 839.2001 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [60/229], Loss: 0.1737, Time: 839.5049 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [65/229], Loss: 0.1703, Time: 839.8067 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [70/229], Loss: 0.1301, Time: 840.0995 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [75/229], Loss: 0.1815, Time: 840.4513 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [80/229], Loss: 0.1754, Time: 840.7471 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [85/229], Loss: 0.1812, Time: 841.0570 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [90/229], Loss: 0.2092, Time: 841.3628 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [95/229], Loss: 0.1999, Time: 841.6746 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [100/229], Loss: 0.1691, Time: 841.9784 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [105/229], Loss: 0.1514, Time: 842.3222 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [110/229], Loss: 0.1739, Time: 842.6240 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [115/229], Loss: 0.1829, Time: 842.9188 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [120/229], Loss: 0.1696, Time: 843.2176 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [125/229], Loss: 0.1911, Time: 843.5154 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [130/229], Loss: 0.2069, Time: 843.8143 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [135/229], Loss: 0.1608, Time: 844.1161 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [140/229], Loss: 0.1535, Time: 844.4139 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [145/229], Loss: 0.1621, Time: 844.7117 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [150/229], Loss: 0.1599, Time: 845.0195 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [155/229], Loss: 0.1667, Time: 845.3213 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [160/229], Loss: 0.1573, Time: 845.6191 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [165/229], Loss: 0.1795, Time: 845.9260 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [170/229], Loss: 0.1882, Time: 846.2308 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [175/229], Loss: 0.1549, Time: 846.5306 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [180/229], Loss: 0.1433, Time: 846.8484 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [185/229], Loss: 0.1624, Time: 847.1562 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [190/229], Loss: 0.1511, Time: 847.4670 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [195/229], Loss: 0.1520, Time: 847.7698 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [200/229], Loss: 0.1840, Time: 848.0616 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [205/229], Loss: 0.2028, Time: 848.3704 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [210/229], Loss: 0.2089, Time: 848.6703 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [215/229], Loss: 0.1294, Time: 848.9801 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [220/229], Loss: 0.1516, Time: 849.2759 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [225/229], Loss: 0.1550, Time: 849.5767 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [5/229], Loss: 0.1351, Time: 850.4692 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [10/229], Loss: 0.1601, Time: 850.7630 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [15/229], Loss: 0.2193, Time: 851.0678 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [20/229], Loss: 0.1701, Time: 851.3726 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [25/229], Loss: 0.1517, Time: 851.6774 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [30/229], Loss: 0.1607, Time: 851.9712 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [35/229], Loss: 0.1768, Time: 852.2640 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [40/229], Loss: 0.2033, Time: 852.5619 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [45/229], Loss: 0.1825, Time: 852.8697 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [50/229], Loss: 0.1601, Time: 853.1745 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [55/229], Loss: 0.1811, Time: 853.4753 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [60/229], Loss: 0.1694, Time: 853.7821 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [65/229], Loss: 0.1687, Time: 854.0929 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [70/229], Loss: 0.1510, Time: 854.4147 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [75/229], Loss: 0.1964, Time: 854.7145 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [80/229], Loss: 0.2103, Time: 855.0243 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [85/229], Loss: 0.1634, Time: 855.3541 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [90/229], Loss: 0.1471, Time: 855.6719 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [95/229], Loss: 0.1847, Time: 855.9778 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [100/229], Loss: 0.2089, Time: 856.2726 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [105/229], Loss: 0.1661, Time: 856.5684 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [110/229], Loss: 0.1667, Time: 856.8692 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [115/229], Loss: 0.1778, Time: 857.2120 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [120/229], Loss: 0.1645, Time: 857.5158 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [125/229], Loss: 0.1598, Time: 857.8386 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [130/229], Loss: 0.2040, Time: 858.1684 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [135/229], Loss: 0.1837, Time: 858.4612 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [140/229], Loss: 0.1475, Time: 858.7540 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [145/229], Loss: 0.2009, Time: 859.0469 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [150/229], Loss: 0.1560, Time: 859.3467 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [155/229], Loss: 0.1762, Time: 859.6505 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [160/229], Loss: 0.2048, Time: 859.9553 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [165/229], Loss: 0.1527, Time: 860.2571 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [170/229], Loss: 0.1438, Time: 860.5629 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [175/229], Loss: 0.2052, Time: 860.8667 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [180/229], Loss: 0.1842, Time: 861.1715 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [185/229], Loss: 0.1754, Time: 861.4704 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [190/229], Loss: 0.1926, Time: 861.7842 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [195/229], Loss: 0.1730, Time: 862.0830 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [200/229], Loss: 0.1750, Time: 862.3948 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [205/229], Loss: 0.1667, Time: 862.7016 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [210/229], Loss: 0.1839, Time: 863.0044 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [215/229], Loss: 0.1560, Time: 863.3052 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [220/229], Loss: 0.1693, Time: 863.5961 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [225/229], Loss: 0.1813, Time: 863.8999 secs, learning rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(YTrain)\n",
    "start_time = time.time()\n",
    "model = model.float()\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "loss_tmp = 0\n",
    "norm = 1\n",
    "for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss1 = criterion(norm*outputs, norm*y.float())\n",
    "        loss2 = torch.mean(outputs**2 - y.float()**2)\n",
    "        loss = loss1 + loss2\n",
    "        loss_tmp += loss.item()\n",
    "loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ind = np.arange(int(total_step/batch_size))\n",
    "    random.shuffle(ind)\n",
    "    for i,k in enumerate(ind):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XTrain[k*batch_size:(k+1)*batch_size,:,:,:], YTrain[k*batch_size:(k+1)*batch_size,:]\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x.float())\n",
    "        loss1 = criterion(norm*outputs, norm*y.float())\n",
    "        loss2 = torch.mean(outputs**2 - y.float()**2)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 5== 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs, learning rate: {:.4f}'\n",
    "                    .format(epoch + 1, num_epochs, i + 1, int(total_step/batch_size), loss.item(), time.time() - start_time, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    loss_tmp = 0\n",
    "    result = []\n",
    "    for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss1 = criterion(norm*outputs, norm*y.float())\n",
    "        loss2 = torch.mean(outputs**2 - y.float()**2)\n",
    "        loss = loss1 + loss2\n",
    "        loss_tmp += loss.item()\n",
    "        result.append(outputs)\n",
    "    loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 2.0)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x396 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(loss_train)), loss_train, label = 'Training error')\n",
    "plt.plot(np.arange(0, len(loss_train)+1, int(total_step/batch_size)), loss_val, label = 'Validation error')\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim([0,2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(-1.0, 5.0)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x396 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFeCAYAAACYZlYBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2HUlEQVR4nO3deXRU9f3/8ecsSSb7HrZAEvZdICiiCFZwQxG1IKhFWywgav1WqyK4gUULrda91rpVqb+6i7VSFAVFEBRQkH1fk5CNJGSf7f7+gIxEEkgwyTB3Xo9zPCZ37sy8581kXnM/997PtRiGYSAiIiKmYfV3ASIiItK0FO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjJ2fxcAcNVVVxEVFQVAamoqf/rTn/xckYiISODye7hXV1djGAbz5s3zdykiIiKm4Pdh+S1btlBZWcnEiRO54YYbWLt2rb9LEhERCWgWf89Qt3XrVtatW8fYsWPZs2cPkyZNYuHChdjtdQ8quN0e7HZbC1cpIiISOPw+LJ+RkUFaWhoWi4WMjAzi4uLIz8+nTZs2da5fVFTRpM+fnBxNfn5pkz6mWag3dVNf6qfe1E+9qZv6Ur+a3iQnRzf6vn4fln/33XeZM2cOALm5uZSVlZGcnOznqkRERAKX37fcx4wZw/Tp07n22muxWCw8+uij9Q7Ji4iIyMn5PUVDQ0N5/PHH/V2GiIiIafh9WF5ERESalsJdRETEZBTuIiIiJqNwFxERMRmFu4iIiMko3EVExFRuu20ya9asqrXsyScf46OP5h+37pgxo6iurmbevH+yadOGWrdVV1czZsyoEz7Xhx++j9vtZvv2rbz66os/u/am4vdT4URExJzeXryDVVvyTriOzWbB42n4LOhndk/hmgs6n3CdUaOuZOHCj8nMPBMAl8vF8uVfMWXKrfXeZ8KEXze4hmPNm/cql1xyGV26dKNLl26n9BjNQeEuIiKmcv75w3nhheeoqqrC4XDw1Vdfkpk5kIcemoHTWU1hYQGTJt3C0KHn++7zyCMzGT78Ivr27cfDD99PaWkp7dql+m7//vs1vPrqi3i9XiorK3noodn88MP3HDpUyMyZMxg79lo+/PA9Zs36E59++j/efvvfhISE0L59B+655z4+/fR/rFixnOrqKrKyDnD99TcycuSJRwV+DoW7iIg0i2su6HzSrezmmFs+LCyMoUPPZ+nSJVx00aUsWPAfBgwYyEUXXcqAAQNZv34dL7/8Qq1wrzF//ntkZHRiypRb2bhxA999txqA3bt38eCDfyQpKZnXX3+FJUs+48Ybb+Kf/3yZmTMfZePG9QCUlBTz8ssv8OqrbxAREcnTTz/Ohx++R3h4BOXlZfz1r8+yf/8+pk27Q+EuIiLSGKNGXcVzzz1F//6ZlJaWcvbZ5/Laay/z8ccfAhbcbned99u/fx/nnHMuAL169fZNh56cnMyTT/6F8PAI8vPz6NPnjDrvn52dRUZGRyIiIgE444wBrFq1kp49e9O5c1cAUlJa4XQ6m/gV16YD6kRExHQ6depMZWU577zzJpdddgUvvfR3LrnkMh544I8MGDCw3vtlZGSwYcORrfBt27b4vgTMnfsIM2Y8xH33zSQp6ceLm1ksVo69cnqbNu3Ys2c3lZWVAKxd+x3t23c4uq6lyV9nfRTuIiJiSpdddgUffTSfESMu5he/GM5zzz3FrbdOYtWqbyguLq7zPqNH/5Ls7CymTr2J999/h5CQEAAuvvhSbrllElOnTqSiooKCgnwAzjijH3fddbvv/nFxcUycOIXbb5/C5Mm/pqSkmCuvHNPsr/WnLMaxXzkCQFPvm9G1hOun3tRNfamfelM/9aZu6kv9Avp67iIiItK0FO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjKaoU5EREzlmWeeYOvWzRw6VEhVVRVt27YjLi6e2bPnnvB+8+b9k8zMgfTs2bvO25966nHGjbue1q1bN0fZTUrnuescy3qpN3VTX+qn3tQvGHvz/o7/8n3e+hOuY7Na8HgbHkP9U/pwdefLG7TuggUfsXfvHqZO/V2DH/908nPOc9eWu4iImN4jj8ykpKSEw4dLmDv3rzz//DPk5eVSWFjAuecOZfLkW3xXhjt0qLDOK7jddttk7r57Bp999gk5OdkUFRWRm5vD7353J4MGDWb58q94+eW/ExkZRXR0DJ06deamm6b45fUq3EVEpFlc3fnyk25lt+SIRmbmQMaNu56cnGx69erDvfc+QHV1NVdfPZLJk2+pte7JruAWEhLK448/zapVK/n3v99g4MCzePLJx3jhhVdISEhk1qz7W+Q11UfhLiIiQaFDhzQAYmJi2Lx5I999t5rIyEicTtdx657sCm5du3Y7entrnM5qiouLiIyMJCEhETgy53xhYWFzvZST0tHyIiISFCyWI5G3YMF/iYqK5qGHZjN+/K+orq7ip4efnewKbj+9OT4+gYqKcoqKigDYuHFD0xV+CrTlLiIiQSUz80xmzbqfjRvXExISQmpqe99V3k6V1Wrljjvu4e67/4/IyCgMw0tqavsmqrjxdLR8EB7B2lDqTd3Ul/qpN/VTb+pmpr7Mm/cq48ZdT2hoKA8//ABnnjmISy9t2JH9ddHR8iIiIn4WERHBlCm/xuFw0Lp1W4YPv8hvtSjcRUREmsAvfzmOX/5ynL/LAHRAnYiIiOko3EVERExG4S4iImIyCncRERGTUbiLiIiYjMJdRETEZBTuIiIiJqNwFxERMRmFu4iIiMko3EVERExG4S4iImIyCncRERGTUbiLiIiYzGkR7oWFhQwbNoydO3f6uxQREZGA5/dwd7lcPPjggzgcDn+XIiIiYgp+D/e5c+cyfvx4UlJS/F2KiIiIKdj9+eTvv/8+CQkJnHfeefzjH/9o0H3i4yOw221NWkdycnSTPp6ZqDd1U1/qp97UT72pm/pSv1PtjcUwDKOJa2mw66+/HovFgsViYfPmzaSnp/P888+TnJxc733y80ubtIbk5Ogmf0yzUG/qpr7UT72pn3pTN/WlfjW9OZWA9+uW+xtvvOH7ecKECcycOfOEwS4iIiIn5/d97iIiItK0/Lrlfqx58+b5uwQRERFT0Ja7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETMbu7wI8Hg/3338/u3fvxmKxMGvWLLp27ervskRERAKW37fclyxZAsCbb77J73//e5544gk/VyQiIhLYLIZhGP4uwu12Y7fb+eCDD1i5ciVz5849wboe7HZbC1YnIiISWPw+LA9gt9uZNm0aixYt4umnnz7hukVFFU363MnJ0eTnlzbpY5qFelM39aV+6k391Ju6qS/1q+lNcnJ0o+/r92H5GnPnzuWTTz7hgQceoKKiaQNcREQkmPg93OfPn88LL7wAQHh4OBaLBavV72WJiIgELL8Py1900UVMnz6d66+/HrfbzYwZM3A4HP4uS0REJGD5PdwjIiJ46qmn/F2GiIiIaWj8W0RExGQU7iIiIiajcBcRETEZhbuIiIjJKNxFRERMRuEuIiJiMgp3ERERk1G4i4iImIzCXURExGQU7iIiIiajcBcRETEZhbuIiIjJKNxFRERMRuEuIiJiMgp3ERERk1G4i4iImIzCXURExGQU7iIiIiajcBcRETEZhbuIiIjJKNxFRERMRuEuIiJiMgp3ERERk1G4i4iImIzCXURExGQU7iIiIiajcBcRETEZhbuIiIjJKNxFRERMRuEuIiJiMgp3ERERk1G4i4iImEyjwr2goIDnn3+eadOmUVhYyIIFC9iyZUtz1SYiIiKnoMHhvn79ei6++GJWrFjBxx9/TEVFBd9++y3XXHMNy5Yta84aRUREpBEaHO5z5sxh8uTJvP7664SEhAAwc+ZMJk+ezOOPP95sBYqIiEjjNDjcN23axKWXXnrc8tGjR7Nr164mLUpEREROXYPDPTExkZ07dx63fM2aNaSkpDRpUSIiInLq7A1dcdKkSTzwwANMmjQJwzBYvnw5OTk5vP7669x1113NWaOIiIg0QoPDfdy4cSQnJ/Pyyy/jcDh4/PHHycjI4JFHHmHkyJHNWaOIiIg0QoPDfdWqVQwdOpQLLrig1nKn08lnn33GiBEjmrw4ERERabyT7nP3er14PB5uuOEGioqK8Hq9tf7bsmULd955Z0vUKiIiIg1wwi33N998k5kzZ2KxWDAMg6FDh9a53rnnntssxYmY1ZZD2yl3lZMSkULbyFbYrLY61/MaXgCsFk0meTrbUbybFdmrOKftWRRWHSLEGkKriGQ2Fm6he0JX2ke39XeJEmROGO7jx4+nU6dOeL1ebrzxRp5++mliY2N9t1ssFiIiIujatespPbnL5WLGjBlkZWXhdDqZOnUqw4cPP6XHEgkE7+/4LyEWOwv3LvYtc9gcRISEExUSSX5lIQNS+mK1WAm3O1h18HsiQsI5P/VcNhZuxWELI84RS1RIJANS+lJcXUKriBQc9jA/vqrglVuRz/PrXiG/shCAlQdXH7eOdddCruk6mvMiMoHQFq5QgpXFMAyjIStmZWXRtm1bLBZLkz35e++9x5YtW7jvvvsoLi7myiuv5IsvvjjhffLzS5vs+QGSk6Ob/DHNQr2p26n2Jbc8j4e/eey45SHWEFxe1ynXc0ZSL/qn9KVNZCvaRLaisOoQiY6EekcDmpMZ3zOFlYcIs4cd+fJVUcine5dwqKoIgJzyXEqch4+7T4IjnqKqYs5qPYBvDq7xLQ+x2ukS34nJfW5kRfYqOsamkRrkW/VmfM80lZreJCdHN/q+DQ738vJy3nzzTXbs2IHH4wHAMAycTiebN2/m008/bfSTl5eXYxgGUVFRFBUVMWbMGD7//PMT3sft9mC3t/yHlsjP8fW+NTy54iXf7+F2B+P6jOKs1H7EhEWzfO8qCiuLiAgJp8pdzbqDm8grK2R8nysID3GQV15A96TOVLgqcXqcfLBpIdsP7an1HCG2ECyA0+NiQJve3DLoRmLCogAoc5bj9nrwGl4SwuNa7oWfhmo+8mo2VAoqDpF9OJfuSZ34bNeRqbRLqkrJKj1I66hkPt62GAsW+rbqzoHDOeSVF9Z6vB7JXRiWPohKVxWvrX2Xm8+cwND0QRRXlZAUkcD7m/7HprztOD1OthQcP1fIny68l04Jac38qiXYNDjc77jjDlauXMk555zDwoULufTSS9m7dy/r16/ntttu47bbbjvlIsrKypg6dSrXXHMNo0aNOuG62nJvOepN3RrTF5fXzY6iXbyw/p+4vG4A7sq8jQ7R7X7WlrVhGJS6ythetIt/bvo37aPaUVxdQlRoJC6vi7yKAgA6xWbQKS6dz/Z96dt/f8eAqbSLasNn+75kSNtBxDviTrmOn/LHe+ZgeS5xYXE47GE4PU6yyw9is9iZv+NjXF4X/VP6ArA2fz2JjoQjxzu4K3B73bSJbEVB5aETjpxYLVaSwxPJrcgHYFjqOQxLPZdvctZwVusBtI48MomX1/CSW5FPm8hWdT5OcnI0e7PzmL/zY37I30Spq6zW7bGhMUSFRnJd91+SHtOhKVoTEPQ5U78W2XIfOHAgTz/9NOeccw5XXHEFjz76KL1792bOnDlkZ2fz9NNPN/rJAXJycrj11lu57rrrGDNmzEnXV7i3HPWmbg3ty5ZD23l+3Su4jSMjXUPanU3HmDQGtcls0nrcXjd264+Hz5S7Kli09ws+37/UF+jHig6JIjE8gT2H99E9vgu9ErsRGxbDgJQzfAfPnurut8a8ZwzDwG14qHBVsCJnNeWuI6MLvZN6UFRVRMfYdL7O/pbYsBhCbCHYLFaKqw+DYeDlyMdWbnke6wo2kuCI58IOw/g6+1v2l2U3quYQq530mA5sL/5xGu3u8V1IiUgmtyKPi9J+Qbf4zpS5yqn2VJPgiD+lAxyP7Y3X8GIYBgv3LmbB7kW11gu3h3Nx2i+wW+1UuCrIbNXP9wXCjPQ5U7+fE+4NPs/d6XSSnp4OQJcuXVi/fj29e/dm/PjxXHfddY1+YjhyCdmJEyfy4IMPMnjw4FN6DJHTkWEY/GvzO75gP6/dYMZ3u6pZnuvYYAeIDIngys4jGdLubKo91azOXcune5cA0CepJxsKNvu2GrcUbWdL0XYA1uVvxGN4yC47yM19f82Bshz6Jfdu0n33mwq3sjJnNQ57GDuL93CwIu+4dZZmfd3oxz1UVcRb2+bXe3tkSAS/6zeJclcFcWExVLqr2VWyh+TwRNJiOhAbFk2Fq5IQWwh2i63OLzfRoVFEE9Xo2upitVjBApdlXMjw9kNZeXA1ZyT1YnvxLt7Y/A7zdy7wrbs0awV/yLyVMFsosWExTfL8Yn4NDvfOnTuzfPlyxo4dS5cuXVi9ejXXXnsthw8fxul0ntKT//3vf+fw4cP87W9/429/+xsAL774Ig6H45QeT+R0kF9RyIsbXqeoupjo0CiSwxO5KO38Fq8jKTwBgHZRbbg0fTj7SrPoHJdBUVUx+ZUFZJfl8s72D33rr8lb5/v52AP/hqWeS3pMe8pdFWSXHWR0p0uJCo3E7XVjtVjJKc+luPown+5dzOheF3L4cBXlznIOVRWxtWgHsWExGMCB0mwKqw7VqrH10SHsg+W5AHSIbkdcWBxOjxOn18mhqmKSwxPJiE2j3FWB5+iW/YGybL7LW8fg1mcyNHUwmw5t42B5LikRyfRO7MEnexfTNa4TieHxeAwvCY54wmy1j1TPiK099B0REv7zm34KHPYwzk89cjrxWa0H0Ck2nT2H92EYBluLdvJ1zrfMWvlnokIieejse/xWpwSWBg/LL1myhNtvv53777+foUOHMnLkSDIzM9m+fTv9+/fnySefbOZSj9CwfMtRb+p2or5sK9rBS+v/Rbm7AoBxXa9iaOrpOSplGAavbXoTm8VGv5TebCvaSUxoNB/v/tR3fEBdQq0hJIUnklOei0GDPj6AI1u+CWHxZMR2ICOmAxmx6SSGx/tqWVewka5xnUwbXqfy9+Tyurl76YO+f48+ST25qdf1hNhCmqNEv9DnTP1aZJ87wIEDB/B4PKSlpbFlyxY+/PBD4uPjueGGG1psa1vh3nLUm7rV1ZfXNr1JVlkOZc4ySpw/3jZr8DSSwhNbusSfpbi6hE2F2+gUm4bFYuHr7FUs2vdFg+57ToeBhBkOVuasptJdRVpMewa3OZNu8Z1IDk9q0lNpA82p/j3tPbyfJfuXs78si4PluWTEdKBDTCqlzjJ+1eOa40YkAo0+Z+rXIuE+ffp07rvvPqKiau9zKikp4YEHHjjlA+oaS+HectSbuh3blzJXORWuCh5e+ZhvK3Zou3MY02UUxdUlJB4dGjeDw85SYkKjyS47SHRoFHarnZ3Fu0mP7cCne5dwVqsB9O/YzdebSncV4XbtYqvxc/+eSp1l3Lvs4VrL+qf05dpuVxMZEvFzy/Mbfc7Ur9kOqFu9ejV79uwBYP78+XTv3p3IyMha6+zatYvly5c3+olFAl2Fq5LZ3zxOqfPIwWlnthqA1WLhkvQLsFltpgp2gJjQIx8wbaNa+5b1TuoBwNWdLz9ufQV704oOjWJQ60x+KNjIOW3O4vP9S/k+7wcOV5dyx4CbOewso8RZQofoVH+XKqeBE4Z7VFQUzz//PIZhYBgGr776Klbrj6eA1Ew/e8899zR7oSKnk4LKQ7y/47++YAe4qvNlxIY1/hu2SEP9qsdY3N6rCbWFUOYq55uDa9hZsps7v7wfp9eFBQt/PGd6k85dIIGpwcPyEyZM4LnnniM0NBSHw8HWrVtZunQpvXv3btHT2DQs33LUm7oVksfMJX89MtubI55eid0Z3GYgaTHt/V2a3+k9U7/m6E1J9WHe3/FfsssOkl1+EAALFn4/4GYsWEiJSCI6tGlO32sues/Ur0XOc7/pppsYNmwYzz33HO3bt+dXv/oVCQkJPPfcc9x7772MHz++0U8uEihW565lWdZK4sLi+C5vLV7Dyy9ShzAyYwQRAby/UwJbbFgMv+l1ZJ6RzYXbeHbdSxgYPPHd8wAkhScy8+x7gvpAxmDV4GmWnnjiCaZMmcLgwYN59913SUpKYuHChTz22GO8/PLLzVmjiF95DS+vbvx/bC/exarc70iJSmJynxsY0/UKBbucNuq6AE1BZSHPrn2JrLIcP1Qk/tTgLffdu3czevRoLBYLixcvZsSIEVgsFnr06EFe3vGzTIkEMrfXzTvb/4PNYmXLoR21bpt1wR9wlWpLSE4v0aFRpEa15UBZNlaLlTBbGKlRbdhStJ1n177Eg2ffrYMcg0iDwz0lJYUtW7ZQUlLC9u3bmTlzJgDLli2jXbt2zVWfSIszDIMfCjaxLGulb1n3+C70T+lDoiOBOEcM+aXaRyinn2ln3n7kAGgMrBYrVouVd7f/hyX7l3HX0gfpGteJw85SQm2h3Jl5CyHWBkeABJgG/8v+5je/4Xe/+x1Wq5V+/fqRmZnpmzZ2zpw5zVmjSIvZUbybv//wKpXuKt+ysV1H+6YHFTmd1cxZf6xL0odzuLqU7cW72Fb84yVnV+as5rx2Z7dwhdJSGjVD3ebNm8nKymLIkCE4HA7Wrl2Lw+Gge/fuzVljLTpavuUEU28Mw2B/aRbPrH2RCnclAO2j2vLLLlfQOS6j1gFJwdSXxlJv6ufv3ngNL06PkypPNTNXzMVjeOmb1IsRHYaSEZvG3sP7SQxPICok8uQP1oT83ZfTWYscLQ/Qo0cPevTo4fu9X79+jX5CkdPRypzV/GvLO77fLVgY03U0neMy/FiVSNOxWqw47A4cdgdT+vyaf299j7X561mbv57Bbc5kRc4qokIiub3/ZNpFtfF3ufIzaYeLBK28inxsFhvxjjiWHFgGHJlV7aGz78HldZHgiPdzhSLNo0diVx4+Zzrbi3by1Pf/YEXOKuDIdMp/+vZJruw8kqHtziHURBeoCTYKdwlKVe4q/rL6Wao81aSEJ3GwIo9eid255YyJ/i5NpMV0ie/ExekXsHDP51ySPpxwu4P5OxbwwY6PqXRVMqrTJf4uUU6Rwl2CimEYvLntA3YV7/HtWz9YkUfPxG5c332Mn6sTaXmXZ1zE2a0Hkhxx5OqFnWIzeGzNsyzcu5hvDn5Hekx7Lu94Ea0jW/m5UmkMhbsElQNl2b5T3KwWKzf1/hVew8sZSb2wWW1+rk6k5VksFl+wA2TEduDs1gNZeXA1RdXFFOUXs75gExN6jmNgq37+K1QaReEuQWHpgRUcrMglu+ygb9mk3hPom9zLj1WJnJ5+2eVyeiZ2pW9ybzYWbuFfm9/mjc3vUFBZSGRIJJkpfTU742lO4S6mVuGqpMJdwTvbP8RreIEjW+xzhjwY0NfAFmlOESERZB7dSu+X3JtqdzWvb36Lj3Z9AsD/dn/GHzJvIcERr3nrT1MKdzGloqpiVueuZcHuRTi9LgAuaH8ekSERpMW0V7CLNMKgNplEh0ZxoCybkurDfHFgOQ+umEOI1c7EXtfTK7G7dmudZhTuYjprctfxz03/9m2pA6TFtGdUx0t0ao/IKeqZ2I2eid0wDIPs8ly2Fe3A5XXzwvrXaBWRzM19f01kSKTvi/OhqiK2F+3irNYDtHXvBwp3MY2FexazJnct2eUHCbWF8ovUIQxLPZfCqkO0j2pLiIJd5GezWCzcesZEPIaXh1f+heLqEnIr8pm18i84bA4m9ZlAoiOBZ9e9REFlIZ/sXczI9BH0T+mLzWrD4/WwNn8D3RO6EGEPByCvooBwu+O0v/Z8IGnU9LOnA00/23ICoTcl1aVsOrQVm8XKa5veBMBhC+N3/SeRHtOhWZ4zEPriL+pN/czYm32HD7C9eBfF1SUs3v/VCdcNsdo5r91gDpRm++a4jwuLpdJdidPjIjYshl+0H8LSAyvIbHUGXsNLu6g2nNmqv+9COMHm50w/q3A34R9cUzmde+M1vKzMWc3CPZ9TWFXkW94lriNju45u1ukzT+e++Jt6Uz+z98ZrePnvrk/5ZO9iAAa26kdueR77y7I5s1V/NhRurnVBpoawWqzYLDY6RLfj9wNuDoiAz68oJCo0skkur9tic8uL+NthZylfZ3+L3Wrngx0f17rtjOTeTO5zg58qEwluVouVyzteRN/knnSITsVqseL0ODGAMFso83csYNG+L+gYm8bEXtfzzcHv6JPUg7i4CMJd0ews3kNuRR6xYTH8/Yd/Ake+MHgNLztL9vDapjdpH92OuNAYvBi0iWzNmty1OL1Orul6pT9fOgDF1SV8e/A7Ptr1Cee2HcT4blf5tR6FuwQMl9fNnG+fosR5uNbyc9qcSY/EbvRObLmrE4rI8awWa63dYaG2UN/Pl6QPx2EP49y2g4gOjeKS9AsASI4/snXaJb4jXeI7AjCodSbbi3fRMTaN1blrAVidu9b380/9kL+JSX0mkBbTvnle2DHKXOVklx3E5XWRV1GAgcGC3Z9ReXTGS4B2Ua2bvY6TUbjLaW9N7joq3ZXYrfbjgh0gs1U/uid08UNlItJQDnsYl6QPb9C6v+ox1vfz2K6jmfbVLN/vI9NHsK80iw2Fm33LiqqL+fPqZwBIciSQHtuB7UU7qfY46ZHYjWu6jiYm9Pih7YLKQyQ44rBarJRUl1LuKqftCYJ5e9FOXlw/j3J3Ra3lobZQUiKSyKsoACAz5YwGvc7mpHCX05bL48LldfPKxjd8yyxYuDNzKocqi+if0pf8ygLNeS1iMsfuW48KieSyjAv5ePciftdvku+LvNfwUlRVwmf7vqTcVc53eT9gYFBYVURB1SHfFR+/z/uB/IoCRnW8mOzyg5zbdhDbinby+b4v2X14H5dnXEyVp4rP9n0JwKzB06j2OH3H7Rx2lvLZ3i85WJHH5kPbAOge34VtxTsJtzuocFVyTdcrGdxmIAWVh6hwV5wWs/fpgDqTH+Tyc/izNwWVhTzx3d8pri7xLYsKieSarleS2cq/34r1nqmfelM/9aZuDemL1/BSUFlISkRyvevsL80iKiSSak81q3PXckZyH1Kj2vDvre+xPPvbRtcVbg8nMiSCgspC37JIewS/7TOBrvGdMAwDi8WC2+vGbm2e7WQdUCemsu/wAZ747nnfzHJRIZHc1u+3tI5I0bnqIkHIarGeMNgB2ke38/18eceLfT+P63oVNoudak81cGT2yqjQSHIr8skqywEgKTyRbvGdfF8Cwu3hVLorqXRXkuCIp39KHwam9CMxPME3SU/NxDzNFew/1+lZlQStw85SPj46Zeyl6cNJj+lAekwHokIj/V2aiAQgm9XGuG5X1nnbpsKtLMtayXU9xhAVEsmZrfoTHRpNXFgsXx5YTp+knifcB386U7jLacHlcbEqdy3/3voeXsNLuN3ByIwLA+K8VhEJTDVT6tboEt/J9/PFR4/mD1QKd/GroqpivjiwnK+yVlDtcQKQEp7EeamDFewiIqdI4S4txjAMvstbx7aiI1NPFlYV+Y4+jbRHEB8Zz8j04b5LTYqIyKlRuEuL8Bpevs9bzysb/1+t5RkxaZzdJpNBrTN1sJyISBNRuEuzyq8o5P0d/2VXyR7KXOW+5dGhUZzb5iwu73ixLgcpItLEFO7SbNxeN8+te4n8Y84TBXhy2CPaShcRaUYKd2kShmFQ5anCbrGzImcVe0sPsL1oZ60rtgH0SuyuYBcRaWYKd2kSX2Wt5O1t80l0xFNQdQg4cpBcv+TeDO8wjAW7F3FFx0toHZni50pFRMxP4S6nrMpdjcvr4vVNb7Hp0FYAX7BP7HUd/VP6+k5nu63fb/1Wp4hIsFG4S6NVuav4fP9XLNn/FZXuKt/yngndiAqNZEBKX/ok9fRjhSIiwU3hLg3m9rrJKsvh831LWZO3zrd8ePuhXNl5pCadERE5TSjc5aSq3FWsyv2er7O/ZV9pFgCRIRHcdsZvSY1uq1AXETnNnBbhvm7dOh577DHmzZvn71LkGFXuanaV7OWNze9wsCLPt3xQ60xGZlxIUniCH6sTEZH6+D3cX3zxRf7zn/8QHh7u71KCnmEYbC3aQYIjHoDHvvs3u4v3A0cuu1rmKueStAsY1ekSf5bpF1v3FfHfFXvxeg1CQ204nR5/l3RaMmNvOrWL5eqhHf1dhkijWAzDMPxZwCeffEK3bt245557ePvtt0+6vtvtwW63tUBl5renaD9f7F7B0PRBvLTmTXYc2nPcOnarnZsGjGN4pyEcOJxD66gU7Nbg6//Tb33Pom/3+bsM8ZP/PHaFZlKUgOL3LfeLL76YAwcONHj9oqKKJn3+5ORo8vNLm/QxT1eGYeDyuvg6ZxXtIlvzyd4lbD60jQXbl9S5/rD0s7ky7XJCbaHk55cSRhRF1U3b/0BRXnHkinV/mnI2PTolk18QHO+ZxkpOijZVbx5/cy1b9hWTl1eK1frzwj2YPmsaQ32pX01vkpOjG31fv4e7NA/DMHAbHpweJ1aLhc/2fsmKnNWkxbTnh4KNAIRYf5wpzmFzUOWpItQawszB9xIbFq0/umN4jw5whdis2GxWbFYdRFgXs/XGdjTQvYaBFW25S+BQuJvIpsKtzN+5gKTwRIqrSthbuv+4dWqCHcDlddExNo0zknvTO7E7pc5yYsNiiA1r/LdEs/N6j4T7z916k8BiOfrv7fEaaG+gBBKF+2nMa3ipcFcSFRLpW1blrqakuoRWkSm4PC72lh7gsLOUao+TpQeWk1WWQ1ZZTq3HiQ2NZlCbgQB8uncJvRN7kBHbgY92fULX+M6M6DAMgNaRSD08CvegZDu6n73my51IoDgtwj01NbVBB9OZhdfw1jo33DAMthfvokN0O2wWGwVVh0gJT+KjXZ/wxYFl3NZvEkVVxXy+fyn7j55nXp/u8V3ondTDN4tcr8Ru/KbXdb7b+yT1ICk8kaiQSFpHpNAtoXOzvU4zqflwtyncg4r1mGF5kUByWoS7GRiG4QvtmqNqD1UV4fF6SY5IBI5sda/MWc2C3Yvol9Kb9Jg0PIaH/+1eRImzlLiwWKo9TirdlbUe+4nvnq/3eXsldifeEUdRVTHlrgou63ghHWPTARjRYRi2nxzZXnMbQL+UPk3wyoODb1heR0wHFesxw/IigUTh3ggHy3MxgEp3JbtL9rGjeDcHy3NpHdmKDYWb8RpeksMT6RCdSmRIJEuzvgagQ3QqFiy19oEvz/6W5dnf1nr84uoSAJLDE2tdAz3UGoLT66q1bu/E7pzTdhB9knrUO0OcLq3adGo+2zUsH1xqRmoMhbsEGIV7A31xYDnvbf8Ir+E97ra8ygLfz/mVhbWCGWBf6Y+n+oVYQ5jc5wZ+KNjEV1krfMvHd7uK/aVZOD0ubug5DsMw2FK0g/bRbbFZbJS5yil3lRMfFkdcWKzOuW1hXu+Rf3cNywcXbblLoFK418Hj9VBQWUiVp5r/7fmc9QWbgCMTuvw03K/oeAmp0e1Ij2mPzWIl1BbKgbJsiqpKqPZUExcWS7g9HMPwsiJnNb9oP4SUiCR6Jnbjgvbn8c62DxnTZRStfnqdcwv0Suzm+zUyJAJIbu6XLvXwaFg+KFl1QJ0EKIX7UWXOcsJsoeRU5PLOtv+wq2TPcevcnXkbO0p20yOhK60ikvF4Pcft04Yjw/AdolOPXx5Te1lKRBK39rupyV6DNJ+az3Zle3DRAXUSqBTuQKmzjJkr/kyryGSyynJwe93EhcWSEZvGoNYDWLB7Ee2jU0mNbktqdFvf/eoKdjEnr9fAarFod0iQqdly17C8BJqgDne3182b6z9k5d61VHmq2Ht4P1aLlZt6/4r+yX18H+R9knr6uVLxN4/X0MF0Qcg3Q53CXQJMUIf7NwfX8P6Whb7fI+0RXNN1NANS+vqxKjkdeQ1DB9MFoR+H5f1ciEgjBXW4r8heBcAvO19Ol/jOtD9myF3kWF6vgYmmTJcG0gF1EqiCOtzPazeYy3pcQI9IDbvLidXsc5fgYtOpcBKggjrcB7XJ1JXPpEE0LB+cdLS8BCoNNIo0gMdr+K4QJsGjZleMhuUl0CjcRRrA69WWezDSPncJVAp3kQbwGtrnHox8+9w1LC8BRuEu0gA6zz04WXWeuwQohbtIAxgalg9KCncJVAp3kQbw6FS4oKR97hKoFO4iDeA1NCwfjHTJVwlUCneRBvB6UbgHIZvOc5cApXAXaQANywcnDctLoFK4izSAznMPThqWl0ClcBc5CcMwtM89SGlYXgKVwl3kJGo+15XtwUfD8hKoFO4iJ1Gz1aZh+eCj67lLoFK4i5xEzf5Wqy7oHnRsmsRGApQ+rUROouaDXRvuwcdi0QF1EpgU7iInUTMsrwPqgo+23CVQKdxFTuLHYXmFe7DxXc9dR8tLgFG4i5xEzVabDqgLPjrPXQKVwl3kJLzacg9atqP73A2FuwQYhbvISfx4QJ3CPdhoy10ClcJd5CQ8OqAuaFk1Q50EKIW7yElon3vwsupoeQlQCneRk9CwfPCy6jx3CVAKd5GTqPlc17B88NGFYyRQKdxFTkJb7sFLF46RQKVwFzkJj/a5By3tc5dApXAXOQlNPxu8NCwvgUrhLnISP05i4+dCpMVZdJ67BCh9XImchEf73IOWTfvcJUAp3EVOomZIVvvcg8+Pk9j4uRCRRrL7uwCv18vMmTPZunUroaGhzJ49m7S0NH+XJeKjueWDl6aflUDl9y33zz77DKfTyVtvvcUf/vAH5syZ4++SRGrRJV+Dl67nLoHK71vua9as4bzzzgOgX79+bNiwocWe+1+fbuW77QX6w62H1WpRbwCX2wton3swqvk3/2FnAb9/ZtnPeyz9PdXJbH2xAFcMyeAX/dv5tQ6/h3tZWRlRUVG+3202G263G7u97tLi4yOw221N8tyJ8RFEOkKa5LHE3MJCbZzTL5Xk5GgA3//leGbqjWEYnHtGW/ZkH/Z3KRIgrFZISohssr+DU30cv4d7VFQU5eXlvt+9Xm+9wQ5QVFTRZM996ZntuWFkT/LzS5vsMc0kOTlavfmJ/PxS9eUEzNibmy7t3iSPY8beNAWz9qUpXlNNb04l4P2+z33AgAEsXboUgLVr19K1a1c/VyQiIhLY/L7lfuGFF7J8+XLGjx+PYRg8+uij/i5JREQkoPk93K1WKw8//LC/yxARETENvw/Li4iISNNSuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJiMwl1ERMRkFO4iIiImo3AXERExGYW7iIiIySjcRURETEbhLiIiYjIKdxEREZNRuIuIiJjMaRHuixYt4g9/+IO/yxARETEFu78LmD17NsuWLaNHjx7+LkVERMQU/L7lPmDAAGbOnOnvMkREREyjxbbc33nnHV577bVayx599FFGjhzJN9980+DHSU6OburSmuUxzUK9qZv6Uj/1pn7qTd3Ul/qdam9aLNzHjh3L2LFjW+rpREREgpbfh+VFRESkaSncRURETMZiGIbh7yJERESk6WjLXURExGQU7iIiIiajcBcRETEZv89Q5y9er5eZM2eydetWQkNDmT17Nmlpaf4uyy/WrVvHY489xrx589i7dy/33nsvFouFLl268NBDD2G1Wnn22Wf54osvsNvtzJgxg759+/q77GbjcrmYMWMGWVlZOJ1Opk6dSufOnYO+LwAej4f777+f3bt3Y7FYmDVrFmFhYerNMQoLC7n66qt55ZVXsNvt6s1RV111FVFRUQCkpqYybtw4HnnkEWw2G0OGDOG2224Lys/lF154gcWLF+Nyubj22ms566yzmuY9YwSpTz75xJg2bZphGIbx/fffGzfffLOfK/KPf/zjH8bll19ujB071jAMw5gyZYqxcuVKwzAM44EHHjA+/fRTY8OGDcaECRMMr9drZGVlGVdffbU/S2527777rjF79mzDMAyjqKjIGDZsmPpy1KJFi4x7773XMAzDWLlypXHzzTerN8dwOp3GLbfcYlx00UXGjh071JujqqqqjNGjR9dadsUVVxh79+41vF6v8dvf/tbYuHFj0H0ur1y50pgyZYrh8XiMsrIy4+mnn26y90zQDsuvWbOG8847D4B+/fqxYcMGP1fkHx06dOCZZ57x/b5x40bOOussAIYOHcrXX3/NmjVrGDJkCBaLhbZt2+LxeDh06JC/Sm52l1xyCf/3f/8HgGEY2Gw29eWoESNG8Mc//hGA7OxsYmJi1JtjzJ07l/Hjx5OSkgLo76nGli1bqKysZOLEidxwww2sWrUKp9NJhw4dsFgsDBkyxNebYPpcXrZsGV27duXWW2/l5ptv5vzzz2+y90zQhntZWZlviAjAZrPhdrv9WJF/XHzxxdjtP+6dMQwDi8UCQGRkJKWlpcf1qma5WUVGRhIVFUVZWRm33347v//979WXY9jtdqZNm8Yf//hHRo0apd4c9f7775OQkOALJ9DfUw2Hw8FNN93Eyy+/zKxZs5g+fTrh4eG+2+vrjdk/l4uKitiwYQNPPfUUs2bN4q677mqy90zQ7nOPioqivLzc97vX660VcsHKav3x+155eTkxMTHH9aq8vJzoaHPPBZ2Tk8Ott97Kddddx6hRo/jLX/7iuy2Y+1Jj7ty53HXXXVxzzTVUV1f7lgdzb9577z0sFgsrVqxg8+bNTJs2rdbWVTD3JiMjg7S0NCwWCxkZGURHR1NcXOy7vaY3VVVVQfW5HBcXR8eOHQkNDaVjx46EhYVx8OBB3+0/5z0TtFvuAwYMYOnSpQCsXbuWrl27+rmi00PPnj19F/JZunQpAwcOZMCAASxbtgyv10t2djZer5eEhAQ/V9p8CgoKmDhxInfffTdjxowB1Jca8+fP54UXXgAgPDwci8VC79691RvgjTfe4F//+hfz5s2jR48ezJ07l6FDh6o3wLvvvsucOXMAyM3NpbKykoiICPbt24dhGCxbtszXm2D6XM7MzOSrr77CMAxfXwYPHtwk75mgnaGu5qjMbdu2YRgGjz76KJ06dfJ3WX5x4MAB7rzzTt5++212797NAw88gMvlomPHjsyePRubzcYzzzzD0qVL8Xq9TJ8+nYEDB/q77GYze/Zs/ve//9GxY0ffsvvuu4/Zs2cHdV8AKioqmD59OgUFBbjdbiZNmkSnTp2C/j3zUxMmTGDmzJlYrVb1BnA6nUyfPp3s7GwsFgt33XUXVquVRx99FI/Hw5AhQ7jjjjuC8nP5z3/+M9988w2GYXDHHXeQmpraJO+ZoA13ERERswraYXkRERGzUriLiIiYjMJdRETEZBTuIiIiJqNwFxERMRmFu0iQ2rx5M6tXr+abb76hW7dupp4JTCTYKNxFgtStt97K7t276d+/P8uWLTP1TGAiwUbhLhLkQkNDSU5O9ncZItKEFO4iQWjChAlkZWVx//33c8EFF/iG5Q8cOEC3bt34/PPPueCCC+jfvz9z5sxh69atXH311fTr14+bb76ZiooK32O99dZbDB8+nP79+3Pttdfyww8/+PGViQgo3EWC0jPPPEPr1q259957mTFjxnG3v/jii/ztb39j5syZvPrqq9x+++3cfffdvPjii6xatYr33nsPgMWLF/PUU08xffp0PvjgA4YOHcqNN95IXl5eS78kETmGwl0kCMXFxWGz2YiKiqrz6lJTp06le/fujB49mri4OC677DIGDx7MmWeeyVlnncWuXbsAeOmll5g8eTIjRowgPT2dqVOn0rt3b955552WfkkicgwdQSMix0lNTfX9HBYWRtu2bX2/OxwOnE4nADt37uSvf/0rTz31lO92p9NJ69atW65YETmOwl1EjvPTI+et1roH+TweD9OmTWPIkCG1lkdERDRbbSJychqWF5FTlpGRwcGDB0lLS/P998orr/Dtt9/6uzSRoKZwFwlSkZGR7Nq1i5KSklN+jN/85jfMmzePDz74gH379vHss8/y3nvv0bFjxyasVEQaS8PyIkHq+uuvZ+7cub4j30/FyJEjKSws5NlnnyUvL4+OHTvy3HPP0aNHjyasVEQay2IYhuHvIkRERKTpaFheRETEZBTuIiIiJqNwFxERMRmFu4iIiMko3EVERExG4S4iImIyCncRERGTUbiLiIiYzP8HR6tWjPTySoYAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(result)), YVal, label = 'Validation')\n",
    "plt.plot(np.arange(len(result)), result, label = 'Training')\n",
    "plt.ylabel('state', fontsize = 14)\n",
    "plt.xlabel('time', fontsize = 14)\n",
    "plt.legend()\n",
    "plt.ylim([-1,5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}