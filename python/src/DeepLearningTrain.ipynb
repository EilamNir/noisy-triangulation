{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/cuda_test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from simulation.generate_path import generate_path\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from estimation.distance_sensor import distance_sensors\n",
    "from estimation.non_iterative_estimator import non_iterative_estimator\n",
    "from estimation.kalman_filter_from_points_with_acc import kalman_filter_from_points_acc\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2897, 1)\n",
      "(1, 4, 2897)\n"
     ]
    }
   ],
   "source": [
    "# create test data\n",
    "target_initial_pos = np.array([0, 0, 5000])\n",
    "target_speed_xy = 50\n",
    "target_speed_z = 10\n",
    "target_rot_speed = 3\n",
    "time_res = 0.1\n",
    "\n",
    "path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "path1.add_straight_interval(100)\n",
    "path1.add_xy_turn_interval(90, -np.deg2rad(target_rot_speed))\n",
    "path1.add_straight_interval(100)\n",
    "outliers = np.random.randint(0, 100, size=len(path1.path))\n",
    "outliers = outliers > (100 - 20)\n",
    "\n",
    "# create noisy sensors\n",
    "sensors = distance_sensors([[-5000,0,0],[ 400, -7400, 0],[ 800, 800, 0]], 15)\n",
    "sensors.calculate_measurements(path1.path)\n",
    "non_it_est = non_iterative_estimator(sensors, path1.path[0,:])\n",
    "estimated_path = non_it_est.estimate_path()\n",
    "\n",
    "sensors_noisy = distance_sensors([[-5000,0,0],[ 400, -7400, 0],[ 800, 800, 0]], 200)\n",
    "sensors_noisy.calculate_measurements(path1.path)\n",
    "non_it_est_noisy = non_iterative_estimator(sensors, path1.path[0,:])\n",
    "estimated_path_noisy = non_it_est.estimate_path()\n",
    "\n",
    "sigma_a = 1\n",
    "sigma_v = 500\n",
    "kf = kalman_filter_from_points_acc(time_res, sigma_a, sigma_v, non_diag_reduction_ratio=2)\n",
    "kf_path, P, X = kf.filter_path(estimated_path)\n",
    "\n",
    "sample = 1\n",
    "XTest = []\n",
    "for i in np.arange(len(kf_path) - sample):\n",
    "    # tmp = np.concatenate((kf_path[i, :].reshape(1,-1), np.reshape(P[i, :, :], (1,-1)), X[i,:].reshape(1,-1)), 1)\n",
    "    tmp = np.array([7000, 5000, 3000]).reshape(1,3)\n",
    "    # if outliers[i+1]:\n",
    "        # tmp =  np.concatenate((tmp, estimated_path_noisy[i+1, :].reshape(1,-1)),1)\n",
    "        # tmp =  estimated_path_noisy[i+1, :].reshape(1,-1)\n",
    "    # else:\n",
    "        # tmp =  np.concatenate((tmp, estimated_path[i+1, :].reshape(1,-1)),1)\n",
    "        # tmp =  estimated_path[i+1, :].reshape(1,-1)\n",
    "\n",
    "    tmp = np.concatenate((tmp, outliers[i+1].reshape(1,1)), 1)\n",
    "\n",
    "    # tmp = outliers[i+1].reshape(1,1)\n",
    "    tmp = tmp.reshape(1, tmp.shape[1] ,1)\n",
    "    if i > 0:\n",
    "        XTest = np.concatenate((XTest, tmp), 2)\n",
    "    else:\n",
    "        XTest = tmp\n",
    "\n",
    "YTest = outliers[1:].reshape(-1,1)\n",
    "\n",
    "print(np.shape(YTest))\n",
    "print(np.shape(XTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538, 1)\n",
      "(1, 4, 538)\n"
     ]
    }
   ],
   "source": [
    "# create train data\n",
    "run_number = 50\n",
    "for k in np.arange(run_number):\n",
    "    target_initial_pos = np.random.randint(-7000, 7000, size=(1, 3))[0]\n",
    "    sensors_pos = np.random.randint(-7000, 7000, size=(3, 3))[:,:]\n",
    "    target_speed_xy = 50\n",
    "    target_speed_z = 10\n",
    "    target_rot_speed = 3\n",
    "    time_res = 0.1\n",
    "\n",
    "    path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "    path1.add_straight_interval(np.random.randint(0,100,size=1)[0])\n",
    "    path1.add_xy_turn_interval(np.random.randint(0,100,size=1)[0], -random.choice([-1, 1])*np.deg2rad(target_rot_speed))\n",
    "    outliers = np.random.randint(0, 100, size=len(path1.path))\n",
    "    outliers = outliers > (100 - 20)\n",
    "\n",
    "    # create noisy sensors\n",
    "    sensors = distance_sensors(sensors_pos, 15)\n",
    "    sensors.calculate_measurements(path1.path)\n",
    "    non_it_est = non_iterative_estimator(sensors, path1.path[0,:])\n",
    "    estimated_path = non_it_est.estimate_path()\n",
    "\n",
    "    sensors_noisy = distance_sensors(sensors_pos, 200)\n",
    "    sensors_noisy.calculate_measurements(path1.path)\n",
    "    non_it_est_noisy = non_iterative_estimator(sensors, path1.path[0,:])\n",
    "    estimated_path_noisy = non_it_est.estimate_path()\n",
    "\n",
    "    sigma_a = 1\n",
    "    sigma_v = 500\n",
    "    kf = kalman_filter_from_points_acc(time_res, sigma_a, sigma_v, non_diag_reduction_ratio=2)\n",
    "    kf_path, P, X = kf.filter_path(estimated_path)\n",
    "\n",
    "    sample = 1\n",
    "    XTrain = []\n",
    "    for i in np.arange(len(kf_path) - sample):\n",
    "        # tmp = np.concatenate((kf_path[i, :].reshape(1,-1), np.reshape(P[i, :, :], (1,-1)), X[i,:].reshape(1,-1)), 1)\n",
    "        tmp = np.array([-50, -800, -5000]).reshape(1,3)\n",
    "        # if outliers[i+1]:\n",
    "            # tmp =  np.concatenate((tmp, estimated_path_noisy[i+1, :].reshape(1,-1)),1)\n",
    "            # tmp =  estimated_path_noisy[i+1, :].reshape(1,-1)\n",
    "        # else:\n",
    "            # tmp =  np.concatenate((tmp, estimated_path[i+1, :].reshape(1,-1)),1)\n",
    "            # tmp =  estimated_path[i+1, :].reshape(1,-1)\n",
    "\n",
    "        tmp = np.concatenate((tmp, outliers[i+1].reshape(1,1)), 1)\n",
    "\n",
    "        # tmp = outliers[i+1].reshape(1,1)\n",
    "        tmp = tmp.reshape(1, tmp.shape[1] ,1)\n",
    "        if i > 0:\n",
    "            XTrain = np.concatenate((XTrain, tmp), 2)\n",
    "        else:\n",
    "            XTrain = tmp\n",
    "\n",
    "    YTrain = outliers[1:].reshape(-1,1)\n",
    "\n",
    "print(np.shape(YTrain))\n",
    "print(np.shape(XTrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "ind = np.arange(len(YTrain))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XVal = torch.from_numpy(np.transpose(XTest[:,:,ind], (2, 0, 1)))\n",
    "YVal = torch.from_numpy(YTest[ind,:])\n",
    "\n",
    "XTrain = torch.from_numpy(np.transpose(XTrain[:,:,ind], (2, 0, 1)))\n",
    "YTrain = torch.from_numpy(YTrain[ind,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create network\n",
    "class state_estimat(nn.Module):\n",
    "    def __init__(self, d_in, num_classes):\n",
    "        # initialzing the parent object (important!)\n",
    "        super(state_estimat, self).__init__()\n",
    "        # Create a pipeline - a sequence of layers\n",
    "        self.pipe = torch.nn.Sequential(\n",
    "            # nn.Conv1d(1, 16, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(97, 10),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(97, 2),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(4, num_classes))\n",
    "            # nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "state_estimat(\n",
      "  (pipe): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters:\n",
    "# num_epochs = 100\n",
    "num_epochs = 60\n",
    "# batch_size = 512\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "learning_rate_drop_period = 10\n",
    "\n",
    "# Device configuration, as before\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(device)\n",
    "# create model\n",
    "model = state_estimat(d_in=10, num_classes=1).to(device)\n",
    "print(model)\n",
    "# Loss and optimizer\n",
    "# criterion = torch.nn.BCELoss()\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=learning_rate_drop_period, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Step [5/134], Loss: 2197957.0000, Time: 0.5214 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [10/134], Loss: 2112210.2500, Time: 0.5231 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [15/134], Loss: 2029300.5000, Time: 0.5241 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [20/134], Loss: 1946754.2500, Time: 0.5250 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [25/134], Loss: 1867242.5000, Time: 0.5260 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [30/134], Loss: 1790760.5000, Time: 0.5269 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [35/134], Loss: 1714950.7500, Time: 0.5279 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [40/134], Loss: 1641466.7500, Time: 0.5288 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [45/134], Loss: 1571046.5000, Time: 0.5297 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [50/134], Loss: 1502894.0000, Time: 0.5307 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [55/134], Loss: 1437688.5000, Time: 0.5316 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [60/134], Loss: 1374661.8750, Time: 0.5326 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [65/134], Loss: 1311758.6250, Time: 0.5335 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [70/134], Loss: 1252365.3750, Time: 0.5344 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [75/134], Loss: 1196335.5000, Time: 0.5354 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [80/134], Loss: 1140418.0000, Time: 0.5363 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [85/134], Loss: 1087749.2500, Time: 0.5372 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [90/134], Loss: 1035826.5000, Time: 0.5382 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [95/134], Loss: 985845.3750, Time: 0.5391 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [100/134], Loss: 938877.5000, Time: 0.5400 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [105/134], Loss: 893150.1250, Time: 0.5410 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [110/134], Loss: 849722.5000, Time: 0.5420 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [115/134], Loss: 807478.2500, Time: 0.5429 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [120/134], Loss: 765913.8750, Time: 0.5439 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [125/134], Loss: 727504.6250, Time: 0.5448 secs, learning rate: 0.0010\n",
      "Epoch [1/60], Step [130/134], Loss: 689712.3125, Time: 0.5458 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [5/134], Loss: 626428.1875, Time: 0.5814 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [10/134], Loss: 593339.1250, Time: 0.5828 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [15/134], Loss: 562098.3750, Time: 0.5838 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [20/134], Loss: 531800.5000, Time: 0.5848 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [25/134], Loss: 502439.3750, Time: 0.5857 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [30/134], Loss: 475949.7500, Time: 0.5867 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [35/134], Loss: 448762.8750, Time: 0.5876 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [40/134], Loss: 423200.1875, Time: 0.5886 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [45/134], Loss: 399186.5000, Time: 0.5895 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [50/134], Loss: 376306.5312, Time: 0.5904 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [55/134], Loss: 354520.8750, Time: 0.5914 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [60/134], Loss: 333789.2812, Time: 0.5923 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [65/134], Loss: 314384.7500, Time: 0.5933 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [70/134], Loss: 295337.1250, Time: 0.5943 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [75/134], Loss: 277833.0938, Time: 0.5952 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [80/134], Loss: 261214.3125, Time: 0.5961 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [85/134], Loss: 245175.2812, Time: 0.5971 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [90/134], Loss: 229709.7500, Time: 0.5980 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [95/134], Loss: 215319.9219, Time: 0.5990 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [100/134], Loss: 201945.8750, Time: 0.5999 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [105/134], Loss: 188581.9219, Time: 0.6009 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [110/134], Loss: 176645.8281, Time: 0.6018 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [115/134], Loss: 165148.7500, Time: 0.6028 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [120/134], Loss: 154297.8906, Time: 0.6037 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [125/134], Loss: 144062.8438, Time: 0.6047 secs, learning rate: 0.0010\n",
      "Epoch [2/60], Step [130/134], Loss: 134217.0938, Time: 0.6056 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [5/134], Loss: 118264.0156, Time: 0.6414 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [10/134], Loss: 110130.0547, Time: 0.6435 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [15/134], Loss: 102658.3438, Time: 0.6446 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [20/134], Loss: 95305.6875, Time: 0.6456 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [25/134], Loss: 88729.9531, Time: 0.6465 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [30/134], Loss: 82561.2812, Time: 0.6474 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [35/134], Loss: 76627.0000, Time: 0.6484 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [40/134], Loss: 70926.6875, Time: 0.6493 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [45/134], Loss: 65732.8750, Time: 0.6503 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [50/134], Loss: 60877.0234, Time: 0.6512 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [55/134], Loss: 56341.3867, Time: 0.6521 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [60/134], Loss: 51985.2891, Time: 0.6531 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [65/134], Loss: 48040.8125, Time: 0.6540 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [70/134], Loss: 44477.1602, Time: 0.6550 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [75/134], Loss: 41047.8828, Time: 0.6559 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [80/134], Loss: 37856.7227, Time: 0.6568 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [85/134], Loss: 34988.3516, Time: 0.6578 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [90/134], Loss: 32130.8203, Time: 0.6587 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [95/134], Loss: 29478.2891, Time: 0.6596 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [100/134], Loss: 27106.0527, Time: 0.6606 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [105/134], Loss: 25074.9141, Time: 0.6615 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [110/134], Loss: 22950.7832, Time: 0.6624 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [115/134], Loss: 20985.4062, Time: 0.6634 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [120/134], Loss: 19242.0664, Time: 0.6643 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [125/134], Loss: 17701.3359, Time: 0.6653 secs, learning rate: 0.0010\n",
      "Epoch [3/60], Step [130/134], Loss: 16142.9385, Time: 0.6662 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [5/134], Loss: 13748.5859, Time: 0.7020 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [10/134], Loss: 12621.6514, Time: 0.7040 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [15/134], Loss: 11469.8701, Time: 0.7051 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [20/134], Loss: 10464.6816, Time: 0.7060 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [25/134], Loss: 9592.2842, Time: 0.7070 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [30/134], Loss: 8691.7881, Time: 0.7080 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [35/134], Loss: 7959.7739, Time: 0.7089 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [40/134], Loss: 7198.0723, Time: 0.7099 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [45/134], Loss: 6543.3452, Time: 0.7108 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [50/134], Loss: 5943.6982, Time: 0.7118 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [55/134], Loss: 5394.6489, Time: 0.7127 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [60/134], Loss: 4929.5591, Time: 0.7136 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [65/134], Loss: 4469.0781, Time: 0.7146 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [70/134], Loss: 4048.3755, Time: 0.7155 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [75/134], Loss: 3632.8486, Time: 0.7164 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [80/134], Loss: 3285.2114, Time: 0.7174 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [85/134], Loss: 2997.6265, Time: 0.7183 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [90/134], Loss: 2708.1968, Time: 0.7192 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [95/134], Loss: 2444.8794, Time: 0.7202 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [100/134], Loss: 2255.0015, Time: 0.7211 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [105/134], Loss: 1964.5441, Time: 0.7223 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [110/134], Loss: 1768.2343, Time: 0.7234 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [115/134], Loss: 1590.5140, Time: 0.7244 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [120/134], Loss: 1469.8130, Time: 0.7253 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [125/134], Loss: 1284.2622, Time: 0.7263 secs, learning rate: 0.0010\n",
      "Epoch [4/60], Step [130/134], Loss: 1152.7140, Time: 0.7272 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [5/134], Loss: 947.2535, Time: 0.7631 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [10/134], Loss: 848.4955, Time: 0.7651 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [15/134], Loss: 773.9847, Time: 0.7662 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [20/134], Loss: 678.9391, Time: 0.7671 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [25/134], Loss: 619.7703, Time: 0.7681 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [30/134], Loss: 554.0690, Time: 0.7690 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [35/134], Loss: 483.0978, Time: 0.7699 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [40/134], Loss: 441.6616, Time: 0.7709 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [45/134], Loss: 383.3823, Time: 0.7718 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [50/134], Loss: 350.9918, Time: 0.7728 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [55/134], Loss: 303.1111, Time: 0.7737 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [60/134], Loss: 277.9731, Time: 0.7747 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [65/134], Loss: 238.8196, Time: 0.7756 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [70/134], Loss: 219.6456, Time: 0.7766 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [75/134], Loss: 195.1043, Time: 0.7775 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [80/134], Loss: 166.2303, Time: 0.7785 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [85/134], Loss: 147.0716, Time: 0.7794 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [90/134], Loss: 136.2298, Time: 0.7803 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [95/134], Loss: 126.5049, Time: 0.7813 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [100/134], Loss: 101.2079, Time: 0.7822 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [105/134], Loss: 89.1477, Time: 0.7832 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [110/134], Loss: 88.2500, Time: 0.7841 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [115/134], Loss: 73.5942, Time: 0.7850 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [120/134], Loss: 60.5876, Time: 0.7860 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [125/134], Loss: 61.2918, Time: 0.7869 secs, learning rate: 0.0010\n",
      "Epoch [5/60], Step [130/134], Loss: 50.3972, Time: 0.7878 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [5/134], Loss: 40.0785, Time: 0.8232 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [10/134], Loss: 38.4561, Time: 0.8244 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [15/134], Loss: 30.9520, Time: 0.8254 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [20/134], Loss: 27.1983, Time: 0.8264 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [25/134], Loss: 26.5740, Time: 0.8273 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [30/134], Loss: 20.9822, Time: 0.8283 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [35/134], Loss: 18.3825, Time: 0.8292 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [40/134], Loss: 18.3214, Time: 0.8302 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [45/134], Loss: 14.1237, Time: 0.8311 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [50/134], Loss: 14.3447, Time: 0.8320 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [55/134], Loss: 9.0348, Time: 0.8330 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [60/134], Loss: 7.8161, Time: 0.8339 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [65/134], Loss: 10.0077, Time: 0.8348 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [70/134], Loss: 8.8630, Time: 0.8358 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [75/134], Loss: 4.9754, Time: 0.8367 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [80/134], Loss: 4.2533, Time: 0.8376 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [85/134], Loss: 4.8915, Time: 0.8386 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [90/134], Loss: 3.0915, Time: 0.8395 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [95/134], Loss: 3.7524, Time: 0.8405 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [100/134], Loss: 2.2426, Time: 0.8415 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [105/134], Loss: 1.9102, Time: 0.8424 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [110/134], Loss: 2.5627, Time: 0.8433 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [115/134], Loss: 2.2643, Time: 0.8443 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [120/134], Loss: 1.1666, Time: 0.8452 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [125/134], Loss: 0.9774, Time: 0.8462 secs, learning rate: 0.0010\n",
      "Epoch [6/60], Step [130/134], Loss: 2.3004, Time: 0.8471 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [5/134], Loss: 1.8979, Time: 0.8829 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [10/134], Loss: 0.4594, Time: 0.8849 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [15/134], Loss: 0.9604, Time: 0.8859 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [20/134], Loss: 0.3020, Time: 0.8868 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [25/134], Loss: 1.3014, Time: 0.8878 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [30/134], Loss: 0.6987, Time: 0.8887 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [35/134], Loss: 0.1573, Time: 0.8896 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [40/134], Loss: 1.0294, Time: 0.8906 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [45/134], Loss: 0.5242, Time: 0.8916 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [50/134], Loss: 0.0717, Time: 0.8925 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [55/134], Loss: 0.4486, Time: 0.8934 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [60/134], Loss: 0.4182, Time: 0.8944 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [65/134], Loss: 0.7529, Time: 0.8953 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [70/134], Loss: 0.0211, Time: 0.8963 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [75/134], Loss: 0.0148, Time: 0.8972 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [80/134], Loss: 0.3328, Time: 0.8981 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [85/134], Loss: 0.3171, Time: 0.8991 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [90/134], Loss: 0.3023, Time: 0.9000 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [95/134], Loss: 0.0011, Time: 0.9009 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [100/134], Loss: 0.0001, Time: 0.9019 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [105/134], Loss: 0.2652, Time: 0.9028 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [110/134], Loss: 0.0009, Time: 0.9038 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [115/134], Loss: 0.0019, Time: 0.9047 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [120/134], Loss: 0.2451, Time: 0.9056 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [125/134], Loss: 0.4764, Time: 0.9066 secs, learning rate: 0.0010\n",
      "Epoch [7/60], Step [130/134], Loss: 0.2355, Time: 0.9075 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [5/134], Loss: 0.4472, Time: 0.9434 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [10/134], Loss: 0.2253, Time: 0.9454 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [15/134], Loss: 0.4300, Time: 0.9465 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [20/134], Loss: 0.0179, Time: 0.9475 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [25/134], Loss: 0.0201, Time: 0.9484 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [30/134], Loss: 0.0210, Time: 0.9494 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [35/134], Loss: 0.6020, Time: 0.9503 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [40/134], Loss: 0.0235, Time: 0.9512 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [45/134], Loss: 0.0246, Time: 0.9522 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [50/134], Loss: 0.0252, Time: 0.9531 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [55/134], Loss: 0.2133, Time: 0.9540 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [60/134], Loss: 0.4005, Time: 0.9550 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [65/134], Loss: 0.2122, Time: 0.9559 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [70/134], Loss: 0.3948, Time: 0.9568 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [75/134], Loss: 0.3905, Time: 0.9578 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [80/134], Loss: 0.2089, Time: 0.9587 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [85/134], Loss: 0.3795, Time: 0.9596 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [90/134], Loss: 0.2069, Time: 0.9607 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [95/134], Loss: 0.0401, Time: 0.9616 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [100/134], Loss: 0.2064, Time: 0.9626 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [105/134], Loss: 0.2066, Time: 0.9635 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [110/134], Loss: 0.0401, Time: 0.9644 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [115/134], Loss: 0.2064, Time: 0.9654 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [120/134], Loss: 0.0395, Time: 0.9663 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [125/134], Loss: 0.2067, Time: 0.9672 secs, learning rate: 0.0010\n",
      "Epoch [8/60], Step [130/134], Loss: 0.3728, Time: 0.9682 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [5/134], Loss: 0.3709, Time: 1.0036 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [10/134], Loss: 0.2056, Time: 1.0047 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [15/134], Loss: 0.0450, Time: 1.0057 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [20/134], Loss: 0.0468, Time: 1.0066 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [25/134], Loss: 0.3623, Time: 1.0075 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [30/134], Loss: 0.0476, Time: 1.0085 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [35/134], Loss: 0.2050, Time: 1.0095 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [40/134], Loss: 0.0432, Time: 1.0104 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [45/134], Loss: 0.2060, Time: 1.0113 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [50/134], Loss: 0.2060, Time: 1.0123 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [55/134], Loss: 0.3695, Time: 1.0132 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [60/134], Loss: 0.0428, Time: 1.0141 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [65/134], Loss: 0.3706, Time: 1.0151 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [70/134], Loss: 0.2061, Time: 1.0160 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [75/134], Loss: 0.2055, Time: 1.0169 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [80/134], Loss: 0.0463, Time: 1.0179 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [85/134], Loss: 0.0477, Time: 1.0188 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [90/134], Loss: 0.2046, Time: 1.0197 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [95/134], Loss: 0.2047, Time: 1.0207 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [100/134], Loss: 0.0450, Time: 1.0216 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [105/134], Loss: 0.2059, Time: 1.0225 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [110/134], Loss: 0.3717, Time: 1.0235 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [115/134], Loss: 0.3713, Time: 1.0244 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [120/134], Loss: 0.3679, Time: 1.0253 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [125/134], Loss: 0.2050, Time: 1.0262 secs, learning rate: 0.0010\n",
      "Epoch [9/60], Step [130/134], Loss: 0.0453, Time: 1.0272 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [5/134], Loss: 0.2059, Time: 1.0629 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [10/134], Loss: 0.0393, Time: 1.0641 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [15/134], Loss: 0.2075, Time: 1.0651 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [20/134], Loss: 0.2085, Time: 1.0661 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [25/134], Loss: 0.2086, Time: 1.0670 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [30/134], Loss: 0.3832, Time: 1.0679 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [35/134], Loss: 0.2076, Time: 1.0689 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [40/134], Loss: 0.0387, Time: 1.0698 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [45/134], Loss: 0.3739, Time: 1.0708 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [50/134], Loss: 0.0394, Time: 1.0717 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [55/134], Loss: 0.0393, Time: 1.0727 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [60/134], Loss: 0.2066, Time: 1.0736 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [65/134], Loss: 0.3762, Time: 1.0746 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [70/134], Loss: 0.3772, Time: 1.0755 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [75/134], Loss: 0.2068, Time: 1.0764 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [80/134], Loss: 0.2061, Time: 1.0773 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [85/134], Loss: 0.2052, Time: 1.0783 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [90/134], Loss: 0.3635, Time: 1.0792 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [95/134], Loss: 0.0487, Time: 1.0801 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [100/134], Loss: 0.2042, Time: 1.0811 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [105/134], Loss: 0.2039, Time: 1.0820 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [110/134], Loss: 0.3550, Time: 1.0829 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [115/134], Loss: 0.2035, Time: 1.0839 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [120/134], Loss: 0.0537, Time: 1.0849 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [125/134], Loss: 0.2037, Time: 1.0858 secs, learning rate: 0.0010\n",
      "Epoch [10/60], Step [130/134], Loss: 0.0502, Time: 1.0868 secs, learning rate: 0.0010\n",
      "Epoch [11/60], Step [5/134], Loss: 0.2044, Time: 1.1223 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [10/134], Loss: 0.0478, Time: 1.1235 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [15/134], Loss: 0.0478, Time: 1.1244 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [20/134], Loss: 0.2044, Time: 1.1253 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [25/134], Loss: 0.0478, Time: 1.1262 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [30/134], Loss: 0.3611, Time: 1.1272 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [35/134], Loss: 0.2044, Time: 1.1281 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [40/134], Loss: 0.3607, Time: 1.1290 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [45/134], Loss: 0.3608, Time: 1.1300 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [50/134], Loss: 0.2044, Time: 1.1309 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [55/134], Loss: 0.0481, Time: 1.1318 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [60/134], Loss: 0.3606, Time: 1.1328 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [65/134], Loss: 0.2043, Time: 1.1337 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [70/134], Loss: 0.2043, Time: 1.1346 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [75/134], Loss: 0.2044, Time: 1.1355 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [80/134], Loss: 0.0479, Time: 1.1365 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [85/134], Loss: 0.2044, Time: 1.1374 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [90/134], Loss: 0.0476, Time: 1.1383 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [95/134], Loss: 0.0477, Time: 1.1392 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [100/134], Loss: 0.2044, Time: 1.1402 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [105/134], Loss: 0.0478, Time: 1.1411 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [110/134], Loss: 0.0475, Time: 1.1420 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [115/134], Loss: 0.2045, Time: 1.1429 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [120/134], Loss: 0.0474, Time: 1.1441 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [125/134], Loss: 0.2045, Time: 1.1452 secs, learning rate: 0.0001\n",
      "Epoch [11/60], Step [130/134], Loss: 0.0472, Time: 1.1463 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [5/134], Loss: 0.2046, Time: 1.1812 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [10/134], Loss: 0.3619, Time: 1.1833 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [15/134], Loss: 0.2044, Time: 1.1845 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [20/134], Loss: 0.0476, Time: 1.1855 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [25/134], Loss: 0.2044, Time: 1.1864 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [30/134], Loss: 0.2043, Time: 1.1874 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [35/134], Loss: 0.2043, Time: 1.1883 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [40/134], Loss: 0.0485, Time: 1.1893 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [45/134], Loss: 0.2043, Time: 1.1902 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [50/134], Loss: 0.0481, Time: 1.1911 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [55/134], Loss: 0.2043, Time: 1.1920 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [60/134], Loss: 0.0477, Time: 1.1930 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [65/134], Loss: 0.2044, Time: 1.1939 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [70/134], Loss: 0.3616, Time: 1.1952 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [75/134], Loss: 0.0473, Time: 1.1966 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [80/134], Loss: 0.0469, Time: 1.1976 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [85/134], Loss: 0.0466, Time: 1.1985 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [90/134], Loss: 0.0462, Time: 1.1995 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [95/134], Loss: 0.0461, Time: 1.2004 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [100/134], Loss: 0.2048, Time: 1.2014 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [105/134], Loss: 0.2048, Time: 1.2023 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [110/134], Loss: 0.3644, Time: 1.2032 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [115/134], Loss: 0.2048, Time: 1.2042 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [120/134], Loss: 0.0458, Time: 1.2052 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [125/134], Loss: 0.3640, Time: 1.2061 secs, learning rate: 0.0001\n",
      "Epoch [12/60], Step [130/134], Loss: 0.2048, Time: 1.2071 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [5/134], Loss: 0.3640, Time: 1.2430 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [10/134], Loss: 0.2048, Time: 1.2441 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [15/134], Loss: 0.0457, Time: 1.2451 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [20/134], Loss: 0.2048, Time: 1.2460 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [25/134], Loss: 0.0456, Time: 1.2470 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [30/134], Loss: 0.2048, Time: 1.2479 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [35/134], Loss: 0.3645, Time: 1.2489 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [40/134], Loss: 0.0452, Time: 1.2498 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [45/134], Loss: 0.0450, Time: 1.2508 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [50/134], Loss: 0.2050, Time: 1.2517 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [55/134], Loss: 0.3654, Time: 1.2527 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [60/134], Loss: 0.2050, Time: 1.2536 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [65/134], Loss: 0.0450, Time: 1.2545 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [70/134], Loss: 0.3648, Time: 1.2555 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [75/134], Loss: 0.3646, Time: 1.2564 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [80/134], Loss: 0.2049, Time: 1.2574 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [85/134], Loss: 0.3648, Time: 1.2583 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [90/134], Loss: 0.2050, Time: 1.2592 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [95/134], Loss: 0.0449, Time: 1.2602 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [100/134], Loss: 0.2050, Time: 1.2611 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [105/134], Loss: 0.2049, Time: 1.2620 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [110/134], Loss: 0.0457, Time: 1.2630 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [115/134], Loss: 0.0460, Time: 1.2639 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [120/134], Loss: 0.2047, Time: 1.2649 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [125/134], Loss: 0.0461, Time: 1.2658 secs, learning rate: 0.0001\n",
      "Epoch [13/60], Step [130/134], Loss: 0.0461, Time: 1.2668 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [5/134], Loss: 0.0456, Time: 1.3027 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [10/134], Loss: 0.0454, Time: 1.3045 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [15/134], Loss: 0.2048, Time: 1.3056 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [20/134], Loss: 0.0452, Time: 1.3065 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [25/134], Loss: 0.2049, Time: 1.3075 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [30/134], Loss: 0.2049, Time: 1.3084 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [35/134], Loss: 0.2049, Time: 1.3094 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [40/134], Loss: 0.3650, Time: 1.3103 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [45/134], Loss: 0.2050, Time: 1.3112 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [50/134], Loss: 0.0450, Time: 1.3122 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [55/134], Loss: 0.2049, Time: 1.3131 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [60/134], Loss: 0.0452, Time: 1.3140 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [65/134], Loss: 0.2050, Time: 1.3150 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [70/134], Loss: 0.2050, Time: 1.3159 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [75/134], Loss: 0.0443, Time: 1.3169 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [80/134], Loss: 0.5266, Time: 1.3178 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [85/134], Loss: 0.0446, Time: 1.3188 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [90/134], Loss: 0.0447, Time: 1.3197 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [95/134], Loss: 0.2050, Time: 1.3207 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [100/134], Loss: 0.2051, Time: 1.3216 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [105/134], Loss: 0.3659, Time: 1.3226 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [110/134], Loss: 0.2051, Time: 1.3236 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [115/134], Loss: 0.2051, Time: 1.3245 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [120/134], Loss: 0.2050, Time: 1.3255 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [125/134], Loss: 0.3650, Time: 1.3264 secs, learning rate: 0.0001\n",
      "Epoch [14/60], Step [130/134], Loss: 0.0451, Time: 1.3274 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [5/134], Loss: 0.0451, Time: 1.3634 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [10/134], Loss: 0.2049, Time: 1.3649 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [15/134], Loss: 0.2050, Time: 1.3658 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [20/134], Loss: 0.0449, Time: 1.3668 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [25/134], Loss: 0.2049, Time: 1.3677 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [30/134], Loss: 0.0445, Time: 1.3687 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [35/134], Loss: 0.2051, Time: 1.3696 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [40/134], Loss: 0.2052, Time: 1.3705 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [45/134], Loss: 0.3663, Time: 1.3715 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [50/134], Loss: 0.2052, Time: 1.3724 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [55/134], Loss: 0.0438, Time: 1.3734 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [60/134], Loss: 0.0434, Time: 1.3743 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [65/134], Loss: 0.3676, Time: 1.3753 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [70/134], Loss: 0.5298, Time: 1.3762 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [75/134], Loss: 0.0435, Time: 1.3771 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [80/134], Loss: 0.2052, Time: 1.3781 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [85/134], Loss: 0.2052, Time: 1.3791 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [90/134], Loss: 0.2051, Time: 1.3800 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [95/134], Loss: 0.2051, Time: 1.3809 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [100/134], Loss: 0.0441, Time: 1.3819 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [105/134], Loss: 0.0439, Time: 1.3828 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [110/134], Loss: 0.3669, Time: 1.3838 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [115/134], Loss: 0.2053, Time: 1.3847 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [120/134], Loss: 0.3671, Time: 1.3856 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [125/134], Loss: 0.2052, Time: 1.3866 secs, learning rate: 0.0001\n",
      "Epoch [15/60], Step [130/134], Loss: 0.2051, Time: 1.3875 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [5/134], Loss: 0.0444, Time: 1.4232 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [10/134], Loss: 0.0445, Time: 1.4243 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [15/134], Loss: 0.2051, Time: 1.4254 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [20/134], Loss: 0.0442, Time: 1.4263 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [25/134], Loss: 0.2051, Time: 1.4273 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [30/134], Loss: 0.2051, Time: 1.4282 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [35/134], Loss: 0.0441, Time: 1.4292 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [40/134], Loss: 0.3664, Time: 1.4301 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [45/134], Loss: 0.2051, Time: 1.4310 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [50/134], Loss: 0.5280, Time: 1.4320 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [55/134], Loss: 0.2051, Time: 1.4329 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [60/134], Loss: 0.2050, Time: 1.4338 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [65/134], Loss: 0.2049, Time: 1.4348 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [70/134], Loss: 0.0453, Time: 1.4357 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [75/134], Loss: 0.2048, Time: 1.4367 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [80/134], Loss: 0.2048, Time: 1.4376 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [85/134], Loss: 0.0454, Time: 1.4385 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [90/134], Loss: 0.2048, Time: 1.4395 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [95/134], Loss: 0.0453, Time: 1.4404 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [100/134], Loss: 0.0451, Time: 1.4413 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [105/134], Loss: 0.2049, Time: 1.4423 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [110/134], Loss: 0.0448, Time: 1.4432 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [115/134], Loss: 0.2050, Time: 1.4441 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [120/134], Loss: 0.0446, Time: 1.4451 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [125/134], Loss: 0.2050, Time: 1.4460 secs, learning rate: 0.0001\n",
      "Epoch [16/60], Step [130/134], Loss: 0.3659, Time: 1.4469 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [5/134], Loss: 0.0442, Time: 1.4826 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [10/134], Loss: 0.0441, Time: 1.4839 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [15/134], Loss: 0.2051, Time: 1.4849 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [20/134], Loss: 0.2051, Time: 1.4858 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [25/134], Loss: 0.2051, Time: 1.4868 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [30/134], Loss: 0.0444, Time: 1.4877 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [35/134], Loss: 0.0448, Time: 1.4887 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [40/134], Loss: 0.2049, Time: 1.4896 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [45/134], Loss: 0.0449, Time: 1.4906 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [50/134], Loss: 0.2049, Time: 1.4915 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [55/134], Loss: 0.0447, Time: 1.4924 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [60/134], Loss: 0.2050, Time: 1.4934 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [65/134], Loss: 0.2050, Time: 1.4943 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [70/134], Loss: 0.2050, Time: 1.4953 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [75/134], Loss: 0.2050, Time: 1.4964 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [80/134], Loss: 0.3658, Time: 1.4978 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [85/134], Loss: 0.2051, Time: 1.4990 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [90/134], Loss: 0.0439, Time: 1.4999 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [95/134], Loss: 0.0435, Time: 1.5009 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [100/134], Loss: 0.0430, Time: 1.5019 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [105/134], Loss: 0.0424, Time: 1.5028 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [110/134], Loss: 0.2056, Time: 1.5037 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [115/134], Loss: 0.0419, Time: 1.5046 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [120/134], Loss: 0.3695, Time: 1.5057 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [125/134], Loss: 0.3690, Time: 1.5066 secs, learning rate: 0.0001\n",
      "Epoch [17/60], Step [130/134], Loss: 0.0428, Time: 1.5075 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [5/134], Loss: 0.0435, Time: 1.5435 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [10/134], Loss: 0.0432, Time: 1.5454 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [15/134], Loss: 0.3676, Time: 1.5465 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [20/134], Loss: 0.0432, Time: 1.5475 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [25/134], Loss: 0.0431, Time: 1.5484 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [30/134], Loss: 0.0429, Time: 1.5494 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [35/134], Loss: 0.3681, Time: 1.5503 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [40/134], Loss: 0.0428, Time: 1.5512 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [45/134], Loss: 0.0425, Time: 1.5521 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [50/134], Loss: 0.2056, Time: 1.5531 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [55/134], Loss: 0.0420, Time: 1.5541 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [60/134], Loss: 0.0419, Time: 1.5550 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [65/134], Loss: 0.0419, Time: 1.5560 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [70/134], Loss: 0.2057, Time: 1.5569 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [75/134], Loss: 0.5343, Time: 1.5578 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [80/134], Loss: 0.0415, Time: 1.5588 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [85/134], Loss: 0.0413, Time: 1.5597 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [90/134], Loss: 0.3704, Time: 1.5606 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [95/134], Loss: 0.0414, Time: 1.5616 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [100/134], Loss: 0.3699, Time: 1.5625 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [105/134], Loss: 0.0418, Time: 1.5634 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [110/134], Loss: 0.2056, Time: 1.5647 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [115/134], Loss: 0.2055, Time: 1.5658 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [120/134], Loss: 0.2054, Time: 1.5668 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [125/134], Loss: 0.2052, Time: 1.5677 secs, learning rate: 0.0001\n",
      "Epoch [18/60], Step [130/134], Loss: 0.3662, Time: 1.5686 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [5/134], Loss: 0.2049, Time: 1.6044 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [10/134], Loss: 0.0447, Time: 1.6057 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [15/134], Loss: 0.2050, Time: 1.6066 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [20/134], Loss: 0.2051, Time: 1.6076 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [25/134], Loss: 0.0437, Time: 1.6085 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [30/134], Loss: 0.0433, Time: 1.6095 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [35/134], Loss: 0.2053, Time: 1.6104 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [40/134], Loss: 0.0429, Time: 1.6113 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [45/134], Loss: 0.0429, Time: 1.6123 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [50/134], Loss: 0.2054, Time: 1.6132 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [55/134], Loss: 0.2054, Time: 1.6141 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [60/134], Loss: 0.3690, Time: 1.6151 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [65/134], Loss: 0.2056, Time: 1.6160 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [70/134], Loss: 0.2056, Time: 1.6169 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [75/134], Loss: 0.0425, Time: 1.6179 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [80/134], Loss: 0.0431, Time: 1.6188 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [85/134], Loss: 0.0435, Time: 1.6197 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [90/134], Loss: 0.2052, Time: 1.6207 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [95/134], Loss: 0.0438, Time: 1.6216 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [100/134], Loss: 0.0438, Time: 1.6225 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [105/134], Loss: 0.3667, Time: 1.6235 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [110/134], Loss: 0.2052, Time: 1.6244 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [115/134], Loss: 0.5286, Time: 1.6253 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [120/134], Loss: 0.0440, Time: 1.6263 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [125/134], Loss: 0.0442, Time: 1.6272 secs, learning rate: 0.0001\n",
      "Epoch [19/60], Step [130/134], Loss: 0.0444, Time: 1.6281 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [5/134], Loss: 0.0448, Time: 1.6638 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [10/134], Loss: 0.0448, Time: 1.6658 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [15/134], Loss: 0.2048, Time: 1.6670 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [20/134], Loss: 0.3646, Time: 1.6680 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [25/134], Loss: 0.3644, Time: 1.6689 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [30/134], Loss: 0.2048, Time: 1.6698 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [35/134], Loss: 0.0450, Time: 1.6708 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [40/134], Loss: 0.2047, Time: 1.6717 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [45/134], Loss: 0.2047, Time: 1.6726 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [50/134], Loss: 0.0454, Time: 1.6736 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [55/134], Loss: 0.0450, Time: 1.6745 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [60/134], Loss: 0.2049, Time: 1.6754 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [65/134], Loss: 0.2050, Time: 1.6764 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [70/134], Loss: 0.0438, Time: 1.6773 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [75/134], Loss: 0.0440, Time: 1.6782 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [80/134], Loss: 0.3662, Time: 1.6792 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [85/134], Loss: 0.2051, Time: 1.6801 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [90/134], Loss: 0.3656, Time: 1.6810 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [95/134], Loss: 0.0448, Time: 1.6819 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [100/134], Loss: 0.0451, Time: 1.6829 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [105/134], Loss: 0.2048, Time: 1.6838 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [110/134], Loss: 0.2047, Time: 1.6847 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [115/134], Loss: 0.2046, Time: 1.6856 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [120/134], Loss: 0.3629, Time: 1.6865 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [125/134], Loss: 0.0461, Time: 1.6876 secs, learning rate: 0.0001\n",
      "Epoch [20/60], Step [130/134], Loss: 0.2046, Time: 1.6885 secs, learning rate: 0.0001\n",
      "Epoch [21/60], Step [5/134], Loss: 0.2047, Time: 1.7240 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [10/134], Loss: 0.5231, Time: 1.7251 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [15/134], Loss: 0.2047, Time: 1.7262 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [20/134], Loss: 0.2047, Time: 1.7271 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [25/134], Loss: 0.3638, Time: 1.7281 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [30/134], Loss: 0.3637, Time: 1.7290 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [35/134], Loss: 0.3636, Time: 1.7299 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [40/134], Loss: 0.0457, Time: 1.7309 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [45/134], Loss: 0.2047, Time: 1.7319 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [50/134], Loss: 0.2047, Time: 1.7328 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [55/134], Loss: 0.3636, Time: 1.7337 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [60/134], Loss: 0.0457, Time: 1.7347 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [65/134], Loss: 0.3637, Time: 1.7356 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [70/134], Loss: 0.0456, Time: 1.7365 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [75/134], Loss: 0.0456, Time: 1.7374 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [80/134], Loss: 0.0456, Time: 1.7384 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [85/134], Loss: 0.3638, Time: 1.7393 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [90/134], Loss: 0.2047, Time: 1.7402 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [95/134], Loss: 0.0455, Time: 1.7412 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [100/134], Loss: 0.2047, Time: 1.7422 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [105/134], Loss: 0.3639, Time: 1.7431 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [110/134], Loss: 0.2047, Time: 1.7440 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [115/134], Loss: 0.0455, Time: 1.7450 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [120/134], Loss: 0.2047, Time: 1.7459 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [125/134], Loss: 0.2047, Time: 1.7468 secs, learning rate: 0.0000\n",
      "Epoch [21/60], Step [130/134], Loss: 0.0455, Time: 1.7478 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [5/134], Loss: 0.5232, Time: 1.7837 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [10/134], Loss: 0.0455, Time: 1.7851 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [15/134], Loss: 0.2047, Time: 1.7861 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [20/134], Loss: 0.0455, Time: 1.7870 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [25/134], Loss: 0.2047, Time: 1.7880 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [30/134], Loss: 0.3638, Time: 1.7889 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [35/134], Loss: 0.0456, Time: 1.7898 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [40/134], Loss: 0.2047, Time: 1.7908 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [45/134], Loss: 0.2047, Time: 1.7917 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [50/134], Loss: 0.2047, Time: 1.7926 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [55/134], Loss: 0.2047, Time: 1.7936 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [60/134], Loss: 0.2047, Time: 1.7945 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [65/134], Loss: 0.0455, Time: 1.7954 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [70/134], Loss: 0.0455, Time: 1.7964 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [75/134], Loss: 0.0454, Time: 1.7974 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [80/134], Loss: 0.0454, Time: 1.7983 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [85/134], Loss: 0.0453, Time: 1.7992 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [90/134], Loss: 0.2047, Time: 1.8002 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [95/134], Loss: 0.2048, Time: 1.8011 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [100/134], Loss: 0.0451, Time: 1.8020 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [105/134], Loss: 0.2048, Time: 1.8030 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [110/134], Loss: 0.2048, Time: 1.8039 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [115/134], Loss: 0.3646, Time: 1.8048 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [120/134], Loss: 0.2048, Time: 1.8058 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [125/134], Loss: 0.2048, Time: 1.8067 secs, learning rate: 0.0000\n",
      "Epoch [22/60], Step [130/134], Loss: 0.0452, Time: 1.8076 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [5/134], Loss: 0.0452, Time: 1.8430 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [10/134], Loss: 0.0452, Time: 1.8442 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [15/134], Loss: 0.0451, Time: 1.8451 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [20/134], Loss: 0.3645, Time: 1.8461 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [25/134], Loss: 0.3645, Time: 1.8470 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [30/134], Loss: 0.3644, Time: 1.8479 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [35/134], Loss: 0.2048, Time: 1.8489 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [40/134], Loss: 0.2048, Time: 1.8498 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [45/134], Loss: 0.3643, Time: 1.8508 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [50/134], Loss: 0.3642, Time: 1.8517 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [55/134], Loss: 0.2047, Time: 1.8526 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [60/134], Loss: 0.2047, Time: 1.8536 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [65/134], Loss: 0.2047, Time: 1.8545 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [70/134], Loss: 0.0456, Time: 1.8555 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [75/134], Loss: 0.2047, Time: 1.8564 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [80/134], Loss: 0.2047, Time: 1.8573 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [85/134], Loss: 0.2047, Time: 1.8583 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [90/134], Loss: 0.0456, Time: 1.8592 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [95/134], Loss: 0.3638, Time: 1.8601 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [100/134], Loss: 0.0456, Time: 1.8611 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [105/134], Loss: 0.2047, Time: 1.8620 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [110/134], Loss: 0.0455, Time: 1.8629 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [115/134], Loss: 0.3639, Time: 1.8639 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [120/134], Loss: 0.0455, Time: 1.8648 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [125/134], Loss: 0.0454, Time: 1.8657 secs, learning rate: 0.0000\n",
      "Epoch [23/60], Step [130/134], Loss: 0.2047, Time: 1.8667 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [5/134], Loss: 0.2047, Time: 1.9023 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [10/134], Loss: 0.0453, Time: 1.9043 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [15/134], Loss: 0.3641, Time: 1.9055 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [20/134], Loss: 0.2047, Time: 1.9064 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [25/134], Loss: 0.2047, Time: 1.9073 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [30/134], Loss: 0.0452, Time: 1.9083 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [35/134], Loss: 0.0451, Time: 1.9092 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [40/134], Loss: 0.3646, Time: 1.9101 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [45/134], Loss: 0.2048, Time: 1.9111 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [50/134], Loss: 0.0450, Time: 1.9120 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [55/134], Loss: 0.0450, Time: 1.9129 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [60/134], Loss: 0.2048, Time: 1.9139 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [65/134], Loss: 0.0449, Time: 1.9148 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [70/134], Loss: 0.2048, Time: 1.9158 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [75/134], Loss: 0.3647, Time: 1.9167 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [80/134], Loss: 0.2048, Time: 1.9177 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [85/134], Loss: 0.0449, Time: 1.9186 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [90/134], Loss: 0.2048, Time: 1.9196 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [95/134], Loss: 0.2048, Time: 1.9205 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [100/134], Loss: 0.0450, Time: 1.9217 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [105/134], Loss: 0.2048, Time: 1.9233 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [110/134], Loss: 0.0449, Time: 1.9243 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [115/134], Loss: 0.2048, Time: 1.9253 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [120/134], Loss: 0.3648, Time: 1.9263 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [125/134], Loss: 0.2048, Time: 1.9272 secs, learning rate: 0.0000\n",
      "Epoch [24/60], Step [130/134], Loss: 0.3648, Time: 1.9281 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [5/134], Loss: 0.0450, Time: 1.9638 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [10/134], Loss: 0.2048, Time: 1.9649 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [15/134], Loss: 0.0451, Time: 1.9659 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [20/134], Loss: 0.2048, Time: 1.9668 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [25/134], Loss: 0.2048, Time: 1.9678 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [30/134], Loss: 0.3647, Time: 1.9687 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [35/134], Loss: 0.2048, Time: 1.9696 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [40/134], Loss: 0.2048, Time: 1.9706 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [45/134], Loss: 0.3649, Time: 1.9715 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [50/134], Loss: 0.2048, Time: 1.9725 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [55/134], Loss: 0.0447, Time: 1.9734 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [60/134], Loss: 0.3651, Time: 1.9744 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [65/134], Loss: 0.2049, Time: 1.9753 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [70/134], Loss: 0.2049, Time: 1.9763 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [75/134], Loss: 0.0446, Time: 1.9772 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [80/134], Loss: 0.0446, Time: 1.9781 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [85/134], Loss: 0.2049, Time: 1.9791 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [90/134], Loss: 0.0446, Time: 1.9800 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [95/134], Loss: 0.2049, Time: 1.9809 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [100/134], Loss: 0.0447, Time: 1.9819 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [105/134], Loss: 0.0447, Time: 1.9828 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [110/134], Loss: 0.3650, Time: 1.9837 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [115/134], Loss: 0.5252, Time: 1.9849 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [120/134], Loss: 0.3649, Time: 1.9860 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [125/134], Loss: 0.2048, Time: 1.9869 secs, learning rate: 0.0000\n",
      "Epoch [25/60], Step [130/134], Loss: 0.2048, Time: 1.9879 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [5/134], Loss: 0.0451, Time: 2.0231 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [10/134], Loss: 0.2048, Time: 2.0241 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [15/134], Loss: 0.0450, Time: 2.0250 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [20/134], Loss: 0.3646, Time: 2.0260 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [25/134], Loss: 0.2048, Time: 2.0269 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [30/134], Loss: 0.0450, Time: 2.0279 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [35/134], Loss: 0.0450, Time: 2.0289 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [40/134], Loss: 0.0450, Time: 2.0298 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [45/134], Loss: 0.3646, Time: 2.0308 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [50/134], Loss: 0.2048, Time: 2.0317 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [55/134], Loss: 0.2048, Time: 2.0326 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [60/134], Loss: 0.0451, Time: 2.0336 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [65/134], Loss: 0.3643, Time: 2.0345 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [70/134], Loss: 0.0453, Time: 2.0355 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [75/134], Loss: 0.0454, Time: 2.0364 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [80/134], Loss: 0.2047, Time: 2.0373 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [85/134], Loss: 0.2047, Time: 2.0383 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [90/134], Loss: 0.0453, Time: 2.0392 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [95/134], Loss: 0.0453, Time: 2.0401 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [100/134], Loss: 0.2048, Time: 2.0411 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [105/134], Loss: 0.2048, Time: 2.0420 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [110/134], Loss: 0.3644, Time: 2.0429 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [115/134], Loss: 0.0452, Time: 2.0439 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [120/134], Loss: 0.0451, Time: 2.0448 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [125/134], Loss: 0.2048, Time: 2.0457 secs, learning rate: 0.0000\n",
      "Epoch [26/60], Step [130/134], Loss: 0.0451, Time: 2.0467 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [5/134], Loss: 0.3644, Time: 2.0825 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [10/134], Loss: 0.0451, Time: 2.0845 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [15/134], Loss: 0.0451, Time: 2.0856 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [20/134], Loss: 0.3646, Time: 2.0866 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [25/134], Loss: 0.0449, Time: 2.0875 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [30/134], Loss: 0.2048, Time: 2.0885 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [35/134], Loss: 0.2048, Time: 2.0894 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [40/134], Loss: 0.5248, Time: 2.0903 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [45/134], Loss: 0.0449, Time: 2.0913 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [50/134], Loss: 0.2048, Time: 2.0922 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [55/134], Loss: 0.2047, Time: 2.0931 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [60/134], Loss: 0.0453, Time: 2.0941 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [65/134], Loss: 0.0453, Time: 2.0950 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [70/134], Loss: 0.0452, Time: 2.0959 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [75/134], Loss: 0.2047, Time: 2.0968 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [80/134], Loss: 0.0451, Time: 2.0978 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [85/134], Loss: 0.0451, Time: 2.0987 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [90/134], Loss: 0.0451, Time: 2.0996 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [95/134], Loss: 0.2048, Time: 2.1005 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [100/134], Loss: 0.0451, Time: 2.1015 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [105/134], Loss: 0.3646, Time: 2.1024 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [110/134], Loss: 0.0450, Time: 2.1033 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [115/134], Loss: 0.3647, Time: 2.1042 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [120/134], Loss: 0.0450, Time: 2.1052 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [125/134], Loss: 0.2048, Time: 2.1061 secs, learning rate: 0.0000\n",
      "Epoch [27/60], Step [130/134], Loss: 0.0450, Time: 2.1071 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [5/134], Loss: 0.2048, Time: 2.1421 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [10/134], Loss: 0.2048, Time: 2.1430 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [15/134], Loss: 0.2048, Time: 2.1440 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [20/134], Loss: 0.2048, Time: 2.1451 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [25/134], Loss: 0.0448, Time: 2.1462 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [30/134], Loss: 0.2049, Time: 2.1471 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [35/134], Loss: 0.5255, Time: 2.1481 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [40/134], Loss: 0.0445, Time: 2.1490 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [45/134], Loss: 0.2049, Time: 2.1499 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [50/134], Loss: 0.2049, Time: 2.1509 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [55/134], Loss: 0.2049, Time: 2.1519 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [60/134], Loss: 0.3655, Time: 2.1528 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [65/134], Loss: 0.0444, Time: 2.1538 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [70/134], Loss: 0.2049, Time: 2.1547 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [75/134], Loss: 0.0444, Time: 2.1556 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [80/134], Loss: 0.2049, Time: 2.1566 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [85/134], Loss: 0.3657, Time: 2.1575 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [90/134], Loss: 0.2050, Time: 2.1584 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [95/134], Loss: 0.2050, Time: 2.1594 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [100/134], Loss: 0.0443, Time: 2.1604 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [105/134], Loss: 0.0443, Time: 2.1613 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [110/134], Loss: 0.2049, Time: 2.1622 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [115/134], Loss: 0.0444, Time: 2.1632 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [120/134], Loss: 0.3653, Time: 2.1641 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [125/134], Loss: 0.0447, Time: 2.1650 secs, learning rate: 0.0000\n",
      "Epoch [28/60], Step [130/134], Loss: 0.0448, Time: 2.1660 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [5/134], Loss: 0.3647, Time: 2.2012 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [10/134], Loss: 0.3645, Time: 2.2024 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [15/134], Loss: 0.0453, Time: 2.2035 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [20/134], Loss: 0.0453, Time: 2.2044 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [25/134], Loss: 0.0453, Time: 2.2053 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [30/134], Loss: 0.0451, Time: 2.2063 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [35/134], Loss: 0.2048, Time: 2.2072 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [40/134], Loss: 0.2048, Time: 2.2081 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [45/134], Loss: 0.2048, Time: 2.2092 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [50/134], Loss: 0.2048, Time: 2.2101 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [55/134], Loss: 0.2048, Time: 2.2110 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [60/134], Loss: 0.0449, Time: 2.2120 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [65/134], Loss: 0.2048, Time: 2.2129 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [70/134], Loss: 0.0446, Time: 2.2138 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [75/134], Loss: 0.2049, Time: 2.2147 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [80/134], Loss: 0.0445, Time: 2.2157 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [85/134], Loss: 0.0444, Time: 2.2166 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [90/134], Loss: 0.0443, Time: 2.2175 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [95/134], Loss: 0.2049, Time: 2.2184 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [100/134], Loss: 0.0444, Time: 2.2194 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [105/134], Loss: 0.2049, Time: 2.2203 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [110/134], Loss: 0.2049, Time: 2.2212 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [115/134], Loss: 0.2049, Time: 2.2221 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [120/134], Loss: 0.0444, Time: 2.2231 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [125/134], Loss: 0.3654, Time: 2.2240 secs, learning rate: 0.0000\n",
      "Epoch [29/60], Step [130/134], Loss: 0.2049, Time: 2.2249 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [5/134], Loss: 0.2048, Time: 2.2604 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [10/134], Loss: 0.2048, Time: 2.2617 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [15/134], Loss: 0.2048, Time: 2.2627 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [20/134], Loss: 0.2048, Time: 2.2636 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [25/134], Loss: 0.0450, Time: 2.2645 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [30/134], Loss: 0.3645, Time: 2.2655 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [35/134], Loss: 0.3642, Time: 2.2664 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [40/134], Loss: 0.0453, Time: 2.2674 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [45/134], Loss: 0.0453, Time: 2.2683 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [50/134], Loss: 0.0452, Time: 2.2692 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [55/134], Loss: 0.0452, Time: 2.2701 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [60/134], Loss: 0.2047, Time: 2.2711 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [65/134], Loss: 0.3643, Time: 2.2720 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [70/134], Loss: 0.0452, Time: 2.2729 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [75/134], Loss: 0.3641, Time: 2.2739 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [80/134], Loss: 0.2047, Time: 2.2748 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [85/134], Loss: 0.0454, Time: 2.2758 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [90/134], Loss: 0.0454, Time: 2.2767 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [95/134], Loss: 0.2047, Time: 2.2776 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [100/134], Loss: 0.2047, Time: 2.2785 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [105/134], Loss: 0.0452, Time: 2.2795 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [110/134], Loss: 0.2048, Time: 2.2804 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [115/134], Loss: 0.0450, Time: 2.2813 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [120/134], Loss: 0.0450, Time: 2.2823 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [125/134], Loss: 0.2048, Time: 2.2832 secs, learning rate: 0.0000\n",
      "Epoch [30/60], Step [130/134], Loss: 0.0447, Time: 2.2841 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [5/134], Loss: 0.0446, Time: 2.3198 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [10/134], Loss: 0.0446, Time: 2.3209 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [15/134], Loss: 0.0446, Time: 2.3219 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [20/134], Loss: 0.3651, Time: 2.3228 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [25/134], Loss: 0.0446, Time: 2.3238 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [30/134], Loss: 0.0446, Time: 2.3247 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [35/134], Loss: 0.5253, Time: 2.3257 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [40/134], Loss: 0.3651, Time: 2.3266 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [45/134], Loss: 0.2048, Time: 2.3275 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [50/134], Loss: 0.0446, Time: 2.3284 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [55/134], Loss: 0.3651, Time: 2.3294 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [60/134], Loss: 0.2048, Time: 2.3303 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [65/134], Loss: 0.2048, Time: 2.3312 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [70/134], Loss: 0.2048, Time: 2.3322 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [75/134], Loss: 0.2048, Time: 2.3331 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [80/134], Loss: 0.0446, Time: 2.3340 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [85/134], Loss: 0.3651, Time: 2.3350 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [90/134], Loss: 0.2048, Time: 2.3359 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [95/134], Loss: 0.2048, Time: 2.3368 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [100/134], Loss: 0.2048, Time: 2.3378 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [105/134], Loss: 0.0446, Time: 2.3388 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [110/134], Loss: 0.2048, Time: 2.3398 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [115/134], Loss: 0.0446, Time: 2.3407 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [120/134], Loss: 0.0446, Time: 2.3417 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [125/134], Loss: 0.0446, Time: 2.3426 secs, learning rate: 0.0000\n",
      "Epoch [31/60], Step [130/134], Loss: 0.2048, Time: 2.3435 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [5/134], Loss: 0.2048, Time: 2.3790 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [10/134], Loss: 0.3651, Time: 2.3801 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [15/134], Loss: 0.3651, Time: 2.3811 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [20/134], Loss: 0.0446, Time: 2.3820 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [25/134], Loss: 0.0446, Time: 2.3829 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [30/134], Loss: 0.3651, Time: 2.3839 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [35/134], Loss: 0.2048, Time: 2.3848 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [40/134], Loss: 0.2048, Time: 2.3857 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [45/134], Loss: 0.0446, Time: 2.3867 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [50/134], Loss: 0.2048, Time: 2.3876 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [55/134], Loss: 0.2048, Time: 2.3886 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [60/134], Loss: 0.0446, Time: 2.3895 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [65/134], Loss: 0.2048, Time: 2.3904 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [70/134], Loss: 0.2048, Time: 2.3914 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [75/134], Loss: 0.2048, Time: 2.3923 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [80/134], Loss: 0.0446, Time: 2.3932 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [85/134], Loss: 0.0446, Time: 2.3941 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [90/134], Loss: 0.3651, Time: 2.3951 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [95/134], Loss: 0.2048, Time: 2.3960 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [100/134], Loss: 0.2048, Time: 2.3969 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [105/134], Loss: 0.3651, Time: 2.3979 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [110/134], Loss: 0.3651, Time: 2.3988 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [115/134], Loss: 0.2048, Time: 2.3997 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [120/134], Loss: 0.2048, Time: 2.4007 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [125/134], Loss: 0.2048, Time: 2.4019 secs, learning rate: 0.0000\n",
      "Epoch [32/60], Step [130/134], Loss: 0.2048, Time: 2.4029 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [5/134], Loss: 0.2048, Time: 2.4385 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [10/134], Loss: 0.0446, Time: 2.4397 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [15/134], Loss: 0.0446, Time: 2.4407 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [20/134], Loss: 0.0446, Time: 2.4416 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [25/134], Loss: 0.0446, Time: 2.4426 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [30/134], Loss: 0.2048, Time: 2.4435 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [35/134], Loss: 0.2048, Time: 2.4445 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [40/134], Loss: 0.0446, Time: 2.4454 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [45/134], Loss: 0.3651, Time: 2.4463 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [50/134], Loss: 0.0446, Time: 2.4473 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [55/134], Loss: 0.0446, Time: 2.4482 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [60/134], Loss: 0.0446, Time: 2.4491 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [65/134], Loss: 0.2048, Time: 2.4503 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [70/134], Loss: 0.2048, Time: 2.4513 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [75/134], Loss: 0.0446, Time: 2.4523 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [80/134], Loss: 0.2048, Time: 2.4532 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [85/134], Loss: 0.3651, Time: 2.4542 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [90/134], Loss: 0.0446, Time: 2.4551 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [95/134], Loss: 0.3651, Time: 2.4560 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [100/134], Loss: 0.2048, Time: 2.4570 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [105/134], Loss: 0.2048, Time: 2.4579 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [110/134], Loss: 0.0446, Time: 2.4588 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [115/134], Loss: 0.3651, Time: 2.4598 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [120/134], Loss: 0.5253, Time: 2.4607 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [125/134], Loss: 0.0447, Time: 2.4617 secs, learning rate: 0.0000\n",
      "Epoch [33/60], Step [130/134], Loss: 0.0447, Time: 2.4626 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [5/134], Loss: 0.0447, Time: 2.4986 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [10/134], Loss: 0.0447, Time: 2.5005 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [15/134], Loss: 0.0447, Time: 2.5016 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [20/134], Loss: 0.2048, Time: 2.5025 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [25/134], Loss: 0.2048, Time: 2.5034 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [30/134], Loss: 0.0447, Time: 2.5044 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [35/134], Loss: 0.3650, Time: 2.5053 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [40/134], Loss: 0.0447, Time: 2.5062 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [45/134], Loss: 0.3650, Time: 2.5072 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [50/134], Loss: 0.0447, Time: 2.5081 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [55/134], Loss: 0.2048, Time: 2.5090 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [60/134], Loss: 0.3650, Time: 2.5100 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [65/134], Loss: 0.0447, Time: 2.5109 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [70/134], Loss: 0.2048, Time: 2.5118 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [75/134], Loss: 0.2048, Time: 2.5127 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [80/134], Loss: 0.2048, Time: 2.5137 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [85/134], Loss: 0.3650, Time: 2.5146 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [90/134], Loss: 0.0447, Time: 2.5155 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [95/134], Loss: 0.3650, Time: 2.5165 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [100/134], Loss: 0.2048, Time: 2.5178 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [105/134], Loss: 0.0447, Time: 2.5189 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [110/134], Loss: 0.0447, Time: 2.5199 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [115/134], Loss: 0.2048, Time: 2.5208 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [120/134], Loss: 0.2048, Time: 2.5217 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [125/134], Loss: 0.0447, Time: 2.5226 secs, learning rate: 0.0000\n",
      "Epoch [34/60], Step [130/134], Loss: 0.2048, Time: 2.5236 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [5/134], Loss: 0.0447, Time: 2.5592 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [10/134], Loss: 0.0447, Time: 2.5603 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [15/134], Loss: 0.2048, Time: 2.5613 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [20/134], Loss: 0.0447, Time: 2.5622 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [25/134], Loss: 0.2048, Time: 2.5632 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [30/134], Loss: 0.0447, Time: 2.5641 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [35/134], Loss: 0.0447, Time: 2.5650 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [40/134], Loss: 0.2048, Time: 2.5660 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [45/134], Loss: 0.0447, Time: 2.5669 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [50/134], Loss: 0.0447, Time: 2.5678 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [55/134], Loss: 0.2048, Time: 2.5688 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [60/134], Loss: 0.2048, Time: 2.5697 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [65/134], Loss: 0.0447, Time: 2.5706 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [70/134], Loss: 0.3650, Time: 2.5716 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [75/134], Loss: 0.2048, Time: 2.5725 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [80/134], Loss: 0.0447, Time: 2.5734 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [85/134], Loss: 0.2048, Time: 2.5744 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [90/134], Loss: 0.0447, Time: 2.5754 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [95/134], Loss: 0.0447, Time: 2.5763 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [100/134], Loss: 0.0447, Time: 2.5773 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [105/134], Loss: 0.0447, Time: 2.5782 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [110/134], Loss: 0.3650, Time: 2.5792 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [115/134], Loss: 0.2048, Time: 2.5801 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [120/134], Loss: 0.2048, Time: 2.5810 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [125/134], Loss: 0.0447, Time: 2.5823 secs, learning rate: 0.0000\n",
      "Epoch [35/60], Step [130/134], Loss: 0.2048, Time: 2.5842 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [5/134], Loss: 0.2048, Time: 2.6203 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [10/134], Loss: 0.0447, Time: 2.6223 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [15/134], Loss: 0.2048, Time: 2.6232 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [20/134], Loss: 0.2049, Time: 2.6242 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [25/134], Loss: 0.3651, Time: 2.6251 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [30/134], Loss: 0.0446, Time: 2.6261 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [35/134], Loss: 0.0446, Time: 2.6270 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [40/134], Loss: 0.2049, Time: 2.6279 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [45/134], Loss: 0.0446, Time: 2.6289 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [50/134], Loss: 0.2049, Time: 2.6298 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [55/134], Loss: 0.0446, Time: 2.6307 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [60/134], Loss: 0.0446, Time: 2.6317 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [65/134], Loss: 0.2049, Time: 2.6326 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [70/134], Loss: 0.3651, Time: 2.6335 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [75/134], Loss: 0.2049, Time: 2.6344 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [80/134], Loss: 0.3651, Time: 2.6354 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [85/134], Loss: 0.2049, Time: 2.6363 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [90/134], Loss: 0.3651, Time: 2.6372 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [95/134], Loss: 0.2049, Time: 2.6381 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [100/134], Loss: 0.3651, Time: 2.6391 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [105/134], Loss: 0.0446, Time: 2.6400 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [110/134], Loss: 0.2049, Time: 2.6409 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [115/134], Loss: 0.2049, Time: 2.6419 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [120/134], Loss: 0.3651, Time: 2.6428 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [125/134], Loss: 0.0446, Time: 2.6437 secs, learning rate: 0.0000\n",
      "Epoch [36/60], Step [130/134], Loss: 0.2048, Time: 2.6446 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [5/134], Loss: 0.0446, Time: 2.6801 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [10/134], Loss: 0.2048, Time: 2.6813 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [15/134], Loss: 0.0446, Time: 2.6823 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [20/134], Loss: 0.0446, Time: 2.6832 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [25/134], Loss: 0.0446, Time: 2.6842 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [30/134], Loss: 0.0446, Time: 2.6851 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [35/134], Loss: 0.0446, Time: 2.6862 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [40/134], Loss: 0.2048, Time: 2.6872 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [45/134], Loss: 0.3650, Time: 2.6881 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [50/134], Loss: 0.0446, Time: 2.6891 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [55/134], Loss: 0.0446, Time: 2.6900 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [60/134], Loss: 0.2049, Time: 2.6909 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [65/134], Loss: 0.2049, Time: 2.6919 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [70/134], Loss: 0.2049, Time: 2.6928 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [75/134], Loss: 0.0446, Time: 2.6938 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [80/134], Loss: 0.3651, Time: 2.6947 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [85/134], Loss: 0.3651, Time: 2.6956 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [90/134], Loss: 0.2049, Time: 2.6966 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [95/134], Loss: 0.2049, Time: 2.6975 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [100/134], Loss: 0.2049, Time: 2.6984 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [105/134], Loss: 0.0446, Time: 2.6994 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [110/134], Loss: 0.0446, Time: 2.7003 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [115/134], Loss: 0.2049, Time: 2.7012 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [120/134], Loss: 0.0446, Time: 2.7022 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [125/134], Loss: 0.0446, Time: 2.7031 secs, learning rate: 0.0000\n",
      "Epoch [37/60], Step [130/134], Loss: 0.3651, Time: 2.7040 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [5/134], Loss: 0.2049, Time: 2.7397 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [10/134], Loss: 0.3651, Time: 2.7408 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [15/134], Loss: 0.0446, Time: 2.7418 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [20/134], Loss: 0.3651, Time: 2.7427 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [25/134], Loss: 0.2049, Time: 2.7437 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [30/134], Loss: 0.3651, Time: 2.7446 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [35/134], Loss: 0.2049, Time: 2.7455 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [40/134], Loss: 0.3651, Time: 2.7465 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [45/134], Loss: 0.2049, Time: 2.7474 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [50/134], Loss: 0.3651, Time: 2.7483 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [55/134], Loss: 0.0446, Time: 2.7493 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [60/134], Loss: 0.3651, Time: 2.7502 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [65/134], Loss: 0.2049, Time: 2.7511 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [70/134], Loss: 0.2049, Time: 2.7521 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [75/134], Loss: 0.2049, Time: 2.7531 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [80/134], Loss: 0.3651, Time: 2.7540 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [85/134], Loss: 0.0446, Time: 2.7549 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [90/134], Loss: 0.2049, Time: 2.7559 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [95/134], Loss: 0.3651, Time: 2.7568 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [100/134], Loss: 0.2049, Time: 2.7577 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [105/134], Loss: 0.0446, Time: 2.7587 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [110/134], Loss: 0.0446, Time: 2.7596 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [115/134], Loss: 0.0446, Time: 2.7605 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [120/134], Loss: 0.3651, Time: 2.7615 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [125/134], Loss: 0.3651, Time: 2.7625 secs, learning rate: 0.0000\n",
      "Epoch [38/60], Step [130/134], Loss: 0.2049, Time: 2.7634 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [5/134], Loss: 0.0446, Time: 2.7987 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [10/134], Loss: 0.2049, Time: 2.7999 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [15/134], Loss: 0.2049, Time: 2.8009 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [20/134], Loss: 0.3652, Time: 2.8018 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [25/134], Loss: 0.2049, Time: 2.8028 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [30/134], Loss: 0.0445, Time: 2.8037 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [35/134], Loss: 0.2049, Time: 2.8046 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [40/134], Loss: 0.2049, Time: 2.8056 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [45/134], Loss: 0.0445, Time: 2.8065 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [50/134], Loss: 0.0445, Time: 2.8075 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [55/134], Loss: 0.0445, Time: 2.8084 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [60/134], Loss: 0.2049, Time: 2.8094 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [65/134], Loss: 0.0445, Time: 2.8103 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [70/134], Loss: 0.3652, Time: 2.8113 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [75/134], Loss: 0.2049, Time: 2.8122 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [80/134], Loss: 0.0446, Time: 2.8131 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [85/134], Loss: 0.3651, Time: 2.8141 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [90/134], Loss: 0.0446, Time: 2.8150 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [95/134], Loss: 0.2048, Time: 2.8159 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [100/134], Loss: 0.0446, Time: 2.8168 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [105/134], Loss: 0.0446, Time: 2.8178 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [110/134], Loss: 0.2048, Time: 2.8187 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [115/134], Loss: 0.0446, Time: 2.8196 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [120/134], Loss: 0.0446, Time: 2.8208 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [125/134], Loss: 0.0446, Time: 2.8220 secs, learning rate: 0.0000\n",
      "Epoch [39/60], Step [130/134], Loss: 0.0446, Time: 2.8229 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [5/134], Loss: 0.0446, Time: 2.8583 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [10/134], Loss: 0.3650, Time: 2.8594 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [15/134], Loss: 0.2048, Time: 2.8605 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [20/134], Loss: 0.0446, Time: 2.8615 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [25/134], Loss: 0.2049, Time: 2.8624 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [30/134], Loss: 0.0445, Time: 2.8633 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [35/134], Loss: 0.2049, Time: 2.8643 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [40/134], Loss: 0.3652, Time: 2.8652 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [45/134], Loss: 0.2049, Time: 2.8661 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [50/134], Loss: 0.0445, Time: 2.8671 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [55/134], Loss: 0.3652, Time: 2.8680 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [60/134], Loss: 0.0445, Time: 2.8689 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [65/134], Loss: 0.0445, Time: 2.8699 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [70/134], Loss: 0.3652, Time: 2.8708 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [75/134], Loss: 0.2049, Time: 2.8717 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [80/134], Loss: 0.2049, Time: 2.8727 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [85/134], Loss: 0.0445, Time: 2.8736 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [90/134], Loss: 0.2049, Time: 2.8745 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [95/134], Loss: 0.0445, Time: 2.8755 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [100/134], Loss: 0.0445, Time: 2.8764 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [105/134], Loss: 0.2049, Time: 2.8773 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [110/134], Loss: 0.0445, Time: 2.8782 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [115/134], Loss: 0.2049, Time: 2.8792 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [120/134], Loss: 0.0445, Time: 2.8801 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [125/134], Loss: 0.0445, Time: 2.8810 secs, learning rate: 0.0000\n",
      "Epoch [40/60], Step [130/134], Loss: 0.0445, Time: 2.8820 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [5/134], Loss: 0.2049, Time: 2.9174 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [10/134], Loss: 0.3652, Time: 2.9188 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [15/134], Loss: 0.0445, Time: 2.9197 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [20/134], Loss: 0.0445, Time: 2.9207 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [25/134], Loss: 0.2049, Time: 2.9216 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [30/134], Loss: 0.0445, Time: 2.9225 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [35/134], Loss: 0.3652, Time: 2.9235 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [40/134], Loss: 0.2049, Time: 2.9244 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [45/134], Loss: 0.5255, Time: 2.9253 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [50/134], Loss: 0.3652, Time: 2.9263 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [55/134], Loss: 0.0445, Time: 2.9272 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [60/134], Loss: 0.2049, Time: 2.9281 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [65/134], Loss: 0.2049, Time: 2.9291 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [70/134], Loss: 0.2049, Time: 2.9300 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [75/134], Loss: 0.2049, Time: 2.9309 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [80/134], Loss: 0.2049, Time: 2.9319 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [85/134], Loss: 0.3652, Time: 2.9328 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [90/134], Loss: 0.0445, Time: 2.9337 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [95/134], Loss: 0.3652, Time: 2.9347 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [100/134], Loss: 0.2049, Time: 2.9356 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [105/134], Loss: 0.2049, Time: 2.9365 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [110/134], Loss: 0.0445, Time: 2.9375 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [115/134], Loss: 0.0445, Time: 2.9384 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [120/134], Loss: 0.2049, Time: 2.9393 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [125/134], Loss: 0.3652, Time: 2.9403 secs, learning rate: 0.0000\n",
      "Epoch [41/60], Step [130/134], Loss: 0.2049, Time: 2.9412 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [5/134], Loss: 0.3652, Time: 2.9769 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [10/134], Loss: 0.2049, Time: 2.9787 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [15/134], Loss: 0.3652, Time: 2.9799 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [20/134], Loss: 0.0445, Time: 2.9809 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [25/134], Loss: 0.2049, Time: 2.9818 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [30/134], Loss: 0.0445, Time: 2.9827 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [35/134], Loss: 0.3652, Time: 2.9837 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [40/134], Loss: 0.0445, Time: 2.9846 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [45/134], Loss: 0.2049, Time: 2.9856 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [50/134], Loss: 0.3652, Time: 2.9865 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [55/134], Loss: 0.2049, Time: 2.9874 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [60/134], Loss: 0.3652, Time: 2.9884 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [65/134], Loss: 0.0445, Time: 2.9893 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [70/134], Loss: 0.0445, Time: 2.9902 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [75/134], Loss: 0.0445, Time: 2.9912 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [80/134], Loss: 0.3652, Time: 2.9921 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [85/134], Loss: 0.0445, Time: 2.9930 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [90/134], Loss: 0.2049, Time: 2.9939 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [95/134], Loss: 0.5255, Time: 2.9949 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [100/134], Loss: 0.3652, Time: 2.9958 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [105/134], Loss: 0.0445, Time: 2.9968 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [110/134], Loss: 0.2049, Time: 2.9977 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [115/134], Loss: 0.0445, Time: 2.9986 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [120/134], Loss: 0.2049, Time: 2.9996 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [125/134], Loss: 0.2049, Time: 3.0005 secs, learning rate: 0.0000\n",
      "Epoch [42/60], Step [130/134], Loss: 0.2049, Time: 3.0014 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [5/134], Loss: 0.2049, Time: 3.0375 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [10/134], Loss: 0.3652, Time: 3.0390 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [15/134], Loss: 0.0445, Time: 3.0399 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [20/134], Loss: 0.0445, Time: 3.0409 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [25/134], Loss: 0.2049, Time: 3.0418 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [30/134], Loss: 0.2049, Time: 3.0428 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [35/134], Loss: 0.0445, Time: 3.0437 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [40/134], Loss: 0.2049, Time: 3.0446 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [45/134], Loss: 0.0445, Time: 3.0456 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [50/134], Loss: 0.2049, Time: 3.0465 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [55/134], Loss: 0.0445, Time: 3.0474 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [60/134], Loss: 0.3652, Time: 3.0484 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [65/134], Loss: 0.2049, Time: 3.0493 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [70/134], Loss: 0.2049, Time: 3.0502 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [75/134], Loss: 0.2049, Time: 3.0512 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [80/134], Loss: 0.3652, Time: 3.0521 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [85/134], Loss: 0.0445, Time: 3.0530 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [90/134], Loss: 0.3652, Time: 3.0540 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [95/134], Loss: 0.5255, Time: 3.0549 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [100/134], Loss: 0.0445, Time: 3.0558 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [105/134], Loss: 0.0445, Time: 3.0568 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [110/134], Loss: 0.3652, Time: 3.0577 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [115/134], Loss: 0.0445, Time: 3.0586 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [120/134], Loss: 0.2049, Time: 3.0597 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [125/134], Loss: 0.0445, Time: 3.0606 secs, learning rate: 0.0000\n",
      "Epoch [43/60], Step [130/134], Loss: 0.0445, Time: 3.0616 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [5/134], Loss: 0.0445, Time: 3.0971 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [10/134], Loss: 0.5255, Time: 3.0984 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [15/134], Loss: 0.2049, Time: 3.0994 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [20/134], Loss: 0.2049, Time: 3.1003 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [25/134], Loss: 0.2049, Time: 3.1012 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [30/134], Loss: 0.0445, Time: 3.1022 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [35/134], Loss: 0.3652, Time: 3.1031 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [40/134], Loss: 0.0445, Time: 3.1041 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [45/134], Loss: 0.3652, Time: 3.1050 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [50/134], Loss: 0.2049, Time: 3.1059 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [55/134], Loss: 0.0445, Time: 3.1069 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [60/134], Loss: 0.3652, Time: 3.1078 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [65/134], Loss: 0.0445, Time: 3.1087 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [70/134], Loss: 0.3652, Time: 3.1097 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [75/134], Loss: 0.2049, Time: 3.1106 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [80/134], Loss: 0.0445, Time: 3.1115 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [85/134], Loss: 0.2049, Time: 3.1124 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [90/134], Loss: 0.0445, Time: 3.1134 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [95/134], Loss: 0.0445, Time: 3.1143 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [100/134], Loss: 0.0445, Time: 3.1152 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [105/134], Loss: 0.2049, Time: 3.1162 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [110/134], Loss: 0.2049, Time: 3.1171 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [115/134], Loss: 0.0445, Time: 3.1181 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [120/134], Loss: 0.3652, Time: 3.1190 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [125/134], Loss: 0.0445, Time: 3.1199 secs, learning rate: 0.0000\n",
      "Epoch [44/60], Step [130/134], Loss: 0.0445, Time: 3.1209 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [5/134], Loss: 0.2049, Time: 3.1564 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [10/134], Loss: 0.2049, Time: 3.1579 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [15/134], Loss: 0.3652, Time: 3.1593 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [20/134], Loss: 0.0445, Time: 3.1603 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [25/134], Loss: 0.0445, Time: 3.1613 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [30/134], Loss: 0.5255, Time: 3.1622 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [35/134], Loss: 0.2049, Time: 3.1631 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [40/134], Loss: 0.0445, Time: 3.1641 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [45/134], Loss: 0.2049, Time: 3.1650 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [50/134], Loss: 0.3652, Time: 3.1659 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [55/134], Loss: 0.2049, Time: 3.1669 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [60/134], Loss: 0.3652, Time: 3.1678 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [65/134], Loss: 0.0445, Time: 3.1687 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [70/134], Loss: 0.0445, Time: 3.1696 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [75/134], Loss: 0.2049, Time: 3.1706 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [80/134], Loss: 0.0445, Time: 3.1715 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [85/134], Loss: 0.0445, Time: 3.1724 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [90/134], Loss: 0.0445, Time: 3.1734 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [95/134], Loss: 0.3652, Time: 3.1743 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [100/134], Loss: 0.2049, Time: 3.1752 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [105/134], Loss: 0.2049, Time: 3.1762 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [110/134], Loss: 0.2049, Time: 3.1771 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [115/134], Loss: 0.2049, Time: 3.1780 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [120/134], Loss: 0.0445, Time: 3.1790 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [125/134], Loss: 0.0445, Time: 3.1800 secs, learning rate: 0.0000\n",
      "Epoch [45/60], Step [130/134], Loss: 0.2049, Time: 3.1809 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [5/134], Loss: 0.2049, Time: 3.2165 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [10/134], Loss: 0.0445, Time: 3.2179 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [15/134], Loss: 0.3652, Time: 3.2191 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [20/134], Loss: 0.0445, Time: 3.2200 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [25/134], Loss: 0.2049, Time: 3.2210 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [30/134], Loss: 0.0445, Time: 3.2222 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [35/134], Loss: 0.2049, Time: 3.2236 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [40/134], Loss: 0.2049, Time: 3.2245 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [45/134], Loss: 0.2049, Time: 3.2254 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [50/134], Loss: 0.0445, Time: 3.2264 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [55/134], Loss: 0.0445, Time: 3.2273 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [60/134], Loss: 0.2049, Time: 3.2283 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [65/134], Loss: 0.2049, Time: 3.2292 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [70/134], Loss: 0.2049, Time: 3.2301 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [75/134], Loss: 0.2049, Time: 3.2310 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [80/134], Loss: 0.0445, Time: 3.2320 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [85/134], Loss: 0.3652, Time: 3.2329 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [90/134], Loss: 0.3652, Time: 3.2343 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [95/134], Loss: 0.3652, Time: 3.2355 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [100/134], Loss: 0.0445, Time: 3.2365 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [105/134], Loss: 0.0445, Time: 3.2374 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [110/134], Loss: 0.0445, Time: 3.2386 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [115/134], Loss: 0.3652, Time: 3.2397 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [120/134], Loss: 0.0445, Time: 3.2407 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [125/134], Loss: 0.2049, Time: 3.2416 secs, learning rate: 0.0000\n",
      "Epoch [46/60], Step [130/134], Loss: 0.0445, Time: 3.2425 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [5/134], Loss: 0.3652, Time: 3.2773 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [10/134], Loss: 0.2049, Time: 3.2783 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [15/134], Loss: 0.2049, Time: 3.2793 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [20/134], Loss: 0.0445, Time: 3.2802 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [25/134], Loss: 0.3652, Time: 3.2812 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [30/134], Loss: 0.2049, Time: 3.2821 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [35/134], Loss: 0.0445, Time: 3.2831 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [40/134], Loss: 0.0445, Time: 3.2840 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [45/134], Loss: 0.0445, Time: 3.2849 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [50/134], Loss: 0.0445, Time: 3.2859 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [55/134], Loss: 0.2049, Time: 3.2868 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [60/134], Loss: 0.0445, Time: 3.2878 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [65/134], Loss: 0.0445, Time: 3.2887 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [70/134], Loss: 0.2049, Time: 3.2896 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [75/134], Loss: 0.2049, Time: 3.2906 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [80/134], Loss: 0.2049, Time: 3.2915 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [85/134], Loss: 0.0445, Time: 3.2924 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [90/134], Loss: 0.0445, Time: 3.2934 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [95/134], Loss: 0.0445, Time: 3.2943 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [100/134], Loss: 0.0445, Time: 3.2952 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [105/134], Loss: 0.3652, Time: 3.2962 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [110/134], Loss: 0.0445, Time: 3.2971 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [115/134], Loss: 0.0445, Time: 3.2980 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [120/134], Loss: 0.0445, Time: 3.2990 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [125/134], Loss: 0.2049, Time: 3.2999 secs, learning rate: 0.0000\n",
      "Epoch [47/60], Step [130/134], Loss: 0.0445, Time: 3.3008 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [5/134], Loss: 0.2049, Time: 3.3364 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [10/134], Loss: 0.2049, Time: 3.3378 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [15/134], Loss: 0.0445, Time: 3.3387 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [20/134], Loss: 0.0445, Time: 3.3397 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [25/134], Loss: 0.0445, Time: 3.3406 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [30/134], Loss: 0.2049, Time: 3.3416 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [35/134], Loss: 0.2049, Time: 3.3425 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [40/134], Loss: 0.0445, Time: 3.3434 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [45/134], Loss: 0.2049, Time: 3.3444 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [50/134], Loss: 0.0445, Time: 3.3453 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [55/134], Loss: 0.2049, Time: 3.3463 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [60/134], Loss: 0.2049, Time: 3.3472 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [65/134], Loss: 0.2049, Time: 3.3481 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [70/134], Loss: 0.3652, Time: 3.3491 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [75/134], Loss: 0.2049, Time: 3.3500 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [80/134], Loss: 0.0445, Time: 3.3509 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [85/134], Loss: 0.2049, Time: 3.3519 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [90/134], Loss: 0.3652, Time: 3.3528 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [95/134], Loss: 0.0445, Time: 3.3537 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [100/134], Loss: 0.0445, Time: 3.3547 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [105/134], Loss: 0.0445, Time: 3.3556 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [110/134], Loss: 0.2049, Time: 3.3565 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [115/134], Loss: 0.0445, Time: 3.3575 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [120/134], Loss: 0.5255, Time: 3.3584 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [125/134], Loss: 0.2049, Time: 3.3595 secs, learning rate: 0.0000\n",
      "Epoch [48/60], Step [130/134], Loss: 0.0445, Time: 3.3604 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [5/134], Loss: 0.2049, Time: 3.3959 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [10/134], Loss: 0.2049, Time: 3.3970 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [15/134], Loss: 0.2049, Time: 3.3980 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [20/134], Loss: 0.0445, Time: 3.3989 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [25/134], Loss: 0.0445, Time: 3.3999 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [30/134], Loss: 0.2049, Time: 3.4008 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [35/134], Loss: 0.3652, Time: 3.4017 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [40/134], Loss: 0.2049, Time: 3.4027 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [45/134], Loss: 0.0445, Time: 3.4036 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [50/134], Loss: 0.0445, Time: 3.4046 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [55/134], Loss: 0.3652, Time: 3.4055 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [60/134], Loss: 0.2049, Time: 3.4064 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [65/134], Loss: 0.2049, Time: 3.4074 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [70/134], Loss: 0.3652, Time: 3.4083 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [75/134], Loss: 0.2049, Time: 3.4093 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [80/134], Loss: 0.2049, Time: 3.4102 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [85/134], Loss: 0.3652, Time: 3.4111 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [90/134], Loss: 0.0445, Time: 3.4121 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [95/134], Loss: 0.2049, Time: 3.4131 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [100/134], Loss: 0.0445, Time: 3.4141 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [105/134], Loss: 0.2049, Time: 3.4150 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [110/134], Loss: 0.3652, Time: 3.4159 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [115/134], Loss: 0.0445, Time: 3.4169 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [120/134], Loss: 0.2049, Time: 3.4178 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [125/134], Loss: 0.2049, Time: 3.4187 secs, learning rate: 0.0000\n",
      "Epoch [49/60], Step [130/134], Loss: 0.0445, Time: 3.4197 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [5/134], Loss: 0.0445, Time: 3.4557 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [10/134], Loss: 0.0445, Time: 3.4571 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [15/134], Loss: 0.5255, Time: 3.4580 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [20/134], Loss: 0.0445, Time: 3.4590 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [25/134], Loss: 0.3652, Time: 3.4599 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [30/134], Loss: 0.0445, Time: 3.4609 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [35/134], Loss: 0.3652, Time: 3.4618 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [40/134], Loss: 0.2049, Time: 3.4627 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [45/134], Loss: 0.3652, Time: 3.4637 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [50/134], Loss: 0.0445, Time: 3.4646 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [55/134], Loss: 0.0445, Time: 3.4655 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [60/134], Loss: 0.0445, Time: 3.4665 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [65/134], Loss: 0.2049, Time: 3.4674 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [70/134], Loss: 0.2049, Time: 3.4683 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [75/134], Loss: 0.2049, Time: 3.4693 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [80/134], Loss: 0.0445, Time: 3.4702 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [85/134], Loss: 0.3652, Time: 3.4711 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [90/134], Loss: 0.2049, Time: 3.4721 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [95/134], Loss: 0.3652, Time: 3.4730 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [100/134], Loss: 0.2049, Time: 3.4739 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [105/134], Loss: 0.2049, Time: 3.4749 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [110/134], Loss: 0.2049, Time: 3.4758 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [115/134], Loss: 0.2049, Time: 3.4767 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [120/134], Loss: 0.0445, Time: 3.4777 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [125/134], Loss: 0.3652, Time: 3.4786 secs, learning rate: 0.0000\n",
      "Epoch [50/60], Step [130/134], Loss: 0.2049, Time: 3.4796 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [5/134], Loss: 0.2049, Time: 3.5154 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [10/134], Loss: 0.0445, Time: 3.5167 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [15/134], Loss: 0.2049, Time: 3.5177 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [20/134], Loss: 0.2049, Time: 3.5186 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [25/134], Loss: 0.0445, Time: 3.5196 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [30/134], Loss: 0.0445, Time: 3.5205 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [35/134], Loss: 0.2049, Time: 3.5215 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [40/134], Loss: 0.0445, Time: 3.5224 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [45/134], Loss: 0.0445, Time: 3.5233 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [50/134], Loss: 0.0445, Time: 3.5242 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [55/134], Loss: 0.0445, Time: 3.5252 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [60/134], Loss: 0.2049, Time: 3.5261 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [65/134], Loss: 0.3652, Time: 3.5270 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [70/134], Loss: 0.0445, Time: 3.5279 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [75/134], Loss: 0.0445, Time: 3.5289 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [80/134], Loss: 0.2049, Time: 3.5298 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [85/134], Loss: 0.0445, Time: 3.5307 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [90/134], Loss: 0.2049, Time: 3.5317 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [95/134], Loss: 0.0445, Time: 3.5326 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [100/134], Loss: 0.2049, Time: 3.5335 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [105/134], Loss: 0.0445, Time: 3.5345 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [110/134], Loss: 0.2049, Time: 3.5354 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [115/134], Loss: 0.3652, Time: 3.5363 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [120/134], Loss: 0.2049, Time: 3.5372 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [125/134], Loss: 0.2049, Time: 3.5383 secs, learning rate: 0.0000\n",
      "Epoch [51/60], Step [130/134], Loss: 0.3652, Time: 3.5392 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [5/134], Loss: 0.2049, Time: 3.5748 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [10/134], Loss: 0.0445, Time: 3.5759 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [15/134], Loss: 0.2049, Time: 3.5770 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [20/134], Loss: 0.3652, Time: 3.5779 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [25/134], Loss: 0.3652, Time: 3.5789 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [30/134], Loss: 0.2049, Time: 3.5798 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [35/134], Loss: 0.3652, Time: 3.5807 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [40/134], Loss: 0.0445, Time: 3.5817 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [45/134], Loss: 0.2049, Time: 3.5826 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [50/134], Loss: 0.2049, Time: 3.5836 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [55/134], Loss: 0.0445, Time: 3.5845 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [60/134], Loss: 0.2049, Time: 3.5854 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [65/134], Loss: 0.0445, Time: 3.5864 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [70/134], Loss: 0.2049, Time: 3.5874 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [75/134], Loss: 0.2049, Time: 3.5883 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [80/134], Loss: 0.2049, Time: 3.5893 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [85/134], Loss: 0.2049, Time: 3.5902 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [90/134], Loss: 0.3652, Time: 3.5911 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [95/134], Loss: 0.0445, Time: 3.5921 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [100/134], Loss: 0.3652, Time: 3.5930 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [105/134], Loss: 0.2049, Time: 3.5940 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [110/134], Loss: 0.0445, Time: 3.5949 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [115/134], Loss: 0.5255, Time: 3.5958 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [120/134], Loss: 0.2049, Time: 3.5968 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [125/134], Loss: 0.0445, Time: 3.5977 secs, learning rate: 0.0000\n",
      "Epoch [52/60], Step [130/134], Loss: 0.0445, Time: 3.5987 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [5/134], Loss: 0.0445, Time: 3.6345 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [10/134], Loss: 0.3652, Time: 3.6365 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [15/134], Loss: 0.0445, Time: 3.6378 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [20/134], Loss: 0.2049, Time: 3.6387 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [25/134], Loss: 0.0445, Time: 3.6397 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [30/134], Loss: 0.2049, Time: 3.6406 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [35/134], Loss: 0.2049, Time: 3.6415 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [40/134], Loss: 0.2049, Time: 3.6425 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [45/134], Loss: 0.3652, Time: 3.6434 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [50/134], Loss: 0.0445, Time: 3.6444 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [55/134], Loss: 0.3652, Time: 3.6453 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [60/134], Loss: 0.0445, Time: 3.6463 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [65/134], Loss: 0.0445, Time: 3.6472 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [70/134], Loss: 0.2049, Time: 3.6481 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [75/134], Loss: 0.2049, Time: 3.6491 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [80/134], Loss: 0.2049, Time: 3.6500 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [85/134], Loss: 0.2049, Time: 3.6509 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [90/134], Loss: 0.2049, Time: 3.6519 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [95/134], Loss: 0.2049, Time: 3.6528 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [100/134], Loss: 0.3652, Time: 3.6537 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [105/134], Loss: 0.0445, Time: 3.6546 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [110/134], Loss: 0.2049, Time: 3.6556 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [115/134], Loss: 0.0445, Time: 3.6569 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [120/134], Loss: 0.0445, Time: 3.6580 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [125/134], Loss: 0.2049, Time: 3.6589 secs, learning rate: 0.0000\n",
      "Epoch [53/60], Step [130/134], Loss: 0.3652, Time: 3.6598 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [5/134], Loss: 0.2049, Time: 3.6951 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [10/134], Loss: 0.0445, Time: 3.6962 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [15/134], Loss: 0.0445, Time: 3.6973 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [20/134], Loss: 0.0445, Time: 3.6982 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [25/134], Loss: 0.2049, Time: 3.6992 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [30/134], Loss: 0.3652, Time: 3.7001 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [35/134], Loss: 0.2049, Time: 3.7010 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [40/134], Loss: 0.2049, Time: 3.7020 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [45/134], Loss: 0.2049, Time: 3.7029 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [50/134], Loss: 0.0445, Time: 3.7038 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [55/134], Loss: 0.2049, Time: 3.7048 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [60/134], Loss: 0.2049, Time: 3.7057 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [65/134], Loss: 0.2049, Time: 3.7066 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [70/134], Loss: 0.3652, Time: 3.7076 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [75/134], Loss: 0.3652, Time: 3.7085 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [80/134], Loss: 0.3652, Time: 3.7095 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [85/134], Loss: 0.0445, Time: 3.7106 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [90/134], Loss: 0.0445, Time: 3.7115 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [95/134], Loss: 0.2049, Time: 3.7124 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [100/134], Loss: 0.2049, Time: 3.7134 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [105/134], Loss: 0.3652, Time: 3.7143 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [110/134], Loss: 0.2049, Time: 3.7152 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [115/134], Loss: 0.2049, Time: 3.7162 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [120/134], Loss: 0.5255, Time: 3.7171 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [125/134], Loss: 0.2049, Time: 3.7181 secs, learning rate: 0.0000\n",
      "Epoch [54/60], Step [130/134], Loss: 0.0445, Time: 3.7190 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [5/134], Loss: 0.2049, Time: 3.7548 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [10/134], Loss: 0.0445, Time: 3.7567 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [15/134], Loss: 0.3652, Time: 3.7578 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [20/134], Loss: 0.2049, Time: 3.7588 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [25/134], Loss: 0.0445, Time: 3.7598 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [30/134], Loss: 0.3652, Time: 3.7607 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [35/134], Loss: 0.0445, Time: 3.7616 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [40/134], Loss: 0.0445, Time: 3.7626 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [45/134], Loss: 0.2049, Time: 3.7635 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [50/134], Loss: 0.2049, Time: 3.7644 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [55/134], Loss: 0.0445, Time: 3.7654 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [60/134], Loss: 0.0445, Time: 3.7663 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [65/134], Loss: 0.2049, Time: 3.7673 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [70/134], Loss: 0.2049, Time: 3.7682 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [75/134], Loss: 0.0445, Time: 3.7691 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [80/134], Loss: 0.3652, Time: 3.7701 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [85/134], Loss: 0.0445, Time: 3.7710 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [90/134], Loss: 0.3652, Time: 3.7723 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [95/134], Loss: 0.0445, Time: 3.7739 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [100/134], Loss: 0.0445, Time: 3.7749 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [105/134], Loss: 0.2049, Time: 3.7758 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [110/134], Loss: 0.3652, Time: 3.7767 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [115/134], Loss: 0.3652, Time: 3.7776 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [120/134], Loss: 0.0445, Time: 3.7786 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [125/134], Loss: 0.3652, Time: 3.7795 secs, learning rate: 0.0000\n",
      "Epoch [55/60], Step [130/134], Loss: 0.3652, Time: 3.7805 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [5/134], Loss: 0.0445, Time: 3.8163 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [10/134], Loss: 0.3652, Time: 3.8173 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [15/134], Loss: 0.2049, Time: 3.8182 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [20/134], Loss: 0.0445, Time: 3.8192 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [25/134], Loss: 0.0445, Time: 3.8201 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [30/134], Loss: 0.2049, Time: 3.8211 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [35/134], Loss: 0.3652, Time: 3.8221 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [40/134], Loss: 0.5255, Time: 3.8230 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [45/134], Loss: 0.3652, Time: 3.8240 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [50/134], Loss: 0.0445, Time: 3.8250 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [55/134], Loss: 0.5255, Time: 3.8260 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [60/134], Loss: 0.3652, Time: 3.8269 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [65/134], Loss: 0.2049, Time: 3.8279 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [70/134], Loss: 0.0445, Time: 3.8289 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [75/134], Loss: 0.2049, Time: 3.8299 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [80/134], Loss: 0.3652, Time: 3.8309 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [85/134], Loss: 0.2049, Time: 3.8318 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [90/134], Loss: 0.3652, Time: 3.8328 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [95/134], Loss: 0.0445, Time: 3.8338 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [100/134], Loss: 0.2049, Time: 3.8348 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [105/134], Loss: 0.2049, Time: 3.8357 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [110/134], Loss: 0.2049, Time: 3.8367 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [115/134], Loss: 0.0445, Time: 3.8376 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [120/134], Loss: 0.0445, Time: 3.8386 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [125/134], Loss: 0.2049, Time: 3.8395 secs, learning rate: 0.0000\n",
      "Epoch [56/60], Step [130/134], Loss: 0.2049, Time: 3.8404 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [5/134], Loss: 0.2049, Time: 3.8774 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [10/134], Loss: 0.0445, Time: 3.8789 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [15/134], Loss: 0.2049, Time: 3.8799 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [20/134], Loss: 0.0445, Time: 3.8808 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [25/134], Loss: 0.2049, Time: 3.8818 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [30/134], Loss: 0.2049, Time: 3.8827 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [35/134], Loss: 0.3652, Time: 3.8837 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [40/134], Loss: 0.3652, Time: 3.8847 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [45/134], Loss: 0.2049, Time: 3.8856 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [50/134], Loss: 0.3652, Time: 3.8865 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [55/134], Loss: 0.0445, Time: 3.8875 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [60/134], Loss: 0.3652, Time: 3.8884 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [65/134], Loss: 0.3652, Time: 3.8894 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [70/134], Loss: 0.0445, Time: 3.8903 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [75/134], Loss: 0.0445, Time: 3.8912 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [80/134], Loss: 0.0445, Time: 3.8922 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [85/134], Loss: 0.0445, Time: 3.8931 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [90/134], Loss: 0.3652, Time: 3.8940 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [95/134], Loss: 0.2049, Time: 3.8950 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [100/134], Loss: 0.0445, Time: 3.8959 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [105/134], Loss: 0.3652, Time: 3.8968 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [110/134], Loss: 0.2049, Time: 3.8978 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [115/134], Loss: 0.3652, Time: 3.8987 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [120/134], Loss: 0.2049, Time: 3.8997 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [125/134], Loss: 0.2049, Time: 3.9006 secs, learning rate: 0.0000\n",
      "Epoch [57/60], Step [130/134], Loss: 0.0445, Time: 3.9016 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [5/134], Loss: 0.0445, Time: 3.9372 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [10/134], Loss: 0.2049, Time: 3.9394 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [15/134], Loss: 0.2049, Time: 3.9407 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [20/134], Loss: 0.0445, Time: 3.9417 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [25/134], Loss: 0.2049, Time: 3.9426 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [30/134], Loss: 0.0445, Time: 3.9436 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [35/134], Loss: 0.2049, Time: 3.9445 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [40/134], Loss: 0.2049, Time: 3.9455 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [45/134], Loss: 0.2049, Time: 3.9464 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [50/134], Loss: 0.0445, Time: 3.9473 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [55/134], Loss: 0.0445, Time: 3.9483 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [60/134], Loss: 0.0445, Time: 3.9492 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [65/134], Loss: 0.2049, Time: 3.9501 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [70/134], Loss: 0.3652, Time: 3.9510 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [75/134], Loss: 0.2049, Time: 3.9520 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [80/134], Loss: 0.0445, Time: 3.9529 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [85/134], Loss: 0.2049, Time: 3.9538 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [90/134], Loss: 0.2049, Time: 3.9548 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [95/134], Loss: 0.2049, Time: 3.9557 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [100/134], Loss: 0.0445, Time: 3.9566 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [105/134], Loss: 0.2049, Time: 3.9576 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [110/134], Loss: 0.0445, Time: 3.9585 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [115/134], Loss: 0.2049, Time: 3.9594 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [120/134], Loss: 0.3652, Time: 3.9604 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [125/134], Loss: 0.2049, Time: 3.9613 secs, learning rate: 0.0000\n",
      "Epoch [58/60], Step [130/134], Loss: 0.3652, Time: 3.9622 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [5/134], Loss: 0.0445, Time: 3.9974 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [10/134], Loss: 0.0445, Time: 3.9986 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [15/134], Loss: 0.0445, Time: 3.9996 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [20/134], Loss: 0.3652, Time: 4.0005 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [25/134], Loss: 0.2049, Time: 4.0015 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [30/134], Loss: 0.2049, Time: 4.0024 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [35/134], Loss: 0.0445, Time: 4.0033 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [40/134], Loss: 0.0445, Time: 4.0043 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [45/134], Loss: 0.3652, Time: 4.0052 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [50/134], Loss: 0.0445, Time: 4.0061 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [55/134], Loss: 0.2049, Time: 4.0071 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [60/134], Loss: 0.3652, Time: 4.0080 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [65/134], Loss: 0.0445, Time: 4.0089 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [70/134], Loss: 0.0445, Time: 4.0100 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [75/134], Loss: 0.3652, Time: 4.0109 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [80/134], Loss: 0.2049, Time: 4.0118 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [85/134], Loss: 0.0445, Time: 4.0128 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [90/134], Loss: 0.2049, Time: 4.0137 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [95/134], Loss: 0.0445, Time: 4.0146 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [100/134], Loss: 0.2049, Time: 4.0156 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [105/134], Loss: 0.5255, Time: 4.0170 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [110/134], Loss: 0.0445, Time: 4.0191 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [115/134], Loss: 0.2049, Time: 4.0201 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [120/134], Loss: 0.2049, Time: 4.0211 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [125/134], Loss: 0.2049, Time: 4.0220 secs, learning rate: 0.0000\n",
      "Epoch [59/60], Step [130/134], Loss: 0.2049, Time: 4.0229 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [5/134], Loss: 0.0445, Time: 4.0583 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [10/134], Loss: 0.0445, Time: 4.0595 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [15/134], Loss: 0.3652, Time: 4.0605 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [20/134], Loss: 0.2049, Time: 4.0614 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [25/134], Loss: 0.2049, Time: 4.0624 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [30/134], Loss: 0.2049, Time: 4.0633 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [35/134], Loss: 0.3652, Time: 4.0642 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [40/134], Loss: 0.2049, Time: 4.0651 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [45/134], Loss: 0.2049, Time: 4.0661 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [50/134], Loss: 0.0445, Time: 4.0671 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [55/134], Loss: 0.3652, Time: 4.0680 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [60/134], Loss: 0.2049, Time: 4.0689 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [65/134], Loss: 0.2049, Time: 4.0698 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [70/134], Loss: 0.3652, Time: 4.0708 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [75/134], Loss: 0.2049, Time: 4.0717 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [80/134], Loss: 0.2049, Time: 4.0726 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [85/134], Loss: 0.0445, Time: 4.0735 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [90/134], Loss: 0.0445, Time: 4.0745 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [95/134], Loss: 0.3652, Time: 4.0754 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [100/134], Loss: 0.0445, Time: 4.0763 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [105/134], Loss: 0.2049, Time: 4.0772 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [110/134], Loss: 0.0445, Time: 4.0785 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [115/134], Loss: 0.2049, Time: 4.0796 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [120/134], Loss: 0.0445, Time: 4.0805 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [125/134], Loss: 0.3652, Time: 4.0815 secs, learning rate: 0.0000\n",
      "Epoch [60/60], Step [130/134], Loss: 0.2049, Time: 4.0824 secs, learning rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(YTrain)\n",
    "start_time = time.time()\n",
    "model = model.float()\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "loss_tmp = 0\n",
    "norm = 1\n",
    "for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm*outputs, norm*y.float().reshape(1,1,1))\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().reshape(1,1,1))\n",
    "        # loss1 = criterion(norm*outputs, norm*y.float().T)\n",
    "        # loss2 = torch.mean(outputs**2 - y.float().T**2)\n",
    "        # loss = loss1 + loss2\n",
    "        \n",
    "        loss_tmp += loss.item()\n",
    "loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ind = np.arange(int(total_step/batch_size))\n",
    "    random.shuffle(ind)\n",
    "    for i,k in enumerate(ind):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XTrain[k*batch_size:(k+1)*batch_size,:,:], YTrain[k*batch_size:(k+1)*batch_size,:]\n",
    "        # x, y = XVal[k*batch_size:(k+1)*batch_size,:,:], YVal[k*batch_size:(k+1)*batch_size,:]\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm*outputs, norm*y.float().reshape(batch_size,1,1))\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().reshape(batch_size,1,1))\n",
    "        # loss1 = criterion(norm*outputs, norm*y.float().T)\n",
    "        # loss2 = torch.mean(outputs**2 - y.float().T**2)\n",
    "        # loss = loss1 + loss2\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 5== 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs, learning rate: {:.4f}'\n",
    "                    .format(epoch + 1, num_epochs, i + 1, int(total_step/batch_size), loss.item(), time.time() - start_time, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    loss_tmp = 0\n",
    "    result = []\n",
    "    for i in range(len(YVal)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XVal[i,:,:], YVal[i,:]\n",
    "\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        y = y.unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass val\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(norm*outputs, norm*y.float().reshape(1,1,1))\n",
    "        # loss = criterion(nn.Sigmoid()(norm*outputs), norm*y.float().reshape(1,1,1))\n",
    "        # loss1 = criterion(norm*outputs, norm*y.float().T)\n",
    "        # loss2 = torch.mean(outputs**2 - y.float().T**2)\n",
    "        # loss = loss1 + loss2\n",
    "        \n",
    "        loss_tmp += loss.item()\n",
    "        result.append(outputs[0,0].item())\n",
    "        # result.append(nn.Sigmoid()(outputs[0,0]).item())\n",
    "    loss_val.append(loss_tmp/len(YVal))\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(loss_train)), loss_train, label = 'Training error')\n",
    "plt.plot(np.arange(0, len(loss_train)+1, int(total_step/batch_size)), loss_val, label = 'Validation error')\n",
    "plt.ylabel('loss', fontsize = 14)\n",
    "plt.xlabel('steps', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbdb7959ff0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.style.use('seaborn')\n",
    "plt.plot(np.arange(len(result)), YVal, label = 'expected')\n",
    "plt.plot(np.arange(len(result)), result, label = 'model output')\n",
    "plt.ylabel('state', fontsize = 14)\n",
    "plt.xlabel('time', fontsize = 14)\n",
    "plt.legend()\n",
    "# plt.ylim([-0.01,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "442\n"
     ]
    }
   ],
   "source": [
    "print(len([i for i in YVal if i[0]]))\n",
    "print(len([i for i in YVal if not i[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
