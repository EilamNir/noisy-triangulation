{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation.generate_path import generate_path\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from estimation.distance_sensor import distance_sensors\n",
    "from estimation.non_iterative_estimator import non_iterative_estimator\n",
    "from estimation.kalman_filter_from_points import kalman_filter_from_points\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2896, 1)\n",
      "(4, 3, 3, 2896)\n"
     ]
    }
   ],
   "source": [
    "# create test data\n",
    "target_initial_pos = np.array([0, 0, 5000])\n",
    "target_speed_xy = 50\n",
    "target_speed_z = 10\n",
    "target_rot_speed = 3\n",
    "time_res = 0.1\n",
    "\n",
    "path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "path1.add_straight_interval(100)\n",
    "path1.add_xy_turn_interval(90, -np.deg2rad(target_rot_speed))\n",
    "path1.add_straight_interval(100)\n",
    "\n",
    "# create noisy sensors\n",
    "sensors = distance_sensors([[-5000,0,0],[ 400, -7400, 0],[ 800, 800, 0]], 15)\n",
    "sensors.calculate_measurements(path1.path)\n",
    "\n",
    "sample = 3\n",
    "XTest = []\n",
    "for i in np.arange(len(path1.path) - sample + 1):\n",
    "    tmp = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i,:], (1,3))), 0)\n",
    "    tmp = tmp.reshape(4,3,1)\n",
    "    for j in np.arange(1,sample):\n",
    "        matrix = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i+j,:], (1,3))), 0)\n",
    "        matrix = matrix.reshape(4,3,1)\n",
    "        tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "    if i > 0:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = np.concatenate((XTest, tmp), 3)\n",
    "    else:\n",
    "        tmp = tmp.reshape(4,3,sample,1)\n",
    "        XTest = tmp\n",
    "\n",
    "YTest = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTest))\n",
    "print(np.shape(XTest))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_outliers(point):\n",
    "    point[0] += random.choice(np.random.randint(13, 20), np.random.randint(-20, -13))\n",
    "    point[1] += random.choice(np.random.randint(13, 20), np.random.randint(-20, -13))\n",
    "    point[2] += random.choice(np.random.randint(13, 20), np.random.randint(-20, -13))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create train data\n",
    "run_number = 50\n",
    "for k in np.arange(run_number):\n",
    "    target_initial_pos = np.random.randint(-7000, 7000, size=(1, 3))[0]\n",
    "    sensors_pos = np.random.randint(-7000, 7000, size=(3, 3))[:,:]\n",
    "    target_speed_xy = 50\n",
    "    target_speed_z = 10\n",
    "    target_rot_speed = 3\n",
    "    time_res = 0.1\n",
    "\n",
    "    path1 = generate_path(0, target_speed_xy, target_speed_z, target_initial_pos, time_res)\n",
    "    path1.add_straight_interval(np.random.randint(0,100,size=1)[0])\n",
    "    path1.add_xy_turn_interval(np.random.randint(0,100,size=1)[0], -random.choice([-1, 1])*np.deg2rad(target_rot_speed))\n",
    "    outliers = np.random.randint(0, 100, size=len(path1.path))\n",
    "    outliers = outliers > 90\n",
    "\n",
    "    # create noisy sensors\n",
    "    sensors = distance_sensors(sensors_pos, 15)\n",
    "    sensors.calculate_measurements(path1.path)\n",
    "\n",
    "    non_it_est = non_iterative_estimator(sensors, path1.path[0,:])\n",
    "    estimated_path = non_it_est.estimate_path()\n",
    "\n",
    "    sigma_a = 1\n",
    "    sigma_v = 500\n",
    "    kf = kalman_filter_from_points(time_res, sigma_a, sigma_v, non_diag_reduction_ratio=2)\n",
    "    kf_path, P, X = kf.filter_path(estimated_path)\n",
    "\n",
    "    sample = 3\n",
    "    XTrain = []\n",
    "    for i in np.arange(len(kf_path) - sample + 1):\n",
    "        tmp = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i,:], (1,3))), 0)\n",
    "        tmp = tmp.reshape(4,3,1)\n",
    "        for j in np.arange(1,sample):\n",
    "            matrix = np.concatenate((sensors.sensor_locations, np.reshape(sensors.noisy_distances[i+j,:], (1,3))), 0)\n",
    "            matrix = matrix.reshape(4,3,1)\n",
    "            tmp = np.concatenate((tmp, matrix),axis=2)\n",
    "        if i > 0:\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = np.concatenate((XTrain, tmp), 3)\n",
    "        else:\n",
    "            tmp = tmp.reshape(4,3,sample,1)\n",
    "            XTrain = tmp\n",
    "\n",
    "    YTrain = path1.state_key[sample-1:]\n",
    "\n",
    "print(np.shape(YTrain))\n",
    "print(np.shape(XTrain))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "ind = np.arange(len(YTrain))\n",
    "random.shuffle(ind)\n",
    "\n",
    "XVal = torch.from_numpy(np.transpose(XTest[:,:,:,ind], (3, 2, 0, 1)))\n",
    "YVal = torch.from_numpy(YTest[ind,:])\n",
    "\n",
    "XTrain = torch.from_numpy(np.transpose(XTrain[:,:,:,ind], (3, 2, 0, 1)))\n",
    "YTrain = torch.from_numpy(YTrain[ind,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "# create network\n",
    "class state_estimat(nn.Module):\n",
    "    def __init__(self, d_in, num_classes):\n",
    "        # initialzing the parent object (important!)\n",
    "        super(state_estimat, self).__init__()\n",
    "        # Create a pipeline - a sequence of layers\n",
    "        self.pipe = torch.nn.Sequential(\n",
    "            nn.Conv2d(d_in, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, num_classes),\n",
    "            nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "# hyper-parameters:\n",
    "num_epochs = 20\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "learning_rate_drop_period = 3\n",
    "input_shape = [3,4,3]\n",
    "\n",
    "# Device configuration, as before\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# create model\n",
    "model = state_estimat(d_in=3, num_classes=1).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\envs\\deep_learn\\lib\\site-packages\\torch\\nn\\modules\\container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "D:\\Programs\\Anaconda\\envs\\deep_learn\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1, 8])) that is different to the input size (torch.Size([8, 64, 4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/1877], Loss: 0.5000, Time: 0.6075 secs\n",
      "Epoch [1/20], Step [200/1877], Loss: 0.6211, Time: 1.0815 secs\n",
      "Epoch [2/20], Step [100/1877], Loss: 0.5000, Time: 1.6665 secs\n",
      "Epoch [2/20], Step [200/1877], Loss: 0.6211, Time: 2.0481 secs\n",
      "Epoch [3/20], Step [100/1877], Loss: 0.5000, Time: 2.6798 secs\n",
      "Epoch [3/20], Step [200/1877], Loss: 0.6211, Time: 3.1241 secs\n",
      "Epoch [4/20], Step [100/1877], Loss: 0.5000, Time: 3.7715 secs\n",
      "Epoch [4/20], Step [200/1877], Loss: 0.6211, Time: 4.2313 secs\n",
      "Epoch [5/20], Step [100/1877], Loss: 0.5000, Time: 4.9030 secs\n",
      "Epoch [5/20], Step [200/1877], Loss: 0.6211, Time: 5.3872 secs\n",
      "Epoch [6/20], Step [100/1877], Loss: 0.5000, Time: 6.0121 secs\n",
      "Epoch [6/20], Step [200/1877], Loss: 0.6211, Time: 6.5120 secs\n",
      "Epoch [7/20], Step [100/1877], Loss: 0.5000, Time: 7.2774 secs\n",
      "Epoch [7/20], Step [200/1877], Loss: 0.6211, Time: 7.8242 secs\n",
      "Epoch [8/20], Step [100/1877], Loss: 0.5000, Time: 8.4803 secs\n",
      "Epoch [8/20], Step [200/1877], Loss: 0.6211, Time: 8.9645 secs\n",
      "Epoch [9/20], Step [100/1877], Loss: 0.5000, Time: 9.6206 secs\n",
      "Epoch [9/20], Step [200/1877], Loss: 0.6211, Time: 10.1049 secs\n",
      "Epoch [10/20], Step [100/1877], Loss: 0.5000, Time: 10.7610 secs\n",
      "Epoch [10/20], Step [200/1877], Loss: 0.6211, Time: 11.2609 secs\n",
      "Epoch [11/20], Step [100/1877], Loss: 0.5000, Time: 11.9170 secs\n",
      "Epoch [11/20], Step [200/1877], Loss: 0.6211, Time: 12.4012 secs\n",
      "Epoch [12/20], Step [100/1877], Loss: 0.5000, Time: 13.0417 secs\n",
      "Epoch [12/20], Step [200/1877], Loss: 0.6211, Time: 13.5036 secs\n",
      "Epoch [13/20], Step [100/1877], Loss: 0.5000, Time: 14.1499 secs\n",
      "Epoch [13/20], Step [200/1877], Loss: 0.6211, Time: 14.6094 secs\n",
      "Epoch [14/20], Step [100/1877], Loss: 0.5000, Time: 15.2655 secs\n",
      "Epoch [14/20], Step [200/1877], Loss: 0.6211, Time: 15.7822 secs\n",
      "Epoch [15/20], Step [100/1877], Loss: 0.5000, Time: 16.4208 secs\n",
      "Epoch [15/20], Step [200/1877], Loss: 0.6211, Time: 16.8895 secs\n",
      "Epoch [16/20], Step [100/1877], Loss: 0.5000, Time: 17.5920 secs\n",
      "Epoch [16/20], Step [200/1877], Loss: 0.6211, Time: 18.0606 secs\n",
      "Epoch [17/20], Step [100/1877], Loss: 0.5000, Time: 18.8574 secs\n",
      "Epoch [17/20], Step [200/1877], Loss: 0.6211, Time: 19.4111 secs\n",
      "Epoch [18/20], Step [100/1877], Loss: 0.5000, Time: 20.1048 secs\n",
      "Epoch [18/20], Step [200/1877], Loss: 0.6211, Time: 20.5914 secs\n",
      "Epoch [19/20], Step [100/1877], Loss: 0.5000, Time: 21.2456 secs\n",
      "Epoch [19/20], Step [200/1877], Loss: 0.6211, Time: 21.7454 secs\n",
      "Epoch [20/20], Step [100/1877], Loss: 0.5000, Time: 22.3623 secs\n",
      "Epoch [20/20], Step [200/1877], Loss: 0.6211, Time: 22.8227 secs\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(YTrain)\n",
    "start_time = time.time()\n",
    "model = model.float()\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(int(total_step/batch_size)):\n",
    "        # each i is a batch of 128 samples\n",
    "        x, y = XTrain[i*batch_size:(i+1)*batch_size,:,:,:], YTrain[i*batch_size:(i+1)*batch_size,:]\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x.float())\n",
    "        loss = criterion(outputs, y.float().T)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time: {:.4f} secs'\n",
    "                    .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}